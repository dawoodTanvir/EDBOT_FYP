{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ef65df7b67de454f9a6cc9d21ec76b32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_be237253887a4b22994c1e9d9110bae7",
              "IPY_MODEL_a1cc62c7a4924a8091c4b437453058ee",
              "IPY_MODEL_57322bbcb82d49b094bf450ded10bb02"
            ],
            "layout": "IPY_MODEL_65e5f0774c524096aee07993682a347f"
          }
        },
        "be237253887a4b22994c1e9d9110bae7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_457888ee56954287968d992b2e49142c",
            "placeholder": "​",
            "style": "IPY_MODEL_e9fb5bd8f43e4746a02de533296349bc",
            "value": "modules.json: 100%"
          }
        },
        "a1cc62c7a4924a8091c4b437453058ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9371241ceb26473ba735df9cdf53120e",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fb8df3f416274479acc9d6f3e0b5ff14",
            "value": 349
          }
        },
        "57322bbcb82d49b094bf450ded10bb02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d202180d105481995c8b433b32c646a",
            "placeholder": "​",
            "style": "IPY_MODEL_e8c54681ab0a4d7b8e14f43618d8771c",
            "value": " 349/349 [00:00&lt;00:00, 26.3kB/s]"
          }
        },
        "65e5f0774c524096aee07993682a347f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "457888ee56954287968d992b2e49142c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9fb5bd8f43e4746a02de533296349bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9371241ceb26473ba735df9cdf53120e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb8df3f416274479acc9d6f3e0b5ff14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6d202180d105481995c8b433b32c646a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8c54681ab0a4d7b8e14f43618d8771c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed69ec01893f43fd9ba74e04f137d852": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_db4423260d1e4c7393587e90c7e7dfeb",
              "IPY_MODEL_b25d70a3f4d145eaaac0326cd2416edc",
              "IPY_MODEL_6f334da4f15247e286336327e190c33a"
            ],
            "layout": "IPY_MODEL_35daa86e93fd46a7baea7a27d41574f2"
          }
        },
        "db4423260d1e4c7393587e90c7e7dfeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c48d4dc736e44cbf9b9e53adef99bcff",
            "placeholder": "​",
            "style": "IPY_MODEL_ef28b2c739af4d0d8ccebc8f0e07e761",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "b25d70a3f4d145eaaac0326cd2416edc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65510ca89ea54e6e8f1afd1127328ebb",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_afe46bcc0b39445d9453c93f6a5c05c3",
            "value": 116
          }
        },
        "6f334da4f15247e286336327e190c33a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bddd616ce494f0f845223f800531221",
            "placeholder": "​",
            "style": "IPY_MODEL_c01db2ac6be5475aaeb865f95308a34c",
            "value": " 116/116 [00:00&lt;00:00, 9.23kB/s]"
          }
        },
        "35daa86e93fd46a7baea7a27d41574f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c48d4dc736e44cbf9b9e53adef99bcff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef28b2c739af4d0d8ccebc8f0e07e761": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "65510ca89ea54e6e8f1afd1127328ebb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afe46bcc0b39445d9453c93f6a5c05c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7bddd616ce494f0f845223f800531221": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c01db2ac6be5475aaeb865f95308a34c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03557d37810c4b44a77911d5c9c73756": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7ac947b71baf4be1a52ca6ea31297495",
              "IPY_MODEL_e720a0081d8a429dbd9e5732c4ff7246",
              "IPY_MODEL_10dc73ce4e194e0a8a3ed8d1d0923021"
            ],
            "layout": "IPY_MODEL_d8c6e468b280494cbaaf904af873678e"
          }
        },
        "7ac947b71baf4be1a52ca6ea31297495": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7342dd3ed8864173a6d598c0363b1f33",
            "placeholder": "​",
            "style": "IPY_MODEL_da3525d50acd4c56aa4471e9b4309d01",
            "value": "README.md: 100%"
          }
        },
        "e720a0081d8a429dbd9e5732c4ff7246": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_461162a0c1ea48c98171406f0cb2c3b1",
            "max": 10659,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e133e7fc1de444f7843d08bb686d1fb9",
            "value": 10659
          }
        },
        "10dc73ce4e194e0a8a3ed8d1d0923021": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03e7b5d38e4c4f099f27262c424aac59",
            "placeholder": "​",
            "style": "IPY_MODEL_44def13723554c7fbba7adf9ca8f1484",
            "value": " 10.7k/10.7k [00:00&lt;00:00, 681kB/s]"
          }
        },
        "d8c6e468b280494cbaaf904af873678e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7342dd3ed8864173a6d598c0363b1f33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da3525d50acd4c56aa4471e9b4309d01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "461162a0c1ea48c98171406f0cb2c3b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e133e7fc1de444f7843d08bb686d1fb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "03e7b5d38e4c4f099f27262c424aac59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44def13723554c7fbba7adf9ca8f1484": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "179e73fc8c7b4f7eb9d35dcd485f9785": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6106a14f16b54db39fab92ca7c62a9f6",
              "IPY_MODEL_f338ff5e2c0c4d46bb7d8176dbb739e6",
              "IPY_MODEL_b3ab940394d7493bb6b3dc8c724a70ee"
            ],
            "layout": "IPY_MODEL_3d49182a77894ac087c46543c667f00a"
          }
        },
        "6106a14f16b54db39fab92ca7c62a9f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b8a0f1da92c42fe80d6358cdb936dd4",
            "placeholder": "​",
            "style": "IPY_MODEL_e5d50a4f24e34c4e86ec034c5c730143",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "f338ff5e2c0c4d46bb7d8176dbb739e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5932f22e37f4af18a8918fa9112099a",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_88c2c32e02084fe0a02f1e7786961e20",
            "value": 53
          }
        },
        "b3ab940394d7493bb6b3dc8c724a70ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_595765200ae244669772b50dd89af015",
            "placeholder": "​",
            "style": "IPY_MODEL_e500bbcd979b4e0d94ecd4c451208bac",
            "value": " 53.0/53.0 [00:00&lt;00:00, 4.21kB/s]"
          }
        },
        "3d49182a77894ac087c46543c667f00a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b8a0f1da92c42fe80d6358cdb936dd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5d50a4f24e34c4e86ec034c5c730143": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5932f22e37f4af18a8918fa9112099a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88c2c32e02084fe0a02f1e7786961e20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "595765200ae244669772b50dd89af015": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e500bbcd979b4e0d94ecd4c451208bac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cbb7468048e148c4820d239cfa6018b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6a62591d7ab04637931b57835fa83b00",
              "IPY_MODEL_d804868e0d544e4287bac53e6b18373a",
              "IPY_MODEL_4ae10def424c49e9be90546e1fe21cfa"
            ],
            "layout": "IPY_MODEL_14416ff5496742afba093638e5fbb234"
          }
        },
        "6a62591d7ab04637931b57835fa83b00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b389d1f48dc44e799e8b1b8c38e5a60d",
            "placeholder": "​",
            "style": "IPY_MODEL_2de7424dbd49406984a7301fe64e6b83",
            "value": "config.json: 100%"
          }
        },
        "d804868e0d544e4287bac53e6b18373a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d9d5f63af46423699cdb54208410d01",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_adbce660e9b64188901592d5d70ae530",
            "value": 612
          }
        },
        "4ae10def424c49e9be90546e1fe21cfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40a7fffdd6e24c0f9cfcbf82128a8935",
            "placeholder": "​",
            "style": "IPY_MODEL_187668c9757a414e941365be52749ef9",
            "value": " 612/612 [00:00&lt;00:00, 51.6kB/s]"
          }
        },
        "14416ff5496742afba093638e5fbb234": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b389d1f48dc44e799e8b1b8c38e5a60d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2de7424dbd49406984a7301fe64e6b83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d9d5f63af46423699cdb54208410d01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adbce660e9b64188901592d5d70ae530": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "40a7fffdd6e24c0f9cfcbf82128a8935": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "187668c9757a414e941365be52749ef9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e839fe3c66424455b2571d652330090e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_edf9aef0121849d39c2bb24ce7530efc",
              "IPY_MODEL_02d14ba38dd647ceb75df79afe82f0da",
              "IPY_MODEL_0c85cfe485f946b8b29d376569a7bf2c"
            ],
            "layout": "IPY_MODEL_f05fc79f8f504780b7606bed2a55aec3"
          }
        },
        "edf9aef0121849d39c2bb24ce7530efc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3cbda86b8904b38934583222d11aefa",
            "placeholder": "​",
            "style": "IPY_MODEL_22bb4e793bd7463a9b8a56eae41b7200",
            "value": "model.safetensors: 100%"
          }
        },
        "02d14ba38dd647ceb75df79afe82f0da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f62c2996e824451f8b60981f8d521338",
            "max": 90868376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_45b3c4aad9c94cc1b5795ee47438c1ad",
            "value": 90868376
          }
        },
        "0c85cfe485f946b8b29d376569a7bf2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77f7cafb18644cd686375dfe0f7f800b",
            "placeholder": "​",
            "style": "IPY_MODEL_a504ec265fb545d38a535b85abde10b9",
            "value": " 90.9M/90.9M [00:00&lt;00:00, 207MB/s]"
          }
        },
        "f05fc79f8f504780b7606bed2a55aec3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3cbda86b8904b38934583222d11aefa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22bb4e793bd7463a9b8a56eae41b7200": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f62c2996e824451f8b60981f8d521338": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45b3c4aad9c94cc1b5795ee47438c1ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "77f7cafb18644cd686375dfe0f7f800b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a504ec265fb545d38a535b85abde10b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f317d97a2f14bb9911d6215fd3d2b20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a649e6b35e1747a4bacd26d49f769e9c",
              "IPY_MODEL_7401ec1e75d7476e8fe7d0f03f692329",
              "IPY_MODEL_9436d5b47fcf4439b02afd412de23d0f"
            ],
            "layout": "IPY_MODEL_51c30af78b9b4189a45ea6de596831db"
          }
        },
        "a649e6b35e1747a4bacd26d49f769e9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d06a19de58c4287acd4b164e307ae9a",
            "placeholder": "​",
            "style": "IPY_MODEL_792d11e2a81a486ebc5b00733a7ef1b1",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "7401ec1e75d7476e8fe7d0f03f692329": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_004b13f1d5b34beabc9e61b2ae1599f3",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b70b120aaa9c4560b02db09eb4a8127e",
            "value": 350
          }
        },
        "9436d5b47fcf4439b02afd412de23d0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9876ad09aa5b4916b8fa05dfa038c9cd",
            "placeholder": "​",
            "style": "IPY_MODEL_6c146e440aa048a18f00591277a920c4",
            "value": " 350/350 [00:00&lt;00:00, 29.9kB/s]"
          }
        },
        "51c30af78b9b4189a45ea6de596831db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d06a19de58c4287acd4b164e307ae9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "792d11e2a81a486ebc5b00733a7ef1b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "004b13f1d5b34beabc9e61b2ae1599f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b70b120aaa9c4560b02db09eb4a8127e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9876ad09aa5b4916b8fa05dfa038c9cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c146e440aa048a18f00591277a920c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ba4d12b5c1c43bebd65f7a308ad0317": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8e6f620f01784303bd8bbc735ae19ace",
              "IPY_MODEL_2517264bb6df413ab74b9e6392b2b7c8",
              "IPY_MODEL_cc18c3308e07466baf107ce4aba58dae"
            ],
            "layout": "IPY_MODEL_5afa9b31a5f147988e4878f888d6bd10"
          }
        },
        "8e6f620f01784303bd8bbc735ae19ace": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35acccbf6153400aa961f6b61447920d",
            "placeholder": "​",
            "style": "IPY_MODEL_0bbcff6f561d4f838abd94bae608d896",
            "value": "vocab.txt: 100%"
          }
        },
        "2517264bb6df413ab74b9e6392b2b7c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f10253e5e4e0465e83fa171466020088",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9fe91a80bac0424caa67f6b996ac74c0",
            "value": 231508
          }
        },
        "cc18c3308e07466baf107ce4aba58dae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee0bc6053a3e42dca41d44d35873d3b6",
            "placeholder": "​",
            "style": "IPY_MODEL_4cb9a599eb7344cfa01f04fccc3af278",
            "value": " 232k/232k [00:00&lt;00:00, 12.1MB/s]"
          }
        },
        "5afa9b31a5f147988e4878f888d6bd10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35acccbf6153400aa961f6b61447920d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bbcff6f561d4f838abd94bae608d896": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f10253e5e4e0465e83fa171466020088": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fe91a80bac0424caa67f6b996ac74c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ee0bc6053a3e42dca41d44d35873d3b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cb9a599eb7344cfa01f04fccc3af278": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cbb8fbe9893a457489fa5ba6b1ae58b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c426d1af2634947aa2b96f4b67aca92",
              "IPY_MODEL_b0fa79ae031744d9b4cc3b0546ef03c2",
              "IPY_MODEL_2ba8e51b62cd45ae886f691e0dfdc05a"
            ],
            "layout": "IPY_MODEL_b8c29d086adc4b648caf4b1903dbfed6"
          }
        },
        "7c426d1af2634947aa2b96f4b67aca92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a003f65e0df64576a1665541f8e77d3c",
            "placeholder": "​",
            "style": "IPY_MODEL_2525bbd0f40143039aa09989510d5e29",
            "value": "tokenizer.json: 100%"
          }
        },
        "b0fa79ae031744d9b4cc3b0546ef03c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3724d25e5ef74c4492bbdf507570085f",
            "max": 466247,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_26c64d14b710440a8eeec7be867c0260",
            "value": 466247
          }
        },
        "2ba8e51b62cd45ae886f691e0dfdc05a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86c2953c8a4b49709a80cca64fc1b25f",
            "placeholder": "​",
            "style": "IPY_MODEL_87551ca7b7c74ee89b082e5004053fcc",
            "value": " 466k/466k [00:00&lt;00:00, 31.3MB/s]"
          }
        },
        "b8c29d086adc4b648caf4b1903dbfed6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a003f65e0df64576a1665541f8e77d3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2525bbd0f40143039aa09989510d5e29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3724d25e5ef74c4492bbdf507570085f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26c64d14b710440a8eeec7be867c0260": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "86c2953c8a4b49709a80cca64fc1b25f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87551ca7b7c74ee89b082e5004053fcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e84191bedd834826893f3f3a7c13ba0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_07dc6ccfd30a4262a2a27171e74d10e4",
              "IPY_MODEL_e7f9894000d6476aa4d9bbef7309ba70",
              "IPY_MODEL_8627f44827fd46149784d6819777707a"
            ],
            "layout": "IPY_MODEL_5f1d4a455d05449aa0a9933a1c82d3c5"
          }
        },
        "07dc6ccfd30a4262a2a27171e74d10e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_931e28c79a5e438fbd79a7d81f5ef0ce",
            "placeholder": "​",
            "style": "IPY_MODEL_b79c7378a0d14711a44777d6fd246c69",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "e7f9894000d6476aa4d9bbef7309ba70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3bc52b12ed634ade874105c87fe4aeed",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_44354ca6cf464d12bbba4320388d0970",
            "value": 112
          }
        },
        "8627f44827fd46149784d6819777707a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_474ea30846ec4c16b38c67253302e41b",
            "placeholder": "​",
            "style": "IPY_MODEL_fadc5e5214e848bfa7ffbb5955abdb1a",
            "value": " 112/112 [00:00&lt;00:00, 9.15kB/s]"
          }
        },
        "5f1d4a455d05449aa0a9933a1c82d3c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "931e28c79a5e438fbd79a7d81f5ef0ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b79c7378a0d14711a44777d6fd246c69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3bc52b12ed634ade874105c87fe4aeed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44354ca6cf464d12bbba4320388d0970": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "474ea30846ec4c16b38c67253302e41b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fadc5e5214e848bfa7ffbb5955abdb1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f414fccf10c47bd878cd5357bee100a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0d7c7beab6ad49d0aa6b964584a9b13b",
              "IPY_MODEL_604ac83ddc2d4e61a60ed40bb461c218",
              "IPY_MODEL_c0b6e2ef9e154b8897037d2f7aa932ca"
            ],
            "layout": "IPY_MODEL_c1726ad1e11e40bf81049891b65e8238"
          }
        },
        "0d7c7beab6ad49d0aa6b964584a9b13b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c712a81c6c745b4915829efab6fde68",
            "placeholder": "​",
            "style": "IPY_MODEL_443aa0cdd8df46fdae312af9ce87c109",
            "value": "1_Pooling/config.json: 100%"
          }
        },
        "604ac83ddc2d4e61a60ed40bb461c218": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d96987e36b6e449688a56c980528823d",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_026ffe18c909432c9bf365e3e73d1460",
            "value": 190
          }
        },
        "c0b6e2ef9e154b8897037d2f7aa932ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b5997d78cb94d93a37d659fb3b95a9f",
            "placeholder": "​",
            "style": "IPY_MODEL_658d4fa1c4904c9089e5950aa3e5b00d",
            "value": " 190/190 [00:00&lt;00:00, 7.29kB/s]"
          }
        },
        "c1726ad1e11e40bf81049891b65e8238": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c712a81c6c745b4915829efab6fde68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "443aa0cdd8df46fdae312af9ce87c109": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d96987e36b6e449688a56c980528823d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "026ffe18c909432c9bf365e3e73d1460": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1b5997d78cb94d93a37d659fb3b95a9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "658d4fa1c4904c9089e5950aa3e5b00d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dawoodTanvir/EDBOT_FYP/blob/main/FYP_Content_Slides_Quiz.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ef65df7b67de454f9a6cc9d21ec76b32",
            "be237253887a4b22994c1e9d9110bae7",
            "a1cc62c7a4924a8091c4b437453058ee",
            "57322bbcb82d49b094bf450ded10bb02",
            "65e5f0774c524096aee07993682a347f",
            "457888ee56954287968d992b2e49142c",
            "e9fb5bd8f43e4746a02de533296349bc",
            "9371241ceb26473ba735df9cdf53120e",
            "fb8df3f416274479acc9d6f3e0b5ff14",
            "6d202180d105481995c8b433b32c646a",
            "e8c54681ab0a4d7b8e14f43618d8771c",
            "ed69ec01893f43fd9ba74e04f137d852",
            "db4423260d1e4c7393587e90c7e7dfeb",
            "b25d70a3f4d145eaaac0326cd2416edc",
            "6f334da4f15247e286336327e190c33a",
            "35daa86e93fd46a7baea7a27d41574f2",
            "c48d4dc736e44cbf9b9e53adef99bcff",
            "ef28b2c739af4d0d8ccebc8f0e07e761",
            "65510ca89ea54e6e8f1afd1127328ebb",
            "afe46bcc0b39445d9453c93f6a5c05c3",
            "7bddd616ce494f0f845223f800531221",
            "c01db2ac6be5475aaeb865f95308a34c",
            "03557d37810c4b44a77911d5c9c73756",
            "7ac947b71baf4be1a52ca6ea31297495",
            "e720a0081d8a429dbd9e5732c4ff7246",
            "10dc73ce4e194e0a8a3ed8d1d0923021",
            "d8c6e468b280494cbaaf904af873678e",
            "7342dd3ed8864173a6d598c0363b1f33",
            "da3525d50acd4c56aa4471e9b4309d01",
            "461162a0c1ea48c98171406f0cb2c3b1",
            "e133e7fc1de444f7843d08bb686d1fb9",
            "03e7b5d38e4c4f099f27262c424aac59",
            "44def13723554c7fbba7adf9ca8f1484",
            "179e73fc8c7b4f7eb9d35dcd485f9785",
            "6106a14f16b54db39fab92ca7c62a9f6",
            "f338ff5e2c0c4d46bb7d8176dbb739e6",
            "b3ab940394d7493bb6b3dc8c724a70ee",
            "3d49182a77894ac087c46543c667f00a",
            "1b8a0f1da92c42fe80d6358cdb936dd4",
            "e5d50a4f24e34c4e86ec034c5c730143",
            "e5932f22e37f4af18a8918fa9112099a",
            "88c2c32e02084fe0a02f1e7786961e20",
            "595765200ae244669772b50dd89af015",
            "e500bbcd979b4e0d94ecd4c451208bac",
            "cbb7468048e148c4820d239cfa6018b4",
            "6a62591d7ab04637931b57835fa83b00",
            "d804868e0d544e4287bac53e6b18373a",
            "4ae10def424c49e9be90546e1fe21cfa",
            "14416ff5496742afba093638e5fbb234",
            "b389d1f48dc44e799e8b1b8c38e5a60d",
            "2de7424dbd49406984a7301fe64e6b83",
            "7d9d5f63af46423699cdb54208410d01",
            "adbce660e9b64188901592d5d70ae530",
            "40a7fffdd6e24c0f9cfcbf82128a8935",
            "187668c9757a414e941365be52749ef9",
            "e839fe3c66424455b2571d652330090e",
            "edf9aef0121849d39c2bb24ce7530efc",
            "02d14ba38dd647ceb75df79afe82f0da",
            "0c85cfe485f946b8b29d376569a7bf2c",
            "f05fc79f8f504780b7606bed2a55aec3",
            "d3cbda86b8904b38934583222d11aefa",
            "22bb4e793bd7463a9b8a56eae41b7200",
            "f62c2996e824451f8b60981f8d521338",
            "45b3c4aad9c94cc1b5795ee47438c1ad",
            "77f7cafb18644cd686375dfe0f7f800b",
            "a504ec265fb545d38a535b85abde10b9",
            "2f317d97a2f14bb9911d6215fd3d2b20",
            "a649e6b35e1747a4bacd26d49f769e9c",
            "7401ec1e75d7476e8fe7d0f03f692329",
            "9436d5b47fcf4439b02afd412de23d0f",
            "51c30af78b9b4189a45ea6de596831db",
            "6d06a19de58c4287acd4b164e307ae9a",
            "792d11e2a81a486ebc5b00733a7ef1b1",
            "004b13f1d5b34beabc9e61b2ae1599f3",
            "b70b120aaa9c4560b02db09eb4a8127e",
            "9876ad09aa5b4916b8fa05dfa038c9cd",
            "6c146e440aa048a18f00591277a920c4",
            "1ba4d12b5c1c43bebd65f7a308ad0317",
            "8e6f620f01784303bd8bbc735ae19ace",
            "2517264bb6df413ab74b9e6392b2b7c8",
            "cc18c3308e07466baf107ce4aba58dae",
            "5afa9b31a5f147988e4878f888d6bd10",
            "35acccbf6153400aa961f6b61447920d",
            "0bbcff6f561d4f838abd94bae608d896",
            "f10253e5e4e0465e83fa171466020088",
            "9fe91a80bac0424caa67f6b996ac74c0",
            "ee0bc6053a3e42dca41d44d35873d3b6",
            "4cb9a599eb7344cfa01f04fccc3af278",
            "cbb8fbe9893a457489fa5ba6b1ae58b7",
            "7c426d1af2634947aa2b96f4b67aca92",
            "b0fa79ae031744d9b4cc3b0546ef03c2",
            "2ba8e51b62cd45ae886f691e0dfdc05a",
            "b8c29d086adc4b648caf4b1903dbfed6",
            "a003f65e0df64576a1665541f8e77d3c",
            "2525bbd0f40143039aa09989510d5e29",
            "3724d25e5ef74c4492bbdf507570085f",
            "26c64d14b710440a8eeec7be867c0260",
            "86c2953c8a4b49709a80cca64fc1b25f",
            "87551ca7b7c74ee89b082e5004053fcc",
            "e84191bedd834826893f3f3a7c13ba0b",
            "07dc6ccfd30a4262a2a27171e74d10e4",
            "e7f9894000d6476aa4d9bbef7309ba70",
            "8627f44827fd46149784d6819777707a",
            "5f1d4a455d05449aa0a9933a1c82d3c5",
            "931e28c79a5e438fbd79a7d81f5ef0ce",
            "b79c7378a0d14711a44777d6fd246c69",
            "3bc52b12ed634ade874105c87fe4aeed",
            "44354ca6cf464d12bbba4320388d0970",
            "474ea30846ec4c16b38c67253302e41b",
            "fadc5e5214e848bfa7ffbb5955abdb1a",
            "0f414fccf10c47bd878cd5357bee100a",
            "0d7c7beab6ad49d0aa6b964584a9b13b",
            "604ac83ddc2d4e61a60ed40bb461c218",
            "c0b6e2ef9e154b8897037d2f7aa932ca",
            "c1726ad1e11e40bf81049891b65e8238",
            "8c712a81c6c745b4915829efab6fde68",
            "443aa0cdd8df46fdae312af9ce87c109",
            "d96987e36b6e449688a56c980528823d",
            "026ffe18c909432c9bf365e3e73d1460",
            "1b5997d78cb94d93a37d659fb3b95a9f",
            "658d4fa1c4904c9089e5950aa3e5b00d"
          ]
        },
        "id": "4MIwLXoUjga8",
        "outputId": "f30a1a81-e3dc-40d0-bbd6-7f493f95f772"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/460.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m460.6/460.6 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.7/412.7 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m111.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m92.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 18 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 696 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.6 [186 kB]\n",
            "Fetched 186 kB in 1s (147 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 124950 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.6_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.6) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.6) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 18 not upgraded.\n",
            "Need to get 4,816 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Fetched 4,816 kB in 2s (2,470 kB/s)\n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 124980 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m86.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2024.12.14)\n",
            "Collecting python-pptx\n",
            "  Downloading python_pptx-1.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (11.1.0)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx)\n",
            "  Downloading XlsxWriter-3.2.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (5.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (4.12.2)\n",
            "Downloading python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading XlsxWriter-3.2.2-py3-none-any.whl (165 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.1/165.1 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: XlsxWriter, python-pptx\n",
            "Successfully installed XlsxWriter-3.2.2 python-pptx-1.0.2\n",
            "Collecting gensim==3.8.3\n",
            "  Downloading gensim-3.8.3.tar.gz (23.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.4/23.4 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.11/dist-packages (from gensim==3.8.3) (1.26.4)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.11/dist-packages (from gensim==3.8.3) (1.13.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from gensim==3.8.3) (1.17.0)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim==3.8.3) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart_open>=1.8.1->gensim==3.8.3) (1.17.2)\n",
            "Building wheels for collected packages: gensim\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for gensim (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for gensim\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for gensim\n",
            "Failed to build gensim\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (gensim)\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting keybert\n",
            "  Downloading keybert-0.8.5-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from keybert) (1.26.4)\n",
            "Requirement already satisfied: rich>=10.4.0 in /usr/local/lib/python3.11/dist-packages (from keybert) (13.9.4)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.11/dist-packages (from keybert) (1.6.1)\n",
            "Requirement already satisfied: sentence-transformers>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from keybert) (3.3.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.4.0->keybert) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.4.0->keybert) (2.18.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.2->keybert) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.2->keybert) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.2->keybert) (3.5.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.3.8->keybert) (4.47.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.3.8->keybert) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.3.8->keybert) (2.5.1+cu124)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.3.8->keybert) (0.27.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.3.8->keybert) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (4.12.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.4.0->keybert) (0.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (0.5.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2024.12.14)\n",
            "Downloading keybert-0.8.5-py3-none-any.whl (37 kB)\n",
            "Installing collected packages: keybert\n",
            "Successfully installed keybert-0.8.5\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2024.12.14)\n",
            "Collecting google_images_download\n",
            "  Downloading google_images_download-2.8.0.tar.gz (14 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting selenium (from google_images_download)\n",
            "  Downloading selenium-4.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium->google_images_download) (2.3.0)\n",
            "Collecting trio~=0.17 (from selenium->google_images_download)\n",
            "  Downloading trio-0.28.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting trio-websocket~=0.9 (from selenium->google_images_download)\n",
            "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.11/dist-packages (from selenium->google_images_download) (2024.12.14)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.11/dist-packages (from selenium->google_images_download) (4.12.2)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.11/dist-packages (from selenium->google_images_download) (1.8.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium->google_images_download) (25.1.0)\n",
            "Collecting sortedcontainers (from trio~=0.17->selenium->google_images_download)\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium->google_images_download) (3.10)\n",
            "Collecting outcome (from trio~=0.17->selenium->google_images_download)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium->google_images_download) (1.3.1)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium->google_images_download)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium->google_images_download) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium->google_images_download) (0.14.0)\n",
            "Downloading selenium-4.28.1-py3-none-any.whl (9.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m120.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio-0.28.0-py3-none-any.whl (486 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.3/486.3 kB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
            "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Building wheels for collected packages: google_images_download\n",
            "  Building wheel for google_images_download (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google_images_download: filename=google_images_download-2.8.0-py2.py3-none-any.whl size=14537 sha256=e47394296d70d6abdc5f0ed67fe2a4af46066d024866bf7f6bfc24212ccd874b\n",
            "  Stored in directory: /root/.cache/pip/wheels/dc/83/37/7303b15f3e8a5bfbd5c7ebbfe13f0c666ada6f8efecc6d77ec\n",
            "Successfully built google_images_download\n",
            "Installing collected packages: sortedcontainers, wsproto, outcome, trio, trio-websocket, selenium, google_images_download\n",
            "Successfully installed google_images_download-2.8.0 outcome-1.3.0.post0 selenium-4.28.1 sortedcontainers-2.4.0 trio-0.28.0 trio-websocket-0.11.1 wsproto-1.2.0\n",
            "Collecting google-search-results\n",
            "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from google-search-results) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (2024.12.14)\n",
            "Building wheels for collected packages: google-search-results\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32009 sha256=6e72311458c80b582874652f9418237cff9432838280c6f30d518c576e739240\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/42/3e/aeb691b02cb7175ec70e2da04b5658d4739d2b41e5f73cd06f\n",
            "Successfully built google-search-results\n",
            "Installing collected packages: google-search-results\n",
            "Successfully installed google-search-results-2.4.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ef65df7b67de454f9a6cc9d21ec76b32"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed69ec01893f43fd9ba74e04f137d852"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "03557d37810c4b44a77911d5c9c73756"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "179e73fc8c7b4f7eb9d35dcd485f9785"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cbb7468048e148c4820d239cfa6018b4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e839fe3c66424455b2571d652330090e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f317d97a2f14bb9911d6215fd3d2b20"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1ba4d12b5c1c43bebd65f7a308ad0317"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cbb8fbe9893a457489fa5ba6b1ae58b7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e84191bedd834826893f3f3a7c13ba0b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f414fccf10c47bd878cd5357bee100a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "<ipython-input-1-f1bbd73c38d2>:36: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/244.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.8/244.8 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/85.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade langchain openai  -q\n",
        "!pip install sentence_transformers -q\n",
        "!apt-get install poppler-utils\n",
        "!apt-get install -y tesseract-ocr\n",
        "!pip install -U langchain-community -q\n",
        "!pip install pillow\n",
        "!pip install requests\n",
        "!pip install python-pptx\n",
        "!pip install gensim==3.8.3\n",
        "!pip install keybert\n",
        "!pip install requests Pillow\n",
        "!pip install google_images_download\n",
        "!pip install google-search-results\n",
        "from pptx import Presentation\n",
        "from pptx.util import Pt, Inches\n",
        "from PIL import Image\n",
        "import random\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "from io import BytesIO\n",
        "import requests\n",
        "# Download necessary NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Initialize KeyBERT\n",
        "from keybert import KeyBERT\n",
        "kw_model = KeyBERT()\n",
        "\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "from langchain.embeddings import SentenceTransformerEmbeddings\n",
        "embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "!pip install pinecone-client -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import getpass\n",
        "import os\n",
        "import time\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "from langchain.embeddings import SentenceTransformerEmbeddings\n",
        "from langchain.vectorstores import Pinecone as LangchainPinecone\n",
        "\n",
        "#074e0d9a-ab5e-48bf-8eae-9effae335521              This is the API to MYDB Insert this\n",
        "\n",
        "# Prompt for Pinecone API key if not set in the environment\n",
        "if not os.getenv(\"PINECONE_API_KEY\"):\n",
        "    os.environ[\"PINECONE_API_KEY\"] = getpass.getpass(\"Enter your Pinecone API key: \")\n",
        "\n",
        "# Retrieve the Pinecone API key from environment variables\n",
        "pinecone_api_key = os.environ.get(\"PINECONE_API_KEY\")\n",
        "\n",
        "# Initialize Pinecone\n",
        "pc = Pinecone(api_key=pinecone_api_key)\n",
        "\n",
        "# Define your index name\n",
        "index_name = \"newdata\"  # Change if desired\n",
        "\n",
        "# Check for existing indexes\n",
        "existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
        "\n",
        "# Create the index if it does not exist\n",
        "if index_name not in existing_indexes:\n",
        "    pc.create_index(\n",
        "        name=index_name,\n",
        "        dimension=384,  # Adjust this to match your embeddings' dimension\n",
        "        metric=\"cosine\",\n",
        "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
        "    )\n",
        "\n",
        "    # Wait until the index is ready\n",
        "    while not pc.describe_index(index_name).status[\"ready\"]:\n",
        "        print(\"Waiting for the index to be ready...\")\n",
        "        time.sleep(1)\n",
        "\n",
        "# Connect to the index\n",
        "index = pc.Index(index_name)\n",
        "\n",
        "# Print connection success message\n",
        "print(f\"Successfully connected to the index: {index_name}\")\n",
        "\n",
        "\n",
        "# Now create a Pinecone index for Langchain using the existing index\n",
        "langchain_index = LangchainPinecone.from_existing_index(\n",
        "    index_name=index_name,\n",
        "    embedding=embeddings\n",
        "\n",
        ")\n",
        "\n",
        "# Output to verify the index creation\n",
        "print(f\"Successfully created or connected to the Langchain index: {langchain_index}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYu3NxcikRHQ",
        "outputId": "c224d7db-8aaf-4861-ad5b-40d917353325"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your Pinecone API key: ··········\n",
            "Successfully connected to the index: newdata\n",
            "Successfully created or connected to the Langchain index: <langchain_community.vectorstores.pinecone.Pinecone object at 0x7ce844f77350>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_similar_docs(query, k=20, score=True):\n",
        "    if score:\n",
        "        similar_docs = langchain_index.similarity_search_with_score(query, k=k)  # Use langchain_index\n",
        "    else:\n",
        "        similar_docs = langchain_index.similarity_search(query, k=k)  # Use langchain_index\n",
        "    return similar_docs"
      ],
      "metadata": {
        "id": "-TBvgxFWkVR6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract Answer from LLM"
      ],
      "metadata": {
        "id": "U3dDS6B-RNrG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# **\n",
        "import os\n",
        "import requests\n",
        "\n",
        "# Set the Hugging Face API key directly inside the script\n",
        "HUGGINGFACE_API_TOKEN = \"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\"  # Replace with your actual API key\n",
        "\n",
        "# Define the model name\n",
        "model_name = \"mistralai/Mistral-7B-Instruct-v0.3\"  # Replace with your chosen model\n",
        "\n",
        "# Construct the API URL\n",
        "HUGGINGFACE_API_URL = f\"https://api-inference.huggingface.co/models/{model_name}\"\n",
        "\n",
        "# Set up the headers with the authorization token\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {HUGGINGFACE_API_TOKEN}\"\n",
        "}\n",
        "\n",
        "# Example query\n",
        "query = \"LSTM\"\n",
        "\n",
        "# Assuming you have a function `get_similar_docs` defined\n",
        "similar_docs = get_similar_docs(query)\n",
        "\n",
        "# Prepare the context from similar_docs\n",
        "context = \"\\n\\n\".join([doc[0].page_content for doc in similar_docs])\n",
        "\n",
        "prompt = f'''\n",
        "Context: {context}\n",
        "Question: {query}\n",
        "\n",
        "Provide a comprehensive explanation strictly following this structure. Always use \"##\" to introduce each section:\n",
        "\n",
        "## 1. *Concept Overview*\n",
        "  • Core definition and purpose\n",
        "  • Key principles\n",
        "  • Relationship to broader computing concepts\n",
        "\n",
        "## 2. *Technical Components*\n",
        "  • Primary elements and their roles\n",
        "  • Relationships and interactions\n",
        "  • Implementation details\n",
        "  • Core algorithms/procedures (if applicable)\n",
        "\n",
        "## 3. *Working Mechanism*\n",
        "  • Step-by-step operational flow\n",
        "  • Critical processes and transformations\n",
        "  • Resource management (if applicable)\n",
        "  • Exception handling (if applicable)\n",
        "\n",
        "## 4. *Implementation Example*\n",
        "  • Use case scenario\n",
        "  • Code implementation or technical design\n",
        "  • Step-by-step execution\n",
        "  • Output analysis\n",
        "\n",
        "## 5. *Best Practices*\n",
        "  • Design considerations\n",
        "  • Optimization techniques\n",
        "  • Common pitfalls\n",
        "  • Performance implications\n",
        "\n",
        "## 6. *Applications*\n",
        "  • Real-world use cases\n",
        "  • Industry applications\n",
        "  • Integration patterns\n",
        "  • Variations and alternatives\n",
        "\n",
        "## 7. *Evaluation*\n",
        "  • Performance metrics\n",
        "  • Testing approaches\n",
        "  • Debugging strategies\n",
        "  • Optimization opportunities\n",
        "\n",
        "## 8. *Practice Problems*\n",
        "  • Concept verification questions\n",
        "  • Implementation challenges\n",
        "  • Problem-solving scenarios\n",
        "  • Solutions with explanations\n",
        "\n",
        "### Format Requirements:\n",
        "- Always use \"##\" to introduce each section header. Avoid using any other format.\n",
        "- Use bullet points for clarity\n",
        "- Show all mathematical steps using proper equation formatting ($...$)\n",
        "- Include clear variable definitions after each equation\n",
        "- Write formulas using LaTeX formatting inside $...$\n",
        "- For matrices use: $\\begin{{bmatrix}} a & b \\\\ c & d \\end{{bmatrix}}$\n",
        "- For fractions use: $\\frac{{numerator}}{{denominator}}$\n",
        "- Use ■ for numbered equations and • for regular points\n",
        "- Demonstrate practical interpretation\n",
        "- Connect to real applications\n",
        "\n",
        "### Equation Guidelines:\n",
        "- Enclose equations in $...$ format\n",
        "- Use proper LaTeX notation for mathematical expressions\n",
        "- Use $\\sum$ for summations\n",
        "- Define each variable after presenting equations\n",
        "- Number important equations using ■\n",
        "- Show step-by-step derivations with clear explanations\n",
        "\n",
        "### Code Guidelines:\n",
        "- Use LaTeX verbatim environment for code blocks:\n",
        "  \\begin{{verbatim}}\n",
        "  code here\n",
        "  \\end{{verbatim}}\n",
        "\n",
        "- For inline code use \\texttt{{code}}\n",
        "- For syntax highlighting:\n",
        "  \\begin{{lstlisting}}[language=Python]\n",
        "  code here\n",
        "  \\end{{lstlisting}}\n",
        "- Include comments explaining code functionality\n",
        "- Show output examples where applicable\n",
        "'''\n",
        "\n",
        "\n",
        "# Function to query Hugging Face Inference API\n",
        "def query_huggingface_api(prompt, max_length=25000):\n",
        "    payload = {\n",
        "        \"inputs\": prompt,\n",
        "        \"parameters\": {\n",
        "            \"max_new_tokens\": max_length,\n",
        "            \"temperature\": 0.5,\n",
        "            \"top_p\": 0.7,\n",
        "            \"top_k\": 50,\n",
        "            \"repetition_penalty\": 1.1,\n",
        "            \"do_sample\": True,\n",
        "            \"stop\": [\"<|endoftext|>\"]\n",
        "        }\n",
        "     }\n",
        "\n",
        "    response = requests.post(\n",
        "        HUGGINGFACE_API_URL,\n",
        "        headers=headers,\n",
        "        json=payload\n",
        "    )\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        #print(response.json())\n",
        "        return response.json()\n",
        "    else:\n",
        "        raise Exception(\n",
        "            f\"Request failed with status code {response.status_code}: {response.text}\"\n",
        "        )\n",
        "\n",
        "# Function to extract answer from API response\n",
        "def extract_answer(api_response):\n",
        "    if isinstance(api_response, list) and len(api_response) > 0:\n",
        "        generated_text = api_response[0].get('generated_text', '')\n",
        "\n",
        "        answer = generated_text.split(\"Answer:\")[-1].strip() if \"Answer:\" in generated_text else generated_text.strip()\n",
        "        if len(answer) > 30000:\n",
        "            answer = answer[:30000] + \"...\"\n",
        "        return answer\n",
        "    else:\n",
        "        return \"No answer generated.\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Generate the answer using Hugging Face Inference API\n",
        "try:\n",
        "    api_response = query_huggingface_api(prompt, max_length=25000)\n",
        "    answer = extract_answer(api_response)\n",
        "    print(\"Answer:\", answer)\n",
        "except Exception as e:\n",
        "    print(\"Error:\", str(e))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIe7L4Okkdrd",
        "outputId": "71d5aaa4-b7b3-4469-e822-e23ae0b25274"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: Context: BIBLIOGRAPHY  Graves, . . Sequence transduction  recurrent neural networks.   . Graves, .  . Jaitly . Towards  speech recognition  recurrent neural networks.   , . . Graves, .  . Schmidhuber . Framewise phoneme classiﬁcation  bidirec tional   other neural network architectures. Neural Networks  , .\n",
            "\n",
            "  vector hmthis information  represented.   limitation   informa   attenuated  repeated application   squashing function . short memories LSTMs, described below,   variant    address  issue,   memory cells  propagate information through  sequence without applying  linearities Hochreiter  Schmidhuber, .  denominator  Equation .   computational bottleneck, because  involves\n",
            "\n",
            "Recurrent neural networks   introduced     language model  technique,  which  context  token  summarized   recurrentlyupdated vector, ,,   ,,..., wherexmis  vector embedding   token wmand  function gdeﬁnes  recur rence.  starting condition   additional parameter   model.   short  memory     complex recurrence,  which  memory   through \n",
            "\n",
            " . LANGUAGE MODELS              Figure .   short memory  architecture. Gates  shown  boxes  dotted edges.    language model,  hmwould    predict   wordwm.  gates  functions   input  previous hidden state.   computed  elementwise sigmoid activations,   , ensuring  their values\n",
            "\n",
            "BIBLIOGRAPHY  , .  . Bansal .  relation extraction using lstms  sequences   structures.   , . . , .  . Hinton . Three  graphical models  statistical language  elling.  Proceedings   International Conference  Machine Learning  , .  . , .  . . Hinton .  scalable hierarchical distributed language model.  Neural Information Processing Systems  , . .\n",
            "\n",
            "sentations  vector space.  Proceedings  International Conference  Learning Represen tations . Mikolov, ., . Deoras, . Povey, . Burget,  . Cernocky . Strategies  training large scale neural network language models.  Proceedings   Workshop  Automatic Speech Recognition  Understanding  , . . Mikolov, ., . Karaﬁ , . Burget, . Cernock ,  . Khudanpur . Recurrent neural network based language model.  INTERSPEECH , . .\n",
            "\n",
            ".. Convolutional Neural Networks  Sequence Labeling  disadvantage  recurrent neural networks    architecture requires iterating through  sequence  inputs  predictions  hidden vector hmmust   puted   previous hidden vector , before predicting   . These iterative computations  difﬁcult  parallelize,    exploit  speedups offered  graph  processing units   operations   matrix multiplication. Convolutional\n",
            "\n",
            " baseline   implemented   neural architecture, using  attention  anism .., which scores  similarity   query      source    ., .      encode  passage   query , using  bidirectional LSTMs  .. BiLSTM   . BiLSTM  . .  query  represented  vertically concatenating   states   right  right passes \n",
            "\n",
            ".. RECURRENT NEURAL NETWORK LANGUAGE MODELS  derivatives automatically,  cache   future .  important distinction   feedforward neural networks considered         computa  graph   ,  varies   length   input.  poses difﬁculties  toolkits   designed around static computation graphs,   TensorFlow Abadi  ., . .. Hyperparameters\n",
            "\n",
            " incorporating  inner product   approximation   likelihood    ,   possible  estimate  parameters  backpropagation.   Mikolov  .,  includes   approximations continuous words   skipgrams. .. Continuous words   recurrent neural network language models,    conditioned   recurrently updated state vector, which  based   representations going      \n",
            "\n",
            ".. RECURRENT NEURAL NETWORK LANGUAGE MODELS    sequence.  language models  deﬁned,  .  , . ,,...,  , . whereφis  matrix   embeddings , andxmdenotes  embedding   .  conversion  wmtoxmis sometimes known   lookup layer , because  simply lookup  embeddings      table  ...  Elman  deﬁnes  simple recurrent operation Elman, ,\n",
            "\n",
            "whereδ   indicator function, taking  value      record   identical   target  .  probability  copying record rfrom  source ,  product    probability   local attention.     model,  attention weights αmare computed   previous decoder state .  computation graph therefore remains  feedforward network,  recurrent paths      .\n",
            "\n",
            " operator  elementwise Hadamard product.    controlled      weights, which parametrize  previous hidden state ..,    current input .., ,   vector offset .., .  overall operation   infor mally summarized  ,   ,,,  ,representing   state after reading token .   outperforms standard recurrent neural networks across   range \n",
            "\n",
            " . APPLICATIONS  SEQUENCE LABELING   predict labels      ONSTART   character.  recent   employed neural network architectures.  example,   .      architecture,  described  .  construct  trellis,  which    scored according   hidden state   ,   transitions  scored according  learned transition weights.  scoring segmentation   computed  \n",
            "\n",
            "beginning   source   greatest impact   encoding ,  therefore impact  words   beginning   target sentence. Later     vanced encoding models,   neural attention ..,  eliminated    reversing  source sentence.  encoder  decoder   implemented   LSTMs ,  multiple layers  hidden states.  shown  Figure .,  hidden state ,  layeriis treated\n",
            "\n",
            "epochs batches   sentences, chosen   similar length    sentence   batch   roughly   amount    process gradi  clipping ..  ensure      gradient never exceeds  predeﬁned value. .. Neural attention  sequencesequence model discussed   previous section   radical depar   statistical machine translation,  which    phrase   target \n",
            "\n",
            "brenner  Blunsom     . ,  strong empirical results.  models  recurrent   utterance level,    complete utterance updates  hidden state.  recurrentconvolutional network  Kalchbrenner  Blunsom   convolu   obtain  representation   individual utterance, while   .    second level  recurrence,  individual words.  enables their method   \n",
            "\n",
            ".. NEURAL SEQUENCE LABELING   practice, numerical stability demands       domain, logαm    logsm,  logαm . logβm    logsm,  logβm . .  application   forward  backward probabilities  shown  Figure ..   forward  backward recurrences operate   trellis, which implies  space complexityO. Because  recurrences require computing    Kterms \n",
            "\n",
            "tentional encoderdecoder translation model discussed  ..   ., .  longer sentence  encoded   sequence  vectors,    token.  decoder  computes attention  these vectors  updating   recurrent state.    generation,    useful  augment  encoderdecoder model   ability   words directly   source.   .  train  model \n",
            "\n",
            " Morphology  Syntax , Volume   Synthesis Lectures  Human Language Technolo . Morgan  Claypool Publishers. Bengio, ., . Vinyals, . Jaitly,  . Shazeer . Scheduled sampling  sequence prediction  recurrent neural networks.   , . . Bengio, ., . Ducharme,  . Vincent,  . Janvin .  neural probabilistic language model.  Journal  Machine Learning Research  , .\n",
            "Question: LSTM\n",
            "\n",
            "Provide a comprehensive explanation strictly following this structure. Always use \"##\" to introduce each section:\n",
            "\n",
            "## 1. *Concept Overview*\n",
            "  • Core definition and purpose\n",
            "  • Key principles\n",
            "  • Relationship to broader computing concepts\n",
            "\n",
            "## 2. *Technical Components*\n",
            "  • Primary elements and their roles\n",
            "  • Relationships and interactions\n",
            "  • Implementation details\n",
            "  • Core algorithms/procedures (if applicable)\n",
            "\n",
            "## 3. *Working Mechanism*\n",
            "  • Step-by-step operational flow\n",
            "  • Critical processes and transformations\n",
            "  • Resource management (if applicable)\n",
            "  • Exception handling (if applicable)\n",
            "\n",
            "## 4. *Implementation Example*\n",
            "  • Use case scenario\n",
            "  • Code implementation or technical design\n",
            "  • Step-by-step execution\n",
            "  • Output analysis\n",
            "\n",
            "## 5. *Best Practices*\n",
            "  • Design considerations\n",
            "  • Optimization techniques\n",
            "  • Common pitfalls\n",
            "  • Performance implications\n",
            "\n",
            "## 6. *Applications*\n",
            "  • Real-world use cases\n",
            "  • Industry applications\n",
            "  • Integration patterns\n",
            "  • Variations and alternatives\n",
            "\n",
            "## 7. *Evaluation*\n",
            "  • Performance metrics\n",
            "  • Testing approaches\n",
            "  • Debugging strategies\n",
            "  • Optimization opportunities\n",
            "\n",
            "## 8. *Practice Problems*\n",
            "  • Concept verification questions\n",
            "  • Implementation challenges\n",
            "  • Problem-solving scenarios\n",
            "  • Solutions with explanations\n",
            "\n",
            "### Format Requirements:\n",
            "- Always use \"##\" to introduce each section header. Avoid using any other format.\n",
            "- Use bullet points for clarity\n",
            "- Show all mathematical steps using proper equation formatting ($...$)\n",
            "- Include clear variable definitions after each equation\n",
            "- Write formulas using LaTeX formatting inside $...$\n",
            "- For matrices use: $\begin{bmatrix} a & b \\ c & d \\end{bmatrix}$\n",
            "- For fractions use: $\frac{numerator}{denominator}$\n",
            "- Use ■ for numbered equations and • for regular points\n",
            "- Demonstrate practical interpretation\n",
            "- Connect to real applications\n",
            "\n",
            "### Equation Guidelines:\n",
            "- Enclose equations in $...$ format\n",
            "- Use proper LaTeX notation for mathematical expressions\n",
            "- Use $\\sum$ for summations\n",
            "- Define each variable after presenting equations\n",
            "- Number important equations using ■\n",
            "- Show step-by-step derivations with clear explanations\n",
            "\n",
            "### Code Guidelines:\n",
            "- Use LaTeX verbatim environment for code blocks:\n",
            "  \begin{verbatim}\n",
            "  code here\n",
            "  \\end{verbatim}\n",
            "\n",
            "- For inline code use \texttt{code}\n",
            "- For syntax highlighting:\n",
            "  \begin{lstlisting}[language=Python]\n",
            "  code here\n",
            "  \\end{lstlisting}\n",
            "- Include comments explaining code functionality\n",
            "- Show output examples where applicable\n",
            "\n",
            "---\n",
            "\n",
            "## 1. **Concept Overview**\n",
            "\n",
            "### Core Definition and Purpose\n",
            "Long Short-Term Memory (LSTM) is a type of recurrent neural network (RNN) that addresses the vanishing gradient problem by introducing memory cells and gates to control the flow of information through the sequence. The primary purpose of LSTM is to learn long-term dependencies within sequential data, such as text, speech, music, and time series data.\n",
            "\n",
            "### Key Principles\n",
            "- Memory cells: Store information from previous timesteps, allowing LSTM to maintain relevant information over extended periods.\n",
            "- Input gate: Controls the flow of new information into the memory cell.\n",
            "- Forget gate: Determines what information should be discarded from the memory cell.\n",
            "- Output gate: Decides what information should be passed on to the next timestep.\n",
            "- Sigmoid activation function: Ensures the values of the gates are between 0 and 1, providing a mechanism for controlling the flow of information.\n",
            "\n",
            "### Relationship to Broader Computing Concepts\n",
            "LSTM is a specialized type of RNN that leverages the core principles of artificial neural networks (ANNs), including weight sharing, nonlinear activation functions, and backpropagation through time (BPTT). It extends these concepts to handle sequential data more effectively, addressing some of the limitations inherent in traditional RNNs.\n",
            "\n",
            "---\n",
            "\n",
            "## 2. **Technical Components**\n",
            "\n",
            "### Primary Elements and Their Roles\n",
            "- Memory cell: Stores information from previous timesteps.\n",
            "- Input gate: Controls the flow of new information into the memory cell.\n",
            "- Forget gate: Determines what information should be discarded from the memory cell.\n",
            "- Output gate: Decides what information should be passed on to the next timestep.\n",
            "- Tanh activation function: Used to normalize the input to the memory cell and the candidate cell.\n",
            "- Sigmoid activation function: Ensures the values of the gates are between 0 and 1, providing a mechanism for controlling the flow of information.\n",
            "\n",
            "### Relationships and Interactions\n",
            "The LSTM cell consists of three main components: the memory cell, the input gate, and the forget gate. Each component interacts with the others to determine the new content of the memory cell at each timestep. Additionally, there is an output gate that decides what information should be passed on to the next timestep.\n",
            "\n",
            "### Implementation Details\n",
            "Each LSTM cell has its own set of weights and biases, which are shared among the input gate, forget gate, memory cell, and output gate. During training, the weights and biases are adjusted using backpropagation through time (BPTT) to minimize the loss function.\n",
            "\n",
            "### Core Algorithms/Procedures\n",
            "At each timestep, the LSTM cell performs the following operations:\n",
            "1. Calculate the input gate vector using a sigmoid activation function applied to the weighted sum of the current input, the previous hidden state, and the bias term.\n",
            "2. Calculate the forget gate vector using a sigmoid activation function applied to the weighted sum of the current input, the previous hidden state, and the bias term.\n",
            "3. Calculate the candidate cell vector using the tanh activation function applied to the weighted sum of the current input, the previous hidden state, and the bias term.\n",
            "4. Update the memory cell by multiplying the forget gate vector with the previous memory cell, adding the input gate vector multiplied by the candidate cell, and passing the result through the output gate using a sigmoid activation function.\n",
            "5. Pass the updated memory cell through the tanh activation function to obtain the new candidate cell.\n",
            "6. Pass the output gate vector through a sigmoid activation function to obtain the output of the LSTM cell.\n",
            "\n",
            "---\n",
            "\n",
            "## 3. **Working Mechanism**\n",
            "\n",
            "### Step-by-Step Operational Flow\n",
            "1. At each timestep, the LSTM cell receives the current input vector xm.\n",
            "2. Calculate the input gate vector i\\_tmusing the weighted sum of xm, the previous hidden state h\\_(t-1), and the bias term b\\_i. Apply the sigmoid activation function to obtain the scaled values between 0 and 1.\n",
            "3. Calculate the forget gate vector f\\_tmusing the weighted sum of xm, the previous hidden state h\\_(t-1), and the bias term b\\_f. Apply the sigmoid activation function to obtain the scaled values between 0 and 1.\n",
            "4. Calculate the candidate cell vector c\\_tmusing the tanh activation function applied to the weighted sum of xm, the previous hidden state h\\_(t-1), and the bias term b\\_c.\n",
            "5. Update the memory cell using the input gate vector i\\_t, the forget gate vector f\\_t, and the candidate cell vector c\\_t. Multiply the forget gate vector f\\_t with the previous memory cell cm\\_(t-1), add the input gate vector i\\_t multiplied by the candidate cell vector c\\_t, and pass the result through the output gate using a sigmoid activation function.\n",
            "6. Pass the updated memory cell through the tanh activation function to obtain the new candidate cell.\n",
            "7. Pass the output gate vector o\\_t through a sigmoid activation function to obtain the output of the LSTM cell.\n",
            "\n",
            "### Critical Processes and Transformations\n",
            "The critical processes in the LSTM cell involve the interaction between the input gate, forget gate, and output gate. These gates control the flow of information into, out of, and within the memory cell, respectively. The tanh activation function is used to normalize the input to the memory cell and the candidate cell, ensuring that the resulting values lie within the range [-1, 1].\n",
            "\n",
            "### Resource Management (if applicable)\n",
            "The LSTM cell manages resources primarily by adjusting the weights and biases during training using backpropagation through time (BPTT). This allows the model to learn optimal values for each weight and bias, minimizing the loss function and improving the accuracy of the predictions.\n",
            "\n",
            "### Exception Handling (if applicable)\n",
            "No specific exception handling is required for the LSTM cell itself. However, during training, it is common to encounter issues such as exploding or vanishing gradients, which can be addressed using techniques like gradient clipping, learning rate decay, and regularization.\n",
            "\n",
            "---\n",
            "\n",
            "## 4. **Implementation Example**\n",
            "\n",
            "### Use Case Scenario\n",
            "For this example, we will implement an LSTM cell for language modeling, where the goal is to predict the next word in a given sequence of words.\n",
            "\n",
            "### Code Implementation or Technical Design\n",
            "Here's a simplified Python implementation of an LSTM cell using NumPy:\n",
            "\n",
            "```python\n",
            "import numpy as np\n",
            "\n",
            "class LSTMCell:\n",
            "    def __init__(self, input_size, hidden_size):\n",
            "        self.W_xi = np.random.rand(input_size + hidden_size, hidden_size)\n",
            "        self.W_hf = np.random.rand(input_size + hidden_size, hidden_size)\n",
            "        self.W_fc = np.random.rand(input_size + hidden_size, hidden_size)\n",
            "        self.W_oc = np.random.rand(hidden_size, hidden_size)\n",
            "        self.W_o = np.random.rand(hidden_size, 1)\n",
            "        self.b_i = np.zeros((1, hidden_size))\n",
            "        self.b_f = np.zeros((1, hidden_size))\n",
            "        self.b_c = np.zeros((1, hidden_size))\n",
            "        self.b_o = np.zeros((1, hidden_size))\n",
            "        self.b = np.zeros((1, 1))\n",
            "\n",
            "    def forward(self, x, h):\n",
            "        # Weighted sums for input gates, forget gates, and candidate cells\n",
            "        i = np.sigmoid(np.dot(self.W_xi, np.concatenate([x, h], axis=-1)) + self.b_i)\n",
            "        f = np.sigmoid(np.dot(self.W_hf, np.concatenate([x, h], axis=-1)) + self.b_f)\n",
            "        c = np.tanh(np.dot(self.W_fc, np.concatenate([x, h], axis=-1)) + self.b_c)\n",
            "\n",
            "        # Update memory cell\n",
            "        ic = i * c\n",
            "        fc = f * self.cm\n",
            "        new_c = ic + fc\n",
            "        new_c = np.tanh(new_c)\n",
            "\n",
            "        # Output gate\n",
            "        o = np.sigmoid(np.dot(self.W_oc, np.concatenate([x, new_c], axis=-1)) + self.b_o)\n",
            "\n",
            "        # Output of the LSTM cell\n",
            "        self.output = o * np.tanh(new_c)\n",
            "        self.cm = new_c\n",
            "\n",
            "# Initialize the LSTM cell\n",
            "lstm = LSTMCell(input_size=10, hidden_size=5)\n",
            "\n",
            "# Set up some random input and hidden states\n",
            "x = np.random.rand(10, 10)\n",
            "h = np.random.rand(1, 5)\n",
            "\n",
            "# Run the LSTM cell forward\n",
            "lstm.forward(x, h)\n",
            "```\n",
            "\n",
            "### Step-by-Step Execution\n",
            "1. Instantiate the LSTM cell with the desired input size and hidden size.\n",
            "2. Set up some random input and hidden states.\n",
            "3. Call the `forward()` method on the LSTM cell, passing in the input and hidden states.\n",
            "4. The LSTM cell calculates the input gate, forget gate, and candidate cell vectors, updates the memory cell, and computes the output of the LSTM cell.\n",
            "\n",
            "### Output Analysis\n",
            "After running the LSTM cell, you can access the output of the LSTM cell using the `output` attribute and the updated memory cell using the `cm` attribute.\n",
            "\n",
            "---\n",
            "\n",
            "## 5. **Best Practices**\n",
            "\n",
            "### Design Considerations\n",
            "- Choose appropriate input and hidden sizes based on the complexity of the task and the available data.\n",
            "- Use dropout during training to prevent overfitting.\n",
            "- Consider using multiple layers of LSTM cells to capture deeper dependencies.\n",
            "\n",
            "### Optimization Techniques\n",
            "- Use gradient clipping to prevent exploding or vanishing gradients.\n",
            "- Adjust the learning rate during training to improve convergence.\n",
            "- Experiment with different optimization algorithms, such as Adam or RMSProp.\n",
            "\n",
            "### Common Pitfalls\n",
            "- Failing to properly initialize the weights and biases can lead to poor performance.\n",
            "- Using too small or too large learning rates can cause slow convergence or oscillation.\n",
            "- Ignoring regularization techniques can lead to overfitting.\n",
            "\n",
            "### Performance Implications\n",
            "Optimal performance depends on finding the right balance between the input size, hidden size, number of layers, learning rate, and regularization strength. A well-tuned LSTM model can achieve impressive results on various sequential data tasks.\n",
            "\n",
            "---\n",
            "\n",
            "## 6. **Applications**\n",
            "\n",
            "### Real-World Use Cases\n",
            "- Language modeling: Predicting the next word in a given sequence of words.\n",
            "- Text generation: Creating coherent and meaningful sentences or paragraphs.\n",
            "- Speech recognition: Transcribing spoken language into written text.\n",
            "- Music composition: Generating melodies or harmonies based on given input.\n",
            "- Time series forecasting: Predicting future values based on historical data.\n",
            "\n",
            "### Industry Applications\n",
            "- Natural Language Processing (NLP): Improving chatbots, virtual assistants, and machine translation systems.\n",
            "- Finance: Analyzing financial trends and making predictions about stock prices.\n",
            "- Healthcare: Monitoring patient health data and predicting disease outbreaks.\n",
            "\n",
            "### Integration Patterns\n",
            "LSTMs can be integrated into deep learning frameworks such as TensorFlow, PyTorch, and MXNet. They can also be combined with other neural network architectures, such as convolutional neural networks (CNNs) or transformers, to create more powerful models.\n",
            "\n",
            "### Variations and Alternatives\n",
            "- Gated Recurrent Units (GRUs): Simplified version of LSTMs that combines the input and forget gates.\n",
            "- Echo State Networks (ESNs): Randomly connected recurrent neural networks with a sparsely connected reservoir.\n",
            "- Long Short-Term Memory Convolutional Networks (LSTM-CNNs): Combination of LSTMs and CNNs for image and video analysis.\n",
            "\n",
            "---\n",
            "\n",
            "## 7. **Evaluation**\n",
            "\n",
            "### Performance Metrics\n",
            "- Accuracy: Percentage of correct predictions compared to the actual values.\n",
            "- Loss: Measure of the difference between predicted and actual values.\n",
            "- Perplexity: Measure of the expected number of tokens needed to generate a sample, lower values indicate better performance.\n",
            "\n",
            "### Testing Approaches\n",
            "- Cross-validation: Split the dataset into training, validation, and test sets to evaluate the model's generalization capabilities.\n",
            "- Hyperparameter tuning: Experiment with different hyperparameters to find the best configuration for the model.\n",
            "\n",
            "### Debugging Strategies\n",
            "- Visualize the internal workings of the LSTM cell, such as the memory cell contents or attention weights, to gain insights into the model's behavior.\n",
            "- Use tools like TensorBoard or PyTorch's built-in visualization tools to monitor the training progress and identify potential issues.\n",
            "\n",
            "### Optimization Opportunities\n",
            "- Increase the dataset size to improve the model's ability to learn complex patterns.\n",
            "- Experiment with different architectures, such as combining LSTMs with CNNs or transformers, to capture more diverse dependencies.\n",
            "- Investigate advanced techniques like attention mechanisms or reinforcement learning to further enhance the model's performance.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clean the answer from api response"
      ],
      "metadata": {
        "id": "GqWZo8EbRSmf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Answer:\", answer)"
      ],
      "metadata": {
        "id": "n-1etPIcHaMC",
        "outputId": "5ed3e19c-8e4c-4b4a-985e-00d1e286d9fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: Context: BIBLIOGRAPHY  Graves, . . Sequence transduction  recurrent neural networks.   . Graves, .  . Jaitly . Towards  speech recognition  recurrent neural networks.   , . . Graves, .  . Schmidhuber . Framewise phoneme classiﬁcation  bidirec tional   other neural network architectures. Neural Networks  , .\n",
            "\n",
            "  vector hmthis information  represented.   limitation   informa   attenuated  repeated application   squashing function . short memories LSTMs, described below,   variant    address  issue,   memory cells  propagate information through  sequence without applying  linearities Hochreiter  Schmidhuber, .  denominator  Equation .   computational bottleneck, because  involves\n",
            "\n",
            "Recurrent neural networks   introduced     language model  technique,  which  context  token  summarized   recurrentlyupdated vector, ,,   ,,..., wherexmis  vector embedding   token wmand  function gdeﬁnes  recur rence.  starting condition   additional parameter   model.   short  memory     complex recurrence,  which  memory   through \n",
            "\n",
            " . LANGUAGE MODELS              Figure .   short memory  architecture. Gates  shown  boxes  dotted edges.    language model,  hmwould    predict   wordwm.  gates  functions   input  previous hidden state.   computed  elementwise sigmoid activations,   , ensuring  their values\n",
            "\n",
            "BIBLIOGRAPHY  , .  . Bansal .  relation extraction using lstms  sequences   structures.   , . . , .  . Hinton . Three  graphical models  statistical language  elling.  Proceedings   International Conference  Machine Learning  , .  . , .  . . Hinton .  scalable hierarchical distributed language model.  Neural Information Processing Systems  , . .\n",
            "\n",
            "sentations  vector space.  Proceedings  International Conference  Learning Represen tations . Mikolov, ., . Deoras, . Povey, . Burget,  . Cernocky . Strategies  training large scale neural network language models.  Proceedings   Workshop  Automatic Speech Recognition  Understanding  , . . Mikolov, ., . Karaﬁ , . Burget, . Cernock ,  . Khudanpur . Recurrent neural network based language model.  INTERSPEECH , . .\n",
            "\n",
            ".. Convolutional Neural Networks  Sequence Labeling  disadvantage  recurrent neural networks    architecture requires iterating through  sequence  inputs  predictions  hidden vector hmmust   puted   previous hidden vector , before predicting   . These iterative computations  difﬁcult  parallelize,    exploit  speedups offered  graph  processing units   operations   matrix multiplication. Convolutional\n",
            "\n",
            " baseline   implemented   neural architecture, using  attention  anism .., which scores  similarity   query      source    ., .      encode  passage   query , using  bidirectional LSTMs  .. BiLSTM   . BiLSTM  . .  query  represented  vertically concatenating   states   right  right passes \n",
            "\n",
            ".. RECURRENT NEURAL NETWORK LANGUAGE MODELS  derivatives automatically,  cache   future .  important distinction   feedforward neural networks considered         computa  graph   ,  varies   length   input.  poses difﬁculties  toolkits   designed around static computation graphs,   TensorFlow Abadi  ., . .. Hyperparameters\n",
            "\n",
            " incorporating  inner product   approximation   likelihood    ,   possible  estimate  parameters  backpropagation.   Mikolov  .,  includes   approximations continuous words   skipgrams. .. Continuous words   recurrent neural network language models,    conditioned   recurrently updated state vector, which  based   representations going      \n",
            "\n",
            ".. RECURRENT NEURAL NETWORK LANGUAGE MODELS    sequence.  language models  deﬁned,  .  , . ,,...,  , . whereφis  matrix   embeddings , andxmdenotes  embedding   .  conversion  wmtoxmis sometimes known   lookup layer , because  simply lookup  embeddings      table  ...  Elman  deﬁnes  simple recurrent operation Elman, ,\n",
            "\n",
            "whereδ   indicator function, taking  value      record   identical   target  .  probability  copying record rfrom  source ,  product    probability   local attention.     model,  attention weights αmare computed   previous decoder state .  computation graph therefore remains  feedforward network,  recurrent paths      .\n",
            "\n",
            " operator  elementwise Hadamard product.    controlled      weights, which parametrize  previous hidden state ..,    current input .., ,   vector offset .., .  overall operation   infor mally summarized  ,   ,,,  ,representing   state after reading token .   outperforms standard recurrent neural networks across   range \n",
            "\n",
            " . APPLICATIONS  SEQUENCE LABELING   predict labels      ONSTART   character.  recent   employed neural network architectures.  example,   .      architecture,  described  .  construct  trellis,  which    scored according   hidden state   ,   transitions  scored according  learned transition weights.  scoring segmentation   computed  \n",
            "\n",
            "beginning   source   greatest impact   encoding ,  therefore impact  words   beginning   target sentence. Later     vanced encoding models,   neural attention ..,  eliminated    reversing  source sentence.  encoder  decoder   implemented   LSTMs ,  multiple layers  hidden states.  shown  Figure .,  hidden state ,  layeriis treated\n",
            "\n",
            "epochs batches   sentences, chosen   similar length    sentence   batch   roughly   amount    process gradi  clipping ..  ensure      gradient never exceeds  predeﬁned value. .. Neural attention  sequencesequence model discussed   previous section   radical depar   statistical machine translation,  which    phrase   target \n",
            "\n",
            "brenner  Blunsom     . ,  strong empirical results.  models  recurrent   utterance level,    complete utterance updates  hidden state.  recurrentconvolutional network  Kalchbrenner  Blunsom   convolu   obtain  representation   individual utterance, while   .    second level  recurrence,  individual words.  enables their method   \n",
            "\n",
            ".. NEURAL SEQUENCE LABELING   practice, numerical stability demands       domain, logαm    logsm,  logαm . logβm    logsm,  logβm . .  application   forward  backward probabilities  shown  Figure ..   forward  backward recurrences operate   trellis, which implies  space complexityO. Because  recurrences require computing    Kterms \n",
            "\n",
            "tentional encoderdecoder translation model discussed  ..   ., .  longer sentence  encoded   sequence  vectors,    token.  decoder  computes attention  these vectors  updating   recurrent state.    generation,    useful  augment  encoderdecoder model   ability   words directly   source.   .  train  model \n",
            "\n",
            " Morphology  Syntax , Volume   Synthesis Lectures  Human Language Technolo . Morgan  Claypool Publishers. Bengio, ., . Vinyals, . Jaitly,  . Shazeer . Scheduled sampling  sequence prediction  recurrent neural networks.   , . . Bengio, ., . Ducharme,  . Vincent,  . Janvin .  neural probabilistic language model.  Journal  Machine Learning Research  , .\n",
            "Question: Lstm\n",
            "\n",
            "Provide a comprehensive explanation strictly following this structure. Always use \"##\" to introduce each section:\n",
            "\n",
            "## 1. *Concept Overview*\n",
            "  • Core definition and purpose\n",
            "  • Key principles\n",
            "  • Relationship to broader computing concepts\n",
            "\n",
            "## 2. *Technical Components*\n",
            "  • Primary elements and their roles\n",
            "  • Relationships and interactions\n",
            "  • Implementation details\n",
            "  • Core algorithms/procedures (if applicable)\n",
            "\n",
            "## 3. *Working Mechanism*\n",
            "  • Step-by-step operational flow\n",
            "  • Critical processes and transformations\n",
            "  • Resource management (if applicable)\n",
            "  • Exception handling (if applicable)\n",
            "\n",
            "## 4. *Implementation Example*\n",
            "  • Use case scenario\n",
            "  • Code implementation or technical design\n",
            "  • Step-by-step execution\n",
            "  • Output analysis\n",
            "\n",
            "## 5. *Best Practices*\n",
            "  • Design considerations\n",
            "  • Optimization techniques\n",
            "  • Common pitfalls\n",
            "  • Performance implications\n",
            "\n",
            "## 6. *Applications*\n",
            "  • Real-world use cases\n",
            "  • Industry applications\n",
            "  • Integration patterns\n",
            "  • Variations and alternatives\n",
            "\n",
            "## 7. *Evaluation*\n",
            "  • Performance metrics\n",
            "  • Testing approaches\n",
            "  • Debugging strategies\n",
            "  • Optimization opportunities\n",
            "\n",
            "## 8. *Practice Problems*\n",
            "  • Concept verification questions\n",
            "  • Implementation challenges\n",
            "  • Problem-solving scenarios\n",
            "  • Solutions with explanations\n",
            "\n",
            "### Format Requirements:\n",
            "- Always use \"##\" to introduce each section header. Avoid using any other format.\n",
            "- Use bullet points for clarity\n",
            "- Show all mathematical steps using proper equation formatting ($...$)\n",
            "- Include clear variable definitions after each equation\n",
            "- Write formulas using LaTeX formatting inside $...$\n",
            "- For matrices use: $\begin{bmatrix} a & b \\ c & d \\end{bmatrix}$\n",
            "- For fractions use: $\frac{numerator}{denominator}$\n",
            "- Use ■ for numbered equations and • for regular points\n",
            "- Demonstrate practical interpretation\n",
            "- Connect to real applications\n",
            "\n",
            "### Equation Guidelines:\n",
            "- Enclose equations in $...$ format\n",
            "- Use proper LaTeX notation for mathematical expressions\n",
            "- Use $\\sum$ for summations\n",
            "- Define each variable after presenting equations\n",
            "- Number important equations using ■\n",
            "- Show step-by-step derivations with clear explanations\n",
            "\n",
            "### Code Guidelines:\n",
            "- Use LaTeX verbatim environment for code blocks:\n",
            "  \begin{verbatim}\n",
            "  code here\n",
            "  \\end{verbatim}\n",
            "\n",
            "- For inline code use \texttt{code}\n",
            "- For syntax highlighting:\n",
            "  \begin{lstlisting}[language=Python]\n",
            "  code here\n",
            "  \\end{lstlisting}\n",
            "- Include comments explaining code functionality\n",
            "- Show output examples where applicable\n",
            "\n",
            "## 1. *Concept Overview*\n",
            "  • **Core definition and purpose**: Long Short-Term Memory (LSTM) is a type of recurrent neural network (RNN) that addresses the vanishing gradient problem by introducing memory cells, allowing it to learn long-term dependencies in sequential data. The primary purpose of LSTM is to model and generate sequences, such as text, music, and speech, by capturing the temporal relationships between elements in the sequence.\n",
            "\n",
            "  • **Key principles**: LSTM introduces three types of gates—the forget gate, the input gate, and the output gate—that control the flow of information into and out of memory cells. These gates are responsible for deciding what information to retain, update, and discard during the processing of a sequence. Additionally, LSTM uses a cell state, which acts as a temporary storage unit for information, allowing it to maintain relevant information over time.\n",
            "\n",
            "  • **Relationship to broader computing concepts**: LSTM is closely related to other RNN architectures, such as Elman networks and simple RNNs, but offers improved performance due to its ability to handle long-term dependencies more effectively. LSTM shares many similarities with traditional computer memory systems, as both store and retrieve information based on specific addressing mechanisms. However, unlike traditional memory systems, LSTM does not have a fixed size and can dynamically adjust its memory capacity depending on the sequence length.\n",
            "\n",
            "## 2. *Technical Components*\n",
            "  • **Primary elements and their roles**: The main components of an LSTM include the forget gate, input gate, output gate, and cell state. Each component plays a crucial role in managing the flow of information within the network.\n",
            "\n",
            "  - **Forget Gate**: Determines which information from the previous cell state should be forgotten. It takes the previous cell state and the current input as inputs and produces a weighted sum that represents the importance of each piece of information.\n",
            "\n",
            "  - **Input Gate**: Decides which new information should be written into the cell state. It also takes the previous cell state and the current input as inputs and produces a weighted sum that represents the importance of each piece of information to be added to the cell state.\n",
            "\n",
            "  - **Output Gate**: Controls the flow of information from the cell state to the hidden state. It takes the current cell state and the current input as inputs and produces a weighted sum that represents the importance of each piece of information to be passed to the hidden state.\n",
            "\n",
            "  - **Cell State**: Temporarily stores information throughout the processing of a sequence. It is updated based on the decisions made by the forget gate, input gate, and output gate.\n",
            "\n",
            "  • **Relationships and interactions**: The interactions between the components of an LSTM occur during the forward pass, where the current hidden state is calculated based on the previous hidden state, the current input, and the outputs of the forget gate, input gate, and output gate. The cell state is updated based on the decisions made by the forget gate and input gate, while the hidden state is determined by the output gate and the updated cell state.\n",
            "\n",
            "  • **Implementation details**: LSTMs are typically implemented using software libraries such as TensorFlow, PyTorch, or Keras. These libraries provide pre-built LSTM modules that can be easily integrated into deep learning models. During training, the model learns the weights associated with each component, allowing it to make informed decisions about the flow of information.\n",
            "\n",
            "  • **Core algorithms/procedures**: The core algorithm used in LSTM is the forward pass, which calculates the current hidden state based on the previous hidden state, the current input, and the outputs of the forget gate, input gate, and output gate. The backward pass, on the other hand, computes the gradients required for backpropagation, enabling the model to adjust its weights during training.\n",
            "\n",
            "## 3. *Working Mechanism*\n",
            "  • **Step-by-step operational flow**: During the forward pass, the LSTM first calculates the forget gate, input gate, and output gate activations using sigmoid functions. Then, it calculates the candidate cell state and the new cell state using tanh functions. Finally, it updates the cell state and calculates the hidden state using the output gate activation.\n",
            "\n",
            "  - **Forget Gate**: Calculates the weighted sum of the previous cell state and the current input, passing them through a sigmoid function to produce a value between 0 and 1. This value determines how much of the previous cell state should be forgotten.\n",
            "\n",
            "  - **Input Gate**: Calculates the weighted sum of the previous cell state, the current input, and a bias term, passing them through a sigmoid function to produce a value between 0 and 1. This value determines how much new information should be written into the cell state.\n",
            "\n",
            "  - **Candidate Cell State**: Calculates the weighted sum of the previous cell state, the current input, and a bias term, passing them through a tanh function to produce a value between -1 and 1. This value represents the potential new cell state.\n",
            "\n",
            "  - **New Cell State**: Calculates the product of the input gate activation and the candidate cell state, then adds the result to the forget gate's output multiplied by the previous cell state. This calculation determines the final cell state update.\n",
            "\n",
            "  - **Hidden State**: Calculates the output gate activation, then passes the new cell state through a sigmoid function to determine which parts of the new cell state should be passed to the hidden state. Finally, it passes the remaining parts of the new cell state through a tanh function to normalize the hidden state values.\n",
            "\n",
            "  • **Critical processes and transformations**: The critical processes in an LSTM involve determining which information to forget, write, and retain, as well as updating the cell state and hidden state based on these decisions. The transformations performed by the LSTM include weighted sums, sigmoid and tanh activations, and multiplications.\n",
            "\n",
            "  • **Resource management**: LSTMs do not require explicit resource management, as they are typically implemented within deep learning frameworks that handle resource allocation. However, during training, the model may require significant computational resources, particularly when dealing with long sequences or large datasets.\n",
            "\n",
            "  • **Exception handling**: LSTMs do not explicitly handle exceptions, as they are primarily focused on processing sequential data. However, during training, common exceptions such as NaN (Not-a-Number) errors may occur due to numerical instability or incorrect initialization of weights. These exceptions can be handled using techniques such as gradient clipping or weight initialization schemes that minimize the occurrence of NaNs.\n",
            "\n",
            "## 4. *Implementation Example*\n",
            "  • **Use case scenario**: An example use case for LSTMs is language modeling, where the goal is to predict the next word in a sentence given the preceding words. In this scenario, an LSTM is trained on a large corpus of text, learning the probabilities of each word given the previous words in the sequence.\n",
            "\n",
            "  • **Code implementation or technical design**: Here is an example implementation of an LSTM language model using Python and TensorFlow:\n",
            "\n",
            "  \begin{verbatim}\n",
            "  import tensorflow as tf\n",
            "\n",
            "  # Define the LSTM cell\n",
            "  lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units=128)\n",
            "\n",
            "  # Define the input placeholders\n",
            "  inputs = tf.placeholder(tf.int32, shape=[None, None])\n",
            "  targets = tf.placeholder(tf.int32, shape=[None])\n",
            "\n",
            "  # Define the embedding layer\n",
            "  embedding = tf.Variable(tf.random_uniform([vocab_size, num_units], minval=-1.0, maxval=1.0))\n",
            "  embedded_inputs = tf.nn.embedding_lookup(embedding, inputs)\n",
            "\n",
            "  # Initialize the initial hidden state\n",
            "  hidden_state = tf.zeros([batch_size, num_units])\n",
            "\n",
            "  # Perform the forward pass through the LSTM\n",
            "  outputs, _ = tf.nn.dynamic_rnn(lstm_cell, embedded_inputs, initial_state=hidden_state)\n",
            "\n",
            "  # Extract the last hidden state as the final representation\n",
            "  final_hidden_state = outputs[:, -1, :]\n",
            "\n",
            "  # Define the loss function (e.g., cross-entropy loss)\n",
            "  loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels=targets, logits=final_hidden_state))\n",
            "\n",
            "  # Define the optimizer (e.g., Adam optimizer)\n",
            "  optimizer = tf.train.AdamOptimizer()\n",
            "\n",
            "  # Train the model\n",
            "  with tf.Session() as sess:\n",
            "      sess.run(tf.global_variables_initializer())\n",
            "      for epoch in range(num_epochs):\n",
            "          for batch_index in range(num_batches):\n",
            "              batch_inputs, batch_targets = get_next_batch(batch_size)\n",
            "              _, loss_value = sess.run([optimizer, loss], feed_dict={inputs: batch_inputs, targets: batch_targets})\n",
            "              if batch_index % display_steps == 0:\n",
            "                  print(\"Epoch:\", epoch + 1, \", Loss:\", loss_value)\n",
            "   \\end{verbatim}\n",
            "\n",
            "  • **Step-by-step execution**: The code above defines an LSTM language model, initializes the necessary variables, performs the forward pass through the LSTM, calculates the loss, and trains the model using the Adam optimizer. During training, the model iterates over batches of data, updating its weights to minimize the loss.\n",
            "\n",
            "  • **Output analysis**: The output of the model is the predicted probability distribution over the vocabulary for each input sequence. The predicted word with the highest probability is selected as the output.\n",
            "\n",
            "## 5. *Best Practices*\n",
            "  • **Design considerations**: When designing an LSTM model, consider the sequence length, the number of layers, the number of hidden units, and the choice of activation functions. Experiment with different hyperparameter settings to find the optimal configuration for your specific task.\n",
            "\n",
            "  • **Optimization techniques**: To improve the performance of your LSTM model, consider using techniques such as dropout, batch normalization, and gradient clipping. These techniques help prevent overfitting and improve the model's generalization capabilities.\n",
            "\n",
            "  • **Common pitfalls**: One common pitfall when working with LSTMs is the vanishing or exploding gradient problem. This can be addressed by using techniques such as gradient clipping, weight initialization schemes, and normalizing the inputs. Another pitfall is choosing an inappropriate sequence length, leading to poor performance.\n",
            "\n",
            "  • **Performance implications**: The performance of an LSTM model depends on various factors, including the quality and quantity of the training data, the choice of hyperparameters, and the complexity of the task at hand. A well-designed and properly trained LSTM model can achieve state-of-the-art results on a wide range of sequential data tasks.\n",
            "\n",
            "## 6. *Applications*\n",
            "  • **Real-world use cases**: LSTMs have been successfully applied to various real-world problems, including natural language processing (such as language modeling, machine translation, and sentiment analysis), speech recognition, music generation, and video analysis.\n",
            "\n",
            "  • **Industry applications**: LSTMs are widely used in industries such as artificial intelligence, robotics, and autonomous vehicles for tasks like speech recognition, natural language understanding, and decision making. They are also used in entertainment industries for music composition and video game development.\n",
            "\n",
            "  • **Integration patterns**: LSTMs can be integrated into deep learning pipelines alongside other neural network layers, such as convolutional neural networks (CNNs) and fully connected layers. They can also be combined with attention mechanisms to further improve their performance on sequential data tasks.\n",
            "\n",
            "  • **Variations and alternatives**: There are several variations of LSTMs, such as GRUs (Gated Recurrent Units) and ESNs (Echo State Networks). These variants offer different trade-offs in terms of computational efficiency, memory requirements, and performance.\n",
            "\n",
            "## 7. *Evaluation*\n",
            "  • **Performance metrics**: Common performance metrics for evaluating LSTM models include accuracy, perplexity, and F1 score. Accuracy measures the proportion of correct predictions, while perplexity quantifies the average number of possible outcomes for a given prediction. The F1 score combines precision and recall to evaluate the model's overall performance.\n",
            "\n",
            "  • **Testing approaches**: To test an LSTM model, divide the available data into training, validation, and testing sets. Train the model on the training set, tune the hyperparameters on the validation set, and evaluate the model's performance on the testing set.\n",
            "\n",
            "  • **Debugging strategies**: When debugging an LSTM model, start by checking the model's architecture, hyperparameters, and training procedure for any inconsistencies. Visualize the learned weights and activations to gain insights into the model's behavior. If necessary, collect more data or adjust the data preprocessing steps.\n",
            "\n",
            "  • **Optimization opportunities**: To further optimize an LSTM model, experiment with different optimization algorithms, learning rates, and regularization techniques. Consider using techniques such as transfer learning or ensemble methods to leverage pre-trained models or combine multiple models for improved performance.\n",
            "\n",
            "## 8. *Practice Problems*\n",
            "  • **Concept verification questions**:\n",
            "    1. What is the primary difference between LSTMs and traditional RNNs?\n",
            "    2. How does the forget gate in an LSTM decide which information to forget?\n",
            "    3. What is the role of the cell state in an LSTM?\n",
            "    4. Why are LSTMs useful for handling long-term dependencies in sequential data?\n",
            "    5. What is the purpose of the output gate in an LSTM?\n",
            "\n",
            "  • **Implementation challenges**:\n",
            "    1. Implement an LSTM language model from scratch using numpy and backpropagation.\n",
            "    2. Extend the LSTM language model to handle character-level language modeling.\n",
            "    3. Modify the LSTM language model to incorporate attention mechanisms.\n",
            "    4. Train an LSTM model on a custom dataset (e.g., movie reviews or news articles) and compare its performance to a baseline model.\n",
            "\n",
            "  • **Problem-solving scenarios**:\n",
            "    1. A researcher is training an LSTM model for machine translation but observes that the model often generates nonsensical translations. Investigate possible causes and propose solutions.\n",
            "    2. A developer is working on a speech recognition system using LSTMs but finds that the model struggles with long audio clips. Suggest improvements to address this issue.\n",
            "    3. A data scientist is working on a sentiment analysis project using LSTMs but notices that the model's performance drops significantly when dealing with negative sentiments. Explain why this might happen and suggest ways to improve the model's performance.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_answer(text):\n",
        "   \"\"\"Extract the answer, removing everything before 'Show output examples where applicable'\"\"\"\n",
        "   # Find the index of the end section\n",
        "   start_index = text.find(\"Show output examples where applicable\")\n",
        "\n",
        "   if start_index == -1:\n",
        "       return text.strip()\n",
        "\n",
        "   return text[start_index + len(\"Show output examples where applicable\"):].strip()\n",
        "\n",
        "# Usage\n",
        "clean_answer = extract_answer(answer)\n",
        "print(clean_answer)"
      ],
      "metadata": {
        "id": "LLopdHdAHPz4",
        "outputId": "bff2a3c7-0bb0-45f7-e246-d5f10385b675",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---\n",
            "\n",
            "## 1. **Concept Overview**\n",
            "\n",
            "### Core Definition and Purpose\n",
            "Long Short-Term Memory (LSTM) is a type of recurrent neural network (RNN) that addresses the vanishing gradient problem by introducing memory cells and gates to control the flow of information through the sequence. The primary purpose of LSTM is to learn long-term dependencies within sequential data, such as text, speech, music, and time series data.\n",
            "\n",
            "### Key Principles\n",
            "- Memory cells: Store information from previous timesteps, allowing LSTM to maintain relevant information over extended periods.\n",
            "- Input gate: Controls the flow of new information into the memory cell.\n",
            "- Forget gate: Determines what information should be discarded from the memory cell.\n",
            "- Output gate: Decides what information should be passed on to the next timestep.\n",
            "- Sigmoid activation function: Ensures the values of the gates are between 0 and 1, providing a mechanism for controlling the flow of information.\n",
            "\n",
            "### Relationship to Broader Computing Concepts\n",
            "LSTM is a specialized type of RNN that leverages the core principles of artificial neural networks (ANNs), including weight sharing, nonlinear activation functions, and backpropagation through time (BPTT). It extends these concepts to handle sequential data more effectively, addressing some of the limitations inherent in traditional RNNs.\n",
            "\n",
            "---\n",
            "\n",
            "## 2. **Technical Components**\n",
            "\n",
            "### Primary Elements and Their Roles\n",
            "- Memory cell: Stores information from previous timesteps.\n",
            "- Input gate: Controls the flow of new information into the memory cell.\n",
            "- Forget gate: Determines what information should be discarded from the memory cell.\n",
            "- Output gate: Decides what information should be passed on to the next timestep.\n",
            "- Tanh activation function: Used to normalize the input to the memory cell and the candidate cell.\n",
            "- Sigmoid activation function: Ensures the values of the gates are between 0 and 1, providing a mechanism for controlling the flow of information.\n",
            "\n",
            "### Relationships and Interactions\n",
            "The LSTM cell consists of three main components: the memory cell, the input gate, and the forget gate. Each component interacts with the others to determine the new content of the memory cell at each timestep. Additionally, there is an output gate that decides what information should be passed on to the next timestep.\n",
            "\n",
            "### Implementation Details\n",
            "Each LSTM cell has its own set of weights and biases, which are shared among the input gate, forget gate, memory cell, and output gate. During training, the weights and biases are adjusted using backpropagation through time (BPTT) to minimize the loss function.\n",
            "\n",
            "### Core Algorithms/Procedures\n",
            "At each timestep, the LSTM cell performs the following operations:\n",
            "1. Calculate the input gate vector using a sigmoid activation function applied to the weighted sum of the current input, the previous hidden state, and the bias term.\n",
            "2. Calculate the forget gate vector using a sigmoid activation function applied to the weighted sum of the current input, the previous hidden state, and the bias term.\n",
            "3. Calculate the candidate cell vector using the tanh activation function applied to the weighted sum of the current input, the previous hidden state, and the bias term.\n",
            "4. Update the memory cell by multiplying the forget gate vector with the previous memory cell, adding the input gate vector multiplied by the candidate cell, and passing the result through the output gate using a sigmoid activation function.\n",
            "5. Pass the updated memory cell through the tanh activation function to obtain the new candidate cell.\n",
            "6. Pass the output gate vector through a sigmoid activation function to obtain the output of the LSTM cell.\n",
            "\n",
            "---\n",
            "\n",
            "## 3. **Working Mechanism**\n",
            "\n",
            "### Step-by-Step Operational Flow\n",
            "1. At each timestep, the LSTM cell receives the current input vector xm.\n",
            "2. Calculate the input gate vector i\\_tmusing the weighted sum of xm, the previous hidden state h\\_(t-1), and the bias term b\\_i. Apply the sigmoid activation function to obtain the scaled values between 0 and 1.\n",
            "3. Calculate the forget gate vector f\\_tmusing the weighted sum of xm, the previous hidden state h\\_(t-1), and the bias term b\\_f. Apply the sigmoid activation function to obtain the scaled values between 0 and 1.\n",
            "4. Calculate the candidate cell vector c\\_tmusing the tanh activation function applied to the weighted sum of xm, the previous hidden state h\\_(t-1), and the bias term b\\_c.\n",
            "5. Update the memory cell using the input gate vector i\\_t, the forget gate vector f\\_t, and the candidate cell vector c\\_t. Multiply the forget gate vector f\\_t with the previous memory cell cm\\_(t-1), add the input gate vector i\\_t multiplied by the candidate cell vector c\\_t, and pass the result through the output gate using a sigmoid activation function.\n",
            "6. Pass the updated memory cell through the tanh activation function to obtain the new candidate cell.\n",
            "7. Pass the output gate vector o\\_t through a sigmoid activation function to obtain the output of the LSTM cell.\n",
            "\n",
            "### Critical Processes and Transformations\n",
            "The critical processes in the LSTM cell involve the interaction between the input gate, forget gate, and output gate. These gates control the flow of information into, out of, and within the memory cell, respectively. The tanh activation function is used to normalize the input to the memory cell and the candidate cell, ensuring that the resulting values lie within the range [-1, 1].\n",
            "\n",
            "### Resource Management (if applicable)\n",
            "The LSTM cell manages resources primarily by adjusting the weights and biases during training using backpropagation through time (BPTT). This allows the model to learn optimal values for each weight and bias, minimizing the loss function and improving the accuracy of the predictions.\n",
            "\n",
            "### Exception Handling (if applicable)\n",
            "No specific exception handling is required for the LSTM cell itself. However, during training, it is common to encounter issues such as exploding or vanishing gradients, which can be addressed using techniques like gradient clipping, learning rate decay, and regularization.\n",
            "\n",
            "---\n",
            "\n",
            "## 4. **Implementation Example**\n",
            "\n",
            "### Use Case Scenario\n",
            "For this example, we will implement an LSTM cell for language modeling, where the goal is to predict the next word in a given sequence of words.\n",
            "\n",
            "### Code Implementation or Technical Design\n",
            "Here's a simplified Python implementation of an LSTM cell using NumPy:\n",
            "\n",
            "```python\n",
            "import numpy as np\n",
            "\n",
            "class LSTMCell:\n",
            "    def __init__(self, input_size, hidden_size):\n",
            "        self.W_xi = np.random.rand(input_size + hidden_size, hidden_size)\n",
            "        self.W_hf = np.random.rand(input_size + hidden_size, hidden_size)\n",
            "        self.W_fc = np.random.rand(input_size + hidden_size, hidden_size)\n",
            "        self.W_oc = np.random.rand(hidden_size, hidden_size)\n",
            "        self.W_o = np.random.rand(hidden_size, 1)\n",
            "        self.b_i = np.zeros((1, hidden_size))\n",
            "        self.b_f = np.zeros((1, hidden_size))\n",
            "        self.b_c = np.zeros((1, hidden_size))\n",
            "        self.b_o = np.zeros((1, hidden_size))\n",
            "        self.b = np.zeros((1, 1))\n",
            "\n",
            "    def forward(self, x, h):\n",
            "        # Weighted sums for input gates, forget gates, and candidate cells\n",
            "        i = np.sigmoid(np.dot(self.W_xi, np.concatenate([x, h], axis=-1)) + self.b_i)\n",
            "        f = np.sigmoid(np.dot(self.W_hf, np.concatenate([x, h], axis=-1)) + self.b_f)\n",
            "        c = np.tanh(np.dot(self.W_fc, np.concatenate([x, h], axis=-1)) + self.b_c)\n",
            "\n",
            "        # Update memory cell\n",
            "        ic = i * c\n",
            "        fc = f * self.cm\n",
            "        new_c = ic + fc\n",
            "        new_c = np.tanh(new_c)\n",
            "\n",
            "        # Output gate\n",
            "        o = np.sigmoid(np.dot(self.W_oc, np.concatenate([x, new_c], axis=-1)) + self.b_o)\n",
            "\n",
            "        # Output of the LSTM cell\n",
            "        self.output = o * np.tanh(new_c)\n",
            "        self.cm = new_c\n",
            "\n",
            "# Initialize the LSTM cell\n",
            "lstm = LSTMCell(input_size=10, hidden_size=5)\n",
            "\n",
            "# Set up some random input and hidden states\n",
            "x = np.random.rand(10, 10)\n",
            "h = np.random.rand(1, 5)\n",
            "\n",
            "# Run the LSTM cell forward\n",
            "lstm.forward(x, h)\n",
            "```\n",
            "\n",
            "### Step-by-Step Execution\n",
            "1. Instantiate the LSTM cell with the desired input size and hidden size.\n",
            "2. Set up some random input and hidden states.\n",
            "3. Call the `forward()` method on the LSTM cell, passing in the input and hidden states.\n",
            "4. The LSTM cell calculates the input gate, forget gate, and candidate cell vectors, updates the memory cell, and computes the output of the LSTM cell.\n",
            "\n",
            "### Output Analysis\n",
            "After running the LSTM cell, you can access the output of the LSTM cell using the `output` attribute and the updated memory cell using the `cm` attribute.\n",
            "\n",
            "---\n",
            "\n",
            "## 5. **Best Practices**\n",
            "\n",
            "### Design Considerations\n",
            "- Choose appropriate input and hidden sizes based on the complexity of the task and the available data.\n",
            "- Use dropout during training to prevent overfitting.\n",
            "- Consider using multiple layers of LSTM cells to capture deeper dependencies.\n",
            "\n",
            "### Optimization Techniques\n",
            "- Use gradient clipping to prevent exploding or vanishing gradients.\n",
            "- Adjust the learning rate during training to improve convergence.\n",
            "- Experiment with different optimization algorithms, such as Adam or RMSProp.\n",
            "\n",
            "### Common Pitfalls\n",
            "- Failing to properly initialize the weights and biases can lead to poor performance.\n",
            "- Using too small or too large learning rates can cause slow convergence or oscillation.\n",
            "- Ignoring regularization techniques can lead to overfitting.\n",
            "\n",
            "### Performance Implications\n",
            "Optimal performance depends on finding the right balance between the input size, hidden size, number of layers, learning rate, and regularization strength. A well-tuned LSTM model can achieve impressive results on various sequential data tasks.\n",
            "\n",
            "---\n",
            "\n",
            "## 6. **Applications**\n",
            "\n",
            "### Real-World Use Cases\n",
            "- Language modeling: Predicting the next word in a given sequence of words.\n",
            "- Text generation: Creating coherent and meaningful sentences or paragraphs.\n",
            "- Speech recognition: Transcribing spoken language into written text.\n",
            "- Music composition: Generating melodies or harmonies based on given input.\n",
            "- Time series forecasting: Predicting future values based on historical data.\n",
            "\n",
            "### Industry Applications\n",
            "- Natural Language Processing (NLP): Improving chatbots, virtual assistants, and machine translation systems.\n",
            "- Finance: Analyzing financial trends and making predictions about stock prices.\n",
            "- Healthcare: Monitoring patient health data and predicting disease outbreaks.\n",
            "\n",
            "### Integration Patterns\n",
            "LSTMs can be integrated into deep learning frameworks such as TensorFlow, PyTorch, and MXNet. They can also be combined with other neural network architectures, such as convolutional neural networks (CNNs) or transformers, to create more powerful models.\n",
            "\n",
            "### Variations and Alternatives\n",
            "- Gated Recurrent Units (GRUs): Simplified version of LSTMs that combines the input and forget gates.\n",
            "- Echo State Networks (ESNs): Randomly connected recurrent neural networks with a sparsely connected reservoir.\n",
            "- Long Short-Term Memory Convolutional Networks (LSTM-CNNs): Combination of LSTMs and CNNs for image and video analysis.\n",
            "\n",
            "---\n",
            "\n",
            "## 7. **Evaluation**\n",
            "\n",
            "### Performance Metrics\n",
            "- Accuracy: Percentage of correct predictions compared to the actual values.\n",
            "- Loss: Measure of the difference between predicted and actual values.\n",
            "- Perplexity: Measure of the expected number of tokens needed to generate a sample, lower values indicate better performance.\n",
            "\n",
            "### Testing Approaches\n",
            "- Cross-validation: Split the dataset into training, validation, and test sets to evaluate the model's generalization capabilities.\n",
            "- Hyperparameter tuning: Experiment with different hyperparameters to find the best configuration for the model.\n",
            "\n",
            "### Debugging Strategies\n",
            "- Visualize the internal workings of the LSTM cell, such as the memory cell contents or attention weights, to gain insights into the model's behavior.\n",
            "- Use tools like TensorBoard or PyTorch's built-in visualization tools to monitor the training progress and identify potential issues.\n",
            "\n",
            "### Optimization Opportunities\n",
            "- Increase the dataset size to improve the model's ability to learn complex patterns.\n",
            "- Experiment with different architectures, such as combining LSTMs with CNNs or transformers, to capture more diverse dependencies.\n",
            "- Investigate advanced techniques like attention mechanisms or reinforcement learning to further enhance the model's performance.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def format_text(text):\n",
        "    \"\"\"\n",
        "    Format text with the following rules:\n",
        "    1. Change single asterisks to double asterisks\n",
        "    2. Convert '###' to bullet points\n",
        "    3. Convert dashes to numbered lists, resetting numbers after each bullet point\n",
        "\n",
        "    Args:\n",
        "        text (str): Input text to be formatted\n",
        "    Returns:\n",
        "        str: Formatted text\n",
        "    \"\"\"\n",
        "    # Split text into lines for processing\n",
        "    lines = text.split('\\n')\n",
        "    formatted_lines = []\n",
        "\n",
        "    # Initialize counters for each indentation level\n",
        "    number_counters = {}\n",
        "    current_indent = 0\n",
        "\n",
        "    for i, line in enumerate(lines):\n",
        "        # Skip empty lines but preserve them\n",
        "        if not line.strip():\n",
        "            formatted_lines.append(line)\n",
        "            continue\n",
        "\n",
        "        # Handle single asterisks to double asterisks\n",
        "        # Use negative lookbehind and lookahead to avoid modifying double asterisks\n",
        "        line = re.sub(r'(?<![\\*])\\*(?![\\*])([^\\*]+)(?<![\\*])\\*(?![\\*])', r'**\\1**', line)\n",
        "\n",
        "        # Get the indentation level of the current line\n",
        "        indent = len(line) - len(line.lstrip())\n",
        "\n",
        "        # Convert ### to bullet points\n",
        "        if line.strip().startswith('####'):\n",
        "            # When we encounter a bullet point, reset all numbering counters\n",
        "            number_counters = {}\n",
        "            line = line.replace('####', '•')\n",
        "            current_indent = indent\n",
        "\n",
        "        # Convert ### to bullet points\n",
        "        if line.strip().startswith('###'):\n",
        "            # When we encounter a bullet point, reset all numbering counters\n",
        "            number_counters = {}\n",
        "            line = line.replace('###', '•')\n",
        "            current_indent = indent\n",
        "\n",
        "\n",
        "\n",
        "        if line.strip().startswith('---'):\n",
        "            # When we encounter a bullet point, reset all numbering counters\n",
        "            number_counters = {}\n",
        "            line = line.replace('---', ' ')\n",
        "            current_indent = indent\n",
        "\n",
        "        # Handle numbered lists (lines starting with dash)\n",
        "        elif line.strip().startswith('-'):\n",
        "            # Reset counters for deeper indentation levels when indent changes\n",
        "            if indent > current_indent:\n",
        "                # Keep only counters for less indented levels\n",
        "                number_counters = {k: v for k, v in number_counters.items() if k < indent}\n",
        "\n",
        "            # Initialize or increment counter for this indentation level\n",
        "            if indent not in number_counters:\n",
        "                number_counters[indent] = 1\n",
        "            else:\n",
        "                number_counters[indent] += 1\n",
        "\n",
        "            # Replace dash with the current number for this indentation level\n",
        "            line = re.sub(r'^\\s*-', f\"{' ' * indent}{number_counters[indent]}.\", line, 1)\n",
        "            current_indent = indent\n",
        "        else:\n",
        "            # For non-list lines, keep track of the current indentation\n",
        "            current_indent = indent\n",
        "\n",
        "        formatted_lines.append(line)\n",
        "\n",
        "    return '\\n'.join(formatted_lines)\n",
        "\n",
        "def process_file(input_text):\n",
        "    \"\"\"\n",
        "    Process the entire file and apply formatting\n",
        "\n",
        "    Args:\n",
        "        input_text (str): Content of the input file\n",
        "    Returns:\n",
        "        str: Formatted content\n",
        "    \"\"\"\n",
        "    # Format the text\n",
        "    formatted_text = format_text(input_text)\n",
        "    return formatted_text\n",
        "\n",
        "# Example usage demonstrating the reset behavior\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "\n",
        "    # Process and print the sample text\n",
        "    result = process_file(clean_answer)\n",
        "    print(result)"
      ],
      "metadata": {
        "id": "wLOjWPC9U0W-",
        "outputId": "f05938c4-7fae-4e0b-de1f-edd06b973716",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "\n",
            "## 1. **Concept Overview**\n",
            "\n",
            "• Core Definition and Purpose\n",
            "Long Short-Term Memory (LSTM) is a type of recurrent neural network (RNN) that addresses the vanishing gradient problem by introducing memory cells and gates to control the flow of information through the sequence. The primary purpose of LSTM is to learn long-term dependencies within sequential data, such as text, speech, music, and time series data.\n",
            "\n",
            "• Key Principles\n",
            "1. Memory cells: Store information from previous timesteps, allowing LSTM to maintain relevant information over extended periods.\n",
            "2. Input gate: Controls the flow of new information into the memory cell.\n",
            "3. Forget gate: Determines what information should be discarded from the memory cell.\n",
            "4. Output gate: Decides what information should be passed on to the next timestep.\n",
            "5. Sigmoid activation function: Ensures the values of the gates are between 0 and 1, providing a mechanism for controlling the flow of information.\n",
            "\n",
            "• Relationship to Broader Computing Concepts\n",
            "LSTM is a specialized type of RNN that leverages the core principles of artificial neural networks (ANNs), including weight sharing, nonlinear activation functions, and backpropagation through time (BPTT). It extends these concepts to handle sequential data more effectively, addressing some of the limitations inherent in traditional RNNs.\n",
            "\n",
            " \n",
            "\n",
            "## 2. **Technical Components**\n",
            "\n",
            "• Primary Elements and Their Roles\n",
            "1. Memory cell: Stores information from previous timesteps.\n",
            "2. Input gate: Controls the flow of new information into the memory cell.\n",
            "3. Forget gate: Determines what information should be discarded from the memory cell.\n",
            "4. Output gate: Decides what information should be passed on to the next timestep.\n",
            "5. Tanh activation function: Used to normalize the input to the memory cell and the candidate cell.\n",
            "6. Sigmoid activation function: Ensures the values of the gates are between 0 and 1, providing a mechanism for controlling the flow of information.\n",
            "\n",
            "• Relationships and Interactions\n",
            "The LSTM cell consists of three main components: the memory cell, the input gate, and the forget gate. Each component interacts with the others to determine the new content of the memory cell at each timestep. Additionally, there is an output gate that decides what information should be passed on to the next timestep.\n",
            "\n",
            "• Implementation Details\n",
            "Each LSTM cell has its own set of weights and biases, which are shared among the input gate, forget gate, memory cell, and output gate. During training, the weights and biases are adjusted using backpropagation through time (BPTT) to minimize the loss function.\n",
            "\n",
            "• Core Algorithms/Procedures\n",
            "At each timestep, the LSTM cell performs the following operations:\n",
            "1. Calculate the input gate vector using a sigmoid activation function applied to the weighted sum of the current input, the previous hidden state, and the bias term.\n",
            "2. Calculate the forget gate vector using a sigmoid activation function applied to the weighted sum of the current input, the previous hidden state, and the bias term.\n",
            "3. Calculate the candidate cell vector using the tanh activation function applied to the weighted sum of the current input, the previous hidden state, and the bias term.\n",
            "4. Update the memory cell by multiplying the forget gate vector with the previous memory cell, adding the input gate vector multiplied by the candidate cell, and passing the result through the output gate using a sigmoid activation function.\n",
            "5. Pass the updated memory cell through the tanh activation function to obtain the new candidate cell.\n",
            "6. Pass the output gate vector through a sigmoid activation function to obtain the output of the LSTM cell.\n",
            "\n",
            " \n",
            "\n",
            "## 3. **Working Mechanism**\n",
            "\n",
            "• Step-by-Step Operational Flow\n",
            "1. At each timestep, the LSTM cell receives the current input vector xm.\n",
            "2. Calculate the input gate vector i\\_tmusing the weighted sum of xm, the previous hidden state h\\_(t-1), and the bias term b\\_i. Apply the sigmoid activation function to obtain the scaled values between 0 and 1.\n",
            "3. Calculate the forget gate vector f\\_tmusing the weighted sum of xm, the previous hidden state h\\_(t-1), and the bias term b\\_f. Apply the sigmoid activation function to obtain the scaled values between 0 and 1.\n",
            "4. Calculate the candidate cell vector c\\_tmusing the tanh activation function applied to the weighted sum of xm, the previous hidden state h\\_(t-1), and the bias term b\\_c.\n",
            "5. Update the memory cell using the input gate vector i\\_t, the forget gate vector f\\_t, and the candidate cell vector c\\_t. Multiply the forget gate vector f\\_t with the previous memory cell cm\\_(t-1), add the input gate vector i\\_t multiplied by the candidate cell vector c\\_t, and pass the result through the output gate using a sigmoid activation function.\n",
            "6. Pass the updated memory cell through the tanh activation function to obtain the new candidate cell.\n",
            "7. Pass the output gate vector o\\_t through a sigmoid activation function to obtain the output of the LSTM cell.\n",
            "\n",
            "• Critical Processes and Transformations\n",
            "The critical processes in the LSTM cell involve the interaction between the input gate, forget gate, and output gate. These gates control the flow of information into, out of, and within the memory cell, respectively. The tanh activation function is used to normalize the input to the memory cell and the candidate cell, ensuring that the resulting values lie within the range [-1, 1].\n",
            "\n",
            "• Resource Management (if applicable)\n",
            "The LSTM cell manages resources primarily by adjusting the weights and biases during training using backpropagation through time (BPTT). This allows the model to learn optimal values for each weight and bias, minimizing the loss function and improving the accuracy of the predictions.\n",
            "\n",
            "• Exception Handling (if applicable)\n",
            "No specific exception handling is required for the LSTM cell itself. However, during training, it is common to encounter issues such as exploding or vanishing gradients, which can be addressed using techniques like gradient clipping, learning rate decay, and regularization.\n",
            "\n",
            " \n",
            "\n",
            "## 4. **Implementation Example**\n",
            "\n",
            "• Use Case Scenario\n",
            "For this example, we will implement an LSTM cell for language modeling, where the goal is to predict the next word in a given sequence of words.\n",
            "\n",
            "• Code Implementation or Technical Design\n",
            "Here's a simplified Python implementation of an LSTM cell using NumPy:\n",
            "\n",
            "```python\n",
            "import numpy as np\n",
            "\n",
            "class LSTMCell:\n",
            "    def __init__(self, input_size, hidden_size):\n",
            "        self.W_xi = np.random.rand(input_size + hidden_size, hidden_size)\n",
            "        self.W_hf = np.random.rand(input_size + hidden_size, hidden_size)\n",
            "        self.W_fc = np.random.rand(input_size + hidden_size, hidden_size)\n",
            "        self.W_oc = np.random.rand(hidden_size, hidden_size)\n",
            "        self.W_o = np.random.rand(hidden_size, 1)\n",
            "        self.b_i = np.zeros((1, hidden_size))\n",
            "        self.b_f = np.zeros((1, hidden_size))\n",
            "        self.b_c = np.zeros((1, hidden_size))\n",
            "        self.b_o = np.zeros((1, hidden_size))\n",
            "        self.b = np.zeros((1, 1))\n",
            "\n",
            "    def forward(self, x, h):\n",
            "        # Weighted sums for input gates, forget gates, and candidate cells\n",
            "        i = np.sigmoid(np.dot(self.W_xi, np.concatenate([x, h], axis=-1)) + self.b_i)\n",
            "        f = np.sigmoid(np.dot(self.W_hf, np.concatenate([x, h], axis=-1)) + self.b_f)\n",
            "        c = np.tanh(np.dot(self.W_fc, np.concatenate([x, h], axis=-1)) + self.b_c)\n",
            "\n",
            "        # Update memory cell\n",
            "        ic = i * c\n",
            "        fc = f * self.cm\n",
            "        new_c = ic + fc\n",
            "        new_c = np.tanh(new_c)\n",
            "\n",
            "        # Output gate\n",
            "        o = np.sigmoid(np.dot(self.W_oc, np.concatenate([x, new_c], axis=-1)) + self.b_o)\n",
            "\n",
            "        # Output of the LSTM cell\n",
            "        self.output = o * np.tanh(new_c)\n",
            "        self.cm = new_c\n",
            "\n",
            "# Initialize the LSTM cell\n",
            "lstm = LSTMCell(input_size=10, hidden_size=5)\n",
            "\n",
            "# Set up some random input and hidden states\n",
            "x = np.random.rand(10, 10)\n",
            "h = np.random.rand(1, 5)\n",
            "\n",
            "# Run the LSTM cell forward\n",
            "lstm.forward(x, h)\n",
            "```\n",
            "\n",
            "• Step-by-Step Execution\n",
            "1. Instantiate the LSTM cell with the desired input size and hidden size.\n",
            "2. Set up some random input and hidden states.\n",
            "3. Call the `forward()` method on the LSTM cell, passing in the input and hidden states.\n",
            "4. The LSTM cell calculates the input gate, forget gate, and candidate cell vectors, updates the memory cell, and computes the output of the LSTM cell.\n",
            "\n",
            "• Output Analysis\n",
            "After running the LSTM cell, you can access the output of the LSTM cell using the `output` attribute and the updated memory cell using the `cm` attribute.\n",
            "\n",
            " \n",
            "\n",
            "## 5. **Best Practices**\n",
            "\n",
            "• Design Considerations\n",
            "1. Choose appropriate input and hidden sizes based on the complexity of the task and the available data.\n",
            "2. Use dropout during training to prevent overfitting.\n",
            "3. Consider using multiple layers of LSTM cells to capture deeper dependencies.\n",
            "\n",
            "• Optimization Techniques\n",
            "1. Use gradient clipping to prevent exploding or vanishing gradients.\n",
            "2. Adjust the learning rate during training to improve convergence.\n",
            "3. Experiment with different optimization algorithms, such as Adam or RMSProp.\n",
            "\n",
            "• Common Pitfalls\n",
            "1. Failing to properly initialize the weights and biases can lead to poor performance.\n",
            "2. Using too small or too large learning rates can cause slow convergence or oscillation.\n",
            "3. Ignoring regularization techniques can lead to overfitting.\n",
            "\n",
            "• Performance Implications\n",
            "Optimal performance depends on finding the right balance between the input size, hidden size, number of layers, learning rate, and regularization strength. A well-tuned LSTM model can achieve impressive results on various sequential data tasks.\n",
            "\n",
            " \n",
            "\n",
            "## 6. **Applications**\n",
            "\n",
            "• Real-World Use Cases\n",
            "1. Language modeling: Predicting the next word in a given sequence of words.\n",
            "2. Text generation: Creating coherent and meaningful sentences or paragraphs.\n",
            "3. Speech recognition: Transcribing spoken language into written text.\n",
            "4. Music composition: Generating melodies or harmonies based on given input.\n",
            "5. Time series forecasting: Predicting future values based on historical data.\n",
            "\n",
            "• Industry Applications\n",
            "1. Natural Language Processing (NLP): Improving chatbots, virtual assistants, and machine translation systems.\n",
            "2. Finance: Analyzing financial trends and making predictions about stock prices.\n",
            "3. Healthcare: Monitoring patient health data and predicting disease outbreaks.\n",
            "\n",
            "• Integration Patterns\n",
            "LSTMs can be integrated into deep learning frameworks such as TensorFlow, PyTorch, and MXNet. They can also be combined with other neural network architectures, such as convolutional neural networks (CNNs) or transformers, to create more powerful models.\n",
            "\n",
            "• Variations and Alternatives\n",
            "1. Gated Recurrent Units (GRUs): Simplified version of LSTMs that combines the input and forget gates.\n",
            "2. Echo State Networks (ESNs): Randomly connected recurrent neural networks with a sparsely connected reservoir.\n",
            "3. Long Short-Term Memory Convolutional Networks (LSTM-CNNs): Combination of LSTMs and CNNs for image and video analysis.\n",
            "\n",
            " \n",
            "\n",
            "## 7. **Evaluation**\n",
            "\n",
            "• Performance Metrics\n",
            "1. Accuracy: Percentage of correct predictions compared to the actual values.\n",
            "2. Loss: Measure of the difference between predicted and actual values.\n",
            "3. Perplexity: Measure of the expected number of tokens needed to generate a sample, lower values indicate better performance.\n",
            "\n",
            "• Testing Approaches\n",
            "1. Cross-validation: Split the dataset into training, validation, and test sets to evaluate the model's generalization capabilities.\n",
            "2. Hyperparameter tuning: Experiment with different hyperparameters to find the best configuration for the model.\n",
            "\n",
            "• Debugging Strategies\n",
            "1. Visualize the internal workings of the LSTM cell, such as the memory cell contents or attention weights, to gain insights into the model's behavior.\n",
            "2. Use tools like TensorBoard or PyTorch's built-in visualization tools to monitor the training progress and identify potential issues.\n",
            "\n",
            "• Optimization Opportunities\n",
            "1. Increase the dataset size to improve the model's ability to learn complex patterns.\n",
            "2. Experiment with different architectures, such as combining LSTMs with CNNs or transformers, to capture more diverse dependencies.\n",
            "3. Investigate advanced techniques like attention mechanisms or reinforcement learning to further enhance the model's performance.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write the content to a text file\n",
        "file_path = \"content.txt\"\n",
        "with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
        "    file.write(result)\n"
      ],
      "metadata": {
        "id": "zSuBgezD_0M1"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####################################################################### IMAGE KEYWORD CODE ################################################################\n",
        "# Function to query Hugging Face Inference API\n",
        "def query_huggingface_api(prompt, max_length=25000):\n",
        "    payload = {\n",
        "        \"inputs\": prompt,\n",
        "        \"parameters\": {\n",
        "            \"max_new_tokens\": max_length,\n",
        "            \"temperature\": 0.5,\n",
        "            \"top_p\": 0.7,\n",
        "            \"top_k\": 50,\n",
        "            \"repetition_penalty\": 1.1,\n",
        "            \"do_sample\": True,\n",
        "            \"stop\": [\"<|endoftext|>\"]\n",
        "        }\n",
        "     }\n",
        "\n",
        "    response = requests.post(\n",
        "        HUGGINGFACE_API_URL,\n",
        "        headers=headers,\n",
        "        json=payload\n",
        "    )\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        #print(response.json())\n",
        "        return response.json()\n",
        "    else:\n",
        "        raise Exception(\n",
        "            f\"Request failed with status code {response.status_code}: {response.text}\"\n",
        "        )\n",
        "\n",
        "def extract_answer(api_response):\n",
        "    \"\"\"\n",
        "    Extracts and validates keywords from the Hugging Face API response.\n",
        "\n",
        "    Args:\n",
        "        api_response (dict): The JSON response from the Hugging Face API\n",
        "\n",
        "    Returns:\n",
        "        str: Cleaned comma-separated list of valid technical visualization keywords\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Required suffixes for validation\n",
        "        valid_suffixes = [\n",
        "            '-visualization',\n",
        "            '-diagram',\n",
        "            '-illustration',\n",
        "            '-example',\n",
        "            '-steps'\n",
        "        ]\n",
        "\n",
        "        # Extract the generated text from the API response\n",
        "        if isinstance(api_response, list):\n",
        "            response_text = api_response[0].get('generated_text', '')\n",
        "        elif isinstance(api_response, dict):\n",
        "            response_text = api_response.get('generated_text', '')\n",
        "        else:\n",
        "            response_text = str(api_response)\n",
        "\n",
        "        # Find the keywords section\n",
        "        marker = \"KEYWORDS (comma-separated):\"\n",
        "        if marker not in response_text:\n",
        "            print(\"No keyword marker found in response\")\n",
        "            return \"\"\n",
        "\n",
        "        # Get everything after the marker\n",
        "        keywords_section = response_text.split(marker)[-1].strip()\n",
        "\n",
        "        # Get the first non-empty line\n",
        "        keyword_lines = [line.strip() for line in keywords_section.split('\\n') if line.strip()]\n",
        "        if not keyword_lines:\n",
        "            print(\"No keyword lines found\")\n",
        "            return \"\"\n",
        "\n",
        "        # Get the comma-separated keywords\n",
        "        keywords = keyword_lines[0]\n",
        "\n",
        "        # Clean up and validate the keywords\n",
        "        cleaned_keywords = []\n",
        "        for keyword in keywords.split(','):\n",
        "            keyword = keyword.strip()\n",
        "\n",
        "            # Validation checks\n",
        "            if (keyword and                # Not empty\n",
        "                '-' in keyword and         # Contains hyphens\n",
        "                any(keyword.endswith(suffix) for suffix in valid_suffixes) and  # Has valid suffix\n",
        "                keyword.count('-') >= 2):  # Has at least 2 hyphens (component-type-suffix)\n",
        "\n",
        "                cleaned_keywords.append(keyword)\n",
        "\n",
        "        # Return 5-7 keywords as specified in the prompt\n",
        "        cleaned_keywords = cleaned_keywords[:7] if len(cleaned_keywords) > 7 else cleaned_keywords\n",
        "\n",
        "        if len(cleaned_keywords) < 5:\n",
        "            print(f\"Not enough valid keywords found: {len(cleaned_keywords)}\")\n",
        "            return \"\"\n",
        "\n",
        "        return ', '.join(cleaned_keywords)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting keywords: {str(e)}\")\n",
        "        return \"\""
      ],
      "metadata": {
        "id": "9hmIXAny65MY",
        "collapsed": true
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####################################################################### IMAGE KEYWORD CODE ################################################################\n",
        "\n",
        "def create_image_keyword_prompt(content):\n",
        "    \"\"\"\n",
        "    Creates a prompt for generating image search keywords that works with any technical topic.\n",
        "\n",
        "    Args:\n",
        "        content (str): Technical content to analyze for image-searchable keywords\n",
        "\n",
        "    Returns:\n",
        "        str: Generic prompt that works with any technical content\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"You are a technical visualization expert. Extract specific image search keywords from the following content:\n",
        "\n",
        "{content}\n",
        "\n",
        "Your task: Generate 5-7 image search keywords that would help find educational diagrams and technical visualizations related to the main concepts in this content.\n",
        "\n",
        "Focus on identifying keywords for:\n",
        "1. System/concept architecture diagrams\n",
        "2. Process flows and sequences\n",
        "3. Component interactions\n",
        "4. Implementation details\n",
        "5. Working mechanisms\n",
        "6. Step-by-step procedures\n",
        "7. Technical examples\n",
        "\n",
        "Keyword Generation Rules:\n",
        "1. Each keyword MUST use hyphens between words\n",
        "2. Each keyword MUST end with exactly ONE of these suffixes:\n",
        "   - -visualization\n",
        "   - -diagram\n",
        "   - -illustration\n",
        "   - -example\n",
        "   - -steps\n",
        "\n",
        "Key Requirements:\n",
        "- Use specific technical terms from the content\n",
        "- Include major concepts and processes\n",
        "- Avoid generic/non-specific terms\n",
        "- Keywords must directly relate to main topics\n",
        "- Each keyword should help find relevant technical diagrams\n",
        "\n",
        "Output Format:\n",
        "ONLY provide a comma-separated list of keywords. Example:\n",
        "concept-architecture-diagram, process-flow-visualization, component-interaction-illustration\n",
        "\n",
        "KEYWORDS (comma-separated):\"\"\"\n",
        "\n",
        "    return prompt\n",
        "\n",
        "# Modify the main function to work with your existing setup\n",
        "def main():\n",
        "    # Use your existing content and context\n",
        "    prompt = create_image_keyword_prompt(result)\n",
        "    #print(prompt)\n",
        "\n",
        "    # Use your existing API call function\n",
        "    api_response = query_huggingface_api(prompt, max_length=25000)\n",
        "\n",
        "    # Extract the keywords\n",
        "    image_keywords = extract_answer(api_response)\n",
        "\n",
        "    print(\"Generated Image Search Keywords:\")\n",
        "    print(image_keywords)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "dEGPFXyTQ4jd",
        "outputId": "c9548a38-ad07-42dd-849f-25dfdf3759ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Image Search Keywords:\n",
            "long-short-term-memory-lstm-cell-visualization, lstm-process-flow-steps, lstm-component-interaction-illustration, lstm-implementation-example, working-mechanism-of-lstm-diagram, lstm-training-procedure-steps, lstm-language-modeling-example\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import requests\n",
        "from pptx import Presentation\n",
        "from pptx.util import Inches, Pt\n",
        "from pptx.enum.text import PP_ALIGN\n",
        "from pptx.dml.color import RGBColor\n",
        "\n",
        "def scrape_images(keyword, num_images=2):\n",
        "    \"\"\"Scrape images from GeeksForGeeks using SERP API\"\"\"\n",
        "    api_key = \"41cf19594f02970e20e9362044f5605347e8e04ce0cf4a9614504c087d2bae2e\"\n",
        "\n",
        "    params = {\n",
        "        \"engine\": \"google_images\",\n",
        "        \"q\": keyword,\n",
        "        \"google_domain\": \"google.com\",\n",
        "        \"gl\": \"us\",\n",
        "        \"hl\": \"en\",\n",
        "        \"api_key\": api_key,\n",
        "    }\n",
        "\n",
        "    response = requests.get(\"https://serpapi.com/search.json\", params=params)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        images = []\n",
        "\n",
        "        if \"images_results\" in data:\n",
        "            for image in data[\"images_results\"]:\n",
        "                if 'geeksforgeeks' in image.get('source', '').lower():\n",
        "                    images.append(image[\"original\"])\n",
        "                    if len(images) >= num_images:\n",
        "                        break\n",
        "            return images\n",
        "\n",
        "        return []\n",
        "    else:\n",
        "        print(f\"Failed to retrieve images. Status code: {response.status_code}\")\n",
        "        return []\n"
      ],
      "metadata": {
        "id": "budrpW1Lg-eF"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final code for slides"
      ],
      "metadata": {
        "id": "Y0PQ_l3-bYTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !sudo apt-get update\n",
        "# !sudo apt-get install texlive-latex-base texlive-fonts-recommended texlive-fonts-extra texlive-latex-extra\n",
        "!pdflatex --version"
      ],
      "metadata": {
        "id": "a4ukERBhpIAk",
        "outputId": "eac860d6-c2f1-4f5a-a693-d98f05661fd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pdfTeX 3.141592653-2.6-1.40.22 (TeX Live 2022/dev/Debian)\n",
            "kpathsea version 6.3.4/dev\n",
            "Copyright 2021 Han The Thanh (pdfTeX) et al.\n",
            "There is NO warranty.  Redistribution of this software is\n",
            "covered by the terms of both the pdfTeX copyright and\n",
            "the Lesser GNU General Public License.\n",
            "For more information about these matters, see the file\n",
            "named COPYING and the pdfTeX source.\n",
            "Primary author of pdfTeX: Han The Thanh (pdfTeX) et al.\n",
            "Compiled with libpng 1.6.37; using libpng 1.6.37\n",
            "Compiled with zlib 1.2.11; using zlib 1.2.11\n",
            "Compiled with xpdf version 4.03\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import requests\n",
        "from PIL import Image\n",
        "import io\n",
        "from pptx import Presentation\n",
        "from pptx.util import Inches, Pt\n",
        "from pptx.enum.text import PP_ALIGN\n",
        "from pptx.dml.color import RGBColor\n",
        "import PyPDF2\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def convert_to_tex(content):\n",
        "    \"\"\"\n",
        "    Convert content to LaTeX with proper section hierarchy and special handling for code blocks and equations.\n",
        "    We insert unique markers (@@@SECTION: ... @@@) that will survive the conversion for easier text extraction.\n",
        "    \"\"\"\n",
        "    tex_content = r\"\"\"\\documentclass{article}\n",
        "\\usepackage{amsmath}\n",
        "\\usepackage{listings}\n",
        "\\usepackage{xcolor}\n",
        "\\usepackage{enumitem}\n",
        "\\usepackage{titlesec}\n",
        "\\usepackage{geometry}\n",
        "\\usepackage{verbatim}\n",
        "\n",
        "\\geometry{\n",
        "    a4paper,\n",
        "    left=1in,\n",
        "    right=1in,\n",
        "    top=1in,\n",
        "    bottom=1in\n",
        "}\n",
        "\n",
        "% Format section titles\n",
        "\\titleformat{\\section}\n",
        "  {\\Large\\bfseries}\n",
        "  {}\n",
        "  {0em}\n",
        "  {}\n",
        "\n",
        "% Code listing settings\n",
        "\\lstset{\n",
        "    backgroundcolor=\\color{gray!10},\n",
        "    basicstyle=\\ttfamily\\small,\n",
        "    breaklines=true,\n",
        "    frame=single,\n",
        "    numbers=left,\n",
        "    numberstyle=\\tiny,\n",
        "    keywordstyle=\\color{blue},\n",
        "    commentstyle=\\color{green!60!black},\n",
        "    stringstyle=\\color{red},\n",
        "    tabsize=4,\n",
        "    showspaces=false,\n",
        "    showstringspaces=false\n",
        "}\n",
        "\n",
        "\\begin{document}\n",
        "\\pagestyle{plain}\n",
        "\"\"\"\n",
        "    # Split on \"## \" markers (if present)\n",
        "    sections = content.split(\"## \")\n",
        "    for section in sections[1:]:\n",
        "        if not section.strip():\n",
        "            continue\n",
        "\n",
        "        # Process main section headers with the expected format (e.g. \"1. **Title**\")\n",
        "        title_match = re.match(r'\\d+\\.\\s+\\*\\*(.*?)\\*\\*', section)\n",
        "        if title_match:\n",
        "            section_title = title_match.group(1).strip()\n",
        "            # Insert our unique marker for later extraction:\n",
        "            tex_content += f\"\\\\section*{{@@@SECTION: {section_title} @@@}}\\n\\n\"\n",
        "            section = re.sub(r'\\d+\\.\\s+\\*\\*.*?\\*\\*\\n', '', section)\n",
        "\n",
        "        paragraphs = section.split(\"\\n\")\n",
        "        in_itemize = False\n",
        "        in_paragraph = False\n",
        "        in_code_block = False\n",
        "        in_verbatim = False\n",
        "        code_content = []\n",
        "\n",
        "        for paragraph in paragraphs:\n",
        "            original_paragraph = paragraph\n",
        "            paragraph = paragraph.rstrip(\"\\n\")\n",
        "            if not paragraph.strip():\n",
        "                if in_itemize:\n",
        "                    tex_content += \"\\\\end{itemize}\\n\"\n",
        "                    in_itemize = False\n",
        "                if in_paragraph:\n",
        "                    tex_content += \"\\n\\n\"\n",
        "                    in_paragraph = False\n",
        "                continue\n",
        "\n",
        "            # Handle verbatim/code blocks\n",
        "            if \"egin{verbatim}\" in paragraph:\n",
        "                in_verbatim = True\n",
        "                tex_content += \"\\\\begin{lstlisting}[language=Python]\\n\"\n",
        "                continue\n",
        "            elif \"\\\\end{verbatim}\" in paragraph:\n",
        "                in_verbatim = False\n",
        "                tex_content += \"\\\\end{lstlisting}\\n\\n\"\n",
        "                continue\n",
        "            elif in_verbatim:\n",
        "                tex_content += paragraph.lstrip() + \"\\n\"\n",
        "                continue\n",
        "            elif paragraph.startswith(\"```python\"):\n",
        "                in_code_block = True\n",
        "                code_content = []\n",
        "                continue\n",
        "            elif paragraph.startswith(\"```\") and in_code_block:\n",
        "                in_code_block = False\n",
        "                tex_content += \"\\\\begin{lstlisting}[language=Python]\\n\"\n",
        "                tex_content += \"\\n\".join(code_content)\n",
        "                tex_content += \"\\n\\\\end{lstlisting}\\n\\n\"\n",
        "                code_content = []\n",
        "                continue\n",
        "            elif in_code_block:\n",
        "                code_content.append(paragraph)\n",
        "                continue\n",
        "\n",
        "            # Handle bullet points and numbered lists\n",
        "            elif paragraph.lstrip().startswith(\"• \"):\n",
        "                if not in_itemize:\n",
        "                    tex_content += \"\\\\begin{itemize}\\n\"\n",
        "                    in_itemize = True\n",
        "                tex_content += f\"\\\\item {paragraph.lstrip()[2:]}\\n\"\n",
        "            elif re.match(r'^\\d+\\.\\s', paragraph):\n",
        "                if not in_itemize:\n",
        "                    tex_content += \"\\\\begin{itemize}\\n\"\n",
        "                    in_itemize = True\n",
        "                paragraph = re.sub(r'^\\d+\\.\\s', '', paragraph)\n",
        "                tex_content += f\"\\\\item {paragraph}\\n\"\n",
        "            else:\n",
        "                if in_itemize:\n",
        "                    tex_content += \"\\\\end{itemize}\\n\"\n",
        "                    in_itemize = False\n",
        "\n",
        "                # Handle equations (display math mode)\n",
        "                if paragraph.count('$') >= 2:\n",
        "                    paragraph = re.sub(r'\\$\\$(.*?)\\$\\$', r'\\\\[\\1\\\\]', paragraph)\n",
        "                    tex_content += paragraph + \"\\n\\n\"\n",
        "                else:\n",
        "                    if not paragraph.startswith(\"\\\\\"):\n",
        "                        if not in_paragraph:\n",
        "                            in_paragraph = True\n",
        "                        tex_content += paragraph + \" \"\n",
        "\n",
        "        if in_itemize:\n",
        "            tex_content += \"\\\\end{itemize}\\n\"\n",
        "        if in_paragraph:\n",
        "            tex_content += \"\\n\\n\"\n",
        "\n",
        "    tex_content += \"\\\\end{document}\"\n",
        "    return tex_content\n",
        "\n",
        "\n",
        "def create_tex_and_compile(tex_content, filename=\"output\"):\n",
        "    \"\"\"\n",
        "    Create and compile LaTeX file.\n",
        "    Returns the path to the generated PDF file.\n",
        "    \"\"\"\n",
        "    filename = os.path.normpath(filename)\n",
        "    tex_file = f\"{filename}.tex\"\n",
        "\n",
        "    with open(tex_file, \"w\", encoding='utf-8') as f:\n",
        "        f.write(tex_content)\n",
        "\n",
        "    # Run pdflatex (you might need to run this twice for proper references)\n",
        "    os.system(f'pdflatex -interaction=nonstopmode \"{tex_file}\"')\n",
        "    pdf_file = f\"{filename}.pdf\"\n",
        "    return pdf_file\n",
        "\n",
        "\n",
        "def scrape_images(keyword, num_images=3):\n",
        "    \"\"\"Scrape images from GeeksForGeeks using SERP API.\"\"\"\n",
        "    api_key = \"df7729cfcc6f85cfea8e18cb9f13ce5180a3ea6e1c22e2e5f3de3ea16bd6e40b\"\n",
        "\n",
        "    params = {\n",
        "        \"engine\": \"google_images\",\n",
        "        \"q\": keyword,\n",
        "        \"google_domain\": \"google.com\",\n",
        "        \"gl\": \"us\",\n",
        "        \"hl\": \"en\",\n",
        "        \"api_key\": api_key,\n",
        "    }\n",
        "\n",
        "    response = requests.get(\"https://serpapi.com/search.json\", params=params)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        images = []\n",
        "        if \"images_results\" in data:\n",
        "            for image in data[\"images_results\"]:\n",
        "                if 'geeksforgeeks' in image.get('source', '').lower():\n",
        "                    images.append(image[\"original\"])\n",
        "                    if len(images) >= num_images:\n",
        "                        break\n",
        "            return images\n",
        "        return []\n",
        "    else:\n",
        "        print(f\"Failed to retrieve images. Status code: {response.status_code}\")\n",
        "        return []\n",
        "\n",
        "\n",
        "def create_image_keyword_prompt(content):\n",
        "    \"\"\"Creates a prompt for generating image search keywords.\"\"\"\n",
        "    prompt = f\"\"\"You are a technical visualization expert. Extract specific image search keywords from the following content:\n",
        "\n",
        "{content}\n",
        "\n",
        "Your task: Generate 5-7 image search keywords that would help find educational diagrams and technical visualizations related to the main concepts in this content.\n",
        "\n",
        "Focus on identifying keywords for:\n",
        "1. System/concept architecture diagrams\n",
        "2. Process flows and sequences\n",
        "3. Component interactions\n",
        "4. Implementation details\n",
        "5. Working mechanisms\n",
        "6. Step-by-step procedures\n",
        "7. Technical examples\n",
        "\n",
        "Keyword Generation Rules:\n",
        "1. Each keyword MUST use hyphens between words\n",
        "2. Each keyword MUST end with exactly ONE of these suffixes:\n",
        "   - -visualization\n",
        "   - -diagram\n",
        "   - -illustration\n",
        "   - -example\n",
        "   - -steps\n",
        "\n",
        "Key Requirements:\n",
        "- Use specific technical terms from the content\n",
        "- Include major concepts and processes\n",
        "- Avoid generic/non-specific terms\n",
        "- Keywords must directly relate to main topics\n",
        "- Each keyword should help find relevant technical diagrams\n",
        "\n",
        "Output Format:\n",
        "ONLY provide a comma-separated list of keywords. Example:\n",
        "concept-architecture-diagram, process-flow-visualization, component-interaction-illustration\n",
        "\n",
        "KEYWORDS (comma-separated):\"\"\"\n",
        "    return prompt\n",
        "\n",
        "\n",
        "def extract_answer(api_response):\n",
        "    \"\"\"Extracts and validates keywords from the API response.\"\"\"\n",
        "    try:\n",
        "        valid_suffixes = ['-visualization', '-diagram', '-illustration', '-example', '-steps']\n",
        "        if isinstance(api_response, list):\n",
        "            response_text = api_response[0].get('generated_text', '')\n",
        "        elif isinstance(api_response, dict):\n",
        "            response_text = api_response.get('generated_text', '')\n",
        "        else:\n",
        "            response_text = str(api_response)\n",
        "\n",
        "        if \"KEYWORDS (comma-separated):\" not in response_text:\n",
        "            return []\n",
        "\n",
        "        keywords_section = response_text.split(\"KEYWORDS (comma-separated):\")[-1].strip()\n",
        "        keyword_lines = [line.strip() for line in keywords_section.split('\\n') if line.strip()]\n",
        "        if not keyword_lines:\n",
        "            return []\n",
        "\n",
        "        keywords = keyword_lines[0]\n",
        "        cleaned_keywords = []\n",
        "        for keyword in keywords.split(','):\n",
        "            keyword = keyword.strip()\n",
        "            if (keyword and '-' in keyword and\n",
        "                any(keyword.endswith(suffix) for suffix in valid_suffixes) and\n",
        "                keyword.count('-') >= 2):\n",
        "                cleaned_keywords.append(keyword)\n",
        "        cleaned_keywords = list(set(cleaned_keywords))\n",
        "        cleaned_keywords = cleaned_keywords[:7]\n",
        "        return cleaned_keywords if len(cleaned_keywords) >= 3 else []\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting keywords: {str(e)}\")\n",
        "        return []\n",
        "\n",
        "\n",
        "def query_huggingface_api(prompt, max_length=25000):\n",
        "    payload = {\n",
        "        \"inputs\": prompt,\n",
        "        \"parameters\": {\n",
        "            \"max_new_tokens\": max_length,\n",
        "            \"temperature\": 0.5,\n",
        "            \"top_p\": 0.7,\n",
        "            \"top_k\": 50,\n",
        "            \"repetition_penalty\": 1.1,\n",
        "            \"do_sample\": True,\n",
        "            \"stop\": [\"<|endoftext|>\"]\n",
        "        }\n",
        "    }\n",
        "\n",
        "    response = requests.post(\n",
        "        HUGGINGFACE_API_URL,\n",
        "        headers=headers,\n",
        "        json=payload\n",
        "    )\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        return response.json()\n",
        "    else:\n",
        "        raise Exception(\n",
        "            f\"Request failed with status code {response.status_code}: {response.text}\"\n",
        "        )\n",
        "\n",
        "\n",
        "def create_title_slide(prs, title):\n",
        "    \"\"\"Create the title slide with specific formatting.\"\"\"\n",
        "    title_slide_layout = prs.slide_layouts[0]\n",
        "    slide = prs.slides.add_slide(title_slide_layout)\n",
        "    title_shape = slide.shapes.title\n",
        "    title_shape.text = title\n",
        "\n",
        "    title_frame = title_shape.text_frame\n",
        "    paragraph = title_frame.paragraphs[0]\n",
        "    paragraph.alignment = PP_ALIGN.CENTER\n",
        "    run = paragraph.runs[0] if paragraph.runs else paragraph.add_run()\n",
        "    run.font.size = Pt(44)\n",
        "    run.font.bold = True\n",
        "    run.font.color.rgb = RGBColor(44, 62, 80)\n",
        "\n",
        "\n",
        "def format_paragraph(paragraph, text, level=0, font_size=17, bold=False):\n",
        "    \"\"\"Helper function to format a paragraph with proper text and styling.\"\"\"\n",
        "    paragraph.text = text\n",
        "    paragraph.level = level\n",
        "    paragraph.alignment = PP_ALIGN.LEFT\n",
        "\n",
        "    run = paragraph.runs[0] if paragraph.runs else paragraph.add_run()\n",
        "    run.font.size = Pt(font_size)\n",
        "    run.font.bold = bold\n",
        "    return paragraph\n",
        "\n",
        "\n",
        "def create_section_slide(prs, title, content):\n",
        "    \"\"\"Create section slides with improved formatting for content.\"\"\"\n",
        "    content_slide_layout = prs.slide_layouts[1]\n",
        "    slide = prs.slides.add_slide(content_slide_layout)\n",
        "\n",
        "    # Format slide title\n",
        "    title_shape = slide.shapes.title\n",
        "    title_frame = title_shape.text_frame\n",
        "    title_para = title_frame.paragraphs[0]\n",
        "    title_para.text = title\n",
        "    title_para.alignment = PP_ALIGN.LEFT\n",
        "    run = title_para.runs[0]\n",
        "    run.font.size = Pt(36)\n",
        "    run.font.bold = True\n",
        "    run.font.color.rgb = RGBColor(44, 62, 80)\n",
        "\n",
        "    # Format content placeholder\n",
        "    content_shape = slide.placeholders[1]\n",
        "    content_frame = content_shape.text_frame\n",
        "    content_frame.clear()\n",
        "\n",
        "    # Process content by paragraphs\n",
        "    paragraphs = content.split('\\n')\n",
        "    for i, para_text in enumerate(paragraphs):\n",
        "        para_text = para_text.strip()\n",
        "        if not para_text:\n",
        "            continue\n",
        "        if i == 0:\n",
        "            para = content_frame.paragraphs[0]\n",
        "        else:\n",
        "            para = content_frame.add_paragraph()\n",
        "        # Bold if the whole line is wrapped in **\n",
        "        if para_text.startswith('**') and para_text.endswith('**'):\n",
        "            text = para_text.strip('*')\n",
        "            format_paragraph(para, text, level=0, font_size=17, bold=True)\n",
        "        else:\n",
        "            format_paragraph(para, para_text, level=0, font_size=17, bold=False)\n",
        "\n",
        "\n",
        "def create_image_slide(prs, title, image_url):\n",
        "    \"\"\"Create a slide with a single centered image.\"\"\"\n",
        "    blank_slide_layout = prs.slide_layouts[6]\n",
        "    slide = prs.slides.add_slide(blank_slide_layout)\n",
        "\n",
        "    try:\n",
        "        # Add title textbox\n",
        "        title_box = slide.shapes.add_textbox(Inches(1), Inches(0.5), Inches(11), Inches(1))\n",
        "        title_frame = title_box.text_frame\n",
        "        paragraph = title_frame.add_paragraph()\n",
        "        paragraph.text = title\n",
        "        paragraph.alignment = PP_ALIGN.CENTER\n",
        "        run = paragraph.runs[0]\n",
        "        run.font.size = Pt(32)\n",
        "        run.font.bold = True\n",
        "        run.font.color.rgb = RGBColor(44, 62, 80)\n",
        "\n",
        "        response = requests.get(image_url)\n",
        "        if response.status_code == 200:\n",
        "            image = Image.open(io.BytesIO(response.content))\n",
        "            if image.format == 'WEBP':\n",
        "                image = image.convert('RGB')\n",
        "\n",
        "            img_path = f\"temp_image_{title.replace(' ', '_')}.png\"\n",
        "            image.save(img_path, 'PNG')\n",
        "\n",
        "            max_width = Inches(10)\n",
        "            max_height = Inches(6)\n",
        "\n",
        "            slide.shapes.add_picture(\n",
        "                img_path,\n",
        "                Inches(1.67),\n",
        "                Inches(2),\n",
        "                width=max_width,\n",
        "                height=max_height\n",
        "            )\n",
        "            os.remove(img_path)\n",
        "            return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating image slide: {str(e)}\")\n",
        "    return False\n",
        "\n",
        "\n",
        "def split_content_for_slides(content, max_chars=550):\n",
        "    \"\"\"Split content into multiple slides with better handling.\"\"\"\n",
        "    if len(content) <= max_chars:\n",
        "        return [content]\n",
        "\n",
        "    parts = []\n",
        "    current_part = \"\"\n",
        "    # Split by newlines and sentence boundaries\n",
        "    paragraphs = re.split(r'(?<=[.!?])\\s+(?=[A-Z])|(?:\\r?\\n){2,}', content)\n",
        "    for para in paragraphs:\n",
        "        para = para.strip()\n",
        "        if not para:\n",
        "            continue\n",
        "        if len(para) > max_chars:\n",
        "            sentences = re.split(r'(?<=[.!?])\\s+', para)\n",
        "            for sentence in sentences:\n",
        "                if len(current_part) + len(sentence) > max_chars:\n",
        "                    if current_part:\n",
        "                        parts.append(current_part.strip())\n",
        "                        current_part = sentence + ' '\n",
        "                else:\n",
        "                    current_part += sentence + ' '\n",
        "        else:\n",
        "            if len(current_part) + len(para) > max_chars:\n",
        "                parts.append(current_part.strip())\n",
        "                current_part = para + '\\n'\n",
        "            else:\n",
        "                current_part += para + '\\n'\n",
        "    if current_part:\n",
        "        parts.append(current_part.strip())\n",
        "    return parts\n",
        "\n",
        "\n",
        "def preprocess_pdf_content(content):\n",
        "    \"\"\"Preprocess PDF content for better slide organization.\"\"\"\n",
        "    # Replace multiple spaces/tabs but preserve newlines.\n",
        "    content = re.sub(r'[ \\t]+', ' ', content)\n",
        "    content = re.sub(r'\\n+', '\\n', content)\n",
        "    # Insert a newline before our section markers if not present.\n",
        "    content = re.sub(r'([^\\n])(@@@SECTION:)', r'\\1\\n\\2', content)\n",
        "    return content\n",
        "\n",
        "\n",
        "def clean_extracted_text(text):\n",
        "    \"\"\"\n",
        "    Clean the extracted text by:\n",
        "    1. Removing leading line numbers and stray replacement characters.\n",
        "    2. Joining broken lines where a sentence is split mid-sentence.\n",
        "    \"\"\"\n",
        "    # Remove common stray characters (like the Unicode replacement char \"�\").\n",
        "    text = text.replace(\"�\", \"\")\n",
        "\n",
        "    # Split text into lines.\n",
        "    lines = text.splitlines()\n",
        "    cleaned_lines = []\n",
        "\n",
        "    # Remove leading numbers (e.g., \"123\" or \"123:\" at the start of each line).\n",
        "    for line in lines:\n",
        "        line = re.sub(r'^\\d+[\\.\\:]*\\s*', '', line)\n",
        "        cleaned_lines.append(line)\n",
        "\n",
        "    # Now join lines if the current line does not end with typical punctuation\n",
        "    # and the next line starts with a lowercase letter or is very short (e.g., less than 4 words).\n",
        "    joined_lines = []\n",
        "    i = 0\n",
        "    while i < len(cleaned_lines):\n",
        "        current_line = cleaned_lines[i].strip()\n",
        "        # Continue joining subsequent lines as long as the condition holds.\n",
        "        while (i + 1 < len(cleaned_lines)):\n",
        "            next_line = cleaned_lines[i + 1].strip()\n",
        "            # If current line doesn't end with punctuation and next line appears to be a sentence continuation,\n",
        "            # join them.\n",
        "            if (current_line and current_line[-1] not in \".!?:;\" and\n",
        "                (next_line and (next_line[0].islower() or len(next_line.split()) < 4))):\n",
        "                current_line = current_line.rstrip() + \" \" + next_line.lstrip()\n",
        "                i += 1\n",
        "            else:\n",
        "                break\n",
        "        joined_lines.append(current_line)\n",
        "        i += 1\n",
        "\n",
        "    # Reconstruct the text.\n",
        "    cleaned_text = \"\\n\".join(joined_lines)\n",
        "    return cleaned_text\n",
        "\n",
        "\n",
        "def create_presentation(full_text, query):\n",
        "    \"\"\"Create the full presentation with content-matched images.\"\"\"\n",
        "    # Load an existing PPTX template or create a new Presentation object.\n",
        "    prs = Presentation(\"Crop.pptx\")\n",
        "    prs.slide_width = Inches(13.333)\n",
        "    prs.slide_height = Inches(9)\n",
        "\n",
        "    create_title_slide(prs, query.upper())\n",
        "\n",
        "    try:\n",
        "        processed_content = preprocess_pdf_content(full_text)\n",
        "        # Clean the text further to fix line-break issues.\n",
        "        processed_content = clean_extracted_text(processed_content)\n",
        "        # Split content on our unique section marker.\n",
        "        sections = re.split(r'@@@SECTION:\\s*(.*?)\\s*@@@', processed_content)\n",
        "        if sections[0].strip() == '':\n",
        "            sections = sections[1:]\n",
        "\n",
        "        images_added = 0\n",
        "        used_keywords = set()\n",
        "\n",
        "        # sections should alternate: [title, body, title, body, ...]\n",
        "        for i in range(0, len(sections), 2):\n",
        "            if i + 1 >= len(sections):\n",
        "                break\n",
        "            sec_title = sections[i].strip()\n",
        "            sec_body = sections[i + 1].strip()\n",
        "\n",
        "            content_parts = split_content_for_slides(sec_body)\n",
        "            for j, part in enumerate(content_parts):\n",
        "                slide_title = f\"{sec_title}\" if j == 0 else f\"{sec_title} (continued)\"\n",
        "                create_section_slide(prs, slide_title, part)\n",
        "\n",
        "            if images_added < 3:\n",
        "                # Generate keywords for this section.\n",
        "                prompt = create_image_keyword_prompt(sec_body)\n",
        "                api_response = query_huggingface_api(prompt, max_length=25000)\n",
        "                keywords = extract_answer(api_response)\n",
        "                available_keywords = [k for k in keywords if k not in used_keywords]\n",
        "                if available_keywords:\n",
        "                    keyword = available_keywords[0]\n",
        "                    images = scrape_images(keyword, num_images=1)\n",
        "                    if images:\n",
        "                        image_slide_title = f\"{sec_title} - Visualization\"\n",
        "                        if create_image_slide(prs, image_slide_title, images[0]):\n",
        "                            images_added += 1\n",
        "                            used_keywords.add(keyword)\n",
        "\n",
        "        output_filename = query.upper() + '.pptx'\n",
        "        prs.save(output_filename)\n",
        "        print(\"Presentation created successfully!\")\n",
        "        print(f\"Total images added: {images_added}\")\n",
        "        print(f\"Saved as: {output_filename}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating presentation: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    \"\"\"\n",
        "    Extract text content from a PDF file.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(pdf_path, 'rb') as file:\n",
        "            pdf_reader = PyPDF2.PdfReader(file)\n",
        "            text_content = []\n",
        "            for page in pdf_reader.pages:\n",
        "                text_content.append(page.extract_text())\n",
        "            return '\\n\\n'.join(text_content)\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting text from PDF: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Define a query/title for the presentation.\n",
        "\n",
        "\n",
        "    # Read the content from a text file (content.txt)\n",
        "    with open('content.txt', 'r', encoding='utf-8') as file:\n",
        "        original_content = file.read()\n",
        "\n",
        "    # Convert the content to LaTeX.\n",
        "    tex_content = convert_to_tex(original_content)\n",
        "    # Optionally, save tex_content to inspect it.\n",
        "    # with open(\"debug_output.tex\", \"w\", encoding=\"utf-8\") as f:\n",
        "    #     f.write(tex_content)\n",
        "\n",
        "    # Create PDF from the LaTeX file.\n",
        "    pdf_path = create_tex_and_compile(tex_content)\n",
        "\n",
        "    # Extract text from the generated PDF.\n",
        "    extracted_text = extract_text_from_pdf(pdf_path)\n",
        "    # Uncomment next line to debug extracted text.\n",
        "    # print(\"Extracted PDF text:\\n\", extracted_text)\n",
        "\n",
        "    # Create the presentation using the extracted text and query title.\n",
        "    create_presentation(extracted_text, query)\n"
      ],
      "metadata": {
        "id": "XEIgN97be92S",
        "outputId": "e320c247-06c5-4e6d-b667-6caea0c3edf1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Presentation created successfully!\n",
            "Total images added: 3\n",
            "Saved as: MY PRESENTATION TITLE.pptx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install PyPDF2 python-pptx Pillow\n"
      ],
      "metadata": {
        "id": "mpTey3-jwPYP",
        "outputId": "c1d205a4-7c88-4f40-f9ec-30c78392ee44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.11/dist-packages (3.0.1)\n",
            "Requirement already satisfied: python-pptx in /usr/local/lib/python3.11/dist-packages (1.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Requirement already satisfied: XlsxWriter>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (3.2.2)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (5.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (4.12.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fpdf\n",
        "!pip install PyPDF2 python-pptx"
      ],
      "metadata": {
        "id": "mTMvIfuQt6yE",
        "outputId": "38cda5ce-6b02-407c-9e7e-ae54b34e2c62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fpdf in /usr/local/lib/python3.11/dist-packages (1.7.2)\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: python-pptx in /usr/local/lib/python3.11/dist-packages (1.0.2)\n",
            "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (11.1.0)\n",
            "Requirement already satisfied: XlsxWriter>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (3.2.2)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (5.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (4.12.2)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pptx import Presentation\n",
        "from pptx.util import Inches, Pt\n",
        "from pptx.enum.text import PP_ALIGN\n",
        "from pptx.dml.color import RGBColor\n",
        "import re\n",
        "\n",
        "def create_title_slide(prs, title):\n",
        "    \"\"\"Create the title slide with specific formatting\"\"\"\n",
        "    title_slide_layout = prs.slide_layouts[0]\n",
        "    slide = prs.slides.add_slide(title_slide_layout)\n",
        "    title_shape = slide.shapes.title\n",
        "    title_shape.text = title\n",
        "\n",
        "    # Format title\n",
        "    title_frame = title_shape.text_frame\n",
        "    paragraph = title_frame.paragraphs[0]\n",
        "    paragraph.alignment = PP_ALIGN.CENTER\n",
        "    run = paragraph.runs[0] if paragraph.runs else paragraph.add_run()\n",
        "    run.font.size = Pt(44)\n",
        "    run.font.bold = True\n",
        "    run.font.color.rgb = RGBColor(44, 62, 80)\n",
        "\n",
        "def format_paragraph(paragraph, text, level=0, font_size=17):\n",
        "    \"\"\"Helper function to format a paragraph with proper text and styling\"\"\"\n",
        "    paragraph.text = text\n",
        "    paragraph.level = level\n",
        "    paragraph.alignment = PP_ALIGN.LEFT\n",
        "\n",
        "    # Create a new run if none exists\n",
        "    run = paragraph.runs[0] if paragraph.runs else paragraph.add_run()\n",
        "    run.font.size = Pt(font_size)\n",
        "\n",
        "    # Make non-bullet point text bold\n",
        "    if level == 0 and text.strip():\n",
        "        run.font.bold = True\n",
        "\n",
        "    return paragraph\n",
        "\n",
        "def create_section_slide(prs, title, content):\n",
        "    \"\"\"Create a content slide with specific formatting\"\"\"\n",
        "    content_slide_layout = prs.slide_layouts[1]\n",
        "    slide = prs.slides.add_slide(content_slide_layout)\n",
        "\n",
        "    # Add and format title\n",
        "    title_shape = slide.shapes.title\n",
        "    title_shape.text = title\n",
        "    title_frame = title_shape.text_frame\n",
        "    paragraph = title_frame.paragraphs[0]\n",
        "    paragraph.alignment = PP_ALIGN.LEFT\n",
        "    run = paragraph.runs[0] if paragraph.runs else paragraph.add_run()\n",
        "    run.text = title\n",
        "    run.font.size = Pt(36)\n",
        "    run.font.bold = True\n",
        "    run.font.color.rgb = RGBColor(44, 62, 80)\n",
        "\n",
        "    # Add and format content\n",
        "    content_shape = slide.placeholders[1]\n",
        "    content_frame = content_shape.text_frame\n",
        "    content_frame.clear()  # Clear existing text\n",
        "\n",
        "    # Split content into paragraphs and remove empty lines\n",
        "    paragraphs = [p for p in content.split('\\n') if p.strip()]\n",
        "\n",
        "    for i, para_text in enumerate(paragraphs):\n",
        "        # Get or create paragraph\n",
        "        if i == 0:\n",
        "            p = content_frame.paragraphs[0]\n",
        "        else:\n",
        "            p = content_frame.add_paragraph()\n",
        "\n",
        "        # Format the paragraph based on whether it's a bullet point\n",
        "        if para_text.strip().startswith('•'):\n",
        "            format_paragraph(p, para_text.strip()[1:].strip(), level=1)\n",
        "        else:\n",
        "            format_paragraph(p, para_text.strip(), level=0)\n",
        "\n",
        "def create_presentation(content):\n",
        "    \"\"\"Create the full presentation\"\"\"\n",
        "    prs = Presentation(\"/content/Crop.pptx\")\n",
        "\n",
        "    # Set slide size to widescreen\n",
        "    prs.slide_width = Inches(13.333)\n",
        "    prs.slide_height = Inches(9)\n",
        "\n",
        "    # Create title slide\n",
        "    create_title_slide(prs, query.upper())\n",
        "\n",
        "    try:\n",
        "        # Split content into sections using regex\n",
        "        sections = re.split(r'##\\s+\\d+\\.\\s+\\*\\*([^*]+)\\*\\*', content)\n",
        "\n",
        "        # Remove empty first element if it exists\n",
        "        if sections[0].strip() == '':\n",
        "            sections = sections[1:]\n",
        "\n",
        "        # Process sections in pairs (title and content)\n",
        "        for i in range(0, len(sections), 2):\n",
        "            if i + 1 >= len(sections):\n",
        "                break\n",
        "\n",
        "            title = sections[i].strip()\n",
        "            content = sections[i + 1].strip()\n",
        "\n",
        "            # Split long content into multiple slides if needed\n",
        "            content_parts = split_content_for_slides(content)\n",
        "\n",
        "            for j, part in enumerate(content_parts):\n",
        "                slide_title = f\"{title}\" if j == 0 else f\"{title} (continued)\"\n",
        "                create_section_slide(prs, slide_title, part)\n",
        "\n",
        "        # Save the presentation\n",
        "        prs.save(query.upper() + '.pptx')\n",
        "        print(\"Presentation created successfully!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating presentation: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "def split_content_for_slides(content, max_chars=450):\n",
        "    \"\"\"Split content into multiple slides if it's too long\"\"\"\n",
        "    if len(content) <= max_chars:\n",
        "        return [content]\n",
        "\n",
        "    parts = []\n",
        "    paragraphs = content.split('\\n')\n",
        "    current_part = \"\"\n",
        "\n",
        "    for para in paragraphs:\n",
        "        if len(current_part) + len(para) > max_chars:\n",
        "            if current_part:\n",
        "                parts.append(current_part.strip())\n",
        "                current_part = para + '\\n'\n",
        "        else:\n",
        "            current_part += para + '\\n'\n",
        "\n",
        "    if current_part:\n",
        "        parts.append(current_part.strip())\n",
        "\n",
        "    return parts\n",
        "\n",
        "# Read the content from paste.txt\n",
        "with open('content.txt', 'r') as file:\n",
        "    content = file.read()\n",
        "\n",
        "# Create the presentation\n",
        "create_presentation(content)"
      ],
      "metadata": {
        "id": "AafTzf9n__Su",
        "outputId": "9d383e1c-0d24-4a48-fcbc-bacc53caaf3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Presentation created successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Proper work is till the above block"
      ],
      "metadata": {
        "id": "OSNpB-Icbjec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ############################# CODE FOR SLIDES ###################################\n",
        "# from pptx import Presentation\n",
        "# from pptx.util import Inches, Pt\n",
        "# from pptx.enum.text import PP_ALIGN\n",
        "# import re\n",
        "# import traceback\n",
        "# import os\n",
        "\n",
        "# def render_code_block(text_frame, content_shape, slide, code_block):\n",
        "#     code_lines = code_block.strip('```').split('\\n')\n",
        "#     code_lines = [line for line in code_lines if not line.startswith('```')]\n",
        "#     for line in code_lines:\n",
        "#         para = text_frame.add_paragraph()\n",
        "#         para.text = line\n",
        "#         para.font.name = 'Consolas'\n",
        "#         para.font.size = Pt(14)\n",
        "#         para.space_after = 0\n",
        "#         para.space_before = 0\n",
        "\n",
        "# def process_content_with_equations(text_frame, content_shape, slide, points, prs):\n",
        "#     vertical_position = content_shape.top + Inches(0.2)\n",
        "#     for point in points:\n",
        "#         if point.startswith('```'):\n",
        "#             render_code_block(text_frame, content_shape, slide, point)\n",
        "#             continue\n",
        "\n",
        "#         para = text_frame.add_paragraph()\n",
        "\n",
        "#         # Handle bold and italic text\n",
        "#         if point.startswith('**') and point.endswith('**'):\n",
        "#             para.text = point.strip('**')\n",
        "#             para.font.bold = True\n",
        "#         elif point.startswith('*') and point.endswith('*'):\n",
        "#             para.text = point.strip('*')\n",
        "#             para.font.italic = True\n",
        "#         else:\n",
        "#             clean_point = point.lstrip('- ').lstrip('*').strip()\n",
        "#             para.text = clean_point\n",
        "\n",
        "#         para.font.size = Pt(18)\n",
        "#         para.space_after = 0\n",
        "#         para.space_before = 0\n",
        "#         vertical_position += Inches(0.3)\n",
        "\n",
        "#     return vertical_position\n",
        "\n",
        "# def is_heading(line):\n",
        "#     \"\"\"\n",
        "#     Enhanced heading detection that handles multiple formats:\n",
        "#     1. Numbered headings (1., 2., etc.)\n",
        "#     2. Markdown headings (#, ##, etc.)\n",
        "#     3. Bold headings (**...**)\n",
        "#     \"\"\"\n",
        "#     line = line.strip()\n",
        "\n",
        "#     # Pattern for numbered headings with or without bold markers\n",
        "#     numbered_pattern = r'^\\d+\\.\\s*\\*?\\*?(.+?)\\*?\\*?$'\n",
        "\n",
        "#     # Pattern for markdown headings\n",
        "#     markdown_pattern = r'^#{1,6}\\s+(.+)$'\n",
        "\n",
        "#     # Pattern for bold headings\n",
        "#     bold_pattern = r'^\\*\\*(.+)\\*\\*$'\n",
        "\n",
        "#     if re.match(numbered_pattern, line):\n",
        "#         match = re.match(numbered_pattern, line)\n",
        "#         return True, match.group(1).strip('* ')\n",
        "#     elif re.match(markdown_pattern, line):\n",
        "#         match = re.match(markdown_pattern, line)\n",
        "#         return True, match.group(1).strip()\n",
        "#     elif re.match(bold_pattern, line):\n",
        "#         match = re.match(bold_pattern, line)\n",
        "#         return True, match.group(1).strip()\n",
        "\n",
        "#     return False, None\n",
        "\n",
        "# def is_point(line):\n",
        "#     \"\"\"\n",
        "#     Detect if a line is a bullet point or numbered point\n",
        "#     \"\"\"\n",
        "#     line = line.strip()\n",
        "#     # Match bullet points (-, •) or numbered points (1., 2., etc.)\n",
        "#     return bool(re.match(r'^[-•]\\s+(.+)', line) or\n",
        "#                 re.match(r'^\\d+\\.\\s+(.+)', line))\n",
        "\n",
        "# def create_presentation(content, query, template_path=None):\n",
        "#     try:\n",
        "#         if template_path and os.path.exists(template_path):\n",
        "#             prs = Presentation(template_path)\n",
        "#         else:\n",
        "#             prs = Presentation()\n",
        "\n",
        "#         # Create title slide\n",
        "#         title_slide_layout = prs.slide_layouts[0] if prs.slide_layouts and len(prs.slide_layouts) > 0 else None\n",
        "#         if title_slide_layout:\n",
        "#             slide = prs.slides.add_slide(title_slide_layout)\n",
        "#             title = slide.shapes.title\n",
        "#             subtitle = slide.placeholders[1]\n",
        "#             title.text = query\n",
        "#             subtitle.text = \"Comprehensive Technical Guide\"\n",
        "\n",
        "#         sections = []\n",
        "#         current_section = None\n",
        "#         current_points = []\n",
        "\n",
        "#         lines = content.split('\\n')\n",
        "#         in_code_block = False\n",
        "#         current_code_block = []\n",
        "\n",
        "#         for line in lines:\n",
        "#             # Handle code blocks\n",
        "#             if line.startswith('```'):\n",
        "#                 if in_code_block:\n",
        "#                     current_points.append('\\n'.join(current_code_block))\n",
        "#                     current_code_block = []\n",
        "#                     in_code_block = False\n",
        "#                 else:\n",
        "#                     in_code_block = True\n",
        "#                     current_code_block.append(line)\n",
        "#                 continue\n",
        "\n",
        "#             if in_code_block:\n",
        "#                 current_code_block.append(line)\n",
        "#                 continue\n",
        "\n",
        "#             # Skip empty lines\n",
        "#             if not line.strip():\n",
        "#                 continue\n",
        "\n",
        "#             # Check if line is a heading\n",
        "#             is_head, heading_text = is_heading(line)\n",
        "\n",
        "#             if is_head:\n",
        "#                 # Save previous section if it exists\n",
        "#                 if current_section and current_points:\n",
        "#                     sections.append((current_section, current_points))\n",
        "#                 current_section = heading_text\n",
        "#                 current_points = []\n",
        "#             elif is_point(line):\n",
        "#                 if current_section:  # Only add points if we have a current section\n",
        "#                     current_points.append(line)\n",
        "\n",
        "#         # Add the last section\n",
        "#         if current_section and current_points:\n",
        "#             sections.append((current_section, current_points))\n",
        "\n",
        "#         # Create content slides\n",
        "#         for slide_num, (section, points) in enumerate(sections, start=1):\n",
        "#             content_slide_layout = prs.slide_layouts[1] if len(prs.slide_layouts) > 1 else prs.slide_layouts[0]\n",
        "#             slide = prs.slides.add_slide(content_slide_layout)\n",
        "\n",
        "#             title_shape = slide.shapes.title\n",
        "#             title_shape.text = section\n",
        "#             title_shape.text_frame.paragraphs[0].font.size = Pt(24)\n",
        "\n",
        "#             content_shape = slide.shapes.placeholders[1]\n",
        "#             text_frame = content_shape.text_frame\n",
        "#             text_frame.clear()\n",
        "\n",
        "#             process_content_with_equations(text_frame, content_shape, slide, points, prs)\n",
        "\n",
        "#             # Add page numbers\n",
        "#             left = prs.slide_width - Inches(1.5)\n",
        "#             top = prs.slide_height - Inches(0.75)\n",
        "#             textbox = slide.shapes.add_textbox(left, top, Inches(1), Inches(0.5))\n",
        "#             p = textbox.text_frame.add_paragraph()\n",
        "#             p.text = f\"Page {slide_num + 1} of {len(sections) + 1}\"\n",
        "#             p.font.size = Pt(10)\n",
        "#             p.alignment = PP_ALIGN.RIGHT\n",
        "\n",
        "#         # Save presentation\n",
        "#         filename = re.sub(r'[<>:\"/\\\\|?*]', '', query)\n",
        "#         filename = re.sub(r'\\s+', '_', filename).lower() + '.pptx'\n",
        "#         prs.save(filename)\n",
        "#         return filename\n",
        "\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error in presentation creation: {e}\")\n",
        "#         traceback.print_exc()\n",
        "#         return str(e)\n",
        "# def main():\n",
        "\n",
        "#     template_path = '/content/Crop.pptx'\n",
        "#     filename = create_presentation(clean_answer, query, template_path)\n",
        "#     print(f\"Presentation saved as: {filename}\")\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     main()"
      ],
      "metadata": {
        "id": "-r4IulHOy3P8",
        "outputId": "8829ad66-e5f9-4296-c3f6-c835f49c8201",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Presentation saved as: lstm.pptx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from pptx import Presentation\n",
        "# from pptx.util import Inches, Pt\n",
        "# from pptx.enum.text import PP_ALIGN\n",
        "# import matplotlib.pyplot as plt\n",
        "# import io\n",
        "# import re\n",
        "# import traceback\n",
        "# import os\n",
        "\n",
        "# def render_code_block(text_frame, content_shape, slide, code_block):\n",
        "#     # Clean up code block\n",
        "#     code_lines = code_block.strip('`').split('\\n')\n",
        "\n",
        "#     # Remove code block delimiters\n",
        "#     code_lines = [line for line in code_lines if not line.startswith('```')]\n",
        "\n",
        "#     # Add code as paragraphs\n",
        "#     for line in code_lines:\n",
        "#         para = text_frame.add_paragraph()\n",
        "#         para.text = line\n",
        "#         para.font.name = 'Consolas'\n",
        "#         para.font.size = Pt(14)\n",
        "#         para.space_after = 0\n",
        "#         para.space_before = 0\n",
        "\n",
        "# def process_content_with_equations(text_frame, content_shape, slide, points, prs):\n",
        "#     vertical_position = content_shape.top + Inches(0.2)\n",
        "\n",
        "#     # Process different types of points\n",
        "#     for point in points:\n",
        "#         # Check if it's a code block\n",
        "#         if point.startswith('```'):\n",
        "#             render_code_block(text_frame, content_shape, slide, point)\n",
        "#             continue\n",
        "\n",
        "#         para = text_frame.add_paragraph()\n",
        "\n",
        "#         # Remove markdown formatting\n",
        "#         clean_point = point.lstrip('- ').lstrip('*').lstrip('**').rstrip('*').rstrip('**').strip()\n",
        "\n",
        "#         # Handle bold text\n",
        "#         if point.startswith('**') and point.endswith('**'):\n",
        "#             clean_point = point.strip('**')\n",
        "#             para.font.bold = True\n",
        "\n",
        "#         # Handle italics\n",
        "#         elif point.startswith('*') and point.endswith('*'):\n",
        "#             clean_point = point.strip('*')\n",
        "#             para.font.italic = True\n",
        "\n",
        "#         para.text = clean_point\n",
        "#         para.font.size = Pt(18)\n",
        "#         para.space_after = 0\n",
        "#         para.space_before = 0\n",
        "\n",
        "#         # Add some vertical spacing\n",
        "#         vertical_position += Inches(0.3)\n",
        "\n",
        "#     return vertical_position\n",
        "\n",
        "# def create_presentation(content, query, template_path=None):\n",
        "#     try:\n",
        "#         # Use template if provided, otherwise create a new presentation\n",
        "#         if template_path and os.path.exists(template_path):\n",
        "#             prs = Presentation(template_path)\n",
        "#         else:\n",
        "#             prs = Presentation()\n",
        "\n",
        "#         # Title slide\n",
        "#         title_slide_layout = prs.slide_layouts[0] if prs.slide_layouts and len(prs.slide_layouts) > 0 else None\n",
        "#         if title_slide_layout:\n",
        "#             slide = prs.slides.add_slide(title_slide_layout)\n",
        "#             title = slide.shapes.title\n",
        "#             subtitle = slide.placeholders[1]\n",
        "\n",
        "#             title.text = query\n",
        "#             subtitle.text = \"Comprehensive Technical Guide\"\n",
        "\n",
        "#         # Parse sections\n",
        "#         sections = []\n",
        "#         current_section = None\n",
        "#         current_points = []\n",
        "\n",
        "#         # Split content into lines\n",
        "#         lines = content.split('\\n')\n",
        "\n",
        "#         # Track code block state\n",
        "#         in_code_block = False\n",
        "#         current_code_block = []\n",
        "\n",
        "#         # Iterate through lines to extract sections\n",
        "#         for line in lines:\n",
        "#             # Check for code block start/end\n",
        "#             if line.startswith('```'):\n",
        "#                 if in_code_block:\n",
        "#                     # End of code block\n",
        "#                     current_points.append('\\n'.join(current_code_block))\n",
        "#                     current_code_block = []\n",
        "#                     in_code_block = False\n",
        "#                 else:\n",
        "#                     # Start of code block\n",
        "#                     in_code_block = True\n",
        "#                     current_code_block.append(line)\n",
        "#                 continue\n",
        "\n",
        "#             # If in code block, accumulate lines\n",
        "#             if in_code_block:\n",
        "#                 current_code_block.append(line)\n",
        "#                 continue\n",
        "\n",
        "#             # Check for section headers\n",
        "#             h3_match = re.match(r'^### (.+)$', line)\n",
        "#             h2_match = re.match(r'^## (.+)$', line)\n",
        "\n",
        "#             # Check for bullet points or numbered list\n",
        "#             is_content_line = (\n",
        "#                 line.startswith('- ') or\n",
        "#                 line.startswith('*') or\n",
        "#                 line.startswith('1.')\n",
        "#             )\n",
        "\n",
        "#             if is_content_line:\n",
        "#                 if current_section:\n",
        "#                     current_points.append(line)\n",
        "\n",
        "#             # Detect new sections\n",
        "#             elif h3_match:\n",
        "#                 # Save previous section if exists\n",
        "#                 if current_section and current_points:\n",
        "#                     sections.append((current_section, current_points))\n",
        "\n",
        "#                 # Start new section\n",
        "#                 current_section = h3_match.group(1)\n",
        "#                 current_points = []\n",
        "\n",
        "#             elif h2_match:\n",
        "#                 # Save previous section if exists\n",
        "#                 if current_section and current_points:\n",
        "#                     sections.append((current_section, current_points))\n",
        "\n",
        "#                 # Start new section with H2 header\n",
        "#                 current_section = h2_match.group(1)\n",
        "#                 current_points = []\n",
        "\n",
        "#         # Add last section\n",
        "#         if current_section and current_points:\n",
        "#             sections.append((current_section, current_points))\n",
        "\n",
        "#         # Create slides for each section\n",
        "#         for slide_num, (section, points) in enumerate(sections, start=1):\n",
        "#             # Use content slide layout or create a new slide\n",
        "#             content_slide_layout = prs.slide_layouts[1] if len(prs.slide_layouts) > 1 else prs.slide_layouts[0]\n",
        "#             slide = prs.slides.add_slide(content_slide_layout)\n",
        "\n",
        "#             # Set slide title\n",
        "#             title_shape = slide.shapes.title\n",
        "#             title_shape.text = section\n",
        "#             title_shape.text_frame.paragraphs[0].font.size = Pt(24)\n",
        "\n",
        "#             # Add content\n",
        "#             content_shape = slide.shapes.placeholders[1]\n",
        "#             text_frame = content_shape.text_frame\n",
        "#             text_frame.clear()\n",
        "\n",
        "#             # Process points\n",
        "#             process_content_with_equations(text_frame, content_shape, slide, points, prs)\n",
        "\n",
        "#             # Add slide number\n",
        "#             left = prs.slide_width - Inches(1.5)\n",
        "#             top = prs.slide_height - Inches(0.75)\n",
        "#             textbox = slide.shapes.add_textbox(left, top, Inches(1), Inches(0.5))\n",
        "#             p = textbox.text_frame.add_paragraph()\n",
        "#             p.text = f\"Page {slide_num + 1} of {len(sections) + 1}\"\n",
        "#             p.font.size = Pt(10)\n",
        "#             p.alignment = PP_ALIGN.RIGHT\n",
        "\n",
        "#         # Generate filename\n",
        "#         filename = re.sub(r'[<>:\"/\\|?*]', '', query)\n",
        "#         filename = re.sub(r'\\s+', '_', filename).lower() + '.pptx'\n",
        "#         prs.save(filename)\n",
        "#         return filename\n",
        "\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error in presentation creation: {e}\")\n",
        "#         traceback.print_exc()\n",
        "#         return str(e)\n",
        "\n",
        "# def main():\n",
        "\n",
        "\n",
        "#     # Optional: Specify a template path\n",
        "#     template_path = '/content/Crop.pptx'  # Replace with path to your .pptx template if desired\n",
        "\n",
        "#     filename = create_presentation(clean_answer, query, template_path)\n",
        "#     print(f\"Presentation saved as: {filename}\")\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     main()"
      ],
      "metadata": {
        "id": "j66u7AjDKH_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pylatex pygments"
      ],
      "metadata": {
        "id": "Yj6Y06YEPh6Q",
        "outputId": "8daf0f8f-5500-423b-de60-345d47a2f7be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pylatex in /usr/local/lib/python3.11/dist-packages (1.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: ordered-set in /usr/local/lib/python3.11/dist-packages (from pylatex) (4.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###########################  .tex code ######################################\n",
        "import os\n",
        "from pylatex import Document, Section, Subsection, Command\n",
        "from pylatex.utils import NoEscape\n",
        "\n",
        "def create_document(clean_answer, query):\n",
        "    # Document setup\n",
        "    geometry_options = {\"margin\": \"1in\"}\n",
        "    doc = Document(geometry_options=geometry_options)\n",
        "\n",
        "    # Add title\n",
        "    doc.preamble.append(Command('title', query))\n",
        "    doc.preamble.append(Command('author', ''))\n",
        "    doc.preamble.append(Command('date', ''))\n",
        "    doc.append(NoEscape(r'\\maketitle'))\n",
        "\n",
        "    # Required packages\n",
        "    doc.packages.append(NoEscape(r'\\usepackage{amsmath}'))\n",
        "    doc.packages.append(NoEscape(r'\\usepackage{listings}'))\n",
        "    doc.packages.append(NoEscape(r'\\usepackage{xcolor}'))\n",
        "\n",
        "    # Code style setup\n",
        "    doc.append(NoEscape(r'''\n",
        "        \\lstset{\n",
        "            language=Python,\n",
        "            basicstyle=\\ttfamily\\footnotesize,\n",
        "            backgroundcolor=\\color{gray!10},\n",
        "            frame=single,\n",
        "            breaklines=true,\n",
        "            numbers=left,\n",
        "            numberstyle=\\tiny,\n",
        "            numbersep=5pt\n",
        "        }\n",
        "    '''))\n",
        "\n",
        "    # Process content\n",
        "    sections = []\n",
        "    current_section = None\n",
        "    current_points = []\n",
        "\n",
        "    for line in clean_answer.split('\\n'):\n",
        "        line = line.strip()\n",
        "        section_match = re.match(r'^(\\d+\\. [^•]+)$', line)\n",
        "        if section_match:\n",
        "            if current_section and current_points:\n",
        "                sections.append((current_section, current_points))\n",
        "            current_section = section_match.group(1)\n",
        "            current_points = []\n",
        "        elif line.startswith('•'):\n",
        "            current_points.append(line)\n",
        "\n",
        "    if current_section and current_points:\n",
        "        sections.append((current_section, current_points))\n",
        "\n",
        "    # Add sections and content\n",
        "    for section_title, points in sections:\n",
        "        with doc.create(Section(section_title.lstrip('0123456789. '))):\n",
        "            for point in points:\n",
        "                content = point.lstrip('•■').strip()\n",
        "                parts = []\n",
        "                current_text = \"\"\n",
        "\n",
        "                # Split text and equations\n",
        "                for part in re.split(r'(\\$[^$]+\\$)', content):\n",
        "                    if part.startswith('$') and part.endswith('$'):\n",
        "                        if current_text.strip():\n",
        "                            parts.append(('text', current_text.strip()))\n",
        "                        parts.append(('equation', part))\n",
        "                        current_text = \"\"\n",
        "                    else:\n",
        "                        current_text += part\n",
        "                if current_text.strip():\n",
        "                    parts.append(('text', current_text.strip()))\n",
        "\n",
        "                # Add content\n",
        "                for part_type, content in parts:\n",
        "                    if part_type == 'text':\n",
        "                        doc.append(content + ' ')\n",
        "                    else:\n",
        "                        doc.append(NoEscape(content + ' '))\n",
        "                doc.append(NoEscape(r'\\\\[0.5em]'))  # Add spacing between points\n",
        "\n",
        "    # Generate PDF\n",
        "    filename = re.sub(r'[<>:\"/\\\\|?*]', '', query)\n",
        "    filename = re.sub(r'\\s+', '_', filename).lower()\n",
        "    doc.generate_pdf(filename, clean_tex=False)\n",
        "    return filename + '.pdf'\n",
        "\n",
        "def main():\n",
        "\n",
        "\n",
        "    filename = create_document(clean_answer, query)\n",
        "    print(f\"PDF saved as: {filename}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "UmGpSQDePJXC",
        "outputId": "616bf024-0fd6-47be-f787-311bd9a7fd6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDF saved as: pointers_in_c++.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-pptx Pillow PyMuPDF matplotlib"
      ],
      "metadata": {
        "id": "cVbVm9QqdRxB",
        "outputId": "1bcc75c9-03ed-4ea7-9a4a-290eb316253e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-pptx in /usr/local/lib/python3.11/dist-packages (1.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Collecting PyMuPDF\n",
            "  Downloading pymupdf-1.25.2-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: XlsxWriter>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (3.2.1)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (5.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (4.12.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Downloading pymupdf-1.25.2-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDF\n",
            "Successfully installed PyMuPDF-1.25.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pptx import Presentation\n",
        "from pptx.util import Inches, Pt\n",
        "from pptx.enum.text import PP_ALIGN\n",
        "import matplotlib.pyplot as plt\n",
        "import io\n",
        "import re\n",
        "from pptx import Presentation\n",
        "from pptx.util import Inches, Pt\n",
        "from pptx.enum.text import PP_ALIGN\n",
        "import matplotlib.pyplot as plt\n",
        "import io\n",
        "import re\n",
        "\n",
        "def render_equation(equation):\n",
        "    plt.figure(figsize=(12, 2))\n",
        "    plt.axis('off')\n",
        "    equation = equation.strip()\n",
        "    plt.text(0.5, 0.5, f'${equation}$', fontsize=36, ha='center', va='center')\n",
        "    buf = io.BytesIO()\n",
        "    plt.savefig(buf, format='png', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    buf.seek(0)\n",
        "    return buf\n",
        "\n",
        "def process_content(slide, point, content_shape):\n",
        "    text_frame = content_shape.text_frame\n",
        "    current_x = content_shape.left\n",
        "    current_y = content_shape.top\n",
        "    line_height = Inches(0.4)\n",
        "\n",
        "    parts = re.split(r'(\\$[^$]+\\$|\\`\\`\\`[\\s\\S]+?\\`\\`\\`)', point.lstrip('•■').strip())\n",
        "\n",
        "    for part in parts:\n",
        "        if part.startswith('$') and part.endswith('$'):\n",
        "            eq_buf = render_equation(part.strip('$'))\n",
        "            slide.shapes.add_picture(\n",
        "                eq_buf,\n",
        "                current_x,\n",
        "                current_y,\n",
        "                width=Inches(2.0)\n",
        "            )\n",
        "            current_x += Inches(2.2)\n",
        "        elif part.startswith('```') and part.endswith('```'):\n",
        "            p = text_frame.add_paragraph()\n",
        "            r = p.add_run()\n",
        "            r.text = part.strip('```')\n",
        "            r.font.name = 'Courier New'\n",
        "            r.font.size = Pt(12)\n",
        "            current_y += line_height\n",
        "            current_x = content_shape.left\n",
        "        else:\n",
        "            if part.strip():\n",
        "                p = text_frame.add_paragraph()\n",
        "                r = p.add_run()\n",
        "                r.text = part.strip()\n",
        "                current_y += line_height\n",
        "                current_x = content_shape.left\n",
        "\n",
        "    return current_y + line_height\n",
        "\n",
        "def create_presentation(clean_answer, query, template_path=None):\n",
        "    prs = Presentation(template_path) if template_path else Presentation()\n",
        "\n",
        "    title_slide = prs.slides.add_slide(prs.slide_layouts[0])\n",
        "    title_slide.shapes.title.text = query\n",
        "\n",
        "    sections = []\n",
        "    current_section = None\n",
        "    current_points = []\n",
        "\n",
        "    for line in clean_answer.split('\\n'):\n",
        "        line = line.strip()\n",
        "        section_match = re.match(r'^(\\d+\\. [^•]+)$', line)\n",
        "        if section_match:\n",
        "            if current_section and current_points:\n",
        "                sections.append((current_section, current_points))\n",
        "            current_section = section_match.group(1)\n",
        "            current_points = []\n",
        "        elif line.startswith('•'):\n",
        "            current_points.append(line)\n",
        "\n",
        "    if current_section and current_points:\n",
        "        sections.append((current_section, current_points))\n",
        "\n",
        "    for section_title, points in sections:\n",
        "        slide = prs.slides.add_slide(prs.slide_layouts[1])\n",
        "        slide.shapes.title.text = section_title.strip()\n",
        "        content_shape = slide.shapes.placeholders[1]\n",
        "        vertical_position = content_shape.top\n",
        "\n",
        "        for point in points:\n",
        "            vertical_position = process_content(slide, point, content_shape)\n",
        "\n",
        "    filename = f\"{query.lower().replace(' ', '_')}.pptx\"\n",
        "    prs.save(filename)\n",
        "    return filename\n",
        "\n",
        "def main():\n",
        "    template_path = \"/content/Crop.pptx\"  # Optional\n",
        "\n",
        "\n",
        "    filename = create_presentation(clean_answer, query, template_path)\n",
        "    print(f\"Presentation saved as: {filename}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "bgIxH6cAdPmT",
        "outputId": "10905602-9015-4256-ac61-ffcc906729e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Presentation saved as: linear_regression.pptx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create prompt for image key words"
      ],
      "metadata": {
        "id": "PRu5t98eRYsj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to query Hugging Face Inference API\n",
        "def query_huggingface_api(prompt, max_length=25000):\n",
        "    payload = {\n",
        "        \"inputs\": prompt,\n",
        "        \"parameters\": {\n",
        "            \"max_new_tokens\": max_length,\n",
        "            \"temperature\": 0.5,\n",
        "            \"top_p\": 0.7,\n",
        "            \"top_k\": 50,\n",
        "            \"repetition_penalty\": 1.1,\n",
        "            \"do_sample\": True,\n",
        "            \"stop\": [\"<|endoftext|>\"]\n",
        "        }\n",
        "     }\n",
        "\n",
        "    response = requests.post(\n",
        "        HUGGINGFACE_API_URL,\n",
        "        headers=headers,\n",
        "        json=payload\n",
        "    )\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        #print(response.json())\n",
        "        return response.json()\n",
        "    else:\n",
        "        raise Exception(\n",
        "            f\"Request failed with status code {response.status_code}: {response.text}\"\n",
        "        )\n",
        "\n",
        "def extract_answer(api_response):\n",
        "    \"\"\"\n",
        "    Extracts and validates keywords from the Hugging Face API response.\n",
        "\n",
        "    Args:\n",
        "        api_response (dict): The JSON response from the Hugging Face API\n",
        "\n",
        "    Returns:\n",
        "        str: Cleaned comma-separated list of valid technical visualization keywords\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Required suffixes for validation\n",
        "        valid_suffixes = [\n",
        "            '-visualization',\n",
        "            '-diagram',\n",
        "            '-illustration',\n",
        "            '-example',\n",
        "            '-steps'\n",
        "        ]\n",
        "\n",
        "        # Extract the generated text from the API response\n",
        "        if isinstance(api_response, list):\n",
        "            response_text = api_response[0].get('generated_text', '')\n",
        "        elif isinstance(api_response, dict):\n",
        "            response_text = api_response.get('generated_text', '')\n",
        "        else:\n",
        "            response_text = str(api_response)\n",
        "\n",
        "        # Find the keywords section\n",
        "        marker = \"KEYWORDS (comma-separated):\"\n",
        "        if marker not in response_text:\n",
        "            print(\"No keyword marker found in response\")\n",
        "            return \"\"\n",
        "\n",
        "        # Get everything after the marker\n",
        "        keywords_section = response_text.split(marker)[-1].strip()\n",
        "\n",
        "        # Get the first non-empty line\n",
        "        keyword_lines = [line.strip() for line in keywords_section.split('\\n') if line.strip()]\n",
        "        if not keyword_lines:\n",
        "            print(\"No keyword lines found\")\n",
        "            return \"\"\n",
        "\n",
        "        # Get the comma-separated keywords\n",
        "        keywords = keyword_lines[0]\n",
        "\n",
        "        # Clean up and validate the keywords\n",
        "        cleaned_keywords = []\n",
        "        for keyword in keywords.split(','):\n",
        "            keyword = keyword.strip()\n",
        "\n",
        "            # Validation checks\n",
        "            if (keyword and                # Not empty\n",
        "                '-' in keyword and         # Contains hyphens\n",
        "                any(keyword.endswith(suffix) for suffix in valid_suffixes) and  # Has valid suffix\n",
        "                keyword.count('-') >= 2):  # Has at least 2 hyphens (component-type-suffix)\n",
        "\n",
        "                cleaned_keywords.append(keyword)\n",
        "\n",
        "        # Return 5-7 keywords as specified in the prompt\n",
        "        cleaned_keywords = cleaned_keywords[:7] if len(cleaned_keywords) > 7 else cleaned_keywords\n",
        "\n",
        "        if len(cleaned_keywords) < 5:\n",
        "            print(f\"Not enough valid keywords found: {len(cleaned_keywords)}\")\n",
        "            return \"\"\n",
        "\n",
        "        return ', '.join(cleaned_keywords)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting keywords: {str(e)}\")\n",
        "        return \"\""
      ],
      "metadata": {
        "id": "xVPwSwbea--T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_image_keyword_prompt(content):\n",
        "    \"\"\"\n",
        "    Creates a prompt for generating image search keywords that works with any technical topic.\n",
        "\n",
        "    Args:\n",
        "        content (str): Technical content to analyze for image-searchable keywords\n",
        "\n",
        "    Returns:\n",
        "        str: Generic prompt that works with any technical content\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"You are a technical visualization expert. Extract specific image search keywords from the following content:\n",
        "\n",
        "{content}\n",
        "\n",
        "Your task: Generate 5-7 image search keywords that would help find educational diagrams and technical visualizations related to the main concepts in this content.\n",
        "\n",
        "Focus on identifying keywords for:\n",
        "1. System/concept architecture diagrams\n",
        "2. Process flows and sequences\n",
        "3. Component interactions\n",
        "4. Implementation details\n",
        "5. Working mechanisms\n",
        "6. Step-by-step procedures\n",
        "7. Technical examples\n",
        "\n",
        "Keyword Generation Rules:\n",
        "1. Each keyword MUST use hyphens between words\n",
        "2. Each keyword MUST end with exactly ONE of these suffixes:\n",
        "   - -visualization\n",
        "   - -diagram\n",
        "   - -illustration\n",
        "   - -example\n",
        "   - -steps\n",
        "\n",
        "Key Requirements:\n",
        "- Use specific technical terms from the content\n",
        "- Include major concepts and processes\n",
        "- Avoid generic/non-specific terms\n",
        "- Keywords must directly relate to main topics\n",
        "- Each keyword should help find relevant technical diagrams\n",
        "\n",
        "Output Format:\n",
        "ONLY provide a comma-separated list of keywords. Example:\n",
        "concept-architecture-diagram, process-flow-visualization, component-interaction-illustration\n",
        "\n",
        "KEYWORDS (comma-separated):\"\"\"\n",
        "\n",
        "    return prompt\n",
        "\n",
        "# Modify the main function to work with your existing setup\n",
        "def main():\n",
        "    # Use your existing content and context\n",
        "    prompt = create_image_keyword_prompt(result)\n",
        "    #print(prompt)\n",
        "\n",
        "    # Use your existing API call function\n",
        "    api_response = query_huggingface_api(prompt, max_length=25000)\n",
        "\n",
        "    # Extract the keywords\n",
        "    image_keywords = extract_answer(api_response)\n",
        "\n",
        "    print(\"Generated Image Search Keywords:\")\n",
        "    print(image_keywords)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ZdPWh_hULMMl",
        "outputId": "cbfb70a2-c0dc-4969-fdf4-635c0ce6541c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Image Search Keywords:\n",
            "long-short-term-memory-lstm-visualization, memory-cell-component-illustration, input-gate-process-steps, forget-gate-functionality-diagram, output-gate-role-illustration, lstm-working-mechanism-diagram, language-modeling-example-visualization\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pptx import Presentation\n",
        "from pptx.util import Pt\n",
        "import random\n",
        "import re\n",
        "\n",
        "def create_ppt_from_text(raw_text, templates, main_topic):\n",
        "    # Select a random template for the presentation\n",
        "    selected_template = random.choice(templates)\n",
        "    prs = Presentation(selected_template)\n",
        "\n",
        "    # Add main title slide (Slide 1)\n",
        "    if prs.slides:\n",
        "        slide = prs.slides[0]\n",
        "        title = slide.shapes.title\n",
        "        title.text = main_topic\n",
        "        title.text_frame.paragraphs[0].font.size = Pt(40)\n",
        "\n",
        "    # Split raw text into sections based on headings\n",
        "    sections = split_into_sections(raw_text)\n",
        "\n",
        "    # Process each section and add slides dynamically\n",
        "    for heading, content in sections:\n",
        "        # Slide Layout for Title and Content\n",
        "        slide_layout = prs.slide_layouts[1]\n",
        "        slide = prs.slides.add_slide(slide_layout)\n",
        "\n",
        "        # Add heading as the title of the slide\n",
        "        title_shape = slide.shapes.title\n",
        "        title_shape.text = heading\n",
        "        title_shape.text_frame.paragraphs[0].font.size = Pt(36)\n",
        "\n",
        "        # Check if the content has bullet points (e.g., with dashes or other markers)\n",
        "        if is_bullet_point_section(content):\n",
        "            bullet_points = create_bullet_points_from_list(content)\n",
        "        else:\n",
        "            bullet_points = create_bullet_points(content)\n",
        "\n",
        "        # Add content as the body of the slide\n",
        "        textbox = slide.shapes.placeholders[1].text_frame\n",
        "        textbox.clear()  # Clear default text\n",
        "\n",
        "        # Add each bullet point\n",
        "        for i, point in enumerate(bullet_points, 1):\n",
        "            p = textbox.add_paragraph()\n",
        "            p.text = f\"{i}- {point.strip()}\"\n",
        "            p.font.size = Pt(10)\n",
        "\n",
        "    # Save the presentation\n",
        "    prs.save(f\"/content/{main_topic}.pptx\")\n",
        "\n",
        "\n",
        "def split_into_sections(raw_text):\n",
        "    # Regular expression to match section headings (e.g., **Concept**, **Example**)\n",
        "    section_pattern = r\"\\*\\*(.*?)\\*\\*\"\n",
        "    sections = []\n",
        "\n",
        "    # Find all sections with their titles and content\n",
        "    matches = re.split(r\"(\\*\\*.*?\\*\\*)\", raw_text)\n",
        "    current_heading = None\n",
        "    current_content = \"\"\n",
        "\n",
        "    for match in matches:\n",
        "        if match.startswith(\"**\") and match.endswith(\"**\"):\n",
        "            if current_heading is not None:\n",
        "                sections.append((current_heading, current_content.strip()))\n",
        "            current_heading = match[2:-2]  # Remove ** from the heading\n",
        "            current_content = \"\"\n",
        "        else:\n",
        "            current_content += match\n",
        "\n",
        "    if current_heading is not None:\n",
        "        sections.append((current_heading, current_content.strip()))  # Add the last section\n",
        "\n",
        "    return sections\n",
        "\n",
        "\n",
        "def is_bullet_point_section(content):\n",
        "    # Check if the section contains bullet point markers like dashes or similar\n",
        "    return bool(re.search(r\"^\\s*-|\\s*\\d+\\.\", content, re.MULTILINE))\n",
        "\n",
        "\n",
        "def create_bullet_points_from_list(content):\n",
        "    # Handle sections with existing bullet points (e.g., Advantages, Disadvantages)\n",
        "    lines = content.split('\\n')\n",
        "    bullet_points = [line.strip('-').strip() for line in lines if line.strip()]\n",
        "    return bullet_points\n",
        "\n",
        "\n",
        "def create_bullet_points(content):\n",
        "    # Split content into sentences based on full stops\n",
        "    sentences = content.split('.')\n",
        "    # Remove empty sentences and strip extra spaces\n",
        "    sentences = [sentence.strip() for sentence in sentences if sentence.strip()]\n",
        "    return sentences\n",
        "\n",
        "\n",
        "# Example usage\n",
        "main_topic = query.upper()\n",
        "\n",
        "\n",
        "\n",
        "templates = [\"/content/Crop.pptx\"]  # Provide the template path\n",
        "\n",
        "create_ppt_from_text(clean_answer, templates, main_topic)\n"
      ],
      "metadata": {
        "id": "YYQB9GIfq06C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#original\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Function to scrape images from GeeksforGeeks using SerpApi\n",
        "def scrape_images(keyword, num_images=2):  # Limit to 1 image\n",
        "    api_key = \"41cf19594f02970e20e9362044f5605347e8e04ce0cf4a9614504c087d2bae2e\"  # Replace with your actual API key\n",
        "\n",
        "\n",
        "    ### 4fb26d3c8969e2792af095f4b95dc1270b0a86736c098c88ddaa72d771b76239    new 0/100\n",
        "\n",
        "    params = {\n",
        "        \"engine\": \"google_images\",\n",
        "        \"q\": keyword,\n",
        "        \"google_domain\": \"google.com\",\n",
        "        \"gl\": \"us\",\n",
        "        \"hl\": \"en\",\n",
        "        \"api_key\": api_key,\n",
        "    }\n",
        "\n",
        "    response = requests.get(\"https://serpapi.com/search.json\", params=params)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        images = []\n",
        "\n",
        "        if \"images_results\" in data:\n",
        "            for image in data[\"images_results\"]:\n",
        "                if 'geeksforgeeks' in image.get('source', '').lower():\n",
        "                    images.append(image[\"original\"])\n",
        "                    if len(images) >= num_images:  # Limit to the desired number of images\n",
        "                        break\n",
        "            return images\n",
        "\n",
        "        return []\n",
        "    else:\n",
        "        print(f\"Failed to retrieve images. Status code: {response.status_code}\")\n",
        "        return []\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "def generate_slide_title(text):\n",
        "    # Use TF-IDF vectorizer to extract important terms, focusing on unigrams\n",
        "    tfidf = TfidfVectorizer(stop_words='english', ngram_range=(1, 1), max_features=10)\n",
        "    tfidf_matrix = tfidf.fit_transform([text])\n",
        "\n",
        "    # Use KMeans clustering to identify key terms\n",
        "    num_clusters = 1  # Only one cluster for the main topic\n",
        "    kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(tfidf_matrix)\n",
        "\n",
        "    # Get the terms with the highest TF-IDF scores in the cluster\n",
        "    feature_names = tfidf.get_feature_names_out()\n",
        "    sorted_items = sorted(zip(kmeans.cluster_centers_[0], feature_names), reverse=True)\n",
        "\n",
        "    # Select the top 3 terms as keywords and create a meaningful title\n",
        "    key_terms = [item[1] for item in sorted_items[:3]]  # Top 3 terms\n",
        "    title = \" \".join(key_terms).title()\n",
        "\n",
        "    # Return the title if it's meaningful; otherwise, fall back to a basic title\n",
        "    if len(title.split()) < 2 or title.lower() in ['summary', 'overview']:  # Avoid trivial titles\n",
        "        return 'Slide Title'\n",
        "    return title\n",
        "\n",
        "\n",
        "def generate_bullet_points(text):\n",
        "    # Split text into sentences and return as bullet points\n",
        "    sentences = nltk.sent_tokenize(text)\n",
        "    bullets = [sentence for sentence in sentences if len(sentence) > 20]\n",
        "    return bullets\n",
        "\n",
        "import random\n",
        "def create_ppt_from_template(raw_text, templates, main_topic):\n",
        "    selected_template = random.choice(templates)\n",
        "    prs = Presentation(\"/content/Crop.pptx\")\n",
        "\n",
        "    # Add main topic to the first slide\n",
        "    if prs.slides:\n",
        "        slide = prs.slides[0]\n",
        "        title = slide.shapes.title\n",
        "        title.text = main_topic\n",
        "        title.text_frame.paragraphs[0].font.size = Pt(40)\n",
        "\n",
        "    # Improved text segmentation\n",
        "    paragraphs = raw_text.split('\\n')\n",
        "    paragraphs = [p for p in paragraphs if p.strip()]\n",
        "\n",
        "    slide_sections = []\n",
        "    current_section = []\n",
        "    for paragraph in paragraphs:\n",
        "        if len(current_section) < 3:\n",
        "            current_section.append(paragraph)\n",
        "        else:\n",
        "            slide_sections.append(' '.join(current_section))\n",
        "            current_section = [paragraph]\n",
        "\n",
        "    if current_section:\n",
        "        slide_sections.append(' '.join(current_section))\n",
        "\n",
        "    # Limit to maximum 10 slides\n",
        "    slide_sections = slide_sections[:15]\n",
        "    used_images = set()  # Track used images to prevent repetition\n",
        "\n",
        "    for section in slide_sections:\n",
        "        slide_title = generate_slide_title(section)\n",
        "        bullets = generate_bullet_points(section)\n",
        "\n",
        "        # Add text slide\n",
        "        slide_layout = prs.slide_layouts[1]\n",
        "        slide = prs.slides.add_slide(slide_layout)\n",
        "\n",
        "        title = slide.shapes.title\n",
        "        title.text = slide_title\n",
        "        title.text_frame.paragraphs[0].font.size = Pt(36)\n",
        "\n",
        "        textbox = slide.shapes.placeholders[1].text_frame\n",
        "        textbox.clear()\n",
        "        for bullet in bullets[:3]:  # Limit to 3 bullets per slide\n",
        "            p = textbox.add_paragraph()\n",
        "            p.text = bullet\n",
        "            p.font.size = Pt(20)\n",
        "\n",
        "        # Add corresponding image slide\n",
        "        images = scrape_images(slide_title, num_images=1)\n",
        "        for img_url in images:\n",
        "            if img_url not in used_images:\n",
        "                used_images.add(img_url)\n",
        "                try:\n",
        "                    response = requests.get(img_url)\n",
        "                    response.raise_for_status()\n",
        "\n",
        "                    img = Image.open(BytesIO(response.content))\n",
        "                    image_stream = BytesIO()\n",
        "                    img.save(image_stream, format=\"PNG\")\n",
        "                    image_stream.seek(0)\n",
        "\n",
        "                    img_slide_layout = prs.slide_layouts[6]\n",
        "                    img_slide = prs.slides.add_slide(img_slide_layout)\n",
        "\n",
        "                    slide_width = prs.slide_width\n",
        "                    slide_height = prs.slide_height\n",
        "                    img_width, img_height = img.size\n",
        "\n",
        "                    aspect_ratio = min((slide_width * 0.8) / img_width, (slide_height * 0.8) / img_height)\n",
        "                    new_width = int(img_width * aspect_ratio)\n",
        "                    new_height = int(img_height * aspect_ratio)\n",
        "\n",
        "                    left = (slide_width - new_width) / 2\n",
        "                    top = (slide_height - new_height) / 2\n",
        "\n",
        "                    img_slide.shapes.add_picture(image_stream, left, top, width=new_width, height=new_height)\n",
        "                    break  # Use only one unique image per section\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error loading image for '{slide_title}': {e}\")\n",
        "\n",
        "    # Save the presentation\n",
        "    prs.save(f\"/content/{main_topic}.pptx\")\n",
        "\n",
        "\n",
        "# Example usage\n",
        "templates = [\n",
        "    '/content/Crop.pptx'\n",
        "]  # List of template file paths\n",
        "\n",
        "sentences = answer.split('.')\n",
        "# Join sentences starting from the third sentence (index 2)\n",
        "updated_answer = '.'.join(sentences[2:]).lstrip('.')\n",
        "print(\"Updated Answer:\", updated_answer)\n",
        "\n",
        "raw_text = updated_answer\n",
        "main_topic = query.upper()\n",
        "\n",
        "# Create a presentation using one random template\n",
        "create_ppt_from_template(raw_text, templates, main_topic)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzC9_4uPkq5y",
        "outputId": "bd7e8d9c-ae4c-4fbb-c45f-7768a6961ae6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated Answer: \n",
            "\n",
            "K Nearest Neighbor (KNN) is an instance-based learning algorithm used for both classification and regression tasks. It's a popular method due to its simplicity and effectiveness, especially when dealing with complex or high-dimensional data.\n",
            "\n",
            "Here's how KNN works:\n",
            "\n",
            "1. **Given a new data point**, we want to predict its class or value based on the existing data points.\n",
            "\n",
            "2. **Calculate the distances** between the new data point and all other data points in our dataset. This can be done using various distance measures such as Euclidean, Manhattan, or Minkowski distances.\n",
            "\n",
            "3. **Find the K closest data points**. The number of nearest neighbors, K, is a parameter that needs to be set beforehand. A common choice is K=5.\n",
            "\n",
            "4. **Predict the class or value** of the new data point by taking a vote from the K closest neighbors. For classification problems, the most common class among the K neighbors is chosen. For regression problems, the average value of the K nearest neighbors is taken.\n",
            "\n",
            "Let's take an example to illustrate this:\n",
            "\n",
            "Suppose we have a dataset containing colors of iris flowers (setosa, versicolor, virginica). We want to classify a new flower whose petal length is 5 cm and width is 3 cm.\n",
            "\n",
            "1. Calculate the distances between the new flower and all other flowers in the dataset. Let's say the 5 closest flowers belong to the following classes:\n",
            "   - Setosa: 3, 2, 1 times\n",
            "   - Versicolor: 1 time\n",
            "   - Virginica: 1 time\n",
            "\n",
            "2. Since the majority of the 5 closest flowers are setosa, we predict the new flower is also setosa.\n",
            "\n",
            "It's important to note that the performance of KNN depends on the value of K and the distance measure used. Cross-validation techniques can be employed to find the best K and distance measure for a particular dataset. Also, KNN is sensitive to noise in the data, so it's essential to clean and preprocess the data before applying KNN.\n",
            "\n",
            "In summary, KNN is a powerful and flexible machine learning algorithm that relies on the idea of finding similar instances in the training data to make predictions about new, unseen instances. Its simplicity and effectiveness make it a popular choice for many real-world applications.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "# Function to generate a more meaningful title dynamically\n",
        "def generate_slide_title(text, num_topics=1, num_keywords=3):\n",
        "    # Clean the text (remove unnecessary spaces, symbols, etc.)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    # Vectorize the text using TF-IDF\n",
        "    vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 2))\n",
        "    tfidf_matrix = vectorizer.fit_transform([text])\n",
        "    feature_names = np.array(vectorizer.get_feature_names_out())\n",
        "\n",
        "    # Apply Latent Dirichlet Allocation (LDA) to extract topics\n",
        "    lda = LatentDirichletAllocation(n_components=num_topics, random_state=0)\n",
        "    lda.fit(tfidf_matrix)\n",
        "\n",
        "    # Get the most important words for each topic (top N)\n",
        "    topic_keywords = []\n",
        "    for topic_idx, topic in enumerate(lda.components_):\n",
        "        top_keywords_idx = topic.argsort()[:-num_keywords - 1:-1]\n",
        "        top_keywords = feature_names[top_keywords_idx]\n",
        "        topic_keywords.append(\" \".join(top_keywords))\n",
        "\n",
        "    # Create a title using the most important topic words\n",
        "    title = topic_keywords[0]  # Use the first topic as the title\n",
        "\n",
        "    return title.title()\n",
        "\n",
        "# Example text\n",
        "text = \"\"\"K Nearest Neighbor (KNN) is an instance-based learning algorithm used for both classification and regression tasks. It's a popular method due to its simplicity and effectiveness, especially when dealing with complex or high-dimensional data. In KNN, we calculate the distances between the new data point and all other points in the dataset, find the closest K points, and predict the class or value of the new point.\"\"\"\n",
        "\n",
        "# Generate slide title dynamically\n",
        "slide_title = generate_slide_title(text)\n",
        "print(slide_title)\n",
        "\n"
      ],
      "metadata": {
        "id": "E1fKlxltWnCE",
        "outputId": "140c39dc-8b6d-46d4-efef-6abc69c2d27d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Points Knn Data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = answer.split('.')\n",
        "# Join sentences starting from the third sentence (index 2)\n",
        "updated_answer = '.'.join(sentences[2:]).lstrip('.')\n"
      ],
      "metadata": {
        "id": "JMnxn2WtLquv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def query_huggingface_api(prompt, max_length=30000):\n",
        "    payload = {\n",
        "        \"inputs\": prompt,\n",
        "        \"parameters\": {\n",
        "            \"max_new_tokens\": max_length,\n",
        "            \"temperature\": 0.7,\n",
        "            \"top_p\": 0.9,\n",
        "            \"top_k\": 40,\n",
        "            \"repetition_penalty\": 1.1,\n",
        "            \"do_sample\": True,\n",
        "            \"stop\": [\"<|endoftext|>\"]\n",
        "        }\n",
        "    }\n",
        "\n",
        "    response = requests.post(\n",
        "        HUGGINGFACE_API_URL,\n",
        "        headers=headers,\n",
        "        json=payload\n",
        "    )\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        print(response.json())\n",
        "        return response.json()\n",
        "    else:\n",
        "        raise Exception(\n",
        "            f\"Request failed with status code {response.status_code}: {response.text}\"\n",
        "        )\n",
        "\n",
        "\n",
        "prompt1 = f\"\"\"\n",
        "You are a question-generation expert. Based on the following content, generate at least 30 questions to assess understanding. Include:\n",
        "- 10 Multiple-choice questions (MCQs): Provide 4 answer options, one of which is correct. Indicate the correct option and difficulty level (easy, medium, hard).\n",
        "- 10 Fill-in-the-blank questions: Provide a sentence with a blank to be filled, the correct answer, and difficulty level.\n",
        "- 15 Short-answer questions: Provide concise questions with answers (1-2 sentences) and indicate the difficulty level.\n",
        "\n",
        "Content:\n",
        "{updated_answer}\n",
        "\n",
        "Ensure the questions vary in difficulty (easy, medium, hard) and cover the entire content comprehensively.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "try:\n",
        "    api_response = query_huggingface_api(prompt1, max_length=25000)\n",
        "    answer = extract_answer(api_response)\n",
        "    print(\"Answer:\", answer)\n",
        "except Exception as e:\n",
        "    print(\"Error:\", str(e))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADQg91vwktFm",
        "outputId": "2e6ddc10-e019-460e-ecf7-a84aca6d34a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'generated_text': \"\\nYou are a question-generation expert. Based on the following content, generate at least 30 questions to assess understanding. Include:\\n- 10 Multiple-choice questions (MCQs): Provide 4 answer options, one of which is correct. Indicate the correct option and difficulty level (easy, medium, hard).\\n- 10 Fill-in-the-blank questions: Provide a sentence with a blank to be filled, the correct answer, and difficulty level.\\n- 15 Short-answer questions: Provide concise questions with answers (1-2 sentences) and indicate the difficulty level.\\n\\nContent:\\n\\n\\nKNN (k-Nearest Neighbors) is a machine learning algorithm used for classification and regression tasks. It's a simple yet effective technique for making predictions based on the proximity of data points in a dataset.\\n\\nLet's consider an example to understand KNN better. Suppose we have a dataset of house prices in a city, and each data point includes attributes such as square footage, number of bedrooms, location, etc. Now, we want to predict the price of a new house that doesn't have a labeled price. Using KNN, we can make a prediction by finding the k-closest houses from our dataset to the new house and then taking the average price of those k houses as our prediction.\\n\\nThe number of neighbors (k) used in KNN can be chosen based on the nature of the data and the desired accuracy. A smaller value of k will make the model more sensitive to outliers, while a larger value will make it less so. The choice of k is a trade-off between simplicity and accuracy.\\n\\nTo calculate the distance between two data points, various metrics can be used, such as Euclidean distance, Manhattan distance, or even custom distances tailored to the specific problem at hand.\\n\\nOne important aspect of KNN is that it doesn't require any assumptions about the underlying distribution of the data, making it a non-parametric method. This flexibility allows it to handle complex relationships between variables and perform well on high-dimensional datasets. However, KNN can become computationally expensive when dealing with large datasets due to the need to calculate distances between all pairs of data points.\\n\\nIn summary, KNN is a popular machine learning algorithm that makes predictions by finding the k-closest data points to a new, unlabeled data point and averaging their labels. Its simplicity and flexibility make it a valuable tool in many applications, though its computational cost can be a concern when dealing with large datasets.\\n\\nEnsure the questions vary in difficulty (easy, medium, hard) and cover the entire content comprehensively.\\n\\n---\\n\\n**Multiple-Choice Questions:**\\n\\n1. What type of machine learning algorithm does KNN belong to? (A) Supervised learning (B) Unsupervised learning (C) Semi-supervised learning (D) Reinforcement learning (Correct Answer: A - Difficulty Level: Easy)\\n\\n2. Which of the following is not a use case for KNN? (A) Classifying emails as spam or not spam (B) Predicting house prices based on attributes like square footage, number of bedrooms, and location (C) Training a model to play chess (D) Clustering customers based on their purchasing behavior (Correct Answer: C - Difficulty Level: Easy)\\n\\n3. How does KNN make predictions? (A) By fitting a linear equation to the data (B) By using decision trees (C) By finding the k-closest data points to a new, unlabeled data point and averaging their labels (D) By using neural networks (Correct Answer: C - Difficulty Level: Medium)\\n\\n4. When choosing the number of neighbors (k) in KNN, what happens if you select a smaller value? (A) The model becomes more resistant to outliers (B) The model becomes sensitive to outliers (Correct Answer: B - Difficulty Level: Medium)\\n\\n5. Which metric is NOT typically used to calculate the distance between two data points in KNN? (A) Euclidean distance (B) Manhattan distance (C) Custom distance (D) Chebyshev distance (Correct Answer: D - Difficulty Level: Hard)\\n\\n6. KNN is considered a ___________ method because it doesn't make any assumptions about the underlying distribution of the data. (A) Parametric (B) Non-parametric (C) Linear (D) Logarithmic (Correct Answer: B - Difficulty Level: Medium)\\n\\n7. One drawback of using KNN is its ____________ cost when dealing with large datasets. (A) Calculation (B) Memory (C) Computational (D) Time (Correct Answer: C - Difficulty Level: Easy)\\n\\n8. In the context of KNN, which step involves calculating the distance between all pairs of data points? (A) Finding the k-closest data points (B) Deciding the value of k (C) Selecting the appropriate distance metric (D) Calculating the average label of the k-closest data points (Correct Answer: A - Difficulty Level: Easy)\\n\\n9. What is the purpose of the k parameter in KNN? (A) To determine the number of data points to compare with the new, unlabeled data point (B) To decide the level of sensitivity to outliers (C) To choose the appropriate distance metric (D) To select the type of learning algorithm (Correct Answer: A - Difficulty Level: Medium)\\n\\n10. KNN can be used for both classification and _______ tasks. (A) Linear regression (B) Clustering (C) Time series forecasting (D) Sentiment analysis (Correct Answer: Both A and B - Difficulty Level: Hard)\\n\\n---\\n\\n**Fill-in-the-blank Questions:**\\n\\n1. KNN is a machine learning algorithm used for _______ and _______ tasks. (Answer: Classification and Regression - Difficulty Level: Easy)\\n\\n2. In KNN, we find the k-closest data points to the new, unlabeled data point and take the average of their _______ as our prediction. (Answer: Labels - Difficulty Level: Easy)\\n\\n3. When choosing the number of neighbors (k) in KNN, a smaller value makes the model more sensitive to _______. (Answer: Outliers - Difficulty Level: Medium)\\n\\n4. Euclidean distance, Manhattan distance, and _______ are examples of distance metrics used in KNN. (Answer: Custom distance - Difficulty Level: Medium)\\n\\n5. KNN is a _______ method because it doesn't make any assumptions about the underlying distribution of the data. (Answer: Non-parametric - Difficulty Level: Medium)\\n\\n6. One drawback of using KNN is its _______ cost when dealing with large datasets. (Answer: Computational - Difficulty Level: Easy)\\n\\n7. In KNN, the goal is to find the k-closest data points by calculating the distance between all pairs of data points. (Answer: True - Difficulty Level: Easy)\\n\\n8. The number of neighbors (k) used in KNN can be chosen based on the nature of the data and the desired ________. (Answer: Accuracy - Difficulty Level: Medium)\\n\\n9. KNN can be used for problems where the relationship between variables is complex and non-linear. (Answer: True - Difficulty Level: Medium)\\n\\n10. KNN doesn't require any assumptions about the shape of the data distribution. (Answer: True - Difficulty Level: Easy)\\n\\n---\\n\\n**Short-answer Questions:**\\n\\n1. Explain the concept of K-Nearest Neighbors (KNN) in your own words. (Difficulty Level: Medium)\\n\\n2. What are some common distance metrics used in KNN? (Difficulty Level: Easy)\\n\\n3. Why is KNN considered a non-parametric method? (Difficulty Level: Medium)\\n\\n4. Discuss the role of the k parameter in KNN. (Difficulty Level: Medium)\\n\\n5. How does the choice of k affect the performance of KNN? (Difficulty Level: Medium)\\n\\n6. What are some potential limitations of using KNN? (Difficulty Level: Medium)\\n\\n7. How does KNN handle high-dimensional datasets compared to other algorithms? (Difficulty Level: Medium)\\n\\n8. Can KNN be used for clustering purposes? If yes, explain how. (Difficulty Level: Medium)\\n\\n9. Describe the process of calculating the distance between two data points in KNN. (Difficulty Level: Medium)\\n\\n10. What is the main idea behind using KNN for classification and regression tasks? (Difficulty Level: Easy)\\n\\n11. Why might KNN become computationally expensive when dealing with large datasets? (Difficulty Level: Easy)\\n\\n12. How can custom distances be used in KNN to better suit specific problems? (Difficulty Level: Medium)\\n\\n13. Explain the difference between Euclidean distance and Manhattan distance. (Difficulty Level: Medium)\\n\\n14. Under what circumstances would a smaller value of k be preferred over a larger value in KNN? (Difficulty Level: Medium)\\n\\n15. What factors should be considered when deciding whether to use KNN for a particular problem? (Difficulty Level: Hard)\"}]\n",
            "Answer: True - Difficulty Level: Easy)\n",
            "\n",
            "---\n",
            "\n",
            "**Short-answer Questions:**\n",
            "\n",
            "1. Explain the concept of K-Nearest Neighbors (KNN) in your own words. (Difficulty Level: Medium)\n",
            "\n",
            "2. What are some common distance metrics used in KNN? (Difficulty Level: Easy)\n",
            "\n",
            "3. Why is KNN considered a non-parametric method? (Difficulty Level: Medium)\n",
            "\n",
            "4. Discuss the role of the k parameter in KNN. (Difficulty Level: Medium)\n",
            "\n",
            "5. How does the choice of k affect the performance of KNN? (Difficulty Level: Medium)\n",
            "\n",
            "6. What are some potential limitations of using KNN? (Difficulty Level: Medium)\n",
            "\n",
            "7. How does KNN handle high-dimensional datasets compared to other algorithms? (Difficulty Level: Medium)\n",
            "\n",
            "8. Can KNN be used for clustering purposes? If yes, explain how. (Difficulty Level: Medium)\n",
            "\n",
            "9. Describe the process of calculating the distance between two data points in KNN. (Difficulty Level: Medium)\n",
            "\n",
            "10. What is the main idea behind using KNN for classification and regression tasks? (Difficulty Level: Easy)\n",
            "\n",
            "11. Why might KNN become computationally expensive when dealing with large datasets? (Difficulty Level: Easy)\n",
            "\n",
            "12. How can custom distances be used in KNN to better suit specific problems? (Difficulty Level: Medium)\n",
            "\n",
            "13. Explain the difference between Euclidean distance and Manhattan distance. (Difficulty Level: Medium)\n",
            "\n",
            "14. Under what circumstances would a smaller value of k be preferred over a larger value in KNN? (Difficulty Level: Medium)\n",
            "\n",
            "15. What factors should be considered when deciding whether to use KNN for a particular problem? (Difficulty Level: Hard)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer = api_response[0][\"generated_text\"]\n",
        "\n",
        "answer = answer.split('\\n')\n",
        "\n",
        "for line in answer:\n",
        "  print(line)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TMgknmskx0n",
        "outputId": "678e4d26-413a-4db1-e6a5-ae44a86470a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "You are a question-generation expert. Based on the following content, generate at least 30 questions to assess understanding. Include:\n",
            "- 10 Multiple-choice questions (MCQs): Provide 4 answer options, one of which is correct. Indicate the correct option and difficulty level (easy, medium, hard).\n",
            "- 10 Fill-in-the-blank questions: Provide a sentence with a blank to be filled, the correct answer, and difficulty level.\n",
            "- 15 Short-answer questions: Provide concise questions with answers (1-2 sentences) and indicate the difficulty level.\n",
            "\n",
            "Content:\n",
            "\n",
            "\n",
            "K-Nearest Neighbors (KNN) is a simple and effective machine learning algorithm used for classification and regression tasks. It works by finding the k closest training examples in the feature space of an input sample and using them to predict the class or value of that sample.\n",
            "\n",
            "Let's break it down:\n",
            "1. **Input**: A new, unlabeled data point x with features X1, X2, ..., Xn.\n",
            "2. **Training set**: A collection of labeled data points D = {(x1, y1), (x2, y2), ..., (xm, ym)}, where each data point xi has m features and a corresponding label yi.\n",
            "3. **Distance metric**: A function that measures the similarity between two data points, such as Euclidean distance or Manhattan distance.\n",
            "4. **k**: A positive integer that determines the number of nearest neighbors to consider when making a prediction.\n",
            "\n",
            "Here's how KNN works:\n",
            "\n",
            "1. Calculate the distance between the new data point x and every training example in the dataset.\n",
            "2. Sort the distances in ascending order, and select the k smallest ones.\n",
            "3. For classification problems, count the number of votes for each class among the k nearest neighbors. Predict the class of the new data point as the one with the most votes. For regression problems, take the average of the labels of the k nearest neighbors.\n",
            "\n",
            "Example: Suppose we have a dataset of iris flowers with four features (sepal length, sepal width, petal length, petal width) and three classes (Setosa, Versicolor, Virginica). We want to classify a new flower with the following features: sepal length = 5.0, sepal width = 3.0, petal length = 1.5, petal width = 0.2.\n",
            "\n",
            "To use KNN, we first calculate the distance between this new flower and all the flowers in our dataset. Let's say we choose k=3. After sorting the distances, we find the three nearest neighbors:\n",
            "\n",
            "- Setosa (distance = 0.2)\n",
            "- Setosa (distance = 0.3)\n",
            "- Versicolor (distance = 0.6)\n",
            "\n",
            "Since all three neighbors belong to the Setosa class, we predict that the new flower is also a Setosa.\n",
            "\n",
            "Advantages of KNN:\n",
            "- Easy to understand and implement\n",
            "- Flexible: can be used for both classification and regression tasks\n",
            "- Works well for high-dimensional datasets\n",
            "\n",
            "Disadvantages of KNN:\n",
            "- Computationally expensive for large datasets due to the need to calculate distances between every pair of data points\n",
            "- Sensitive to the choice of k: choosing too small a value may lead to overfitting, while choosing too large a value may reduce accuracy\n",
            "- Requires careful selection of distance metrics and normalization of features to ensure accurate results\n",
            "\n",
            "Ensure the questions vary in difficulty (easy, medium, hard) and cover the entire content comprehensively.\n",
            "\n",
            "---\n",
            "\n",
            "**Multiple-choice questions:**\n",
            "\n",
            "1. [Easy] Which of the following algorithms uses k nearest neighbors to make predictions?\n",
            "   - Naive Bayes Classifier\n",
            "   - Decision Trees\n",
            "   - Support Vector Machines\n",
            "   - K-Nearest Neighbors\n",
            "   (Correct Answer: K-Nearest Neighbors)\n",
            "\n",
            "2. [Medium] What does K-Nearest Neighbors do in a classification problem?\n",
            "   - Predicts the value of the new data point as the average of the labels of the k nearest neighbors\n",
            "   - Predicts the class of the new data point based on the majority vote among the k nearest neighbors\n",
            "   - Uses the Euclidean distance to measure similarity between data points\n",
            "   - Applies principal component analysis (PCA) to reduce the dimensionality of the data before making predictions\n",
            "   (Correct Answer: Predicts the class of the new data point based on the majority vote among the k nearest neighbors)\n",
            "\n",
            "3. [Hard] In K-Nearest Neighbors, what is the role of the 'k' parameter?\n",
            "   - Determines the number of nearest neighbors to consider when making a prediction\n",
            "   - Determines the number of features to consider when making a prediction\n",
            "   - Determines the maximum allowed distance between the new data point and its nearest neighbor\n",
            "   - Determines the type of distance metric to be used when calculating similarity between data points\n",
            "   (Correct Answer: Determines the number of nearest neighbors to consider when making a prediction)\n",
            "\n",
            "4. [Easy] What are the two main steps in the K-Nearest Neighbors algorithm for classification problems?\n",
            "   - Selecting the k neighbors and counting their votes for each class\n",
            "   - Normalizing the features and applying PCA\n",
            "   - Calculating the distance between the new data point and all training examples\n",
            "   - Applying the chosen distance metric and sorting the distances in descending order\n",
            "   (Correct Answer: Selecting the k neighbors and counting their votes for each class)\n",
            "\n",
            "5. [Medium] What is the difference between K-Nearest Neighbors and Support Vector Machines (SVM)?\n",
            "   - K-Nearest Neighbors is a simple and easy-to-implement algorithm, while SVM requires more computational resources and tuning\n",
            "   - K-Nearest Neighbors is a non-parametric method, while SVM is a parametric method\n",
            "   - K-Nearest Neighbors can handle both classification and regression tasks, while SVM is only suitable for classification\n",
            "   - Both K-Nearest Neighbors and SVM require the user to specify the number of nearest neighbors (k) to consider when making a prediction\n",
            "   (Correct Answer: Both K-Nearest Neighbors and SVM require the user to specify the number of nearest neighbors (k) to consider when making a prediction)\n",
            "\n",
            "6. [Hard] In K-Nearest Neighbors, which of the following statements is true about the prediction process for regression problems?\n",
            "   - The prediction is made based on the average of the labels of the k nearest neighbors\n",
            "   - The prediction is made based on the majority vote among the k nearest neighbors\n",
            "   - The prediction is made by finding the kth nearest neighbor and using its label as the predicted value\n",
            "   - The prediction is made by applying the chosen distance metric and sorting the distances in ascending order\n",
            "   (Correct Answer: The prediction is made based on the average of the labels of the k nearest neighbors)\n",
            "\n",
            "7. [Easy] Which of the following is NOT a disadvantage of K-Nearest Neighbors?\n",
            "   - Computationally expensive for large datasets\n",
            "   - Works well for low-dimensional datasets\n",
            "   - Requires careful selection of distance metrics and normalization of features\n",
            "   - Sensitive to the choice of k\n",
            "   (Correct Answer: Works well for low-dimensional datasets)\n",
            "\n",
            "8. [Medium] Which of the following is NOT a step in the K-Nearest Neighbors algorithm for classification problems?\n",
            "   - Calculating the distance between the new data point and all training examples\n",
            "   - Normalizing the features and applying PCA\n",
            "   - Selecting the k neighbors and counting their votes for each class\n",
            "   - Applying the chosen distance metric and sorting the distances in descending order\n",
            "   (Correct Answer: Normalizing the features and applying PCA)\n",
            "\n",
            "9. [Hard] In the example provided, why did the new flower get classified as Setosa?\n",
            "   - Because all three nearest neighbors belonged to the Setosa class\n",
            "   - Because the Euclidean distance was the smallest among all the other classes\n",
            "   - Because the majority vote among the k nearest neighbors was for Setosa\n",
            "   - Because the new flower had the shortest petal length among all the other flowers\n",
            "   (Correct Answer: Because all three nearest neighbors belonged to the Setosa class)\n",
            "\n",
            "10. [Easy] What is the purpose of selecting the k nearest neighbors in K-Nearest Neighbors?\n",
            "   - To reduce the dimensionality of the data\n",
            "   - To increase the generalization ability of the model\n",
            "   - To improve the computational efficiency of the algorithm\n",
            "   - To ensure that the nearest neighbors are from different classes\n",
            "   (Correct Answer: To improve the computational efficiency of the algorithm)\n",
            "\n",
            "---\n",
            "\n",
            "**Fill-in-the-blank questions:**\n",
            "\n",
            "1. [Easy] The _______ algorithm uses k nearest neighbors to make predictions.\n",
            "Answer: K-Nearest Neighbors\n",
            "\n",
            "2. [Medium] In K-Nearest Neighbors, the prediction is made based on the ________ of the k nearest neighbors.\n",
            "Answer: Majority vote (for classification problems) / Average (for regression problems)\n",
            "\n",
            "3. [Hard] One disadvantage of K-Nearest Neighbors is that it is computationally expensive for large datasets due to the need to calculate distances between every ________.\n",
            "Answer: pair of data points\n",
            "\n",
            "4. [Easy] The K-Nearest Neighbors algorithm requires the user to specify the number of nearest neighbors (k) to consider when making a prediction.\n",
            "Blank: ______\n",
            "\n",
            "5. [Medium] In the K-Nearest Neighbors algorithm, after calculating the distances between the new data point and all training examples, the distances are sorted in _______ order.\n",
            "Answer: Ascending\n",
            "\n",
            "6. [Hard] An advantage of K-Nearest Neighbors is that it can handle both _______ and regression tasks.\n",
            "Answer: Classification and regression\n",
            "\n",
            "7. [Easy] When using K-Nearest Neighbors for classification, if there is a tie in the number of votes for each class among the k nearest neighbors, the algorithm will predict the _______ class.\n",
            "Answer: Class with the lowest index\n",
            "\n",
            "8. [Medium] To improve the performance of K-Nearest Neighbors, it is important to carefully select the _______ and normalize the features.\n",
            "Answer: Distance metric\n",
            "\n",
            "9. [Hard] In the given example, suppose the new flower had a petal length of 1.6 instead of 1.5. If k remains the same, which class would it likely belong to? Explain why.\n",
            "Answer: It might belong to the Versicolor class because the new flower would be closer to the third nearest neighbor, which belongs to the Versicolor class.\n",
            "\n",
            "10. [Easy] The K-Nearest Neighbors algorithm is a _______ method, meaning it makes no assumptions about the underlying distribution of the data.\n",
            "Answer: Non-parametric\n",
            "\n",
            "---\n",
            "\n",
            "**Short-answer questions:**\n",
            "\n",
            "1. [Easy] Briefly explain the role of the 'k' parameter in K-Nearest Neighbors.\n",
            "Answer: The 'k' parameter determines the number of nearest neighbors to consider when making a prediction. A larger value of 'k' means considering more neighbors, potentially reducing the risk of misclassifying the new data point but increasing the computational cost. Conversely, a smaller value of 'k' means considering fewer neighbors, potentially increasing the risk of misclassifying the new data point but decreasing the computational cost.\n",
            "\n",
            "2. [Medium] Why is K-Nearest Neighbors sensitive to the choice of 'k'?\n",
            "Answer: K-Nearest Neighbors is sensitive to the choice of 'k' because an incorrect choice of 'k' can lead to overfitting or underfitting, affecting the accuracy of the predictions. Choosing too small a value of 'k' may result in overfitting, while choosing too large a value of 'k' may result in underfitting.\n",
            "\n",
            "3. [Hard] Describe the process of making a prediction using K-Nearest Neighbors for regression problems.\n",
            "Answer: To make a prediction using K-Nearest Neighbors for regression problems, the algorithm counts the number of votes for each possible value among the k nearest neighbors and takes the average of those values as the predicted value. This approach assumes that similar samples have similar values, and the prediction is an estimate of the mean value of the k nearest neighbors.\n",
            "\n",
            "4. [Easy] What is the difference between classification and regression tasks in the context of K-Nearest Neighbors?\n",
            "Answer: In classification tasks, the goal is to predict the class or category of a new data point, whereas in regression tasks, the goal is to predict a continuous numerical value, such as a real number.\n",
            "\n",
            "5. [Medium] Why is K-Nearest Neighbors considered a non-parametric method?\n",
            "Answer: K-Nearest Neighbors is considered a non-parametric method because it makes no assumptions about the underlying distribution of the data, unlike some other machine learning algorithms like linear regression or logistic regression, which assume a specific form for the data distribution.\n",
            "\n",
            "6. [Hard] Explain why K-Nearest Neighbors may be computationally expensive for large datasets.\n",
            "Answer: K-Nearest Neighbors may be computationally expensive for large datasets because it requires calculating the distance between the new data point and every training example in the dataset, which can become time-consuming and resource-intensive as the size of the dataset grows. This operation is known as the \"curse of dimensionality,\" where the complexity of the algorithm increases exponentially with the number of dimensions or features.\n",
            "\n",
            "7. [Easy] What are the advantages of using K-Nearest Neighbors for high-dimensional datasets?\n",
            "Answer: One advantage of using K-Nearest Neighbors for high-dimensional datasets is that it can still perform reasonably well even when the data is sparse or contains many irrelevant features. This is because K-Nearest Neighbors is a non-parametric method that does not rely on explicit assumptions about the data distribution or the relationships between the features.\n",
            "\n",
            "8. [Medium] Why is it important to carefully select the distance metric in K-Nearest Neighbors?\n",
            "Answer: It is important to carefully select the distance metric in K-Nearest Neighbors because the choice of distance metric affects the similarity between data points and, consequently, the predictions made by the algorithm. Different distance metrics may be better suited for different types of data and applications, so it is essential to choose a distance metric that accurately reflects the underlying structure of the data.\n",
            "\n",
            "9. [Hard] How does K-Nearest Neighbors differ from clustering algorithms like K-Means?\n",
            "Answer: K-Nearest Neighbors is a supervised learning algorithm that makes predictions based on labeled data, whereas K-Means is an unsupervised learning algorithm that groups data points into clusters without any prior knowledge of their labels. Additionally, K-Nearest Neighbors is used for both classification and regression tasks, while K-Means is primarily used for clustering tasks.\n",
            "\n",
            "10. [Easy] What are the potential drawbacks of using K-Nearest Neighbors?\n",
            "Answer: Some potential drawbacks of using K-Nearest Neighbors include its sensitivity to the choice of 'k', its computational expense for large datasets, and its requirement for careful selection of the distance metric and normalization of the features to ensure accurate results. Additionally, K-Nearest Neighbors may not scale well to very high-dimensional datasets due to the curse of dimensionality.\n",
            "\n",
            "11. [Medium] In what ways can K-Nearest Neighbors be improved or optimized?\n",
            "Answer: K-Nearest Neighbors can be improved or optimized in several ways, such as by using efficient data structures like kd-trees or ball trees to speed up the search for the k nearest neighbors, by weighting the contributions of the nearest neighbors based on their distance from the new data point, or by using dimensionality reduction techniques like principal component analysis (PCA) to reduce the number of features and alleviate the curse of dimensionality.\n",
            "\n",
            "12. [Hard] What is the concept of overfitting and underfitting in the context of K-Nearest Neighbors?\n",
            "Answer: Overfitting occurs when a machine learning model learns the noise or random fluctuations in the training data rather than the underlying pattern, leading to poor performance on new, unseen data. Underfitting, on the other hand, refers to a situation where the model is too simple to capture the complexity of the data, resulting in poor performance even on the training data. In the context of K-Nearest Neighbors, choosing an incorrect value of 'k' can lead to overfitting or underfitting, affecting the accuracy of the predictions.\n",
            "\n",
            "13. [Easy] What is the role of the new data point in the K-Nearest Neighbors algorithm?\n",
            "Answer: The new data point plays the role of the query or test point in the K-Nearest Neighbors algorithm. Its features are compared to the features of the training data to determine the k nearest neighbors, and these neighbors are then used to make a prediction about the class or value of the new data point.\n",
            "\n",
            "14. [Medium] What are some common distance metrics used in K-Nearest Neighbors?\n",
            "Answer: Some common distance metrics used in K-Nearest Neighbors include the Euclidean distance, Manhattan distance, Minkowski distance, and Mahalanobis distance. Each distance metric measures the similarity between data points in a different way, and the choice of distance metric depends on the nature of the data and the application at hand.\n",
            "\n",
            "15. [Hard] How can K-Nearest Neighbors be applied to image classification tasks?\n",
            "Answer: K-Nearest Neighbors can be applied to image classification tasks by representing each image as a vector of pixel intensities or features, such as color histograms or texture descriptors. Once the images are represented as vectors, they can be compared using a distance metric like Euclidean distance or Manhattan distance to find the k nearest neighbors, and the predicted class of the new image can be determined based on the majority vote among the k nearest neighbors. Alternatively, K-Nearest Neighbors can also be used for image retrieval tasks, where the goal is to find similar images based on their visual characteristics.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ABO-qH_snG76"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}