{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f889589a66e84b5887ec2a45c565e9e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a4e19a43f9294107970b3098b1be973d",
              "IPY_MODEL_13d7d5eeed054f629534d085e0924a04",
              "IPY_MODEL_bb6514740042411cb96927c95cdd196e"
            ],
            "layout": "IPY_MODEL_3a09afd8c55145089efa339074300545"
          }
        },
        "a4e19a43f9294107970b3098b1be973d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b38ce38479cd43fd92b9ecfa754f1ee4",
            "placeholder": "​",
            "style": "IPY_MODEL_e186658cd437404288b122512b7c88d6",
            "value": "modules.json: 100%"
          }
        },
        "13d7d5eeed054f629534d085e0924a04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48af50866a89493e9be1b116c50ee804",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d6eac0dbde0d4e7c9a6402e340fe21a5",
            "value": 349
          }
        },
        "bb6514740042411cb96927c95cdd196e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e66b9c4129d74f1d8e95f529cc066c98",
            "placeholder": "​",
            "style": "IPY_MODEL_57d8885c648642ae8bc6bacad7149368",
            "value": " 349/349 [00:00&lt;00:00, 24.7kB/s]"
          }
        },
        "3a09afd8c55145089efa339074300545": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b38ce38479cd43fd92b9ecfa754f1ee4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e186658cd437404288b122512b7c88d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48af50866a89493e9be1b116c50ee804": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6eac0dbde0d4e7c9a6402e340fe21a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e66b9c4129d74f1d8e95f529cc066c98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57d8885c648642ae8bc6bacad7149368": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9a59bfaba514a0880b07f75f2a0a99e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c77cca45577b4a18a05ba0153872476d",
              "IPY_MODEL_d7bf9bcc50db48f19481e32b4497f4e2",
              "IPY_MODEL_1af75a189a6749ac88c7f35df94b5dbc"
            ],
            "layout": "IPY_MODEL_85418daca3dc4360870e33637de6b26e"
          }
        },
        "c77cca45577b4a18a05ba0153872476d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91c5edfbff1644dfb80d28cba8fede30",
            "placeholder": "​",
            "style": "IPY_MODEL_142c45424f474e728baeb3bcfb6da978",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "d7bf9bcc50db48f19481e32b4497f4e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e53761401289434a82bc17fead79872b",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3828bcc8c3814882be351be82ed27976",
            "value": 116
          }
        },
        "1af75a189a6749ac88c7f35df94b5dbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32f66616ce5447718aa5d00024dc1a0c",
            "placeholder": "​",
            "style": "IPY_MODEL_c7ed8982e3d24c3994324a05c357dd3c",
            "value": " 116/116 [00:00&lt;00:00, 6.79kB/s]"
          }
        },
        "85418daca3dc4360870e33637de6b26e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91c5edfbff1644dfb80d28cba8fede30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "142c45424f474e728baeb3bcfb6da978": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e53761401289434a82bc17fead79872b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3828bcc8c3814882be351be82ed27976": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "32f66616ce5447718aa5d00024dc1a0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7ed8982e3d24c3994324a05c357dd3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73afb31a568e46a8bec41dbb310b1920": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_50698a61c63c4cd280ce7eabbac16e11",
              "IPY_MODEL_7295706c6c51419cbbce466aac7be50b",
              "IPY_MODEL_2083b3098e974a769c3cc4a821359f62"
            ],
            "layout": "IPY_MODEL_581c5dd00ffe47ec8d05ead6dc035dc7"
          }
        },
        "50698a61c63c4cd280ce7eabbac16e11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0124c477721b4c0da0538b158c6c5ec8",
            "placeholder": "​",
            "style": "IPY_MODEL_bb3bc0e51805485182a735442186d25f",
            "value": "README.md: 100%"
          }
        },
        "7295706c6c51419cbbce466aac7be50b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_972028063b2a4272ac2ef3ba4c4bf9b5",
            "max": 10659,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c9ea025e590d478890fa110a94a73d3d",
            "value": 10659
          }
        },
        "2083b3098e974a769c3cc4a821359f62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e390436fd1dc4d26a315e4fc65af7d07",
            "placeholder": "​",
            "style": "IPY_MODEL_ce15c035fd3c43feb640cb094f58637e",
            "value": " 10.7k/10.7k [00:00&lt;00:00, 980kB/s]"
          }
        },
        "581c5dd00ffe47ec8d05ead6dc035dc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0124c477721b4c0da0538b158c6c5ec8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb3bc0e51805485182a735442186d25f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "972028063b2a4272ac2ef3ba4c4bf9b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9ea025e590d478890fa110a94a73d3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e390436fd1dc4d26a315e4fc65af7d07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce15c035fd3c43feb640cb094f58637e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2044f63cd6914aefa00b9071eedeaa79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d7726a3eab0c41dfb59326588f52be1a",
              "IPY_MODEL_576703f1933e4e6aaea3509e7cebc098",
              "IPY_MODEL_14c0030827304bfd9a0dd08d0417e947"
            ],
            "layout": "IPY_MODEL_02ea4c13adab48039dbc2db0d5ef8546"
          }
        },
        "d7726a3eab0c41dfb59326588f52be1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c27fddfb3b94bcdbb799005c6a0e40d",
            "placeholder": "​",
            "style": "IPY_MODEL_1c8ea07d4b674e399e38fda3bcd30d38",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "576703f1933e4e6aaea3509e7cebc098": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97b47a73f7f543028423f703d1ad335c",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b1efb29b6d984d5896ddf908175272fd",
            "value": 53
          }
        },
        "14c0030827304bfd9a0dd08d0417e947": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f95ef1811201493e803fa045963a3a2a",
            "placeholder": "​",
            "style": "IPY_MODEL_543067b39e3d4e15a8ef9d2e049e0e28",
            "value": " 53.0/53.0 [00:00&lt;00:00, 3.84kB/s]"
          }
        },
        "02ea4c13adab48039dbc2db0d5ef8546": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c27fddfb3b94bcdbb799005c6a0e40d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c8ea07d4b674e399e38fda3bcd30d38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97b47a73f7f543028423f703d1ad335c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1efb29b6d984d5896ddf908175272fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f95ef1811201493e803fa045963a3a2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "543067b39e3d4e15a8ef9d2e049e0e28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db87af87b36148fb89aeec7b78787015": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a2cca778712c428da63f7aaa34ee003e",
              "IPY_MODEL_6b4c81eefe89450a8d7d3e73f90b2cff",
              "IPY_MODEL_e70954c695b04d22adf56b563b2efc82"
            ],
            "layout": "IPY_MODEL_66d04a0bde1e4ce7ad46a43ed2495c42"
          }
        },
        "a2cca778712c428da63f7aaa34ee003e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c44dfea863b4158a480a84b595a5dcc",
            "placeholder": "​",
            "style": "IPY_MODEL_ff7545d72fae4b60914bf6e81f003a7d",
            "value": "config.json: 100%"
          }
        },
        "6b4c81eefe89450a8d7d3e73f90b2cff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9f221a142094de28a7e43333fe279db",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_01b13a6294e74c669d77c2851c71708b",
            "value": 612
          }
        },
        "e70954c695b04d22adf56b563b2efc82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_324ef0bcb57240648634e49493f9bfc0",
            "placeholder": "​",
            "style": "IPY_MODEL_e4ee6ada7bf04e419cabb5fdf7b672d7",
            "value": " 612/612 [00:00&lt;00:00, 48.4kB/s]"
          }
        },
        "66d04a0bde1e4ce7ad46a43ed2495c42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c44dfea863b4158a480a84b595a5dcc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff7545d72fae4b60914bf6e81f003a7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9f221a142094de28a7e43333fe279db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01b13a6294e74c669d77c2851c71708b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "324ef0bcb57240648634e49493f9bfc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4ee6ada7bf04e419cabb5fdf7b672d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2bb60ee070843fbbcd577d46d7f0a8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5ac67891c0664928b67f20f6c73d2b69",
              "IPY_MODEL_94c56065bbc04766a10564493e85458e",
              "IPY_MODEL_c4ddc5588af940f490a4dcc01cf2e5d9"
            ],
            "layout": "IPY_MODEL_e4e1fa1e246242a7b618463f8d7b2ad8"
          }
        },
        "5ac67891c0664928b67f20f6c73d2b69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4604af01b7634262a90312fc109a450e",
            "placeholder": "​",
            "style": "IPY_MODEL_82e4e264f4e4495c95e0629fe0aec979",
            "value": "model.safetensors: 100%"
          }
        },
        "94c56065bbc04766a10564493e85458e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47daf7bb962f4db499bbf299f1472085",
            "max": 90868376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_18c3ea64594444a6b614609985d0b171",
            "value": 90868376
          }
        },
        "c4ddc5588af940f490a4dcc01cf2e5d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_853d8cfc21fe450eba62f6af4058dc3e",
            "placeholder": "​",
            "style": "IPY_MODEL_9c82afe3d6954ff98733ac339f7f0acb",
            "value": " 90.9M/90.9M [00:00&lt;00:00, 164MB/s]"
          }
        },
        "e4e1fa1e246242a7b618463f8d7b2ad8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4604af01b7634262a90312fc109a450e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82e4e264f4e4495c95e0629fe0aec979": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47daf7bb962f4db499bbf299f1472085": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18c3ea64594444a6b614609985d0b171": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "853d8cfc21fe450eba62f6af4058dc3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c82afe3d6954ff98733ac339f7f0acb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8abc28206354f6ba2eb3b4ee985f067": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_39db660d78aa47169352eb5b1404677c",
              "IPY_MODEL_9a0fc10673914e3fa67af87efb194d84",
              "IPY_MODEL_2eb054263d3b40cb9ca5adb475774513"
            ],
            "layout": "IPY_MODEL_8738d056b2ad487591dac8865b90b65c"
          }
        },
        "39db660d78aa47169352eb5b1404677c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cc742b07ef44d999f5580136f8c2bda",
            "placeholder": "​",
            "style": "IPY_MODEL_00f3f40e92aa46b883fe29755e34f859",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "9a0fc10673914e3fa67af87efb194d84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e2dc73023ef4ba08966d515a84d32e7",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_23b5d83c9406401e8d00ab73857864b8",
            "value": 350
          }
        },
        "2eb054263d3b40cb9ca5adb475774513": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b63b2d005c243edab2dfb546fd23992",
            "placeholder": "​",
            "style": "IPY_MODEL_1360228b849a465fb6efa32a5e9f7b18",
            "value": " 350/350 [00:00&lt;00:00, 26.4kB/s]"
          }
        },
        "8738d056b2ad487591dac8865b90b65c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cc742b07ef44d999f5580136f8c2bda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00f3f40e92aa46b883fe29755e34f859": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e2dc73023ef4ba08966d515a84d32e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23b5d83c9406401e8d00ab73857864b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5b63b2d005c243edab2dfb546fd23992": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1360228b849a465fb6efa32a5e9f7b18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d89b48980370451d974e38cd69bc8071": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_441906fea8e540b197ac40066d9a72bc",
              "IPY_MODEL_98f31f24ac254e5cb399b3372cc3f6a4",
              "IPY_MODEL_b697d86fc06042a1ada1e3a971f2152b"
            ],
            "layout": "IPY_MODEL_17550dc98dc14a7e8a16add2e7c5384f"
          }
        },
        "441906fea8e540b197ac40066d9a72bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38578a834e014434aba99a7a4e937b2f",
            "placeholder": "​",
            "style": "IPY_MODEL_39a1e8b9af4b458dab3cf79f4f22084c",
            "value": "vocab.txt: 100%"
          }
        },
        "98f31f24ac254e5cb399b3372cc3f6a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fe3d15411a6481fb55efe165139becc",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b0dc5380b27a43a2a22da9271f96376b",
            "value": 231508
          }
        },
        "b697d86fc06042a1ada1e3a971f2152b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7d25e8bfa904d148ebb30fbd3bb7eba",
            "placeholder": "​",
            "style": "IPY_MODEL_2b118cd3813f49a48fee961787b0bb64",
            "value": " 232k/232k [00:00&lt;00:00, 1.76MB/s]"
          }
        },
        "17550dc98dc14a7e8a16add2e7c5384f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38578a834e014434aba99a7a4e937b2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39a1e8b9af4b458dab3cf79f4f22084c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8fe3d15411a6481fb55efe165139becc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0dc5380b27a43a2a22da9271f96376b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a7d25e8bfa904d148ebb30fbd3bb7eba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b118cd3813f49a48fee961787b0bb64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3e3fe055a3d4db99901b2d267ec45c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ae2facbfc1394a7b98257e9d56f51700",
              "IPY_MODEL_f0b57c514a194ae1939d603f247a2aea",
              "IPY_MODEL_503f70732b104d2a89597df75c5b66ab"
            ],
            "layout": "IPY_MODEL_5cb605762daf4ad29c849df839d43262"
          }
        },
        "ae2facbfc1394a7b98257e9d56f51700": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94f0901ff41d47468a5833b63a4f6829",
            "placeholder": "​",
            "style": "IPY_MODEL_b4657a15e71d46fb8e46a91e80729170",
            "value": "tokenizer.json: 100%"
          }
        },
        "f0b57c514a194ae1939d603f247a2aea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_324cb6a4cf6f451396a4be813cd9d5c3",
            "max": 466247,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_21f0a366c9f1496b92ca5c0021cf98a1",
            "value": 466247
          }
        },
        "503f70732b104d2a89597df75c5b66ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c3ba4510ed542438a86b47192fce0a6",
            "placeholder": "​",
            "style": "IPY_MODEL_7abd6ddaccb04906b5c6df4742562357",
            "value": " 466k/466k [00:00&lt;00:00, 3.44MB/s]"
          }
        },
        "5cb605762daf4ad29c849df839d43262": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94f0901ff41d47468a5833b63a4f6829": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4657a15e71d46fb8e46a91e80729170": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "324cb6a4cf6f451396a4be813cd9d5c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21f0a366c9f1496b92ca5c0021cf98a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5c3ba4510ed542438a86b47192fce0a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7abd6ddaccb04906b5c6df4742562357": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aede8442e4cf4f51ab4c1a5fd5f1b345": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7d18eae2077a4f958965601825bbcaa8",
              "IPY_MODEL_4723c64bc6ce47c29ed5dc6dfa6d87a2",
              "IPY_MODEL_afe63d18049d4fe9b4954df73f37e47a"
            ],
            "layout": "IPY_MODEL_8e966e74fdb745e685e0d8aba36bd828"
          }
        },
        "7d18eae2077a4f958965601825bbcaa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c619234850b144a981b959fa0b72053d",
            "placeholder": "​",
            "style": "IPY_MODEL_afcd0afdc90640dba629a5849f5a2af4",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "4723c64bc6ce47c29ed5dc6dfa6d87a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80025e47373d4a75ba8345e63852c356",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_05f077952164403d9d01424f2cb718b4",
            "value": 112
          }
        },
        "afe63d18049d4fe9b4954df73f37e47a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11636982a5044d008951c77a471e6b6c",
            "placeholder": "​",
            "style": "IPY_MODEL_87cce7e8f526463385e3fe6962b21ada",
            "value": " 112/112 [00:00&lt;00:00, 5.52kB/s]"
          }
        },
        "8e966e74fdb745e685e0d8aba36bd828": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c619234850b144a981b959fa0b72053d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afcd0afdc90640dba629a5849f5a2af4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80025e47373d4a75ba8345e63852c356": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05f077952164403d9d01424f2cb718b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "11636982a5044d008951c77a471e6b6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87cce7e8f526463385e3fe6962b21ada": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fde0166c472d49dfad7ba5e869bfd552": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_815244a1f8d441b28faba990f6987078",
              "IPY_MODEL_89ab681d4d594b04a7c3b5e51d7f2dd2",
              "IPY_MODEL_7bc25538516c44538cb377d040b04adf"
            ],
            "layout": "IPY_MODEL_95322b7dea094dd4ad914f88aae3da78"
          }
        },
        "815244a1f8d441b28faba990f6987078": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d6a25bb68ed463c896e12eef3be6a10",
            "placeholder": "​",
            "style": "IPY_MODEL_83a2b75a338b454e806e64c0373460b1",
            "value": "1_Pooling/config.json: 100%"
          }
        },
        "89ab681d4d594b04a7c3b5e51d7f2dd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7234787e66e34683a90be5a91cc6ebe1",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7de57f84cc1649f2bc6f1e58afa0b0fb",
            "value": 190
          }
        },
        "7bc25538516c44538cb377d040b04adf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1814926db6f14d51aad257afdff946d6",
            "placeholder": "​",
            "style": "IPY_MODEL_ea57bc21eb1f463b9b8de4fe735763b9",
            "value": " 190/190 [00:00&lt;00:00, 12.2kB/s]"
          }
        },
        "95322b7dea094dd4ad914f88aae3da78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d6a25bb68ed463c896e12eef3be6a10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83a2b75a338b454e806e64c0373460b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7234787e66e34683a90be5a91cc6ebe1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7de57f84cc1649f2bc6f1e58afa0b0fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1814926db6f14d51aad257afdff946d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea57bc21eb1f463b9b8de4fe735763b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f889589a66e84b5887ec2a45c565e9e4",
            "a4e19a43f9294107970b3098b1be973d",
            "13d7d5eeed054f629534d085e0924a04",
            "bb6514740042411cb96927c95cdd196e",
            "3a09afd8c55145089efa339074300545",
            "b38ce38479cd43fd92b9ecfa754f1ee4",
            "e186658cd437404288b122512b7c88d6",
            "48af50866a89493e9be1b116c50ee804",
            "d6eac0dbde0d4e7c9a6402e340fe21a5",
            "e66b9c4129d74f1d8e95f529cc066c98",
            "57d8885c648642ae8bc6bacad7149368",
            "e9a59bfaba514a0880b07f75f2a0a99e",
            "c77cca45577b4a18a05ba0153872476d",
            "d7bf9bcc50db48f19481e32b4497f4e2",
            "1af75a189a6749ac88c7f35df94b5dbc",
            "85418daca3dc4360870e33637de6b26e",
            "91c5edfbff1644dfb80d28cba8fede30",
            "142c45424f474e728baeb3bcfb6da978",
            "e53761401289434a82bc17fead79872b",
            "3828bcc8c3814882be351be82ed27976",
            "32f66616ce5447718aa5d00024dc1a0c",
            "c7ed8982e3d24c3994324a05c357dd3c",
            "73afb31a568e46a8bec41dbb310b1920",
            "50698a61c63c4cd280ce7eabbac16e11",
            "7295706c6c51419cbbce466aac7be50b",
            "2083b3098e974a769c3cc4a821359f62",
            "581c5dd00ffe47ec8d05ead6dc035dc7",
            "0124c477721b4c0da0538b158c6c5ec8",
            "bb3bc0e51805485182a735442186d25f",
            "972028063b2a4272ac2ef3ba4c4bf9b5",
            "c9ea025e590d478890fa110a94a73d3d",
            "e390436fd1dc4d26a315e4fc65af7d07",
            "ce15c035fd3c43feb640cb094f58637e",
            "2044f63cd6914aefa00b9071eedeaa79",
            "d7726a3eab0c41dfb59326588f52be1a",
            "576703f1933e4e6aaea3509e7cebc098",
            "14c0030827304bfd9a0dd08d0417e947",
            "02ea4c13adab48039dbc2db0d5ef8546",
            "6c27fddfb3b94bcdbb799005c6a0e40d",
            "1c8ea07d4b674e399e38fda3bcd30d38",
            "97b47a73f7f543028423f703d1ad335c",
            "b1efb29b6d984d5896ddf908175272fd",
            "f95ef1811201493e803fa045963a3a2a",
            "543067b39e3d4e15a8ef9d2e049e0e28",
            "db87af87b36148fb89aeec7b78787015",
            "a2cca778712c428da63f7aaa34ee003e",
            "6b4c81eefe89450a8d7d3e73f90b2cff",
            "e70954c695b04d22adf56b563b2efc82",
            "66d04a0bde1e4ce7ad46a43ed2495c42",
            "5c44dfea863b4158a480a84b595a5dcc",
            "ff7545d72fae4b60914bf6e81f003a7d",
            "c9f221a142094de28a7e43333fe279db",
            "01b13a6294e74c669d77c2851c71708b",
            "324ef0bcb57240648634e49493f9bfc0",
            "e4ee6ada7bf04e419cabb5fdf7b672d7",
            "b2bb60ee070843fbbcd577d46d7f0a8c",
            "5ac67891c0664928b67f20f6c73d2b69",
            "94c56065bbc04766a10564493e85458e",
            "c4ddc5588af940f490a4dcc01cf2e5d9",
            "e4e1fa1e246242a7b618463f8d7b2ad8",
            "4604af01b7634262a90312fc109a450e",
            "82e4e264f4e4495c95e0629fe0aec979",
            "47daf7bb962f4db499bbf299f1472085",
            "18c3ea64594444a6b614609985d0b171",
            "853d8cfc21fe450eba62f6af4058dc3e",
            "9c82afe3d6954ff98733ac339f7f0acb",
            "c8abc28206354f6ba2eb3b4ee985f067",
            "39db660d78aa47169352eb5b1404677c",
            "9a0fc10673914e3fa67af87efb194d84",
            "2eb054263d3b40cb9ca5adb475774513",
            "8738d056b2ad487591dac8865b90b65c",
            "0cc742b07ef44d999f5580136f8c2bda",
            "00f3f40e92aa46b883fe29755e34f859",
            "2e2dc73023ef4ba08966d515a84d32e7",
            "23b5d83c9406401e8d00ab73857864b8",
            "5b63b2d005c243edab2dfb546fd23992",
            "1360228b849a465fb6efa32a5e9f7b18",
            "d89b48980370451d974e38cd69bc8071",
            "441906fea8e540b197ac40066d9a72bc",
            "98f31f24ac254e5cb399b3372cc3f6a4",
            "b697d86fc06042a1ada1e3a971f2152b",
            "17550dc98dc14a7e8a16add2e7c5384f",
            "38578a834e014434aba99a7a4e937b2f",
            "39a1e8b9af4b458dab3cf79f4f22084c",
            "8fe3d15411a6481fb55efe165139becc",
            "b0dc5380b27a43a2a22da9271f96376b",
            "a7d25e8bfa904d148ebb30fbd3bb7eba",
            "2b118cd3813f49a48fee961787b0bb64",
            "e3e3fe055a3d4db99901b2d267ec45c6",
            "ae2facbfc1394a7b98257e9d56f51700",
            "f0b57c514a194ae1939d603f247a2aea",
            "503f70732b104d2a89597df75c5b66ab",
            "5cb605762daf4ad29c849df839d43262",
            "94f0901ff41d47468a5833b63a4f6829",
            "b4657a15e71d46fb8e46a91e80729170",
            "324cb6a4cf6f451396a4be813cd9d5c3",
            "21f0a366c9f1496b92ca5c0021cf98a1",
            "5c3ba4510ed542438a86b47192fce0a6",
            "7abd6ddaccb04906b5c6df4742562357",
            "aede8442e4cf4f51ab4c1a5fd5f1b345",
            "7d18eae2077a4f958965601825bbcaa8",
            "4723c64bc6ce47c29ed5dc6dfa6d87a2",
            "afe63d18049d4fe9b4954df73f37e47a",
            "8e966e74fdb745e685e0d8aba36bd828",
            "c619234850b144a981b959fa0b72053d",
            "afcd0afdc90640dba629a5849f5a2af4",
            "80025e47373d4a75ba8345e63852c356",
            "05f077952164403d9d01424f2cb718b4",
            "11636982a5044d008951c77a471e6b6c",
            "87cce7e8f526463385e3fe6962b21ada",
            "fde0166c472d49dfad7ba5e869bfd552",
            "815244a1f8d441b28faba990f6987078",
            "89ab681d4d594b04a7c3b5e51d7f2dd2",
            "7bc25538516c44538cb377d040b04adf",
            "95322b7dea094dd4ad914f88aae3da78",
            "3d6a25bb68ed463c896e12eef3be6a10",
            "83a2b75a338b454e806e64c0373460b1",
            "7234787e66e34683a90be5a91cc6ebe1",
            "7de57f84cc1649f2bc6f1e58afa0b0fb",
            "1814926db6f14d51aad257afdff946d6",
            "ea57bc21eb1f463b9b8de4fe735763b9"
          ]
        },
        "id": "PdnyXBOLlwUr",
        "outputId": "451bc003-5485-4f51-f4f2-7867e1749457"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/460.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m460.6/460.6 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.7/412.7 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 18 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 696 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.6 [186 kB]\n",
            "Fetched 186 kB in 1s (196 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 124950 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.6_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.6) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.6) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 18 not upgraded.\n",
            "Need to get 4,816 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Fetched 4,816 kB in 2s (2,893 kB/s)\n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 124980 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2024.12.14)\n",
            "Collecting python-pptx\n",
            "  Downloading python_pptx-1.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (11.1.0)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx)\n",
            "  Downloading XlsxWriter-3.2.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (5.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (4.12.2)\n",
            "Downloading python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading XlsxWriter-3.2.2-py3-none-any.whl (165 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.1/165.1 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: XlsxWriter, python-pptx\n",
            "Successfully installed XlsxWriter-3.2.2 python-pptx-1.0.2\n",
            "Collecting gensim==3.8.3\n",
            "  Downloading gensim-3.8.3.tar.gz (23.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.4/23.4 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.11/dist-packages (from gensim==3.8.3) (1.26.4)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.11/dist-packages (from gensim==3.8.3) (1.13.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from gensim==3.8.3) (1.17.0)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim==3.8.3) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart_open>=1.8.1->gensim==3.8.3) (1.17.2)\n",
            "Building wheels for collected packages: gensim\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for gensim (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for gensim\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for gensim\n",
            "Failed to build gensim\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (gensim)\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting keybert\n",
            "  Downloading keybert-0.8.5-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from keybert) (1.26.4)\n",
            "Requirement already satisfied: rich>=10.4.0 in /usr/local/lib/python3.11/dist-packages (from keybert) (13.9.4)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.11/dist-packages (from keybert) (1.6.1)\n",
            "Requirement already satisfied: sentence-transformers>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from keybert) (3.3.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.4.0->keybert) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.4.0->keybert) (2.18.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.2->keybert) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.2->keybert) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.2->keybert) (3.5.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.3.8->keybert) (4.47.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.3.8->keybert) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.3.8->keybert) (2.5.1+cu124)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.3.8->keybert) (0.27.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.3.8->keybert) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (4.12.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.4.0->keybert) (0.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (0.5.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2024.12.14)\n",
            "Downloading keybert-0.8.5-py3-none-any.whl (37 kB)\n",
            "Installing collected packages: keybert\n",
            "Successfully installed keybert-0.8.5\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2024.12.14)\n",
            "Collecting google_images_download\n",
            "  Downloading google_images_download-2.8.0.tar.gz (14 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting selenium (from google_images_download)\n",
            "  Downloading selenium-4.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium->google_images_download) (2.3.0)\n",
            "Collecting trio~=0.17 (from selenium->google_images_download)\n",
            "  Downloading trio-0.28.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting trio-websocket~=0.9 (from selenium->google_images_download)\n",
            "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.11/dist-packages (from selenium->google_images_download) (2024.12.14)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.11/dist-packages (from selenium->google_images_download) (4.12.2)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.11/dist-packages (from selenium->google_images_download) (1.8.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium->google_images_download) (25.1.0)\n",
            "Collecting sortedcontainers (from trio~=0.17->selenium->google_images_download)\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium->google_images_download) (3.10)\n",
            "Collecting outcome (from trio~=0.17->selenium->google_images_download)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium->google_images_download) (1.3.1)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium->google_images_download)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium->google_images_download) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium->google_images_download) (0.14.0)\n",
            "Downloading selenium-4.28.1-py3-none-any.whl (9.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio-0.28.0-py3-none-any.whl (486 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.3/486.3 kB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
            "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Building wheels for collected packages: google_images_download\n",
            "  Building wheel for google_images_download (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google_images_download: filename=google_images_download-2.8.0-py2.py3-none-any.whl size=14537 sha256=8df0e5878247863a53072ff72d564a8836f2a8b0dcd4cba643d4bb5ece5b6a97\n",
            "  Stored in directory: /root/.cache/pip/wheels/dc/83/37/7303b15f3e8a5bfbd5c7ebbfe13f0c666ada6f8efecc6d77ec\n",
            "Successfully built google_images_download\n",
            "Installing collected packages: sortedcontainers, wsproto, outcome, trio, trio-websocket, selenium, google_images_download\n",
            "Successfully installed google_images_download-2.8.0 outcome-1.3.0.post0 selenium-4.28.1 sortedcontainers-2.4.0 trio-0.28.0 trio-websocket-0.11.1 wsproto-1.2.0\n",
            "Collecting google-search-results\n",
            "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from google-search-results) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (2024.12.14)\n",
            "Building wheels for collected packages: google-search-results\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32009 sha256=00de501ed481fd92eb7ef8f3a7d9c5678f5642e7bbd76c66e9cb4f92d49a834f\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/42/3e/aeb691b02cb7175ec70e2da04b5658d4739d2b41e5f73cd06f\n",
            "Successfully built google-search-results\n",
            "Installing collected packages: google-search-results\n",
            "Successfully installed google-search-results-2.4.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f889589a66e84b5887ec2a45c565e9e4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e9a59bfaba514a0880b07f75f2a0a99e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "73afb31a568e46a8bec41dbb310b1920"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2044f63cd6914aefa00b9071eedeaa79"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "db87af87b36148fb89aeec7b78787015"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b2bb60ee070843fbbcd577d46d7f0a8c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c8abc28206354f6ba2eb3b4ee985f067"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d89b48980370451d974e38cd69bc8071"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e3e3fe055a3d4db99901b2d267ec45c6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aede8442e4cf4f51ab4c1a5fd5f1b345"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fde0166c472d49dfad7ba5e869bfd552"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "<ipython-input-1-f1bbd73c38d2>:36: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/244.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.8/244.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/85.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade langchain openai  -q\n",
        "!pip install sentence_transformers -q\n",
        "!apt-get install poppler-utils\n",
        "!apt-get install -y tesseract-ocr\n",
        "!pip install -U langchain-community -q\n",
        "!pip install pillow\n",
        "!pip install requests\n",
        "!pip install python-pptx\n",
        "!pip install gensim==3.8.3\n",
        "!pip install keybert\n",
        "!pip install requests Pillow\n",
        "!pip install google_images_download\n",
        "!pip install google-search-results\n",
        "from pptx import Presentation\n",
        "from pptx.util import Pt, Inches\n",
        "from PIL import Image\n",
        "import random\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "from io import BytesIO\n",
        "import requests\n",
        "# Download necessary NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Initialize KeyBERT\n",
        "from keybert import KeyBERT\n",
        "kw_model = KeyBERT()\n",
        "\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "from langchain.embeddings import SentenceTransformerEmbeddings\n",
        "embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "!pip install pinecone-client -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import getpass\n",
        "import os\n",
        "import time\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "from langchain.embeddings import SentenceTransformerEmbeddings\n",
        "from langchain.vectorstores import Pinecone as LangchainPinecone\n",
        "\n",
        "#074e0d9a-ab5e-48bf-8eae-9effae335521              This is the API to MYDB Insert this\n",
        "\n",
        "# Prompt for Pinecone API key if not set in the environment\n",
        "if not os.getenv(\"PINECONE_API_KEY\"):\n",
        "    os.environ[\"PINECONE_API_KEY\"] = getpass.getpass(\"Enter your Pinecone API key: \")\n",
        "\n",
        "# Retrieve the Pinecone API key from environment variables\n",
        "pinecone_api_key = os.environ.get(\"PINECONE_API_KEY\")\n",
        "\n",
        "# Initialize Pinecone\n",
        "pc = Pinecone(api_key=pinecone_api_key)\n",
        "\n",
        "# Define your index name\n",
        "index_name = \"newdata\"  # Change if desired\n",
        "\n",
        "# Check for existing indexes\n",
        "existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
        "\n",
        "# Create the index if it does not exist\n",
        "if index_name not in existing_indexes:\n",
        "    pc.create_index(\n",
        "        name=index_name,\n",
        "        dimension=384,  # Adjust this to match your embeddings' dimension\n",
        "        metric=\"cosine\",\n",
        "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
        "    )\n",
        "\n",
        "    # Wait until the index is ready\n",
        "    while not pc.describe_index(index_name).status[\"ready\"]:\n",
        "        print(\"Waiting for the index to be ready...\")\n",
        "        time.sleep(1)\n",
        "\n",
        "# Connect to the index\n",
        "index = pc.Index(index_name)\n",
        "\n",
        "# Print connection success message\n",
        "print(f\"Successfully connected to the index: {index_name}\")\n",
        "\n",
        "\n",
        "# Now create a Pinecone index for Langchain using the existing index\n",
        "langchain_index = LangchainPinecone.from_existing_index(\n",
        "    index_name=index_name,\n",
        "    embedding=embeddings\n",
        "\n",
        ")\n",
        "\n",
        "# Output to verify the index creation\n",
        "print(f\"Successfully created or connected to the Langchain index: {langchain_index}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXOif7Tel1UO",
        "outputId": "2274e2d9-637b-4c06-8d31-55549adbaba9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your Pinecone API key: ··········\n",
            "Successfully connected to the index: newdata\n",
            "Successfully created or connected to the Langchain index: <langchain_community.vectorstores.pinecone.Pinecone object at 0x782b9cebde10>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_similar_docs(query, k=20, score=True):\n",
        "    if score:\n",
        "        similar_docs = langchain_index.similarity_search_with_score(query, k=k)  # Use langchain_index\n",
        "    else:\n",
        "        similar_docs = langchain_index.similarity_search(query, k=k)  # Use langchain_index\n",
        "    return similar_docs"
      ],
      "metadata": {
        "id": "uEB5pVkNl1Qw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# **\n",
        "import os\n",
        "import requests\n",
        "\n",
        "# Set the Hugging Face API key directly inside the script\n",
        "HUGGINGFACE_API_TOKEN = \"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\"  # Replace with your actual API key\n",
        "\n",
        "# Define the model name\n",
        "model_name = \"mistralai/Mistral-7B-Instruct-v0.3\"  # Replace with your chosen model\n",
        "\n",
        "# Construct the API URL\n",
        "HUGGINGFACE_API_URL = f\"https://api-inference.huggingface.co/models/{model_name}\"\n",
        "\n",
        "# Set up the headers with the authorization token\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {HUGGINGFACE_API_TOKEN}\"\n",
        "}\n",
        "\n",
        "# Example query\n",
        "query = \"LSTM\"\n",
        "\n",
        "# Assuming you have a function `get_similar_docs` defined\n",
        "similar_docs = get_similar_docs(query)\n",
        "\n",
        "# Prepare the context from similar_docs\n",
        "context = \"\\n\\n\".join([doc[0].page_content for doc in similar_docs])\n",
        "\n",
        "prompt = f'''\n",
        "Context: {context}\n",
        "Question: {query}\n",
        "\n",
        "Provide a comprehensive explanation strictly following this structure. Always use \"##\" to introduce each section:\n",
        "\n",
        "## 1. *Concept Overview*\n",
        "  • Core definition and purpose\n",
        "  • Key principles\n",
        "  • Relationship to broader computing concepts\n",
        "\n",
        "## 2. *Technical Components*\n",
        "  • Primary elements and their roles\n",
        "  • Relationships and interactions\n",
        "  • Implementation details\n",
        "  • Core algorithms/procedures (if applicable)\n",
        "\n",
        "## 3. *Working Mechanism*\n",
        "  • Step-by-step operational flow\n",
        "  • Critical processes and transformations\n",
        "  • Resource management (if applicable)\n",
        "  • Exception handling (if applicable)\n",
        "\n",
        "## 4. *Implementation Example*\n",
        "  • Use case scenario\n",
        "  • Code implementation or technical design\n",
        "  • Step-by-step execution\n",
        "  • Output analysis\n",
        "\n",
        "## 5. *Best Practices*\n",
        "  • Design considerations\n",
        "  • Optimization techniques\n",
        "  • Common pitfalls\n",
        "  • Performance implications\n",
        "\n",
        "## 6. *Applications*\n",
        "  • Real-world use cases\n",
        "  • Industry applications\n",
        "  • Integration patterns\n",
        "  • Variations and alternatives\n",
        "\n",
        "## 7. *Evaluation*\n",
        "  • Performance metrics\n",
        "  • Testing approaches\n",
        "  • Debugging strategies\n",
        "  • Optimization opportunities\n",
        "\n",
        "## 8. *Practice Problems*\n",
        "  • Concept verification questions\n",
        "  • Implementation challenges\n",
        "  • Problem-solving scenarios\n",
        "  • Solutions with explanations\n",
        "\n",
        "### Format Requirements:\n",
        "- Always use \"##\" to introduce each section header. Avoid using any other format.\n",
        "- Use bullet points for clarity\n",
        "- Show all mathematical steps using proper equation formatting ($...$)\n",
        "- Include clear variable definitions after each equation\n",
        "- Write formulas using LaTeX formatting inside $...$\n",
        "- For matrices use: $\\begin{{bmatrix}} a & b \\\\ c & d \\end{{bmatrix}}$\n",
        "- For fractions use: $\\frac{{numerator}}{{denominator}}$\n",
        "- Use ■ for numbered equations and • for regular points\n",
        "- Demonstrate practical interpretation\n",
        "- Connect to real applications\n",
        "\n",
        "### Equation Guidelines:\n",
        "- Enclose equations in $...$ format\n",
        "- Use proper LaTeX notation for mathematical expressions\n",
        "- Use $\\sum$ for summations\n",
        "- Define each variable after presenting equations\n",
        "- Number important equations using ■\n",
        "- Show step-by-step derivations with clear explanations\n",
        "\n",
        "### Code Guidelines:\n",
        "- Use LaTeX verbatim environment for code blocks:\n",
        "  \\begin{{verbatim}}\n",
        "  code here\n",
        "  \\end{{verbatim}}\n",
        "\n",
        "- For inline code use \\texttt{{code}}\n",
        "- For syntax highlighting:\n",
        "  \\begin{{lstlisting}}[language=Python]\n",
        "  code here\n",
        "  \\end{{lstlisting}}\n",
        "- Include comments explaining code functionality\n",
        "- Show output examples where applicable\n",
        "'''\n",
        "\n",
        "\n",
        "# Function to query Hugging Face Inference API\n",
        "def query_huggingface_api(prompt, max_length=25000):\n",
        "    payload = {\n",
        "        \"inputs\": prompt,\n",
        "        \"parameters\": {\n",
        "            \"max_new_tokens\": max_length,\n",
        "            \"temperature\": 0.5,\n",
        "            \"top_p\": 0.7,\n",
        "            \"top_k\": 50,\n",
        "            \"repetition_penalty\": 1.1,\n",
        "            \"do_sample\": True,\n",
        "            \"stop\": [\"<|endoftext|>\"]\n",
        "        }\n",
        "     }\n",
        "\n",
        "    response = requests.post(\n",
        "        HUGGINGFACE_API_URL,\n",
        "        headers=headers,\n",
        "        json=payload\n",
        "    )\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        #print(response.json())\n",
        "        return response.json()\n",
        "    else:\n",
        "        raise Exception(\n",
        "            f\"Request failed with status code {response.status_code}: {response.text}\"\n",
        "        )\n",
        "\n",
        "# Function to extract answer from API response\n",
        "def extract_answer(api_response):\n",
        "    if isinstance(api_response, list) and len(api_response) > 0:\n",
        "        generated_text = api_response[0].get('generated_text', '')\n",
        "\n",
        "        answer = generated_text.split(\"Answer:\")[-1].strip() if \"Answer:\" in generated_text else generated_text.strip()\n",
        "        if len(answer) > 30000:\n",
        "            answer = answer[:30000] + \"...\"\n",
        "        return answer\n",
        "    else:\n",
        "        return \"No answer generated.\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Generate the answer using Hugging Face Inference API\n",
        "try:\n",
        "    api_response = query_huggingface_api(prompt, max_length=25000)\n",
        "    answer = extract_answer(api_response)\n",
        "    print(\"Answer:\", answer)\n",
        "except Exception as e:\n",
        "    print(\"Error:\", str(e))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bC1pi0QOl1OH",
        "outputId": "5b789d1a-270b-4d1d-c76d-e05f066d7965"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: Context: BIBLIOGRAPHY  Graves, . . Sequence transduction  recurrent neural networks.   . Graves, .  . Jaitly . Towards  speech recognition  recurrent neural networks.   , . . Graves, .  . Schmidhuber . Framewise phoneme classiﬁcation  bidirec tional   other neural network architectures. Neural Networks  , .\n",
            "\n",
            "  vector hmthis information  represented.   limitation   informa   attenuated  repeated application   squashing function . short memories LSTMs, described below,   variant    address  issue,   memory cells  propagate information through  sequence without applying  linearities Hochreiter  Schmidhuber, .  denominator  Equation .   computational bottleneck, because  involves\n",
            "\n",
            "Recurrent neural networks   introduced     language model  technique,  which  context  token  summarized   recurrentlyupdated vector, ,,   ,,..., wherexmis  vector embedding   token wmand  function gdeﬁnes  recur rence.  starting condition   additional parameter   model.   short  memory     complex recurrence,  which  memory   through \n",
            "\n",
            " . LANGUAGE MODELS              Figure .   short memory  architecture. Gates  shown  boxes  dotted edges.    language model,  hmwould    predict   wordwm.  gates  functions   input  previous hidden state.   computed  elementwise sigmoid activations,   , ensuring  their values\n",
            "\n",
            "BIBLIOGRAPHY  , .  . Bansal .  relation extraction using lstms  sequences   structures.   , . . , .  . Hinton . Three  graphical models  statistical language  elling.  Proceedings   International Conference  Machine Learning  , .  . , .  . . Hinton .  scalable hierarchical distributed language model.  Neural Information Processing Systems  , . .\n",
            "\n",
            "sentations  vector space.  Proceedings  International Conference  Learning Represen tations . Mikolov, ., . Deoras, . Povey, . Burget,  . Cernocky . Strategies  training large scale neural network language models.  Proceedings   Workshop  Automatic Speech Recognition  Understanding  , . . Mikolov, ., . Karaﬁ , . Burget, . Cernock ,  . Khudanpur . Recurrent neural network based language model.  INTERSPEECH , . .\n",
            "\n",
            ".. Convolutional Neural Networks  Sequence Labeling  disadvantage  recurrent neural networks    architecture requires iterating through  sequence  inputs  predictions  hidden vector hmmust   puted   previous hidden vector , before predicting   . These iterative computations  difﬁcult  parallelize,    exploit  speedups offered  graph  processing units   operations   matrix multiplication. Convolutional\n",
            "\n",
            " baseline   implemented   neural architecture, using  attention  anism .., which scores  similarity   query      source    ., .      encode  passage   query , using  bidirectional LSTMs  .. BiLSTM   . BiLSTM  . .  query  represented  vertically concatenating   states   right  right passes \n",
            "\n",
            ".. RECURRENT NEURAL NETWORK LANGUAGE MODELS  derivatives automatically,  cache   future .  important distinction   feedforward neural networks considered         computa  graph   ,  varies   length   input.  poses difﬁculties  toolkits   designed around static computation graphs,   TensorFlow Abadi  ., . .. Hyperparameters\n",
            "\n",
            " incorporating  inner product   approximation   likelihood    ,   possible  estimate  parameters  backpropagation.   Mikolov  .,  includes   approximations continuous words   skipgrams. .. Continuous words   recurrent neural network language models,    conditioned   recurrently updated state vector, which  based   representations going      \n",
            "\n",
            ".. RECURRENT NEURAL NETWORK LANGUAGE MODELS    sequence.  language models  deﬁned,  .  , . ,,...,  , . whereφis  matrix   embeddings , andxmdenotes  embedding   .  conversion  wmtoxmis sometimes known   lookup layer , because  simply lookup  embeddings      table  ...  Elman  deﬁnes  simple recurrent operation Elman, ,\n",
            "\n",
            "whereδ   indicator function, taking  value      record   identical   target  .  probability  copying record rfrom  source ,  product    probability   local attention.     model,  attention weights αmare computed   previous decoder state .  computation graph therefore remains  feedforward network,  recurrent paths      .\n",
            "\n",
            " operator  elementwise Hadamard product.    controlled      weights, which parametrize  previous hidden state ..,    current input .., ,   vector offset .., .  overall operation   infor mally summarized  ,   ,,,  ,representing   state after reading token .   outperforms standard recurrent neural networks across   range \n",
            "\n",
            " . APPLICATIONS  SEQUENCE LABELING   predict labels      ONSTART   character.  recent   employed neural network architectures.  example,   .      architecture,  described  .  construct  trellis,  which    scored according   hidden state   ,   transitions  scored according  learned transition weights.  scoring segmentation   computed  \n",
            "\n",
            "beginning   source   greatest impact   encoding ,  therefore impact  words   beginning   target sentence. Later     vanced encoding models,   neural attention ..,  eliminated    reversing  source sentence.  encoder  decoder   implemented   LSTMs ,  multiple layers  hidden states.  shown  Figure .,  hidden state ,  layeriis treated\n",
            "\n",
            "epochs batches   sentences, chosen   similar length    sentence   batch   roughly   amount    process gradi  clipping ..  ensure      gradient never exceeds  predeﬁned value. .. Neural attention  sequencesequence model discussed   previous section   radical depar   statistical machine translation,  which    phrase   target \n",
            "\n",
            "brenner  Blunsom     . ,  strong empirical results.  models  recurrent   utterance level,    complete utterance updates  hidden state.  recurrentconvolutional network  Kalchbrenner  Blunsom   convolu   obtain  representation   individual utterance, while   .    second level  recurrence,  individual words.  enables their method   \n",
            "\n",
            ".. NEURAL SEQUENCE LABELING   practice, numerical stability demands       domain, logαm    logsm,  logαm . logβm    logsm,  logβm . .  application   forward  backward probabilities  shown  Figure ..   forward  backward recurrences operate   trellis, which implies  space complexityO. Because  recurrences require computing    Kterms \n",
            "\n",
            "tentional encoderdecoder translation model discussed  ..   ., .  longer sentence  encoded   sequence  vectors,    token.  decoder  computes attention  these vectors  updating   recurrent state.    generation,    useful  augment  encoderdecoder model   ability   words directly   source.   .  train  model \n",
            "\n",
            " Morphology  Syntax , Volume   Synthesis Lectures  Human Language Technolo . Morgan  Claypool Publishers. Bengio, ., . Vinyals, . Jaitly,  . Shazeer . Scheduled sampling  sequence prediction  recurrent neural networks.   , . . Bengio, ., . Ducharme,  . Vincent,  . Janvin .  neural probabilistic language model.  Journal  Machine Learning Research  , .\n",
            "Question: LSTM\n",
            "\n",
            "Provide a comprehensive explanation strictly following this structure. Always use \"##\" to introduce each section:\n",
            "\n",
            "## 1. *Concept Overview*\n",
            "  • Core definition and purpose\n",
            "  • Key principles\n",
            "  • Relationship to broader computing concepts\n",
            "\n",
            "## 2. *Technical Components*\n",
            "  • Primary elements and their roles\n",
            "  • Relationships and interactions\n",
            "  • Implementation details\n",
            "  • Core algorithms/procedures (if applicable)\n",
            "\n",
            "## 3. *Working Mechanism*\n",
            "  • Step-by-step operational flow\n",
            "  • Critical processes and transformations\n",
            "  • Resource management (if applicable)\n",
            "  • Exception handling (if applicable)\n",
            "\n",
            "## 4. *Implementation Example*\n",
            "  • Use case scenario\n",
            "  • Code implementation or technical design\n",
            "  • Step-by-step execution\n",
            "  • Output analysis\n",
            "\n",
            "## 5. *Best Practices*\n",
            "  • Design considerations\n",
            "  • Optimization techniques\n",
            "  • Common pitfalls\n",
            "  • Performance implications\n",
            "\n",
            "## 6. *Applications*\n",
            "  • Real-world use cases\n",
            "  • Industry applications\n",
            "  • Integration patterns\n",
            "  • Variations and alternatives\n",
            "\n",
            "## 7. *Evaluation*\n",
            "  • Performance metrics\n",
            "  • Testing approaches\n",
            "  • Debugging strategies\n",
            "  • Optimization opportunities\n",
            "\n",
            "## 8. *Practice Problems*\n",
            "  • Concept verification questions\n",
            "  • Implementation challenges\n",
            "  • Problem-solving scenarios\n",
            "  • Solutions with explanations\n",
            "\n",
            "### Format Requirements:\n",
            "- Always use \"##\" to introduce each section header. Avoid using any other format.\n",
            "- Use bullet points for clarity\n",
            "- Show all mathematical steps using proper equation formatting ($...$)\n",
            "- Include clear variable definitions after each equation\n",
            "- Write formulas using LaTeX formatting inside $...$\n",
            "- For matrices use: $\begin{bmatrix} a & b \\ c & d \\end{bmatrix}$\n",
            "- For fractions use: $\frac{numerator}{denominator}$\n",
            "- Use ■ for numbered equations and • for regular points\n",
            "- Demonstrate practical interpretation\n",
            "- Connect to real applications\n",
            "\n",
            "### Equation Guidelines:\n",
            "- Enclose equations in $...$ format\n",
            "- Use proper LaTeX notation for mathematical expressions\n",
            "- Use $\\sum$ for summations\n",
            "- Define each variable after presenting equations\n",
            "- Number important equations using ■\n",
            "- Show step-by-step derivations with clear explanations\n",
            "\n",
            "### Code Guidelines:\n",
            "- Use LaTeX verbatim environment for code blocks:\n",
            "  \begin{verbatim}\n",
            "  code here\n",
            "  \\end{verbatim}\n",
            "\n",
            "- For inline code use \texttt{code}\n",
            "- For syntax highlighting:\n",
            "  \begin{lstlisting}[language=Python]\n",
            "  code here\n",
            "  \\end{lstlisting}\n",
            "- Include comments explaining code functionality\n",
            "- Show output examples where applicable\n",
            "\n",
            "## 1. *Concept Overview*\n",
            "**Core definition and purpose:** Long Short-Term Memory (LSTM) is a type of recurrent neural network (RNN) that addresses the vanishing gradient problem by introducing a memory cell and three types of gates: input gate, forget gate, and output gate. The primary goal of LSTM is to maintain relevant information over long periods during sequential data processing.\n",
            "\n",
            "**Key principles:** LSTM uses a memory cell to store information, allowing it to retain crucial data throughout the entire sequence. The gates control the flow of information into and out of the memory cell, enabling LSTM to selectively focus on relevant information while ignoring irrelevant data. This mechanism allows LSTM to handle long-term dependencies effectively.\n",
            "\n",
            "**Relationship to broader computing concepts:** LSTM belongs to the family of artificial neural networks (ANNs), which are inspired by biological neurons and their interconnections. It extends traditional RNNs by incorporating memory mechanisms, making it more suitable for tasks involving long-term dependencies such as language modeling, speech recognition, and machine translation.\n",
            "\n",
            "## 2. *Technical Components*\n",
            "**Primary elements and their roles:**\n",
            "\n",
            "- **Memory Cell**: A central component that stores information over time.\n",
            "- **Input Gate**: Controls the flow of new information into the memory cell.\n",
            "- **Forget Gate**: Determines what information should be forgotten from the memory cell.\n",
            "- **Output Gate**: Decides what information should be released from the memory cell.\n",
            "- **Cell State**: Represents the current state of the memory cell.\n",
            "- **Hidden State**: Represents the internal state of the LSTM at a specific time step.\n",
            "\n",
            "**Relationships and interactions:** The interaction between these components determines how information flows through the LSTM. At each time step, the input gate decides whether to update the cell state, the forget gate determines what part of the existing cell state to keep, and the output gate decides what part of the updated cell state to release as the hidden state.\n",
            "\n",
            "**Implementation details:** LSTM is typically implemented using a sigmoid activation function for the gates and a hyperbolic tangent (tanh) activation function for the cell state. The cell state is updated by adding the new candidate cell state, which is a weighted combination of the input, the old cell state, and the forget gate's output.\n",
            "\n",
            "**Core algorithms/procedures:** The LSTM algorithm consists of four main steps:\n",
            "\n",
            "1. Input Gate: Calculate the input gate's activation using the input, hidden state, and previous cell state.\n",
            "2. Forget Gate: Calculate the forget gate's activation using the input, hidden state, and previous cell state.\n",
            "3. New Candidate Cell State: Calculate the new candidate cell state using the input, forget gate's output, and tanh activation of the new candidate cell state.\n",
            "4. Output Gate: Calculate the output gate's activation using the new candidate cell state, hidden state, and previous cell state.\n",
            "\n",
            "## 3. *Working Mechanism*\n",
            "**Step-by-step operational flow:**\n",
            "\n",
            "1. At each time step, the LSTM receives an input vector xm.\n",
            "2. The input gate calculates its activation i\\_tmusing the input vector, hidden state h\\_(t-1), and previous cell state c\\_(t-1).\n",
            "3. The forget gate calculates its activation f\\_tmusing the same inputs as the input gate.\n",
            "4. The new candidate cell state c\\_tmis calculated using the input vector, forget gate's output ft, and tanh activation of the new candidate cell state.\n",
            "5. The output gate calculates its activation o\\_tmusing the new candidate cell state, hidden state h\\_(t-1), and previous cell state c\\_(t-1).\n",
            "6. The cell state c\\_(t) is updated by multiplying the input gate's output it, forget gate's output ft, and the output gate's output ot, then adding the new candidate cell state c\\_tm.\n",
            "7. The hidden state h\\_(t) is calculated by multiplying the output gate's output ot with the tanh activation of the cell state c\\_(t).\n",
            "\n",
            "**Critical processes and transformations:** The LSTM's critical processes involve controlling the flow of information into and out of the memory cell via the input, forget, and output gates. The memory cell stores the relevant information, while the hidden state represents the internal state of the LSTM at a specific time step.\n",
            "\n",
            "**Resource management (if applicable):** LSTM does not have explicit resource management since it primarily focuses on processing sequential data. However, it requires memory resources to store the cell state and hidden state at each time step.\n",
            "\n",
            "**Exception handling (if applicable):** LSTM does not inherently handle exceptions like traditional programming languages. However, when implementing LSTM in software, common exception handling practices should be followed to manage errors and unexpected situations.\n",
            "\n",
            "## 4. *Implementation Example*\n",
            "**Use case scenario:** An example implementation of LSTM could be training a language model to predict the next word in a sentence given the preceding words.\n",
            "\n",
            "**Code implementation or technical design:** Here's a simplified Python implementation of an LSTM cell using the Keras library:\n",
            "\n",
            "```python\n",
            "from keras.layers import Input, LSTM, Dense\n",
            "\n",
            "inputs = Input(shape=(timesteps, num_features))\n",
            "lstm_layer = LSTM(num_units)\n",
            "hidden_state = lstm_layer(inputs)\n",
            "output = Dense(num_classes)(hidden_state)\n",
            "model = Model(inputs=inputs, outputs=output)\n",
            "```\n",
            "\n",
            "**Step-by-step execution:**\n",
            "\n",
            "1. Define the input shape and create an input layer.\n",
            "2. Create an LSTM layer with the desired number of units.\n",
            "3. Pass the input through the LSTM layer to get the hidden state.\n",
            "4. Create a dense layer with the desired number of output classes.\n",
            "5. Combine the input and output layers to create a model.\n",
            "\n",
            "**Output analysis:** After training the model, you can use it to make predictions on unseen data. For example, given the input sequence [word1, word2, word3], the model will output the predicted next word.\n",
            "\n",
            "## 5. *Best Practices*\n",
            "**Design considerations:** When designing an LSTM model, consider the following best practices:\n",
            "\n",
            "- Choose appropriate hyperparameters such as the number of LSTM units, learning rate, and dropout rate.\n",
            "- Experiment with different architectures, including stacking multiple LSTM layers or combining LSTM with other neural network architectures.\n",
            "- Regularize the model to prevent overfitting.\n",
            "\n",
            "**Optimization techniques:** To optimize LSTM performance, consider the following techniques:\n",
            "\n",
            "- Use efficient optimization algorithms such as Adam or RMSProp.\n",
            "- Apply batch normalization to improve stability and convergence.\n",
            "- Utilize gradient clipping to prevent exploding or vanishing gradients.\n",
            "\n",
            "**Common pitfalls:** Be aware of the following potential issues when working with LSTM:\n",
            "\n",
            "- Vanishing or exploding gradients due to long sequences or poorly chosen hyperparameters.\n",
            "- Overfitting due to insufficient regularization or lack of generalization.\n",
            "- Difficulty in parallelizing computations due to the recursive nature of LSTM.\n",
            "\n",
            "**Performance implications:** The performance of LSTM depends on several factors, including the size of the dataset, the complexity of the task, and the choice of hyperparameters. Training LSTM models can be computationally expensive, so it's essential to choose appropriate hardware and software configurations.\n",
            "\n",
            "## 6. *Applications*\n",
            "**Real-world use cases:** LSTM has been successfully applied in various domains, including:\n",
            "\n",
            "- Natural Language Processing (NLP): Text classification, sentiment analysis, machine translation, and language modeling.\n",
            "- Speech Recognition: Transcription of spoken language into written text.\n",
            "- Time Series Analysis: Predicting future trends based on historical data.\n",
            "\n",
            "**Industry applications:** LSTM is widely used in industries such as:\n",
            "\n",
            "- Artificial Intelligence (AI) and Machine Learning (ML) companies for developing intelligent systems.\n",
            "- Tech giants like Google, Microsoft, and Amazon for improving search engines, virtual assistants, and translation services.\n",
            "- Financial institutions for forecasting stock prices and market trends.\n",
            "\n",
            "**Integration patterns:** LSTM can be integrated into larger deep learning architectures, such as convolutional neural networks (CNNs) and transformers, to further enhance their capabilities.\n",
            "\n",
            "**Variations and alternatives:** There are several variations and alternatives to LSTM, including GRUs (Gated Recurrent Units), Echo State Networks, and Simple Recurrent Units (SRUs). Each has its unique strengths and weaknesses, and choosing the right one depends on the specific requirements of the task at hand.\n",
            "\n",
            "## 7. *Evaluation*\n",
            "**Performance metrics:** To evaluate LSTM performance, commonly used metrics include accuracy, loss, precision, recall, F1 score, and perplexity. The choice of metric depends on the specific task and the nature of the data.\n",
            "\n",
            "**Testing approaches:** Cross-validation, holdout sets, and bootstrap methods are popular testing approaches for evaluating LSTM performance.\n",
            "\n",
            "**Debugging strategies:** Debugging LSTM models can be challenging due to their complex nature. Strategies include visualizing the data, analyzing the gradients, and monitoring the loss and accuracy during training.\n",
            "\n",
            "**Optimization opportunities:** To optimize LSTM performance, consider techniques such as early stopping, learning rate scheduling, and data augmentation.\n",
            "\n",
            "## 8. *Practice Problems*\n",
            "**Concept verification questions:**\n",
            "\n",
            "1. What is the role of the memory cell in LSTM?\n",
            "2. Explain the difference between the input gate, forget gate, and output gate in LSTM.\n",
            "3. How does LSTM handle long-term dependencies compared to traditional RNNs?\n",
            "\n",
            "**Implementation challenges:**\n",
            "\n",
            "1. Implement an LSTM cell from scratch using PyTorch.\n",
            "2. Train an LSTM model to perform sentiment analysis on movie reviews.\n",
            "\n",
            "**Problem-solving scenarios:**\n",
            "\n",
            "1. You are given a sequence of numbers representing stock prices. Develop an LSTM model to predict the next price in the sequence.\n",
            "2. Given a corpus of news articles, develop an LSTM model to classify them as positive, negative, or neutral based on their sentiment.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_answer(text):\n",
        "   \"\"\"Extract the answer, removing everything before 'Show output examples where applicable'\"\"\"\n",
        "   # Find the index of the end section\n",
        "   start_index = text.find(\"Show output examples where applicable\")\n",
        "\n",
        "   if start_index == -1:\n",
        "       return text.strip()\n",
        "\n",
        "   return text[start_index + len(\"Show output examples where applicable\"):].strip()\n",
        "\n",
        "# Usage\n",
        "clean_answer = extract_answer(answer)\n",
        "print(clean_answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "T4s7bF8Fl1LR",
        "outputId": "cd5dad9f-8142-4a5f-98d4-2dc507d38ff7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## 1. *Concept Overview*\n",
            "**Core definition and purpose:** Long Short-Term Memory (LSTM) is a type of recurrent neural network (RNN) that addresses the vanishing gradient problem by introducing a memory cell and three types of gates: input gate, forget gate, and output gate. The primary goal of LSTM is to maintain relevant information over long periods during sequential data processing.\n",
            "\n",
            "**Key principles:** LSTM uses a memory cell to store information, allowing it to retain crucial data throughout the entire sequence. The gates control the flow of information into and out of the memory cell, enabling LSTM to selectively focus on relevant information while ignoring irrelevant data. This mechanism allows LSTM to handle long-term dependencies effectively.\n",
            "\n",
            "**Relationship to broader computing concepts:** LSTM belongs to the family of artificial neural networks (ANNs), which are inspired by biological neurons and their interconnections. It extends traditional RNNs by incorporating memory mechanisms, making it more suitable for tasks involving long-term dependencies such as language modeling, speech recognition, and machine translation.\n",
            "\n",
            "## 2. *Technical Components*\n",
            "**Primary elements and their roles:**\n",
            "\n",
            "- **Memory Cell**: A central component that stores information over time.\n",
            "- **Input Gate**: Controls the flow of new information into the memory cell.\n",
            "- **Forget Gate**: Determines what information should be forgotten from the memory cell.\n",
            "- **Output Gate**: Decides what information should be released from the memory cell.\n",
            "- **Cell State**: Represents the current state of the memory cell.\n",
            "- **Hidden State**: Represents the internal state of the LSTM at a specific time step.\n",
            "\n",
            "**Relationships and interactions:** The interaction between these components determines how information flows through the LSTM. At each time step, the input gate decides whether to update the cell state, the forget gate determines what part of the existing cell state to keep, and the output gate decides what part of the updated cell state to release as the hidden state.\n",
            "\n",
            "**Implementation details:** LSTM is typically implemented using a sigmoid activation function for the gates and a hyperbolic tangent (tanh) activation function for the cell state. The cell state is updated by adding the new candidate cell state, which is a weighted combination of the input, the old cell state, and the forget gate's output.\n",
            "\n",
            "**Core algorithms/procedures:** The LSTM algorithm consists of four main steps:\n",
            "\n",
            "1. Input Gate: Calculate the input gate's activation using the input, hidden state, and previous cell state.\n",
            "2. Forget Gate: Calculate the forget gate's activation using the input, hidden state, and previous cell state.\n",
            "3. New Candidate Cell State: Calculate the new candidate cell state using the input, forget gate's output, and tanh activation of the new candidate cell state.\n",
            "4. Output Gate: Calculate the output gate's activation using the new candidate cell state, hidden state, and previous cell state.\n",
            "\n",
            "## 3. *Working Mechanism*\n",
            "**Step-by-step operational flow:**\n",
            "\n",
            "1. At each time step, the LSTM receives an input vector xm.\n",
            "2. The input gate calculates its activation i\\_tmusing the input vector, hidden state h\\_(t-1), and previous cell state c\\_(t-1).\n",
            "3. The forget gate calculates its activation f\\_tmusing the same inputs as the input gate.\n",
            "4. The new candidate cell state c\\_tmis calculated using the input vector, forget gate's output ft, and tanh activation of the new candidate cell state.\n",
            "5. The output gate calculates its activation o\\_tmusing the new candidate cell state, hidden state h\\_(t-1), and previous cell state c\\_(t-1).\n",
            "6. The cell state c\\_(t) is updated by multiplying the input gate's output it, forget gate's output ft, and the output gate's output ot, then adding the new candidate cell state c\\_tm.\n",
            "7. The hidden state h\\_(t) is calculated by multiplying the output gate's output ot with the tanh activation of the cell state c\\_(t).\n",
            "\n",
            "**Critical processes and transformations:** The LSTM's critical processes involve controlling the flow of information into and out of the memory cell via the input, forget, and output gates. The memory cell stores the relevant information, while the hidden state represents the internal state of the LSTM at a specific time step.\n",
            "\n",
            "**Resource management (if applicable):** LSTM does not have explicit resource management since it primarily focuses on processing sequential data. However, it requires memory resources to store the cell state and hidden state at each time step.\n",
            "\n",
            "**Exception handling (if applicable):** LSTM does not inherently handle exceptions like traditional programming languages. However, when implementing LSTM in software, common exception handling practices should be followed to manage errors and unexpected situations.\n",
            "\n",
            "## 4. *Implementation Example*\n",
            "**Use case scenario:** An example implementation of LSTM could be training a language model to predict the next word in a sentence given the preceding words.\n",
            "\n",
            "**Code implementation or technical design:** Here's a simplified Python implementation of an LSTM cell using the Keras library:\n",
            "\n",
            "```python\n",
            "from keras.layers import Input, LSTM, Dense\n",
            "\n",
            "inputs = Input(shape=(timesteps, num_features))\n",
            "lstm_layer = LSTM(num_units)\n",
            "hidden_state = lstm_layer(inputs)\n",
            "output = Dense(num_classes)(hidden_state)\n",
            "model = Model(inputs=inputs, outputs=output)\n",
            "```\n",
            "\n",
            "**Step-by-step execution:**\n",
            "\n",
            "1. Define the input shape and create an input layer.\n",
            "2. Create an LSTM layer with the desired number of units.\n",
            "3. Pass the input through the LSTM layer to get the hidden state.\n",
            "4. Create a dense layer with the desired number of output classes.\n",
            "5. Combine the input and output layers to create a model.\n",
            "\n",
            "**Output analysis:** After training the model, you can use it to make predictions on unseen data. For example, given the input sequence [word1, word2, word3], the model will output the predicted next word.\n",
            "\n",
            "## 5. *Best Practices*\n",
            "**Design considerations:** When designing an LSTM model, consider the following best practices:\n",
            "\n",
            "- Choose appropriate hyperparameters such as the number of LSTM units, learning rate, and dropout rate.\n",
            "- Experiment with different architectures, including stacking multiple LSTM layers or combining LSTM with other neural network architectures.\n",
            "- Regularize the model to prevent overfitting.\n",
            "\n",
            "**Optimization techniques:** To optimize LSTM performance, consider the following techniques:\n",
            "\n",
            "- Use efficient optimization algorithms such as Adam or RMSProp.\n",
            "- Apply batch normalization to improve stability and convergence.\n",
            "- Utilize gradient clipping to prevent exploding or vanishing gradients.\n",
            "\n",
            "**Common pitfalls:** Be aware of the following potential issues when working with LSTM:\n",
            "\n",
            "- Vanishing or exploding gradients due to long sequences or poorly chosen hyperparameters.\n",
            "- Overfitting due to insufficient regularization or lack of generalization.\n",
            "- Difficulty in parallelizing computations due to the recursive nature of LSTM.\n",
            "\n",
            "**Performance implications:** The performance of LSTM depends on several factors, including the size of the dataset, the complexity of the task, and the choice of hyperparameters. Training LSTM models can be computationally expensive, so it's essential to choose appropriate hardware and software configurations.\n",
            "\n",
            "## 6. *Applications*\n",
            "**Real-world use cases:** LSTM has been successfully applied in various domains, including:\n",
            "\n",
            "- Natural Language Processing (NLP): Text classification, sentiment analysis, machine translation, and language modeling.\n",
            "- Speech Recognition: Transcription of spoken language into written text.\n",
            "- Time Series Analysis: Predicting future trends based on historical data.\n",
            "\n",
            "**Industry applications:** LSTM is widely used in industries such as:\n",
            "\n",
            "- Artificial Intelligence (AI) and Machine Learning (ML) companies for developing intelligent systems.\n",
            "- Tech giants like Google, Microsoft, and Amazon for improving search engines, virtual assistants, and translation services.\n",
            "- Financial institutions for forecasting stock prices and market trends.\n",
            "\n",
            "**Integration patterns:** LSTM can be integrated into larger deep learning architectures, such as convolutional neural networks (CNNs) and transformers, to further enhance their capabilities.\n",
            "\n",
            "**Variations and alternatives:** There are several variations and alternatives to LSTM, including GRUs (Gated Recurrent Units), Echo State Networks, and Simple Recurrent Units (SRUs). Each has its unique strengths and weaknesses, and choosing the right one depends on the specific requirements of the task at hand.\n",
            "\n",
            "## 7. *Evaluation*\n",
            "**Performance metrics:** To evaluate LSTM performance, commonly used metrics include accuracy, loss, precision, recall, F1 score, and perplexity. The choice of metric depends on the specific task and the nature of the data.\n",
            "\n",
            "**Testing approaches:** Cross-validation, holdout sets, and bootstrap methods are popular testing approaches for evaluating LSTM performance.\n",
            "\n",
            "**Debugging strategies:** Debugging LSTM models can be challenging due to their complex nature. Strategies include visualizing the data, analyzing the gradients, and monitoring the loss and accuracy during training.\n",
            "\n",
            "**Optimization opportunities:** To optimize LSTM performance, consider techniques such as early stopping, learning rate scheduling, and data augmentation.\n",
            "\n",
            "## 8. *Practice Problems*\n",
            "**Concept verification questions:**\n",
            "\n",
            "1. What is the role of the memory cell in LSTM?\n",
            "2. Explain the difference between the input gate, forget gate, and output gate in LSTM.\n",
            "3. How does LSTM handle long-term dependencies compared to traditional RNNs?\n",
            "\n",
            "**Implementation challenges:**\n",
            "\n",
            "1. Implement an LSTM cell from scratch using PyTorch.\n",
            "2. Train an LSTM model to perform sentiment analysis on movie reviews.\n",
            "\n",
            "**Problem-solving scenarios:**\n",
            "\n",
            "1. You are given a sequence of numbers representing stock prices. Develop an LSTM model to predict the next price in the sequence.\n",
            "2. Given a corpus of news articles, develop an LSTM model to classify them as positive, negative, or neutral based on their sentiment.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def format_text(text):\n",
        "    \"\"\"\n",
        "    Format text with the following rules:\n",
        "    1. Change single asterisks to double asterisks\n",
        "    2. Convert '###' to bullet points\n",
        "    3. Convert dashes to numbered lists, resetting numbers after each bullet point\n",
        "\n",
        "    Args:\n",
        "        text (str): Input text to be formatted\n",
        "    Returns:\n",
        "        str: Formatted text\n",
        "    \"\"\"\n",
        "    # Split text into lines for processing\n",
        "    lines = text.split('\\n')\n",
        "    formatted_lines = []\n",
        "\n",
        "    # Initialize counters for each indentation level\n",
        "    number_counters = {}\n",
        "    current_indent = 0\n",
        "\n",
        "    for i, line in enumerate(lines):\n",
        "        # Skip empty lines but preserve them\n",
        "        if not line.strip():\n",
        "            formatted_lines.append(line)\n",
        "            continue\n",
        "\n",
        "        # Handle single asterisks to double asterisks\n",
        "        # Use negative lookbehind and lookahead to avoid modifying double asterisks\n",
        "        line = re.sub(r'(?<![\\*])\\*(?![\\*])([^\\*]+)(?<![\\*])\\*(?![\\*])', r'**\\1**', line)\n",
        "\n",
        "        # Get the indentation level of the current line\n",
        "        indent = len(line) - len(line.lstrip())\n",
        "\n",
        "        # Convert ### to bullet points\n",
        "        if line.strip().startswith('###'):\n",
        "            # When we encounter a bullet point, reset all numbering counters\n",
        "            number_counters = {}\n",
        "            line = line.replace('###', '•')\n",
        "            current_indent = indent\n",
        "\n",
        "        # Handle numbered lists (lines starting with dash)\n",
        "        elif line.strip().startswith('-'):\n",
        "            # Reset counters for deeper indentation levels when indent changes\n",
        "            if indent > current_indent:\n",
        "                # Keep only counters for less indented levels\n",
        "                number_counters = {k: v for k, v in number_counters.items() if k < indent}\n",
        "\n",
        "            # Initialize or increment counter for this indentation level\n",
        "            if indent not in number_counters:\n",
        "                number_counters[indent] = 1\n",
        "            else:\n",
        "                number_counters[indent] += 1\n",
        "\n",
        "            # Replace dash with the current number for this indentation level\n",
        "            line = re.sub(r'^\\s*-', f\"{' ' * indent}{number_counters[indent]}.\", line, 1)\n",
        "            current_indent = indent\n",
        "        else:\n",
        "            # For non-list lines, keep track of the current indentation\n",
        "            current_indent = indent\n",
        "\n",
        "        formatted_lines.append(line)\n",
        "\n",
        "    return '\\n'.join(formatted_lines)\n",
        "\n",
        "def process_file(input_text):\n",
        "    \"\"\"\n",
        "    Process the entire file and apply formatting\n",
        "\n",
        "    Args:\n",
        "        input_text (str): Content of the input file\n",
        "    Returns:\n",
        "        str: Formatted content\n",
        "    \"\"\"\n",
        "    # Format the text\n",
        "    formatted_text = format_text(input_text)\n",
        "    return formatted_text\n",
        "\n",
        "# Example usage demonstrating the reset behavior\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "\n",
        "    # Process and print the sample text\n",
        "    result = process_file(clean_answer)\n",
        "    print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "l-RRDvGul1FY",
        "outputId": "59aded87-03ce-4420-c87d-de61f4e783fd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## 1. **Concept Overview**\n",
            "**Core definition and purpose:** Long Short-Term Memory (LSTM) is a type of recurrent neural network (RNN) that addresses the vanishing gradient problem by introducing a memory cell and three types of gates: input gate, forget gate, and output gate. The primary goal of LSTM is to maintain relevant information over long periods during sequential data processing.\n",
            "\n",
            "**Key principles:** LSTM uses a memory cell to store information, allowing it to retain crucial data throughout the entire sequence. The gates control the flow of information into and out of the memory cell, enabling LSTM to selectively focus on relevant information while ignoring irrelevant data. This mechanism allows LSTM to handle long-term dependencies effectively.\n",
            "\n",
            "**Relationship to broader computing concepts:** LSTM belongs to the family of artificial neural networks (ANNs), which are inspired by biological neurons and their interconnections. It extends traditional RNNs by incorporating memory mechanisms, making it more suitable for tasks involving long-term dependencies such as language modeling, speech recognition, and machine translation.\n",
            "\n",
            "## 2. **Technical Components**\n",
            "**Primary elements and their roles:**\n",
            "\n",
            "1. **Memory Cell**: A central component that stores information over time.\n",
            "2. **Input Gate**: Controls the flow of new information into the memory cell.\n",
            "3. **Forget Gate**: Determines what information should be forgotten from the memory cell.\n",
            "4. **Output Gate**: Decides what information should be released from the memory cell.\n",
            "5. **Cell State**: Represents the current state of the memory cell.\n",
            "6. **Hidden State**: Represents the internal state of the LSTM at a specific time step.\n",
            "\n",
            "**Relationships and interactions:** The interaction between these components determines how information flows through the LSTM. At each time step, the input gate decides whether to update the cell state, the forget gate determines what part of the existing cell state to keep, and the output gate decides what part of the updated cell state to release as the hidden state.\n",
            "\n",
            "**Implementation details:** LSTM is typically implemented using a sigmoid activation function for the gates and a hyperbolic tangent (tanh) activation function for the cell state. The cell state is updated by adding the new candidate cell state, which is a weighted combination of the input, the old cell state, and the forget gate's output.\n",
            "\n",
            "**Core algorithms/procedures:** The LSTM algorithm consists of four main steps:\n",
            "\n",
            "1. Input Gate: Calculate the input gate's activation using the input, hidden state, and previous cell state.\n",
            "2. Forget Gate: Calculate the forget gate's activation using the input, hidden state, and previous cell state.\n",
            "3. New Candidate Cell State: Calculate the new candidate cell state using the input, forget gate's output, and tanh activation of the new candidate cell state.\n",
            "4. Output Gate: Calculate the output gate's activation using the new candidate cell state, hidden state, and previous cell state.\n",
            "\n",
            "## 3. **Working Mechanism**\n",
            "**Step-by-step operational flow:**\n",
            "\n",
            "1. At each time step, the LSTM receives an input vector xm.\n",
            "2. The input gate calculates its activation i\\_tmusing the input vector, hidden state h\\_(t-1), and previous cell state c\\_(t-1).\n",
            "3. The forget gate calculates its activation f\\_tmusing the same inputs as the input gate.\n",
            "4. The new candidate cell state c\\_tmis calculated using the input vector, forget gate's output ft, and tanh activation of the new candidate cell state.\n",
            "5. The output gate calculates its activation o\\_tmusing the new candidate cell state, hidden state h\\_(t-1), and previous cell state c\\_(t-1).\n",
            "6. The cell state c\\_(t) is updated by multiplying the input gate's output it, forget gate's output ft, and the output gate's output ot, then adding the new candidate cell state c\\_tm.\n",
            "7. The hidden state h\\_(t) is calculated by multiplying the output gate's output ot with the tanh activation of the cell state c\\_(t).\n",
            "\n",
            "**Critical processes and transformations:** The LSTM's critical processes involve controlling the flow of information into and out of the memory cell via the input, forget, and output gates. The memory cell stores the relevant information, while the hidden state represents the internal state of the LSTM at a specific time step.\n",
            "\n",
            "**Resource management (if applicable):** LSTM does not have explicit resource management since it primarily focuses on processing sequential data. However, it requires memory resources to store the cell state and hidden state at each time step.\n",
            "\n",
            "**Exception handling (if applicable):** LSTM does not inherently handle exceptions like traditional programming languages. However, when implementing LSTM in software, common exception handling practices should be followed to manage errors and unexpected situations.\n",
            "\n",
            "## 4. **Implementation Example**\n",
            "**Use case scenario:** An example implementation of LSTM could be training a language model to predict the next word in a sentence given the preceding words.\n",
            "\n",
            "**Code implementation or technical design:** Here's a simplified Python implementation of an LSTM cell using the Keras library:\n",
            "\n",
            "```python\n",
            "from keras.layers import Input, LSTM, Dense\n",
            "\n",
            "inputs = Input(shape=(timesteps, num_features))\n",
            "lstm_layer = LSTM(num_units)\n",
            "hidden_state = lstm_layer(inputs)\n",
            "output = Dense(num_classes)(hidden_state)\n",
            "model = Model(inputs=inputs, outputs=output)\n",
            "```\n",
            "\n",
            "**Step-by-step execution:**\n",
            "\n",
            "1. Define the input shape and create an input layer.\n",
            "2. Create an LSTM layer with the desired number of units.\n",
            "3. Pass the input through the LSTM layer to get the hidden state.\n",
            "4. Create a dense layer with the desired number of output classes.\n",
            "5. Combine the input and output layers to create a model.\n",
            "\n",
            "**Output analysis:** After training the model, you can use it to make predictions on unseen data. For example, given the input sequence [word1, word2, word3], the model will output the predicted next word.\n",
            "\n",
            "## 5. **Best Practices**\n",
            "**Design considerations:** When designing an LSTM model, consider the following best practices:\n",
            "\n",
            "7. Choose appropriate hyperparameters such as the number of LSTM units, learning rate, and dropout rate.\n",
            "8. Experiment with different architectures, including stacking multiple LSTM layers or combining LSTM with other neural network architectures.\n",
            "9. Regularize the model to prevent overfitting.\n",
            "\n",
            "**Optimization techniques:** To optimize LSTM performance, consider the following techniques:\n",
            "\n",
            "10. Use efficient optimization algorithms such as Adam or RMSProp.\n",
            "11. Apply batch normalization to improve stability and convergence.\n",
            "12. Utilize gradient clipping to prevent exploding or vanishing gradients.\n",
            "\n",
            "**Common pitfalls:** Be aware of the following potential issues when working with LSTM:\n",
            "\n",
            "13. Vanishing or exploding gradients due to long sequences or poorly chosen hyperparameters.\n",
            "14. Overfitting due to insufficient regularization or lack of generalization.\n",
            "15. Difficulty in parallelizing computations due to the recursive nature of LSTM.\n",
            "\n",
            "**Performance implications:** The performance of LSTM depends on several factors, including the size of the dataset, the complexity of the task, and the choice of hyperparameters. Training LSTM models can be computationally expensive, so it's essential to choose appropriate hardware and software configurations.\n",
            "\n",
            "## 6. **Applications**\n",
            "**Real-world use cases:** LSTM has been successfully applied in various domains, including:\n",
            "\n",
            "16. Natural Language Processing (NLP): Text classification, sentiment analysis, machine translation, and language modeling.\n",
            "17. Speech Recognition: Transcription of spoken language into written text.\n",
            "18. Time Series Analysis: Predicting future trends based on historical data.\n",
            "\n",
            "**Industry applications:** LSTM is widely used in industries such as:\n",
            "\n",
            "19. Artificial Intelligence (AI) and Machine Learning (ML) companies for developing intelligent systems.\n",
            "20. Tech giants like Google, Microsoft, and Amazon for improving search engines, virtual assistants, and translation services.\n",
            "21. Financial institutions for forecasting stock prices and market trends.\n",
            "\n",
            "**Integration patterns:** LSTM can be integrated into larger deep learning architectures, such as convolutional neural networks (CNNs) and transformers, to further enhance their capabilities.\n",
            "\n",
            "**Variations and alternatives:** There are several variations and alternatives to LSTM, including GRUs (Gated Recurrent Units), Echo State Networks, and Simple Recurrent Units (SRUs). Each has its unique strengths and weaknesses, and choosing the right one depends on the specific requirements of the task at hand.\n",
            "\n",
            "## 7. **Evaluation**\n",
            "**Performance metrics:** To evaluate LSTM performance, commonly used metrics include accuracy, loss, precision, recall, F1 score, and perplexity. The choice of metric depends on the specific task and the nature of the data.\n",
            "\n",
            "**Testing approaches:** Cross-validation, holdout sets, and bootstrap methods are popular testing approaches for evaluating LSTM performance.\n",
            "\n",
            "**Debugging strategies:** Debugging LSTM models can be challenging due to their complex nature. Strategies include visualizing the data, analyzing the gradients, and monitoring the loss and accuracy during training.\n",
            "\n",
            "**Optimization opportunities:** To optimize LSTM performance, consider techniques such as early stopping, learning rate scheduling, and data augmentation.\n",
            "\n",
            "## 8. **Practice Problems**\n",
            "**Concept verification questions:**\n",
            "\n",
            "1. What is the role of the memory cell in LSTM?\n",
            "2. Explain the difference between the input gate, forget gate, and output gate in LSTM.\n",
            "3. How does LSTM handle long-term dependencies compared to traditional RNNs?\n",
            "\n",
            "**Implementation challenges:**\n",
            "\n",
            "1. Implement an LSTM cell from scratch using PyTorch.\n",
            "2. Train an LSTM model to perform sentiment analysis on movie reviews.\n",
            "\n",
            "**Problem-solving scenarios:**\n",
            "\n",
            "1. You are given a sequence of numbers representing stock prices. Develop an LSTM model to predict the next price in the sequence.\n",
            "2. Given a corpus of news articles, develop an LSTM model to classify them as positive, negative, or neutral based on their sentiment.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write the content to a text file\n",
        "file_path = \"content.txt\"\n",
        "with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
        "    file.write(result)\n"
      ],
      "metadata": {
        "id": "F_5Sj2r6l07e"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get install -y texlive-latex-base texlive-fonts-recommended texlive-fonts-extra texlive-latex-extra dvipng cm-super\n",
        "!pip install python-pptx Pillow matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "GCtBa5Ssmy6s",
        "outputId": "7b533cf4-7e95-4253-8810-597c14181cc5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com (185.125.190.82)] [Waiting \r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com (185.125.190.82)] [Waiting \r0% [Connecting to archive.ubuntu.com (185.125.190.83)] [Waiting for headers] [Waiting for headers] [\r                                                                                                    \rGet:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,306 kB]\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,647 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,604 kB]\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,640 kB]\n",
            "Hit:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,904 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,229 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,521 kB]\n",
            "Fetched 21.2 MB in 2s (8,726 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  cm-super-minimal dvisvgm fonts-adf-accanthis fonts-adf-berenis fonts-adf-gillius\n",
            "  fonts-adf-universalis fonts-cabin fonts-cantarell fonts-comfortaa fonts-croscore\n",
            "  fonts-crosextra-caladea fonts-crosextra-carlito fonts-dejavu-core fonts-dejavu-extra\n",
            "  fonts-droid-fallback fonts-ebgaramond fonts-ebgaramond-extra fonts-font-awesome\n",
            "  fonts-freefont-otf fonts-freefont-ttf fonts-gfs-artemisia fonts-gfs-complutum fonts-gfs-didot\n",
            "  fonts-gfs-neohellenic fonts-gfs-olga fonts-gfs-solomos fonts-go fonts-junicode fonts-lato\n",
            "  fonts-linuxlibertine fonts-lmodern fonts-lobster fonts-lobstertwo fonts-noto-color-emoji\n",
            "  fonts-noto-core fonts-noto-mono fonts-oflb-asana-math fonts-open-sans fonts-roboto-unhinted\n",
            "  fonts-sil-charis fonts-sil-gentium fonts-sil-gentium-basic fonts-sil-gentiumplus\n",
            "  fonts-sil-gentiumplus-compact fonts-stix fonts-texgyre fonts-urw-base35 ghostscript\n",
            "  libapache-pom-java libcommons-logging-java libcommons-parent-java libfontbox-java libfontenc1\n",
            "  libgs9 libgs9-common libidn12 libijs-0.35 libjbig2dec0 libkpathsea6 libpdfbox-java libptexenc1\n",
            "  libruby3.0 libsynctex2 libteckit0 libtexlua53 libtexluajit2 libwoff1 libzzip-0-13 lmodern\n",
            "  pfb2t1c2pfb poppler-data preview-latex-style rake ruby ruby-net-telnet ruby-rubygems ruby-webrick\n",
            "  ruby-xmlrpc ruby3.0 rubygems-integration t1utils tex-common tex-gyre texlive-base\n",
            "  texlive-binaries texlive-fonts-extra-links texlive-latex-recommended texlive-pictures\n",
            "  texlive-plain-generic tipa xfonts-encodings xfonts-utils\n",
            "Suggested packages:\n",
            "  fonts-noto fontforge ghostscript-x libavalon-framework-java libcommons-logging-java-doc\n",
            "  libexcalibur-logkit-java liblog4j1.2-java fonts-japanese-mincho | fonts-ipafont-mincho\n",
            "  fonts-japanese-gothic | fonts-ipafont-gothic fonts-arphic-ukai fonts-arphic-uming fonts-nanum ri\n",
            "  ruby-dev bundler debhelper perl-tk xpdf | pdf-viewer xzdec texlive-fonts-extra-doc\n",
            "  texlive-fonts-recommended-doc texlive-latex-base-doc python3-pygments icc-profiles\n",
            "  libfile-which-perl libspreadsheet-parseexcel-perl texlive-latex-extra-doc\n",
            "  texlive-latex-recommended-doc texlive-luatex texlive-pstricks dot2tex prerex texlive-pictures-doc\n",
            "  vprerex default-jre-headless tipa-doc\n",
            "The following NEW packages will be installed:\n",
            "  cm-super cm-super-minimal dvipng dvisvgm fonts-adf-accanthis fonts-adf-berenis fonts-adf-gillius\n",
            "  fonts-adf-universalis fonts-cabin fonts-cantarell fonts-comfortaa fonts-croscore\n",
            "  fonts-crosextra-caladea fonts-crosextra-carlito fonts-dejavu-core fonts-dejavu-extra\n",
            "  fonts-droid-fallback fonts-ebgaramond fonts-ebgaramond-extra fonts-font-awesome\n",
            "  fonts-freefont-otf fonts-freefont-ttf fonts-gfs-artemisia fonts-gfs-complutum fonts-gfs-didot\n",
            "  fonts-gfs-neohellenic fonts-gfs-olga fonts-gfs-solomos fonts-go fonts-junicode fonts-lato\n",
            "  fonts-linuxlibertine fonts-lmodern fonts-lobster fonts-lobstertwo fonts-noto-color-emoji\n",
            "  fonts-noto-core fonts-noto-mono fonts-oflb-asana-math fonts-open-sans fonts-roboto-unhinted\n",
            "  fonts-sil-charis fonts-sil-gentium fonts-sil-gentium-basic fonts-sil-gentiumplus\n",
            "  fonts-sil-gentiumplus-compact fonts-stix fonts-texgyre fonts-urw-base35 ghostscript\n",
            "  libapache-pom-java libcommons-logging-java libcommons-parent-java libfontbox-java libfontenc1\n",
            "  libgs9 libgs9-common libidn12 libijs-0.35 libjbig2dec0 libkpathsea6 libpdfbox-java libptexenc1\n",
            "  libruby3.0 libsynctex2 libteckit0 libtexlua53 libtexluajit2 libwoff1 libzzip-0-13 lmodern\n",
            "  pfb2t1c2pfb poppler-data preview-latex-style rake ruby ruby-net-telnet ruby-rubygems ruby-webrick\n",
            "  ruby-xmlrpc ruby3.0 rubygems-integration t1utils tex-common tex-gyre texlive-base\n",
            "  texlive-binaries texlive-fonts-extra texlive-fonts-extra-links texlive-fonts-recommended\n",
            "  texlive-latex-base texlive-latex-extra texlive-latex-recommended texlive-pictures\n",
            "  texlive-plain-generic tipa xfonts-encodings xfonts-utils\n",
            "0 upgraded, 98 newly installed, 0 to remove and 21 not upgraded.\n",
            "Need to get 738 MB of archives.\n",
            "After this operation, 2,147 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-droid-fallback all 1:6.0.1r16-1.1build1 [1,805 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-lato all 2.0-2.1 [2,696 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 poppler-data all 0.4.11-1 [2,171 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tex-common all 6.17 [33.7 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libkpathsea6 amd64 2021.20210626.59705-1ubuntu0.2 [60.4 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libptexenc1 amd64 2021.20210626.59705-1ubuntu0.2 [39.1 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libsynctex2 amd64 2021.20210626.59705-1ubuntu0.2 [55.6 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libtexlua53 amd64 2021.20210626.59705-1ubuntu0.2 [120 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libtexluajit2 amd64 2021.20210626.59705-1ubuntu0.2 [267 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 t1utils amd64 1.41-4build2 [61.3 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libteckit0 amd64 2.5.11+ds1-1 [421 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libzzip-0-13 amd64 0.13.72+dfsg.1-1.1 [27.0 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 texlive-binaries amd64 2021.20210626.59705-1ubuntu0.2 [9,860 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-base all 2021.20220204-1 [21.0 MB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-lmodern all 2.004.5-6.1 [4,532 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-latex-base all 2021.20220204-1 [1,128 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-latex-recommended all 2021.20220204-1 [14.4 MB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy/universe amd64 cm-super-minimal all 0.3.4-17 [5,777 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy/universe amd64 pfb2t1c2pfb amd64 0.3-11 [9,342 B]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy/universe amd64 cm-super all 0.3.4-17 [20.2 MB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-urw-base35 all 20200910-1 [6,367 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgs9-common all 9.55.0~dfsg1-0ubuntu5.10 [752 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libidn12 amd64 1.38-4ubuntu1 [60.0 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy/main amd64 libijs-0.35 amd64 0.35-15build2 [16.5 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjbig2dec0 amd64 0.19-3build2 [64.7 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgs9 amd64 9.55.0~dfsg1-0ubuntu5.10 [5,031 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ghostscript amd64 9.55.0~dfsg1-0ubuntu5.10 [49.4 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu jammy/universe amd64 dvipng amd64 1.15-1.1 [78.9 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwoff1 amd64 1.0.2-1build4 [45.2 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu jammy/universe amd64 dvisvgm amd64 2.13.1-1 [1,221 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-adf-accanthis all 0.20190904-2 [203 kB]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-adf-berenis all 0.20190904-2 [313 kB]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-adf-gillius all 0.20190904-2 [190 kB]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-adf-universalis all 0.20190904-2 [112 kB]\n",
            "Get:35 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-cabin all 1.5-3 [141 kB]\n",
            "Get:36 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-cantarell all 0.303-2 [286 kB]\n",
            "Get:37 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-comfortaa all 3.001-3 [129 kB]\n",
            "Get:38 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-croscore all 20201225-1build1 [1,572 kB]\n",
            "Get:39 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-crosextra-caladea all 20130214-2.1 [82.4 kB]\n",
            "Get:40 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-crosextra-carlito all 20130920-1.1 [743 kB]\n",
            "Get:41 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-core all 2.37-2build1 [1,041 kB]\n",
            "Get:42 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-extra all 2.37-2build1 [2,041 kB]\n",
            "Get:43 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-ebgaramond all 0.016+git20210310.42d4f9f2-1 [512 kB]\n",
            "Get:44 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-ebgaramond-extra all 0.016+git20210310.42d4f9f2-1 [2,233 kB]\n",
            "Get:45 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-font-awesome all 5.0.10+really4.7.0~dfsg-4.1 [516 kB]\n",
            "Get:46 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-freefont-otf all 20120503-10build1 [3,054 kB]\n",
            "Get:47 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-freefont-ttf all 20120503-10build1 [2,388 kB]\n",
            "Get:48 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-gfs-artemisia all 1.1-6 [260 kB]\n",
            "Get:49 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-gfs-complutum all 1.1-7 [41.8 kB]\n",
            "Get:50 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-gfs-didot all 1.1-7 [278 kB]\n",
            "Get:51 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-gfs-neohellenic all 1.1-7 [215 kB]\n",
            "Get:52 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-gfs-olga all 1.1-6 [33.5 kB]\n",
            "Get:53 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-gfs-solomos all 1.1-6 [40.9 kB]\n",
            "Get:54 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-go all 0~20170330-1 [369 kB]\n",
            "Get:55 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-junicode all 1.002-2 [828 kB]\n",
            "Get:56 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-linuxlibertine all 5.3.0-6 [1,627 kB]\n",
            "Get:57 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-lobster all 2.0-2.1 [38.9 kB]\n",
            "Get:58 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-lobstertwo all 2.0-2.1 [93.3 kB]\n",
            "Get:59 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 fonts-noto-color-emoji all 2.042-0ubuntu0.22.04.1 [9,944 kB]\n",
            "Get:60 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-noto-core all 20201225-1build1 [12.2 MB]\n",
            "Get:61 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-noto-mono all 20201225-1build1 [397 kB]\n",
            "Get:62 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-oflb-asana-math all 000.907-7build1 [245 kB]\n",
            "Get:63 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-open-sans all 1.11-2 [635 kB]\n",
            "Get:64 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-roboto-unhinted all 2:0~20170802-3 [2,376 kB]\n",
            "Get:65 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-sil-charis all 6.101-1 [3,973 kB]\n",
            "Get:66 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-sil-gentium all 20081126:1.03-4 [245 kB]\n",
            "Get:67 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-sil-gentium-basic all 1.102-1.1 [384 kB]\n",
            "Get:68 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-sil-gentiumplus all 6.101-1 [8,086 kB]\n",
            "Get:69 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-sil-gentiumplus-compact all 5.000-4 [1,514 kB]\n",
            "Get:70 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-texgyre all 20180621-3.1 [10.2 MB]\n",
            "Get:71 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libapache-pom-java all 18-1 [4,720 B]\n",
            "Get:72 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libcommons-parent-java all 43-1 [10.8 kB]\n",
            "Get:73 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libcommons-logging-java all 1.2-2 [60.3 kB]\n",
            "Get:74 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n",
            "Get:75 http://archive.ubuntu.com/ubuntu jammy/main amd64 rubygems-integration all 1.18 [5,336 B]\n",
            "Get:76 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ruby3.0 amd64 3.0.2-7ubuntu2.8 [50.1 kB]\n",
            "Get:77 http://archive.ubuntu.com/ubuntu jammy/main amd64 ruby-rubygems all 3.3.5-2 [228 kB]\n",
            "Get:78 http://archive.ubuntu.com/ubuntu jammy/main amd64 ruby amd64 1:3.0~exp1 [5,100 B]\n",
            "Get:79 http://archive.ubuntu.com/ubuntu jammy/main amd64 rake all 13.0.6-2 [61.7 kB]\n",
            "Get:80 http://archive.ubuntu.com/ubuntu jammy/main amd64 ruby-net-telnet all 0.1.1-2 [12.6 kB]\n",
            "Get:81 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ruby-webrick all 1.7.0-3ubuntu0.1 [52.1 kB]\n",
            "Get:82 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ruby-xmlrpc all 0.3.2-1ubuntu0.1 [24.9 kB]\n",
            "Get:83 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libruby3.0 amd64 3.0.2-7ubuntu2.8 [5,113 kB]\n",
            "Get:84 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]\n",
            "Get:85 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-utils amd64 1:7.7+6build2 [94.6 kB]\n",
            "Get:86 http://archive.ubuntu.com/ubuntu jammy/universe amd64 lmodern all 2.004.5-6.1 [9,471 kB]\n",
            "Get:87 http://archive.ubuntu.com/ubuntu jammy/universe amd64 preview-latex-style all 12.2-1ubuntu1 [185 kB]\n",
            "Get:88 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tex-gyre all 20180621-3.1 [6,209 kB]\n",
            "Get:89 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-fonts-extra all 2021.20220204-1 [484 MB]\n",
            "Get:90 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-stix all 1.1.1-4.1 [589 kB]\n",
            "Get:91 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-fonts-extra-links all 2021.20220204-1 [20.3 kB]\n",
            "Get:92 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-fonts-recommended all 2021.20220204-1 [4,972 kB]\n",
            "Get:93 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libfontbox-java all 1:1.8.16-2 [207 kB]\n",
            "Get:94 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libpdfbox-java all 1:1.8.16-2 [5,199 kB]\n",
            "Get:95 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-pictures all 2021.20220204-1 [8,720 kB]\n",
            "Get:96 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-latex-extra all 2021.20220204-1 [13.9 MB]\n",
            "Get:97 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-plain-generic all 2021.20220204-1 [27.5 MB]\n",
            "Get:98 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tipa all 2:1.3-21 [2,967 kB]\n",
            "Fetched 738 MB in 27s (27.5 MB/s)\n",
            "Extracting templates from packages: 100%\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package fonts-droid-fallback.\n",
            "(Reading database ... 125027 files and directories currently installed.)\n",
            "Preparing to unpack .../00-fonts-droid-fallback_1%3a6.0.1r16-1.1build1_all.deb ...\n",
            "Unpacking fonts-droid-fallback (1:6.0.1r16-1.1build1) ...\n",
            "Selecting previously unselected package fonts-lato.\n",
            "Preparing to unpack .../01-fonts-lato_2.0-2.1_all.deb ...\n",
            "Unpacking fonts-lato (2.0-2.1) ...\n",
            "Selecting previously unselected package poppler-data.\n",
            "Preparing to unpack .../02-poppler-data_0.4.11-1_all.deb ...\n",
            "Unpacking poppler-data (0.4.11-1) ...\n",
            "Selecting previously unselected package tex-common.\n",
            "Preparing to unpack .../03-tex-common_6.17_all.deb ...\n",
            "Unpacking tex-common (6.17) ...\n",
            "Selecting previously unselected package libkpathsea6:amd64.\n",
            "Preparing to unpack .../04-libkpathsea6_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking libkpathsea6:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Selecting previously unselected package libptexenc1:amd64.\n",
            "Preparing to unpack .../05-libptexenc1_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking libptexenc1:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Selecting previously unselected package libsynctex2:amd64.\n",
            "Preparing to unpack .../06-libsynctex2_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking libsynctex2:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Selecting previously unselected package libtexlua53:amd64.\n",
            "Preparing to unpack .../07-libtexlua53_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking libtexlua53:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Selecting previously unselected package libtexluajit2:amd64.\n",
            "Preparing to unpack .../08-libtexluajit2_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking libtexluajit2:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Selecting previously unselected package t1utils.\n",
            "Preparing to unpack .../09-t1utils_1.41-4build2_amd64.deb ...\n",
            "Unpacking t1utils (1.41-4build2) ...\n",
            "Selecting previously unselected package libteckit0:amd64.\n",
            "Preparing to unpack .../10-libteckit0_2.5.11+ds1-1_amd64.deb ...\n",
            "Unpacking libteckit0:amd64 (2.5.11+ds1-1) ...\n",
            "Selecting previously unselected package libzzip-0-13:amd64.\n",
            "Preparing to unpack .../11-libzzip-0-13_0.13.72+dfsg.1-1.1_amd64.deb ...\n",
            "Unpacking libzzip-0-13:amd64 (0.13.72+dfsg.1-1.1) ...\n",
            "Selecting previously unselected package texlive-binaries.\n",
            "Preparing to unpack .../12-texlive-binaries_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking texlive-binaries (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Selecting previously unselected package texlive-base.\n",
            "Preparing to unpack .../13-texlive-base_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-base (2021.20220204-1) ...\n",
            "Selecting previously unselected package fonts-lmodern.\n",
            "Preparing to unpack .../14-fonts-lmodern_2.004.5-6.1_all.deb ...\n",
            "Unpacking fonts-lmodern (2.004.5-6.1) ...\n",
            "Selecting previously unselected package texlive-latex-base.\n",
            "Preparing to unpack .../15-texlive-latex-base_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-latex-base (2021.20220204-1) ...\n",
            "Selecting previously unselected package texlive-latex-recommended.\n",
            "Preparing to unpack .../16-texlive-latex-recommended_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-latex-recommended (2021.20220204-1) ...\n",
            "Selecting previously unselected package cm-super-minimal.\n",
            "Preparing to unpack .../17-cm-super-minimal_0.3.4-17_all.deb ...\n",
            "Unpacking cm-super-minimal (0.3.4-17) ...\n",
            "Selecting previously unselected package pfb2t1c2pfb.\n",
            "Preparing to unpack .../18-pfb2t1c2pfb_0.3-11_amd64.deb ...\n",
            "Unpacking pfb2t1c2pfb (0.3-11) ...\n",
            "Selecting previously unselected package cm-super.\n",
            "Preparing to unpack .../19-cm-super_0.3.4-17_all.deb ...\n",
            "Unpacking cm-super (0.3.4-17) ...\n",
            "Selecting previously unselected package fonts-urw-base35.\n",
            "Preparing to unpack .../20-fonts-urw-base35_20200910-1_all.deb ...\n",
            "Unpacking fonts-urw-base35 (20200910-1) ...\n",
            "Selecting previously unselected package libgs9-common.\n",
            "Preparing to unpack .../21-libgs9-common_9.55.0~dfsg1-0ubuntu5.10_all.deb ...\n",
            "Unpacking libgs9-common (9.55.0~dfsg1-0ubuntu5.10) ...\n",
            "Selecting previously unselected package libidn12:amd64.\n",
            "Preparing to unpack .../22-libidn12_1.38-4ubuntu1_amd64.deb ...\n",
            "Unpacking libidn12:amd64 (1.38-4ubuntu1) ...\n",
            "Selecting previously unselected package libijs-0.35:amd64.\n",
            "Preparing to unpack .../23-libijs-0.35_0.35-15build2_amd64.deb ...\n",
            "Unpacking libijs-0.35:amd64 (0.35-15build2) ...\n",
            "Selecting previously unselected package libjbig2dec0:amd64.\n",
            "Preparing to unpack .../24-libjbig2dec0_0.19-3build2_amd64.deb ...\n",
            "Unpacking libjbig2dec0:amd64 (0.19-3build2) ...\n",
            "Selecting previously unselected package libgs9:amd64.\n",
            "Preparing to unpack .../25-libgs9_9.55.0~dfsg1-0ubuntu5.10_amd64.deb ...\n",
            "Unpacking libgs9:amd64 (9.55.0~dfsg1-0ubuntu5.10) ...\n",
            "Selecting previously unselected package ghostscript.\n",
            "Preparing to unpack .../26-ghostscript_9.55.0~dfsg1-0ubuntu5.10_amd64.deb ...\n",
            "Unpacking ghostscript (9.55.0~dfsg1-0ubuntu5.10) ...\n",
            "Selecting previously unselected package dvipng.\n",
            "Preparing to unpack .../27-dvipng_1.15-1.1_amd64.deb ...\n",
            "Unpacking dvipng (1.15-1.1) ...\n",
            "Selecting previously unselected package libwoff1:amd64.\n",
            "Preparing to unpack .../28-libwoff1_1.0.2-1build4_amd64.deb ...\n",
            "Unpacking libwoff1:amd64 (1.0.2-1build4) ...\n",
            "Selecting previously unselected package dvisvgm.\n",
            "Preparing to unpack .../29-dvisvgm_2.13.1-1_amd64.deb ...\n",
            "Unpacking dvisvgm (2.13.1-1) ...\n",
            "Selecting previously unselected package fonts-adf-accanthis.\n",
            "Preparing to unpack .../30-fonts-adf-accanthis_0.20190904-2_all.deb ...\n",
            "Unpacking fonts-adf-accanthis (0.20190904-2) ...\n",
            "Selecting previously unselected package fonts-adf-berenis.\n",
            "Preparing to unpack .../31-fonts-adf-berenis_0.20190904-2_all.deb ...\n",
            "Unpacking fonts-adf-berenis (0.20190904-2) ...\n",
            "Selecting previously unselected package fonts-adf-gillius.\n",
            "Preparing to unpack .../32-fonts-adf-gillius_0.20190904-2_all.deb ...\n",
            "Unpacking fonts-adf-gillius (0.20190904-2) ...\n",
            "Selecting previously unselected package fonts-adf-universalis.\n",
            "Preparing to unpack .../33-fonts-adf-universalis_0.20190904-2_all.deb ...\n",
            "Unpacking fonts-adf-universalis (0.20190904-2) ...\n",
            "Selecting previously unselected package fonts-cabin.\n",
            "Preparing to unpack .../34-fonts-cabin_1.5-3_all.deb ...\n",
            "Unpacking fonts-cabin (1.5-3) ...\n",
            "Selecting previously unselected package fonts-cantarell.\n",
            "Preparing to unpack .../35-fonts-cantarell_0.303-2_all.deb ...\n",
            "Unpacking fonts-cantarell (0.303-2) ...\n",
            "Selecting previously unselected package fonts-comfortaa.\n",
            "Preparing to unpack .../36-fonts-comfortaa_3.001-3_all.deb ...\n",
            "Unpacking fonts-comfortaa (3.001-3) ...\n",
            "Selecting previously unselected package fonts-croscore.\n",
            "Preparing to unpack .../37-fonts-croscore_20201225-1build1_all.deb ...\n",
            "Unpacking fonts-croscore (20201225-1build1) ...\n",
            "Selecting previously unselected package fonts-crosextra-caladea.\n",
            "Preparing to unpack .../38-fonts-crosextra-caladea_20130214-2.1_all.deb ...\n",
            "Unpacking fonts-crosextra-caladea (20130214-2.1) ...\n",
            "Selecting previously unselected package fonts-crosextra-carlito.\n",
            "Preparing to unpack .../39-fonts-crosextra-carlito_20130920-1.1_all.deb ...\n",
            "Unpacking fonts-crosextra-carlito (20130920-1.1) ...\n",
            "Selecting previously unselected package fonts-dejavu-core.\n",
            "Preparing to unpack .../40-fonts-dejavu-core_2.37-2build1_all.deb ...\n",
            "Unpacking fonts-dejavu-core (2.37-2build1) ...\n",
            "Selecting previously unselected package fonts-dejavu-extra.\n",
            "Preparing to unpack .../41-fonts-dejavu-extra_2.37-2build1_all.deb ...\n",
            "Unpacking fonts-dejavu-extra (2.37-2build1) ...\n",
            "Selecting previously unselected package fonts-ebgaramond.\n",
            "Preparing to unpack .../42-fonts-ebgaramond_0.016+git20210310.42d4f9f2-1_all.deb ...\n",
            "Unpacking fonts-ebgaramond (0.016+git20210310.42d4f9f2-1) ...\n",
            "Selecting previously unselected package fonts-ebgaramond-extra.\n",
            "Preparing to unpack .../43-fonts-ebgaramond-extra_0.016+git20210310.42d4f9f2-1_all.deb ...\n",
            "Unpacking fonts-ebgaramond-extra (0.016+git20210310.42d4f9f2-1) ...\n",
            "Selecting previously unselected package fonts-font-awesome.\n",
            "Preparing to unpack .../44-fonts-font-awesome_5.0.10+really4.7.0~dfsg-4.1_all.deb ...\n",
            "Unpacking fonts-font-awesome (5.0.10+really4.7.0~dfsg-4.1) ...\n",
            "Selecting previously unselected package fonts-freefont-otf.\n",
            "Preparing to unpack .../45-fonts-freefont-otf_20120503-10build1_all.deb ...\n",
            "Unpacking fonts-freefont-otf (20120503-10build1) ...\n",
            "Selecting previously unselected package fonts-freefont-ttf.\n",
            "Preparing to unpack .../46-fonts-freefont-ttf_20120503-10build1_all.deb ...\n",
            "Unpacking fonts-freefont-ttf (20120503-10build1) ...\n",
            "Selecting previously unselected package fonts-gfs-artemisia.\n",
            "Preparing to unpack .../47-fonts-gfs-artemisia_1.1-6_all.deb ...\n",
            "Unpacking fonts-gfs-artemisia (1.1-6) ...\n",
            "Selecting previously unselected package fonts-gfs-complutum.\n",
            "Preparing to unpack .../48-fonts-gfs-complutum_1.1-7_all.deb ...\n",
            "Unpacking fonts-gfs-complutum (1.1-7) ...\n",
            "Selecting previously unselected package fonts-gfs-didot.\n",
            "Preparing to unpack .../49-fonts-gfs-didot_1.1-7_all.deb ...\n",
            "Unpacking fonts-gfs-didot (1.1-7) ...\n",
            "Selecting previously unselected package fonts-gfs-neohellenic.\n",
            "Preparing to unpack .../50-fonts-gfs-neohellenic_1.1-7_all.deb ...\n",
            "Unpacking fonts-gfs-neohellenic (1.1-7) ...\n",
            "Selecting previously unselected package fonts-gfs-olga.\n",
            "Preparing to unpack .../51-fonts-gfs-olga_1.1-6_all.deb ...\n",
            "Unpacking fonts-gfs-olga (1.1-6) ...\n",
            "Selecting previously unselected package fonts-gfs-solomos.\n",
            "Preparing to unpack .../52-fonts-gfs-solomos_1.1-6_all.deb ...\n",
            "Unpacking fonts-gfs-solomos (1.1-6) ...\n",
            "Selecting previously unselected package fonts-go.\n",
            "Preparing to unpack .../53-fonts-go_0~20170330-1_all.deb ...\n",
            "Unpacking fonts-go (0~20170330-1) ...\n",
            "Selecting previously unselected package fonts-junicode.\n",
            "Preparing to unpack .../54-fonts-junicode_1.002-2_all.deb ...\n",
            "Unpacking fonts-junicode (1.002-2) ...\n",
            "Selecting previously unselected package fonts-linuxlibertine.\n",
            "Preparing to unpack .../55-fonts-linuxlibertine_5.3.0-6_all.deb ...\n",
            "Unpacking fonts-linuxlibertine (5.3.0-6) ...\n",
            "Selecting previously unselected package fonts-lobster.\n",
            "Preparing to unpack .../56-fonts-lobster_2.0-2.1_all.deb ...\n",
            "Unpacking fonts-lobster (2.0-2.1) ...\n",
            "Selecting previously unselected package fonts-lobstertwo.\n",
            "Preparing to unpack .../57-fonts-lobstertwo_2.0-2.1_all.deb ...\n",
            "Unpacking fonts-lobstertwo (2.0-2.1) ...\n",
            "Selecting previously unselected package fonts-noto-color-emoji.\n",
            "Preparing to unpack .../58-fonts-noto-color-emoji_2.042-0ubuntu0.22.04.1_all.deb ...\n",
            "Unpacking fonts-noto-color-emoji (2.042-0ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package fonts-noto-core.\n",
            "Preparing to unpack .../59-fonts-noto-core_20201225-1build1_all.deb ...\n",
            "Unpacking fonts-noto-core (20201225-1build1) ...\n",
            "Selecting previously unselected package fonts-noto-mono.\n",
            "Preparing to unpack .../60-fonts-noto-mono_20201225-1build1_all.deb ...\n",
            "Unpacking fonts-noto-mono (20201225-1build1) ...\n",
            "Selecting previously unselected package fonts-oflb-asana-math.\n",
            "Preparing to unpack .../61-fonts-oflb-asana-math_000.907-7build1_all.deb ...\n",
            "Unpacking fonts-oflb-asana-math (000.907-7build1) ...\n",
            "Selecting previously unselected package fonts-open-sans.\n",
            "Preparing to unpack .../62-fonts-open-sans_1.11-2_all.deb ...\n",
            "Unpacking fonts-open-sans (1.11-2) ...\n",
            "Selecting previously unselected package fonts-roboto-unhinted.\n",
            "Preparing to unpack .../63-fonts-roboto-unhinted_2%3a0~20170802-3_all.deb ...\n",
            "Unpacking fonts-roboto-unhinted (2:0~20170802-3) ...\n",
            "Selecting previously unselected package fonts-sil-charis.\n",
            "Preparing to unpack .../64-fonts-sil-charis_6.101-1_all.deb ...\n",
            "Unpacking fonts-sil-charis (6.101-1) ...\n",
            "Selecting previously unselected package fonts-sil-gentium.\n",
            "Preparing to unpack .../65-fonts-sil-gentium_20081126%3a1.03-4_all.deb ...\n",
            "Unpacking fonts-sil-gentium (20081126:1.03-4) ...\n",
            "Selecting previously unselected package fonts-sil-gentium-basic.\n",
            "Preparing to unpack .../66-fonts-sil-gentium-basic_1.102-1.1_all.deb ...\n",
            "Unpacking fonts-sil-gentium-basic (1.102-1.1) ...\n",
            "Selecting previously unselected package fonts-sil-gentiumplus.\n",
            "Preparing to unpack .../67-fonts-sil-gentiumplus_6.101-1_all.deb ...\n",
            "Unpacking fonts-sil-gentiumplus (6.101-1) ...\n",
            "Selecting previously unselected package fonts-sil-gentiumplus-compact.\n",
            "Preparing to unpack .../68-fonts-sil-gentiumplus-compact_5.000-4_all.deb ...\n",
            "Unpacking fonts-sil-gentiumplus-compact (5.000-4) ...\n",
            "Selecting previously unselected package fonts-texgyre.\n",
            "Preparing to unpack .../69-fonts-texgyre_20180621-3.1_all.deb ...\n",
            "Unpacking fonts-texgyre (20180621-3.1) ...\n",
            "Selecting previously unselected package libapache-pom-java.\n",
            "Preparing to unpack .../70-libapache-pom-java_18-1_all.deb ...\n",
            "Unpacking libapache-pom-java (18-1) ...\n",
            "Selecting previously unselected package libcommons-parent-java.\n",
            "Preparing to unpack .../71-libcommons-parent-java_43-1_all.deb ...\n",
            "Unpacking libcommons-parent-java (43-1) ...\n",
            "Selecting previously unselected package libcommons-logging-java.\n",
            "Preparing to unpack .../72-libcommons-logging-java_1.2-2_all.deb ...\n",
            "Unpacking libcommons-logging-java (1.2-2) ...\n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "Preparing to unpack .../73-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Selecting previously unselected package rubygems-integration.\n",
            "Preparing to unpack .../74-rubygems-integration_1.18_all.deb ...\n",
            "Unpacking rubygems-integration (1.18) ...\n",
            "Selecting previously unselected package ruby3.0.\n",
            "Preparing to unpack .../75-ruby3.0_3.0.2-7ubuntu2.8_amd64.deb ...\n",
            "Unpacking ruby3.0 (3.0.2-7ubuntu2.8) ...\n",
            "Selecting previously unselected package ruby-rubygems.\n",
            "Preparing to unpack .../76-ruby-rubygems_3.3.5-2_all.deb ...\n",
            "Unpacking ruby-rubygems (3.3.5-2) ...\n",
            "Selecting previously unselected package ruby.\n",
            "Preparing to unpack .../77-ruby_1%3a3.0~exp1_amd64.deb ...\n",
            "Unpacking ruby (1:3.0~exp1) ...\n",
            "Selecting previously unselected package rake.\n",
            "Preparing to unpack .../78-rake_13.0.6-2_all.deb ...\n",
            "Unpacking rake (13.0.6-2) ...\n",
            "Selecting previously unselected package ruby-net-telnet.\n",
            "Preparing to unpack .../79-ruby-net-telnet_0.1.1-2_all.deb ...\n",
            "Unpacking ruby-net-telnet (0.1.1-2) ...\n",
            "Selecting previously unselected package ruby-webrick.\n",
            "Preparing to unpack .../80-ruby-webrick_1.7.0-3ubuntu0.1_all.deb ...\n",
            "Unpacking ruby-webrick (1.7.0-3ubuntu0.1) ...\n",
            "Selecting previously unselected package ruby-xmlrpc.\n",
            "Preparing to unpack .../81-ruby-xmlrpc_0.3.2-1ubuntu0.1_all.deb ...\n",
            "Unpacking ruby-xmlrpc (0.3.2-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libruby3.0:amd64.\n",
            "Preparing to unpack .../82-libruby3.0_3.0.2-7ubuntu2.8_amd64.deb ...\n",
            "Unpacking libruby3.0:amd64 (3.0.2-7ubuntu2.8) ...\n",
            "Selecting previously unselected package xfonts-encodings.\n",
            "Preparing to unpack .../83-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\n",
            "Unpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Selecting previously unselected package xfonts-utils.\n",
            "Preparing to unpack .../84-xfonts-utils_1%3a7.7+6build2_amd64.deb ...\n",
            "Unpacking xfonts-utils (1:7.7+6build2) ...\n",
            "Selecting previously unselected package lmodern.\n",
            "Preparing to unpack .../85-lmodern_2.004.5-6.1_all.deb ...\n",
            "Unpacking lmodern (2.004.5-6.1) ...\n",
            "Selecting previously unselected package preview-latex-style.\n",
            "Preparing to unpack .../86-preview-latex-style_12.2-1ubuntu1_all.deb ...\n",
            "Unpacking preview-latex-style (12.2-1ubuntu1) ...\n",
            "Selecting previously unselected package tex-gyre.\n",
            "Preparing to unpack .../87-tex-gyre_20180621-3.1_all.deb ...\n",
            "Unpacking tex-gyre (20180621-3.1) ...\n",
            "Selecting previously unselected package texlive-fonts-extra.\n",
            "Preparing to unpack .../88-texlive-fonts-extra_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-fonts-extra (2021.20220204-1) ...\n",
            "Selecting previously unselected package fonts-stix.\n",
            "Preparing to unpack .../89-fonts-stix_1.1.1-4.1_all.deb ...\n",
            "Unpacking fonts-stix (1.1.1-4.1) ...\n",
            "Selecting previously unselected package texlive-fonts-extra-links.\n",
            "Preparing to unpack .../90-texlive-fonts-extra-links_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-fonts-extra-links (2021.20220204-1) ...\n",
            "Selecting previously unselected package texlive-fonts-recommended.\n",
            "Preparing to unpack .../91-texlive-fonts-recommended_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-fonts-recommended (2021.20220204-1) ...\n",
            "Selecting previously unselected package libfontbox-java.\n",
            "Preparing to unpack .../92-libfontbox-java_1%3a1.8.16-2_all.deb ...\n",
            "Unpacking libfontbox-java (1:1.8.16-2) ...\n",
            "Selecting previously unselected package libpdfbox-java.\n",
            "Preparing to unpack .../93-libpdfbox-java_1%3a1.8.16-2_all.deb ...\n",
            "Unpacking libpdfbox-java (1:1.8.16-2) ...\n",
            "Selecting previously unselected package texlive-pictures.\n",
            "Preparing to unpack .../94-texlive-pictures_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-pictures (2021.20220204-1) ...\n",
            "Selecting previously unselected package texlive-latex-extra.\n",
            "Preparing to unpack .../95-texlive-latex-extra_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-latex-extra (2021.20220204-1) ...\n",
            "Selecting previously unselected package texlive-plain-generic.\n",
            "Preparing to unpack .../96-texlive-plain-generic_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-plain-generic (2021.20220204-1) ...\n",
            "Selecting previously unselected package tipa.\n",
            "Preparing to unpack .../97-tipa_2%3a1.3-21_all.deb ...\n",
            "Unpacking tipa (2:1.3-21) ...\n",
            "Setting up pfb2t1c2pfb (0.3-11) ...\n",
            "Setting up fonts-gfs-didot (1.1-7) ...\n",
            "Setting up fonts-gfs-artemisia (1.1-6) ...\n",
            "Setting up fonts-sil-gentium-basic (1.102-1.1) ...\n",
            "Setting up fonts-cantarell (0.303-2) ...\n",
            "Setting up fonts-ebgaramond (0.016+git20210310.42d4f9f2-1) ...\n",
            "Setting up fonts-lato (2.0-2.1) ...\n",
            "Setting up fonts-junicode (1.002-2) ...\n",
            "Setting up fonts-noto-mono (20201225-1build1) ...\n",
            "Setting up libwoff1:amd64 (1.0.2-1build4) ...\n",
            "Setting up fonts-noto-color-emoji (2.042-0ubuntu0.22.04.1) ...\n",
            "Setting up libtexlua53:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Setting up fonts-adf-berenis (0.20190904-2) ...\n",
            "Setting up libijs-0.35:amd64 (0.35-15build2) ...\n",
            "Setting up libtexluajit2:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Setting up libfontbox-java (1:1.8.16-2) ...\n",
            "Setting up fonts-freefont-otf (20120503-10build1) ...\n",
            "Setting up fonts-freefont-ttf (20120503-10build1) ...\n",
            "Setting up fonts-gfs-solomos (1.1-6) ...\n",
            "Setting up fonts-comfortaa (3.001-3) ...\n",
            "Setting up rubygems-integration (1.18) ...\n",
            "Setting up libzzip-0-13:amd64 (0.13.72+dfsg.1-1.1) ...\n",
            "Setting up fonts-sil-gentiumplus-compact (5.000-4) ...\n",
            "Setting up fonts-roboto-unhinted (2:0~20170802-3) ...\n",
            "Setting up fonts-urw-base35 (20200910-1) ...\n",
            "Setting up fonts-open-sans (1.11-2) ...\n",
            "Setting up fonts-sil-gentiumplus (6.101-1) ...\n",
            "Setting up fonts-gfs-neohellenic (1.1-7) ...\n",
            "Setting up fonts-gfs-olga (1.1-6) ...\n",
            "Setting up fonts-oflb-asana-math (000.907-7build1) ...\n",
            "Setting up poppler-data (0.4.11-1) ...\n",
            "Setting up fonts-crosextra-carlito (20130920-1.1) ...\n",
            "Setting up fonts-adf-accanthis (0.20190904-2) ...\n",
            "Setting up tex-common (6.17) ...\n",
            "update-language: texlive-base not installed and configured, doing nothing!\n",
            "Setting up fonts-sil-gentium (20081126:1.03-4) ...\n",
            "Setting up fonts-adf-universalis (0.20190904-2) ...\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Setting up fonts-stix (1.1.1-4.1) ...\n",
            "Setting up fonts-sil-charis (6.101-1) ...\n",
            "Setting up libjbig2dec0:amd64 (0.19-3build2) ...\n",
            "Setting up fonts-go (0~20170330-1) ...\n",
            "Setting up libteckit0:amd64 (2.5.11+ds1-1) ...\n",
            "Setting up libapache-pom-java (18-1) ...\n",
            "Setting up ruby-net-telnet (0.1.1-2) ...\n",
            "Setting up fonts-cabin (1.5-3) ...\n",
            "Setting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Setting up t1utils (1.41-4build2) ...\n",
            "Setting up libidn12:amd64 (1.38-4ubuntu1) ...\n",
            "Setting up fonts-dejavu-core (2.37-2build1) ...\n",
            "Setting up fonts-texgyre (20180621-3.1) ...\n",
            "Setting up fonts-linuxlibertine (5.3.0-6) ...\n",
            "Setting up libkpathsea6:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Setting up fonts-croscore (20201225-1build1) ...\n",
            "Setting up ruby-webrick (1.7.0-3ubuntu0.1) ...\n",
            "Setting up fonts-dejavu-extra (2.37-2build1) ...\n",
            "Setting up fonts-gfs-complutum (1.1-7) ...\n",
            "Setting up fonts-crosextra-caladea (20130214-2.1) ...\n",
            "Setting up fonts-lmodern (2.004.5-6.1) ...\n",
            "Setting up fonts-ebgaramond-extra (0.016+git20210310.42d4f9f2-1) ...\n",
            "Setting up fonts-lobster (2.0-2.1) ...\n",
            "Setting up fonts-droid-fallback (1:6.0.1r16-1.1build1) ...\n",
            "Setting up fonts-adf-gillius (0.20190904-2) ...\n",
            "Setting up ruby-xmlrpc (0.3.2-1ubuntu0.1) ...\n",
            "Setting up fonts-noto-core (20201225-1build1) ...\n",
            "Setting up fonts-font-awesome (5.0.10+really4.7.0~dfsg-4.1) ...\n",
            "Setting up libsynctex2:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Setting up libgs9-common (9.55.0~dfsg1-0ubuntu5.10) ...\n",
            "Setting up libpdfbox-java (1:1.8.16-2) ...\n",
            "Setting up libgs9:amd64 (9.55.0~dfsg1-0ubuntu5.10) ...\n",
            "Setting up preview-latex-style (12.2-1ubuntu1) ...\n",
            "Setting up libcommons-parent-java (43-1) ...\n",
            "Setting up dvisvgm (2.13.1-1) ...\n",
            "Setting up libcommons-logging-java (1.2-2) ...\n",
            "Setting up ghostscript (9.55.0~dfsg1-0ubuntu5.10) ...\n",
            "Setting up xfonts-utils (1:7.7+6build2) ...\n",
            "Setting up fonts-lobstertwo (2.0-2.1) ...\n",
            "Setting up libptexenc1:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Setting up texlive-fonts-extra-links (2021.20220204-1) ...\n",
            "Setting up texlive-binaries (2021.20210626.59705-1ubuntu0.2) ...\n",
            "update-alternatives: using /usr/bin/xdvi-xaw to provide /usr/bin/xdvi.bin (xdvi.bin) in auto mode\n",
            "update-alternatives: using /usr/bin/bibtex.original to provide /usr/bin/bibtex (bibtex) in auto mode\n",
            "Setting up lmodern (2.004.5-6.1) ...\n",
            "Setting up texlive-base (2021.20220204-1) ...\n",
            "/usr/bin/ucfr\n",
            "/usr/bin/ucfr\n",
            "/usr/bin/ucfr\n",
            "/usr/bin/ucfr\n",
            "mktexlsr: Updating /var/lib/texmf/ls-R-TEXLIVEDIST... \n",
            "mktexlsr: Updating /var/lib/texmf/ls-R-TEXMFMAIN... \n",
            "mktexlsr: Updating /var/lib/texmf/ls-R... \n",
            "mktexlsr: Done.\n",
            "tl-paper: setting paper size for dvips to a4: /var/lib/texmf/dvips/config/config-paper.ps\n",
            "tl-paper: setting paper size for dvipdfmx to a4: /var/lib/texmf/dvipdfmx/dvipdfmx-paper.cfg\n",
            "tl-paper: setting paper size for xdvi to a4: /var/lib/texmf/xdvi/XDvi-paper\n",
            "tl-paper: setting paper size for pdftex to a4: /var/lib/texmf/tex/generic/tex-ini-files/pdftexconfig.tex\n",
            "Setting up tex-gyre (20180621-3.1) ...\n",
            "Setting up dvipng (1.15-1.1) ...\n",
            "Setting up texlive-plain-generic (2021.20220204-1) ...\n",
            "Setting up texlive-latex-base (2021.20220204-1) ...\n",
            "Setting up texlive-fonts-extra (2021.20220204-1) ...\n",
            "Setting up texlive-latex-recommended (2021.20220204-1) ...\n",
            "Setting up texlive-pictures (2021.20220204-1) ...\n",
            "Setting up texlive-fonts-recommended (2021.20220204-1) ...\n",
            "Setting up tipa (2:1.3-21) ...\n",
            "Setting up cm-super-minimal (0.3.4-17) ...\n",
            "Setting up texlive-latex-extra (2021.20220204-1) ...\n",
            "Setting up cm-super (0.3.4-17) ...\n",
            "Creating fonts. This may take some time... done.\n",
            "Setting up rake (13.0.6-2) ...\n",
            "Setting up libruby3.0:amd64 (3.0.2-7ubuntu2.8) ...\n",
            "Setting up ruby3.0 (3.0.2-7ubuntu2.8) ...\n",
            "Setting up ruby (1:3.0~exp1) ...\n",
            "Setting up ruby-rubygems (3.3.5-2) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "Processing triggers for tex-common (6.17) ...\n",
            "Running updmap-sys. This may take some time... done.\n",
            "Running mktexlsr /var/lib/texmf ... done.\n",
            "Building format(s) --all.\n",
            "\tThis may take some time... done.\n",
            "Requirement already satisfied: python-pptx in /usr/local/lib/python3.11/dist-packages (1.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: XlsxWriter>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (3.2.2)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (5.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (4.12.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.55.7)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "0QZmD5jwmyzU",
        "outputId": "9cf4b897-57b0-454e-8d02-25a45054e7ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload your PowerPoint template...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e177353c-157d-43c3-8fea-f3c48c4241cc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e177353c-157d-43c3-8fea-f3c48c4241cc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Crop.pptx to Crop (2).pptx\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e03f5b1c-bbea-4cbd-afc5-f61a70062d06\", \"UNDERSTANDING_LSTM_NETWORKS.pptx\", 50787)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_answer(api_response):\n",
        "    \"\"\"Extracts and validates keywords from the API response\"\"\"\n",
        "    try:\n",
        "        valid_suffixes = ['-visualization', '-diagram', '-illustration', '-example', '-steps']\n",
        "\n",
        "        # Handle different input types\n",
        "        if isinstance(api_response, list):\n",
        "            response_text = api_response[0].get('generated_text', '')\n",
        "        elif isinstance(api_response, dict):\n",
        "            response_text = api_response.get('generated_text', '')\n",
        "        else:\n",
        "            response_text = str(api_response)\n",
        "\n",
        "        # Look for the keywords section\n",
        "        if \"KEYWORDS (comma-separated):\" in response_text:\n",
        "            keywords_section = response_text.split(\"KEYWORDS (comma-separated):\")[-1].strip()\n",
        "            keyword_lines = [line.strip() for line in keywords_section.split('\\n') if line.strip()]\n",
        "\n",
        "            if not keyword_lines:\n",
        "                return []\n",
        "\n",
        "            # Take the first line of keywords\n",
        "            keywords = keyword_lines[0]\n",
        "\n",
        "            # Split and clean keywords\n",
        "            cleaned_keywords = []\n",
        "            for keyword in keywords.split(','):\n",
        "                keyword = keyword.strip()\n",
        "                if (keyword and\n",
        "                    '-' in keyword and\n",
        "                    any(keyword.endswith(suffix) for suffix in valid_suffixes) and\n",
        "                    keyword.count('-') >= 2):\n",
        "                    cleaned_keywords.append(keyword)\n",
        "\n",
        "            # Remove duplicates and limit to 7\n",
        "            cleaned_keywords = list(set(cleaned_keywords))[:7]\n",
        "\n",
        "            return cleaned_keywords if len(cleaned_keywords) >= 3 else []\n",
        "\n",
        "        return []\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting keywords: {str(e)}\")\n",
        "        return []"
      ],
      "metadata": {
        "id": "1k8UID7pLhmO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####################################################################### IMAGE KEYWORD CODE ################################################################\n",
        "def create_image_keyword_prompt(content):\n",
        "    \"\"\"\n",
        "    Creates a prompt for generating image search keywords that works with any technical topic.\n",
        "\n",
        "    Args:\n",
        "        content (str): Technical content to analyze for image-searchable keywords\n",
        "\n",
        "    Returns:\n",
        "        str: Generic prompt that works with any technical content\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"You are a technical visualization expert. Extract specific image search keywords from the following content:\n",
        "\n",
        "{content}\n",
        "\n",
        "Your task: Generate 2-3 max most relevant image search keywords that would help find educational diagrams and technical visualizations related to the main concepts in this content.\n",
        "\n",
        "Focus on identifying keywords for:\n",
        "1. System/concept architecture diagrams\n",
        "2. Process flows and sequences\n",
        "3. Component interactions\n",
        "4. Implementation details\n",
        "5. Working mechanisms\n",
        "6. Step-by-step procedures\n",
        "7. Technical examples\n",
        "\n",
        "Keyword Generation Rules:\n",
        "1. Each keyword MUST use hyphens between words\n",
        "2. Each keyword MUST end with exactly ONE of these suffixes:\n",
        "   - -visualization\n",
        "   - -diagram\n",
        "   - -illustration\n",
        "   - -example\n",
        "   - -steps\n",
        "\n",
        "Key Requirements:\n",
        "- Use specific technical terms from the content\n",
        "- Include major concepts and processes\n",
        "- Avoid generic/non-specific terms\n",
        "- Keywords must directly relate to main topics\n",
        "- Each keyword should help find relevant technical diagrams\n",
        "\n",
        "Output Format:\n",
        "ONLY provide a comma-separated list of keywords. Example:\n",
        "concept-architecture-diagram, process-flow-visualization, component-interaction-illustration\n",
        "\n",
        "KEYWORDS (comma-separated):\"\"\"\n",
        "\n",
        "    return prompt\n",
        "\n",
        "# Modify the main function to work with your existing setup\n",
        "def main():\n",
        "    # Use your existing content and context\n",
        "    prompt = create_image_keyword_prompt(result)\n",
        "    #print(prompt)\n",
        "\n",
        "    # Use your existing API call function\n",
        "    api_response = query_huggingface_api(prompt, max_length=25000)\n",
        "\n",
        "    # Extract the keywords\n",
        "    image_keywords = extract_answer(api_response)\n",
        "\n",
        "    print(\"Generated Image Search Keywords:\")\n",
        "    print(image_keywords)\n",
        "\n",
        "    image_keywords = image_keywords[:3]\n",
        "    print(image_keywords)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMN77_iI56gh",
        "outputId": "99cf27f8-b864-405e-da66-5d25522897f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Image Search Keywords:\n",
            "['lstm-cell-diagram', 'lstm-working-mechanism-steps', 'input-gate-forget-gate-output-gate-illustration', 'long-short-term-memory-lstm-visualization', 'lstm-implementation-example']\n",
            "['lstm-cell-diagram', 'lstm-working-mechanism-steps', 'input-gate-forget-gate-output-gate-illustration']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import requests\n",
        "from pptx import Presentation\n",
        "from pptx.util import Inches, Pt\n",
        "from pptx.enum.text import PP_ALIGN\n",
        "from pptx.dml.color import RGBColor\n",
        "\n",
        "def scrape_images(keyword, num_images=4):\n",
        "    \"\"\"Scrape images from GeeksForGeeks using SERP API\"\"\"\n",
        "    api_key = \"df7729cfcc6f85cfea8e18cb9f13ce5180a3ea6e1c22e2e5f3de3ea16bd6e40b\"\n",
        "\n",
        "    params = {\n",
        "        \"engine\": \"google_images\",\n",
        "        \"q\": keyword,\n",
        "        \"google_domain\": \"google.com\",\n",
        "        \"gl\": \"us\",\n",
        "        \"hl\": \"en\",\n",
        "        \"api_key\": api_key,\n",
        "    }\n",
        "\n",
        "    response = requests.get(\"https://serpapi.com/search.json\", params=params)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        images = []\n",
        "\n",
        "        if \"images_results\" in data:\n",
        "            for image in data[\"images_results\"]:\n",
        "                if 'geeksforgeeks' in image.get('source', '').lower():\n",
        "                    images.append(image[\"original\"])\n",
        "                    if len(images) >= num_images:\n",
        "                        break\n",
        "            return images\n",
        "\n",
        "        return []\n",
        "    else:\n",
        "        print(f\"Failed to retrieve images. Status code: {response.status_code}\")\n",
        "        return []\n",
        "\n"
      ],
      "metadata": {
        "id": "hBj1ZMpP6C2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###############################################  WITH IMAGES #######################################\n",
        "import requests\n",
        "from pptx import Presentation\n",
        "from pptx.util import Inches, Pt\n",
        "from pptx.enum.text import PP_ALIGN, MSO_VERTICAL_ANCHOR\n",
        "from pptx.dml.color import RGBColor\n",
        "import re\n",
        "import io\n",
        "from PIL import Image\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class SlideContentManager:\n",
        "    def __init__(self, slide):\n",
        "        self.slide = slide\n",
        "        self.current_top = Inches(2)\n",
        "\n",
        "    def add_content(self, content, level, content_type):\n",
        "        \"\"\"Add content to slide with proper spacing\"\"\"\n",
        "        if content_type in ['code', 'code_continued']:\n",
        "            height = self._add_code_block(content)\n",
        "            self.current_top += height + Inches(0.6)\n",
        "        elif content_type == 'equation':\n",
        "            success = self._add_equation(content)\n",
        "            if success:\n",
        "                self.current_top += Inches(0.8)\n",
        "        elif content_type == 'subheading':\n",
        "            self._add_subheading(content)\n",
        "            self.current_top += Inches(0.6)\n",
        "        elif content_type == 'image':\n",
        "            self._add_image(content)\n",
        "            self.current_top += Inches(2)\n",
        "        else:\n",
        "            self._add_text_content(content, level)\n",
        "            self.current_top += Inches(0.4)\n",
        "\n",
        "    def _add_image(self, image_url):\n",
        "        \"\"\"Add an image to the slide, with optimized sizing and proper centering\"\"\"\n",
        "        try:\n",
        "            # Download the image\n",
        "            response = requests.get(image_url)\n",
        "            if response.status_code == 200:\n",
        "                # Open the image using Pillow\n",
        "                img_buf = io.BytesIO(response.content)\n",
        "                original_img = Image.open(img_buf)\n",
        "\n",
        "                # Convert image to RGB mode\n",
        "                img = original_img.convert('RGB')\n",
        "\n",
        "                # Define slide dimensions in inches (standard 16:9 ratio)\n",
        "                SLIDE_WIDTH_INCHES = 10\n",
        "                SLIDE_HEIGHT_INCHES = 5.625\n",
        "\n",
        "                # Get original image dimensions in pixels\n",
        "                img_width_pixels, img_height_pixels = img.size\n",
        "\n",
        "                # Convert to inches (assuming 96 DPI)\n",
        "                img_width_inches = img_width_pixels / 96\n",
        "                img_height_inches = img_height_pixels / 96\n",
        "\n",
        "                # Calculate maximum allowed dimensions (70% of slide)\n",
        "                max_width_inches = SLIDE_WIDTH_INCHES * 0.7\n",
        "                max_height_inches = SLIDE_HEIGHT_INCHES * 0.7\n",
        "\n",
        "                # Calculate scaling factor to fit within maximum dimensions\n",
        "                width_scale = max_width_inches / img_width_inches\n",
        "                height_scale = max_height_inches / img_height_inches\n",
        "                scale = min(width_scale, height_scale)\n",
        "\n",
        "                # Calculate final dimensions in inches\n",
        "                final_width_inches = img_width_inches * scale\n",
        "                final_height_inches = img_height_inches * scale\n",
        "\n",
        "                # Calculate centering positions in inches\n",
        "                left_inches = (SLIDE_WIDTH_INCHES - final_width_inches) / 2\n",
        "                top_inches = (SLIDE_HEIGHT_INCHES - final_height_inches) / 2\n",
        "\n",
        "                # Convert the image to the new size in pixels\n",
        "                new_width_pixels = int(final_width_inches * 96)\n",
        "                new_height_pixels = int(final_height_inches * 96)\n",
        "                img = img.resize((new_width_pixels, new_height_pixels), Image.LANCZOS)\n",
        "\n",
        "                # Save as PNG\n",
        "                png_buf = io.BytesIO()\n",
        "                img.save(png_buf, format='PNG')\n",
        "                png_buf.seek(0)\n",
        "\n",
        "                # Add image to slide using Inches for all measurements\n",
        "                self.slide.shapes.add_picture(\n",
        "                    png_buf,\n",
        "                    Inches(left_inches),\n",
        "                    Inches(top_inches),\n",
        "                    width=Inches(final_width_inches),\n",
        "                    height=Inches(final_height_inches)\n",
        "                )\n",
        "                print(f\"Successfully added image: {image_url}\")\n",
        "                return True\n",
        "            else:\n",
        "                print(f\"Failed to download image. Status code: {response.status_code}\")\n",
        "                return False\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing image {image_url}: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def _add_text_content(self, text, level):\n",
        "        \"\"\"Add text content with proper formatting\"\"\"\n",
        "        content_shape = self.slide.placeholders[1]\n",
        "        text_frame = content_shape.text_frame\n",
        "\n",
        "        paragraph = text_frame.add_paragraph()\n",
        "        paragraph.level = level\n",
        "\n",
        "        parts = re.split(r'(\\*\\*.*?\\*\\*)', text)\n",
        "        for part in parts:\n",
        "            if part:\n",
        "                run = paragraph.add_run()\n",
        "                if part.startswith('**') and part.endswith('**'):\n",
        "                    run.text = part.strip('*')\n",
        "                    run.font.bold = True\n",
        "                else:\n",
        "                    run.text = part\n",
        "                    run.font.bold = False\n",
        "                run.font.size = Pt(14)\n",
        "\n",
        "        if level == 2:\n",
        "            paragraph.indent = Inches(0.5)\n",
        "\n",
        "    def _add_subheading(self, text):\n",
        "        \"\"\"Add subheading with proper formatting\"\"\"\n",
        "        content_shape = self.slide.placeholders[1]\n",
        "        text_frame = content_shape.text_frame\n",
        "\n",
        "        paragraph = text_frame.add_paragraph()\n",
        "        run = paragraph.add_run()\n",
        "        run.text = text[2:].strip() if text.startswith('##') else text.strip()\n",
        "        run.font.bold = True\n",
        "        run.font.size = Pt(16)\n",
        "\n",
        "    def _add_code_block(self, code):\n",
        "        \"\"\"Add code block with proper spacing\"\"\"\n",
        "        left = Inches(1)\n",
        "        width = Inches(11)\n",
        "\n",
        "        line_height = Inches(0.3)\n",
        "        total_height = len(code.split('\\n')) * line_height + Inches(0.5)\n",
        "\n",
        "        textbox = self.slide.shapes.add_textbox(left, self.current_top, width, total_height)\n",
        "        text_frame = textbox.text_frame\n",
        "\n",
        "        paragraph = text_frame.add_paragraph()\n",
        "        run = paragraph.add_run()\n",
        "        run.text = code\n",
        "        run.font.name = 'Courier New'\n",
        "        run.font.size = Pt(11)\n",
        "\n",
        "        fill = textbox.fill\n",
        "        fill.solid()\n",
        "        fill.fore_color.rgb = RGBColor(245, 245, 245)\n",
        "\n",
        "        return total_height\n",
        "\n",
        "    def _add_equation(self, equation):\n",
        "        \"\"\"Add equation with proper spacing\"\"\"\n",
        "        try:\n",
        "            plt.rc('text', usetex=True)\n",
        "            plt.rc('font', family='serif')\n",
        "\n",
        "            fig = plt.figure(figsize=(10, 1))\n",
        "            plt.axis('off')\n",
        "            plt.text(0.5, 0.5, f'${equation}$',\n",
        "                    fontsize=14,\n",
        "                    horizontalalignment='center',\n",
        "                    verticalalignment='center')\n",
        "\n",
        "            buf = io.BytesIO()\n",
        "            plt.savefig(buf, format='png', dpi=300, bbox_inches='tight', transparent=True)\n",
        "            plt.close(fig)\n",
        "\n",
        "            buf.seek(0)\n",
        "            left = Inches(1)\n",
        "            self.slide.shapes.add_picture(buf, left, self.current_top, height=Inches(0.8))\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"Error rendering equation: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "class SlideGenerator:\n",
        "    def __init__(self, presentation_title, template_path):\n",
        "        self.prs = Presentation(template_path)\n",
        "        self.presentation_title = presentation_title\n",
        "        self.used_images = set()\n",
        "\n",
        "    def _add_title_slide(self):\n",
        "        \"\"\"Create title slide\"\"\"\n",
        "        slide = self.prs.slides.add_slide(self.prs.slide_layouts[0])\n",
        "        title_shape = slide.shapes.title\n",
        "        title_shape.text = self.presentation_title\n",
        "\n",
        "        paragraph = title_shape.text_frame.paragraphs[0]\n",
        "        paragraph.alignment = PP_ALIGN.CENTER\n",
        "        run = paragraph.runs[0]\n",
        "        run.font.size = Pt(44)\n",
        "        run.font.bold = True\n",
        "        run.font.color.rgb = RGBColor(44, 62, 80)\n",
        "\n",
        "    def _create_content_slides(self, title, content_chunk, slide_number=1, total_slides=1, image_keywords=None):\n",
        "        \"\"\"Create content slides with properly spaced images\"\"\"\n",
        "        # Create main content slide\n",
        "        slide = self.prs.slides.add_slide(self.prs.slide_layouts[1])\n",
        "        content_manager = SlideContentManager(slide)\n",
        "\n",
        "        # Add and format slide title\n",
        "        title_shape = slide.shapes.title\n",
        "        clean_title = self._clean_title(title)\n",
        "        title_shape.text = f\"{clean_title} ({slide_number}/{total_slides})\" if total_slides > 1 else clean_title\n",
        "        title_run = title_shape.text_frame.paragraphs[0].runs[0]\n",
        "        title_run.font.size = Pt(32)\n",
        "        title_run.font.bold = True\n",
        "\n",
        "        # Add content\n",
        "        full_content = ' '.join([content for content, _, _ in content_chunk])\n",
        "        for content, level, content_type in content_chunk:\n",
        "            content_manager.add_content(content, level, content_type)\n",
        "\n",
        "        # Handle images after content - STRICT limit to 3 images total\n",
        "        if image_keywords and slide_number == 1 and len(self.used_images) < 3:\n",
        "            for keyword in image_keywords[:3 - len(self.used_images)]:\n",
        "                if len(self.used_images) >= 3:  # Double-check limit\n",
        "                    break\n",
        "\n",
        "                try:\n",
        "                    # Create a new slide for the image\n",
        "                    img_slide = self.prs.slides.add_slide(self.prs.slide_layouts[1])\n",
        "                    img_content_manager = SlideContentManager(img_slide)\n",
        "\n",
        "                    # Set image slide title (smaller font)\n",
        "                    img_title_shape = img_slide.shapes.title\n",
        "                    img_title_shape.text = f\"{clean_title} - {keyword.replace('-', ' ').title()}\"\n",
        "                    img_title_run = img_title_shape.text_frame.paragraphs[0].runs[0]\n",
        "                    img_title_run.font.size = Pt(24)\n",
        "\n",
        "                    # Get and add image\n",
        "                    images = scrape_images(f\"{keyword} related to {full_content}\")\n",
        "                    if images and len(self.used_images) < 3:  # Re-check limit\n",
        "                        image_url = images[0]\n",
        "                        if image_url not in self.used_images:\n",
        "                            if img_content_manager._add_image(image_url):\n",
        "                                self.used_images.add(image_url)\n",
        "                                print(f\"Added image {len(self.used_images)}/3 for keyword: {keyword}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing image for keyword '{keyword}': {e}\")\n",
        "                    continue\n",
        "\n",
        "    def _clean_title(self, title):\n",
        "        \"\"\"Remove markdown formatting from title\"\"\"\n",
        "        return title.replace('**', '').strip()\n",
        "\n",
        "    def generate_presentation(self, content, image_keywords=None):\n",
        "        \"\"\"Generate presentation with content and properly distributed images\"\"\"\n",
        "        sections = re.split(r'##\\s+\\d+\\.\\s+', content)[1:]\n",
        "        self._add_title_slide()\n",
        "\n",
        "        for section in sections:\n",
        "            title_match = re.match(r'\\*\\*(.*?)\\*\\*', section)\n",
        "            if title_match:\n",
        "                title = title_match.group(1)\n",
        "                content = section[title_match.end():].strip()\n",
        "\n",
        "                # Distribute content across slides\n",
        "                chunks = self._distribute_content(content)\n",
        "                for i, chunk in enumerate(chunks, 1):\n",
        "                    self._create_content_slides(\n",
        "                        title,\n",
        "                        chunk,\n",
        "                        i,\n",
        "                        len(chunks),\n",
        "                        image_keywords if i == 1 else None\n",
        "                    )\n",
        "\n",
        "    def _distribute_content(self, content):\n",
        "        \"\"\"Distribute content into well-spaced chunks, keeping related content together\"\"\"\n",
        "        lines = content.split('\\n')\n",
        "        chunks = []\n",
        "        current_chunk = []\n",
        "\n",
        "        for i, line in enumerate(lines):\n",
        "            if line.strip():\n",
        "                # Identify if line is a bullet point or subheading\n",
        "                is_bullet = line.strip().startswith('■') or line.strip().startswith('•')\n",
        "                is_subheading = line.strip().startswith('##')\n",
        "\n",
        "                # Start new chunk if we find a bullet/subheading and already have content\n",
        "                if (is_bullet or is_subheading) and current_chunk:\n",
        "                    chunks.append(current_chunk)\n",
        "                    current_chunk = []\n",
        "\n",
        "                # Add the current line with appropriate type\n",
        "                content_type = 'subheading' if is_subheading else 'text'\n",
        "                level = 1 if is_bullet else 0\n",
        "                current_chunk.append((line.strip(), level, content_type))\n",
        "\n",
        "                # Look ahead to see if next line is related content\n",
        "                if i < len(lines) - 1:\n",
        "                    next_line = lines[i + 1].strip()\n",
        "                    if next_line and not (next_line.startswith('■') or next_line.startswith('•') or next_line.startswith('##')):\n",
        "                        continue\n",
        "\n",
        "            elif current_chunk:  # Empty line and we have content\n",
        "                chunks.append(current_chunk)\n",
        "                current_chunk = []\n",
        "\n",
        "        # Add the last chunk if it exists\n",
        "        if current_chunk:\n",
        "            chunks.append(current_chunk)\n",
        "\n",
        "        # If no chunks were created, return the content as a single chunk\n",
        "        if not chunks:\n",
        "            return [[(content.strip(), 0, 'text')]]\n",
        "\n",
        "        return chunks\n",
        "\n",
        "    def save(self):\n",
        "        \"\"\"Save presentation with query-based filename\"\"\"\n",
        "        filename = f\"{self.presentation_title.replace(' ', '_')}.pptx\"\n",
        "        self.prs.save(filename)\n",
        "        files.download(filename)\n",
        "\n",
        "\n",
        "def create_presentation(query, content, template_path, image_keywords=None):\n",
        "    \"\"\"Main function to create presentation\"\"\"\n",
        "    generator = SlideGenerator(query.upper(), template_path)\n",
        "    generator.generate_presentation(content, image_keywords)\n",
        "    generator.save()\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Please upload your PowerPoint template...\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    template_path = next(iter(uploaded.keys()))\n",
        "\n",
        "    with open('content.txt', 'r') as file:\n",
        "        content = file.read()\n",
        "\n",
        "    prompt = create_image_keyword_prompt(result)\n",
        "    api_response = query_huggingface_api(prompt, max_length=25000)\n",
        "    image_keywords = extract_answer(api_response)\n",
        "    image_keywords = image_keywords[:3]\n",
        "\n",
        "    print(\"Generated Image Search Keywords:\")\n",
        "    print(image_keywords)\n",
        "\n",
        "    # Create the presentation using the generated keywords\n",
        "    create_presentation(query, content, template_path, image_keywords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "4XEeX5DGKPog",
        "outputId": "0834cadb-e8e3-46d2-baf1-c9c6dc1d9fd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload your PowerPoint template...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4a2583f6-b04e-48e0-9a7a-13410d2c5aff\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4a2583f6-b04e-48e0-9a7a-13410d2c5aff\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Crop.pptx to Crop (5).pptx\n",
            "Generated Image Search Keywords:\n",
            "['lstm-cell-diagram', 'lstm-working-mechanism-steps', 'input-gate-forget-gate-output-gate-illustration']\n",
            "Successfully added image: https://media.geeksforgeeks.org/wp-content/uploads/newContent1.png\n",
            "Added image 1/3 for keyword: lstm-cell-diagram\n",
            "Successfully added image: https://media.geeksforgeeks.org/wp-content/uploads/20190702161054/unrolled2.png\n",
            "Added image 2/3 for keyword: input-gate-forget-gate-output-gate-illustration\n",
            "Successfully added image: https://media.geeksforgeeks.org/wp-content/uploads/20240208053129/lstm.webp\n",
            "Added image 3/3 for keyword: lstm-cell-diagram\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_77e57180-526c-465f-bcbd-d0e2ece68828\", \"LSTM.pptx\", 252419)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import requests\n",
        "# from pptx import Presentation\n",
        "# from pptx.util import Inches, Pt\n",
        "# from pptx.enum.text import PP_ALIGN, MSO_VERTICAL_ANCHOR\n",
        "# from pptx.dml.color import RGBColor\n",
        "# import re\n",
        "# import io\n",
        "# from PIL import Image\n",
        "# from google.colab import files\n",
        "\n",
        "# # Function to scrape images from GeeksForGeeks using SERP API\n",
        "# def scrape_images(keyword, num_images=2):\n",
        "#     \"\"\"Scrape images from GeeksForGeeks using SERP API\"\"\"\n",
        "#     api_key = \"41cf19594f02970e20e9362044f5605347e8e04ce0cf4a9614504c087d2bae2e\"\n",
        "\n",
        "#     params = {\n",
        "#         \"engine\": \"google_images\",\n",
        "#         \"q\": keyword,\n",
        "#         \"google_domain\": \"google.com\",\n",
        "#         \"gl\": \"us\",\n",
        "#         \"hl\": \"en\",\n",
        "#         \"api_key\": api_key,\n",
        "#     }\n",
        "\n",
        "#     response = requests.get(\"https://serpapi.com/search.json\", params=params)\n",
        "\n",
        "#     if response.status_code == 200:\n",
        "#         data = response.json()\n",
        "#         images = []\n",
        "\n",
        "#         if \"images_results\" in data:\n",
        "#             for image in data[\"images_results\"]:\n",
        "#                 if 'geeksforgeeks' in image.get('source', '').lower():\n",
        "#                     images.append(image[\"original\"])\n",
        "#                     if len(images) >= num_images:\n",
        "#                         break\n",
        "#             return images\n",
        "\n",
        "#         return []\n",
        "#     else:\n",
        "#         print(f\"Failed to retrieve images. Status code: {response.status_code}\")\n",
        "#         return []\n",
        "\n",
        "# # Function to generate image search keywords using a model\n",
        "# def create_image_keyword_prompt(content):\n",
        "#     \"\"\"Creates a prompt for generating image search keywords\"\"\"\n",
        "#     prompt = f\"\"\"You are a technical visualization expert. Extract specific image search keywords from the following content:\n",
        "\n",
        "# {content}\n",
        "\n",
        "# Your task: Generate 5-7 image search keywords that would help find educational diagrams and technical visualizations related to the main concepts in this content.\n",
        "\n",
        "# Focus on identifying keywords for:\n",
        "# 1. System/concept architecture diagrams\n",
        "# 2. Process flows and sequences\n",
        "# 3. Component interactions\n",
        "# 4. Implementation details\n",
        "# 5. Working mechanisms\n",
        "# 6. Step-by-step procedures\n",
        "# 7. Technical examples\n",
        "\n",
        "# Keyword Generation Rules:\n",
        "# 1. Each keyword MUST use hyphens between words\n",
        "# 2. Each keyword MUST end with exactly ONE of these suffixes:\n",
        "#    - -visualization\n",
        "#    - -diagram\n",
        "#    - -illustration\n",
        "#    - -example\n",
        "#    - -steps\n",
        "\n",
        "# Key Requirements:\n",
        "# - Use specific technical terms from the content\n",
        "# - Include major concepts and processes\n",
        "# - Avoid generic/non-specific terms\n",
        "# - Keywords must directly relate to main topics\n",
        "# - Each keyword should help find relevant technical diagrams\n",
        "\n",
        "# Output Format:\n",
        "# ONLY provide a comma-separated list of keywords. Example:\n",
        "# concept-architecture-diagram, process-flow-visualization, component-interaction-illustration\n",
        "\n",
        "# KEYWORDS (comma-separated):\"\"\"\n",
        "#     return prompt\n",
        "\n",
        "# # Function to extract and validate keywords from the model's response\n",
        "# def extract_answer(api_response):\n",
        "#     \"\"\"Extracts and validates keywords from the API response\"\"\"\n",
        "#     try:\n",
        "#         valid_suffixes = ['-visualization', '-diagram', '-illustration', '-example', '-steps']\n",
        "\n",
        "#         if isinstance(api_response, list):\n",
        "#             response_text = api_response[0].get('generated_text', '')\n",
        "#         elif isinstance(api_response, dict):\n",
        "#             response_text = api_response.get('generated_text', '')\n",
        "#         else:\n",
        "#             response_text = str(api_response)\n",
        "\n",
        "#         if \"KEYWORDS (comma-separated):\" not in response_text:\n",
        "#             return []\n",
        "\n",
        "#         keywords_section = response_text.split(\"KEYWORDS (comma-separated):\")[-1].strip()\n",
        "#         keyword_lines = [line.strip() for line in keywords_section.split('\\n') if line.strip()]\n",
        "#         if not keyword_lines:\n",
        "#             return []\n",
        "\n",
        "#         keywords = keyword_lines[0]\n",
        "#         cleaned_keywords = []\n",
        "\n",
        "#         for keyword in keywords.split(','):\n",
        "#             keyword = keyword.strip()\n",
        "#             if (keyword and\n",
        "#                 '-' in keyword and\n",
        "#                 any(keyword.endswith(suffix) for suffix in valid_suffixes) and\n",
        "#                 keyword.count('-') >= 2):\n",
        "#                 cleaned_keywords.append(keyword)\n",
        "\n",
        "#         cleaned_keywords = list(set(cleaned_keywords))  # Remove duplicates\n",
        "#         cleaned_keywords = cleaned_keywords[:7]\n",
        "\n",
        "#         return cleaned_keywords if len(cleaned_keywords) >= 3 else []\n",
        "\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error extracting keywords: {str(e)}\")\n",
        "#         return []\n",
        "\n",
        "# # Class to manage slide content and add images\n",
        "# class SlideContentManager:\n",
        "#     def __init__(self, slide):\n",
        "#         self.slide = slide\n",
        "#         self.current_top = Inches(2)\n",
        "\n",
        "#     def add_content(self, content, level, content_type):\n",
        "#         \"\"\"Add content to slide with proper spacing\"\"\"\n",
        "#         if content_type in ['code', 'code_continued']:\n",
        "#             height = self._add_code_block(content)\n",
        "#             self.current_top += height + Inches(0.6)\n",
        "#         elif content_type == 'equation':\n",
        "#             success = self._add_equation(content)\n",
        "#             if success:\n",
        "#                 self.current_top += Inches(0.8)\n",
        "#         elif content_type == 'subheading':\n",
        "#             self._add_subheading(content)\n",
        "#             self.current_top += Inches(0.6)\n",
        "#         elif content_type == 'image':\n",
        "#             self._add_image(content)\n",
        "#             self.current_top += Inches(2)  # Adjust spacing for images\n",
        "#         else:\n",
        "#             self._add_text_content(content, level)\n",
        "#             self.current_top += Inches(0.4)\n",
        "\n",
        "#     def _add_image(self, image_url):\n",
        "#         \"\"\"Add an image to the slide\"\"\"\n",
        "#         try:\n",
        "#             response = requests.get(image_url)\n",
        "#             if response.status_code == 200:\n",
        "#                 img_buf = io.BytesIO(response.content)\n",
        "#                 img = Image.open(img_buf)\n",
        "\n",
        "#                 # Resize image to fit slide\n",
        "#                 max_width = Inches(8)\n",
        "#                 max_height = Inches(4.5)\n",
        "#                 img.thumbnail((max_width, max_height), Image.ANTIALIAS)\n",
        "\n",
        "#                 # Save resized image to a buffer\n",
        "#                 resized_buf = io.BytesIO()\n",
        "#                 img.save(resized_buf, format='PNG')\n",
        "#                 resized_buf.seek(0)\n",
        "\n",
        "#                 # Add image to slide\n",
        "#                 left = (Inches(13.33) - img.width) / 2  # Center horizontally\n",
        "#                 self.slide.shapes.add_picture(resized_buf, left, self.current_top)\n",
        "#         except Exception as e:\n",
        "#             print(f\"Error adding image: {str(e)}\")\n",
        "\n",
        "#     def _add_text_content(self, text, level):\n",
        "#         \"\"\"Add text content with proper formatting\"\"\"\n",
        "#         content_shape = self.slide.placeholders[1]\n",
        "#         text_frame = content_shape.text_frame\n",
        "\n",
        "#         paragraph = text_frame.add_paragraph()\n",
        "#         paragraph.level = level\n",
        "\n",
        "#         # Handle text with potential bold sections\n",
        "#         parts = re.split(r'(\\*\\*.*?\\*\\*)', text)\n",
        "#         for part in parts:\n",
        "#             if part:  # Skip empty parts\n",
        "#                 run = paragraph.add_run()\n",
        "#                 if part.startswith('**') and part.endswith('**'):\n",
        "#                     run.text = part.strip('*')\n",
        "#                     run.font.bold = True\n",
        "#                 else:\n",
        "#                     run.text = part\n",
        "#                     run.font.bold = False\n",
        "#                 run.font.size = Pt(14)\n",
        "\n",
        "#         if level == 2:\n",
        "#             paragraph.indent = Inches(0.5)\n",
        "\n",
        "#     def _add_subheading(self, text):\n",
        "#         \"\"\"Add subheading with proper formatting\"\"\"\n",
        "#         content_shape = self.slide.placeholders[1]\n",
        "#         text_frame = content_shape.text_frame\n",
        "\n",
        "#         paragraph = text_frame.add_paragraph()\n",
        "#         run = paragraph.add_run()\n",
        "#         run.text = text[2:].strip()  # Remove bullet point\n",
        "#         run.font.bold = True\n",
        "#         run.font.size = Pt(16)\n",
        "\n",
        "#     def _add_code_block(self, code):\n",
        "#         \"\"\"Add code block with proper spacing\"\"\"\n",
        "#         left = Inches(1)\n",
        "#         width = Inches(11)\n",
        "\n",
        "#         line_height = Inches(0.3)\n",
        "#         total_height = len(code.split('\\n')) * line_height + Inches(0.5)\n",
        "\n",
        "#         textbox = self.slide.shapes.add_textbox(left, self.current_top, width, total_height)\n",
        "#         text_frame = textbox.text_frame\n",
        "\n",
        "#         paragraph = text_frame.add_paragraph()\n",
        "#         run = paragraph.add_run()\n",
        "#         run.text = code\n",
        "#         run.font.name = 'Courier New'\n",
        "#         run.font.size = Pt(11)\n",
        "\n",
        "#         fill = textbox.fill\n",
        "#         fill.solid()\n",
        "#         fill.fore_color.rgb = RGBColor(245, 245, 245)\n",
        "\n",
        "#         return total_height\n",
        "\n",
        "#     def _add_equation(self, equation):\n",
        "#         \"\"\"Add equation with proper spacing\"\"\"\n",
        "#         try:\n",
        "#             plt.rc('text', usetex=True)\n",
        "#             plt.rc('font', family='serif')\n",
        "\n",
        "#             fig = plt.figure(figsize=(10, 1))\n",
        "#             plt.axis('off')\n",
        "#             plt.text(0.5, 0.5, f'${equation}$',\n",
        "#                     fontsize=14,\n",
        "#                     horizontalalignment='center',\n",
        "#                     verticalalignment='center')\n",
        "\n",
        "#             buf = io.BytesIO()\n",
        "#             plt.savefig(buf, format='png', dpi=300, bbox_inches='tight', transparent=True)\n",
        "#             plt.close(fig)\n",
        "\n",
        "#             buf.seek(0)\n",
        "#             left = Inches(1)\n",
        "#             self.slide.shapes.add_picture(buf, left, self.current_top, height=Inches(0.8))\n",
        "#             return True\n",
        "#         except Exception as e:\n",
        "#             print(f\"Error rendering equation: {str(e)}\")\n",
        "#             return False\n",
        "\n",
        "# # Class to generate slides\n",
        "# class SlideGenerator:\n",
        "#     def __init__(self, presentation_title, template_path):\n",
        "#         self.prs = Presentation(template_path)\n",
        "#         self.presentation_title = presentation_title\n",
        "\n",
        "#     def _add_title_slide(self):\n",
        "#         \"\"\"Create title slide\"\"\"\n",
        "#         slide = self.prs.slides.add_slide(self.prs.slide_layouts[0])\n",
        "#         title_shape = slide.shapes.title\n",
        "#         title_shape.text = self.presentation_title\n",
        "\n",
        "#         paragraph = title_shape.text_frame.paragraphs[0]\n",
        "#         paragraph.alignment = PP_ALIGN.CENTER\n",
        "#         run = paragraph.runs[0]\n",
        "#         run.font.size = Pt(44)\n",
        "#         run.font.bold = True\n",
        "#         run.font.color.rgb = RGBColor(44, 62, 80)\n",
        "\n",
        "#     def _create_content_slides(self, title, content_chunk, slide_number=1, total_slides=1):\n",
        "#         \"\"\"Create a content slide\"\"\"\n",
        "#         slide = self.prs.slides.add_slide(self.prs.slide_layouts[1])\n",
        "#         content_manager = SlideContentManager(slide)\n",
        "\n",
        "#         # Add slide title\n",
        "#         title_shape = slide.shapes.title\n",
        "#         clean_title = self._clean_title(title)\n",
        "\n",
        "#         # Add continuation number for split slides\n",
        "#         if total_slides > 1:\n",
        "#             title_shape.text = f\"{clean_title} ({slide_number}/{total_slides})\"\n",
        "#         else:\n",
        "#             title_shape.text = clean_title\n",
        "\n",
        "#         # Format title\n",
        "#         title_run = title_shape.text_frame.paragraphs[0].runs[0]\n",
        "#         title_run.font.size = Pt(32)\n",
        "#         title_run.font.bold = True\n",
        "\n",
        "#         # Add content\n",
        "#         for content, level, content_type in content_chunk:\n",
        "#             content_manager.add_content(content, level, content_type)\n",
        "\n",
        "#         # Generate keywords and scrape images\n",
        "#         prompt = create_image_keyword_prompt(clean_title)\n",
        "#         keywords = extract_answer(prompt)  # Replace with actual model call if needed\n",
        "#         for keyword in keywords:\n",
        "#             images = scrape_images(keyword, num_images=1)\n",
        "#             for image_url in images:\n",
        "#                 content_manager.add_content(image_url, 0, 'image')\n",
        "\n",
        "#     def _clean_title(self, title):\n",
        "#         \"\"\"Remove markdown formatting from title\"\"\"\n",
        "#         return title.replace('**', '').strip()\n",
        "\n",
        "#     def generate_presentation(self, content):\n",
        "#         \"\"\"Generate presentation with properly distributed content\"\"\"\n",
        "#         sections = re.split(r'##\\s+\\d+\\.\\s+', content)[1:]\n",
        "#         self._add_title_slide()\n",
        "\n",
        "#         for section in sections:\n",
        "#             title_match = re.match(r'\\*\\*(.*?)\\*\\*', section)\n",
        "#             if title_match:\n",
        "#                 title = title_match.group(1)\n",
        "#                 content = section[title_match.end():].strip()\n",
        "\n",
        "#                 # Distribute content across slides\n",
        "#                 chunks = self._distribute_content(content)\n",
        "#                 for i, chunk in enumerate(chunks, 1):\n",
        "#                     self._create_content_slides(title, chunk, i, len(chunks))\n",
        "\n",
        "#     def _distribute_content(self, content):\n",
        "#         \"\"\"Distribute content into well-spaced chunks\"\"\"\n",
        "#         # Simplified distribution logic (can be expanded)\n",
        "#         lines = content.split('\\n')\n",
        "#         chunks = []\n",
        "#         current_chunk = []\n",
        "\n",
        "#         for line in lines:\n",
        "#             if line.strip():\n",
        "#                 current_chunk.append((line, 0, 'text'))\n",
        "#             else:\n",
        "#                 if current_chunk:\n",
        "#                     chunks.append(current_chunk)\n",
        "#                     current_chunk = []\n",
        "\n",
        "#         if current_chunk:\n",
        "#             chunks.append(current_chunk)\n",
        "\n",
        "#         return chunks\n",
        "\n",
        "#     def save(self):\n",
        "#         \"\"\"Save presentation with query-based filename\"\"\"\n",
        "#         filename = f\"{self.presentation_title.replace(' ', '_')}.pptx\"\n",
        "#         self.prs.save(filename)\n",
        "#         files.download(filename)\n",
        "\n",
        "# # Main function to create presentation\n",
        "# def create_presentation(query, content, template_path):\n",
        "#     \"\"\"Main function to create presentation\"\"\"\n",
        "#     generator = SlideGenerator(query.upper(), template_path)\n",
        "#     generator.generate_presentation(content)\n",
        "#     generator.save()\n",
        "\n",
        "# # Example usage\n",
        "# if __name__ == \"__main__\":\n",
        "#     print(\"Please upload your PowerPoint template...\")\n",
        "#     uploaded = files.upload()\n",
        "\n",
        "#     template_path = next(iter(uploaded.keys()))\n",
        "\n",
        "#     with open('content.txt', 'r') as file:\n",
        "#         content = file.read()\n",
        "\n",
        "#     create_presentation(query, content, template_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "EwyKh9uFwtZW",
        "outputId": "b7be45bd-c9d2-4465-b937-c0a32895d83a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload your PowerPoint template...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8b3c225d-24f1-4261-b91e-dbaf76cc56c4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8b3c225d-24f1-4261-b91e-dbaf76cc56c4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Crop.pptx to Crop (6).pptx\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c845cb5c-36a7-4cd5-b3a7-494252ef8b42\", \"LSTM.pptx\", 85260)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "aBET00wg4W2C",
        "outputId": "b3bfb163-8048-452c-8684-491ce0f43436"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload your PowerPoint template...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-dd60878f-7ffa-401f-b389-1a8f7240bc5c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-dd60878f-7ffa-401f-b389-1a8f7240bc5c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Crop.pptx to Crop (7).pptx\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_76fa8736-2422-481e-befd-6646596852a9\", \"LSTM.pptx\", 62492)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "################################################  WITHOUT IMAGES ################################3\n",
        "import matplotlib.pyplot as plt\n",
        "from pptx import Presentation\n",
        "from pptx.util import Inches, Pt\n",
        "from pptx.enum.text import PP_ALIGN, MSO_VERTICAL_ANCHOR\n",
        "from pptx.dml.color import RGBColor\n",
        "import re\n",
        "import io\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "import tempfile\n",
        "from google.colab import files\n",
        "\n",
        "class ContentDistributor:\n",
        "    def __init__(self):\n",
        "        self.MAX_POINTS_PER_SLIDE = 5\n",
        "        self.MAX_CODE_LINES_PER_SLIDE = 15\n",
        "        self.TITLE_MARGIN = Inches(0.5)\n",
        "        self.CONTENT_TOP_MARGIN = Inches(0.3)\n",
        "        self.BULLET_SPACING = Inches(0.4)\n",
        "        self.SUB_BULLET_INDENT = Inches(0.5)\n",
        "        self.EQUATION_SPACING = Inches(0.8)\n",
        "        self.CODE_BLOCK_SPACING = Inches(0.6)\n",
        "\n",
        "    def distribute_content(self, content):\n",
        "        \"\"\"Distribute content into well-spaced chunks\"\"\"\n",
        "        chunks = []\n",
        "        current_chunk = []\n",
        "        current_height = 0\n",
        "        point_count = 0\n",
        "\n",
        "        lines = self.process_content_lines(content)\n",
        "        i = 0\n",
        "        while i < len(lines):\n",
        "            line = lines[i]\n",
        "            content, level, content_type = line\n",
        "            line_height = self.calculate_line_height(line)\n",
        "\n",
        "            # Start new slide for subheadings\n",
        "            if content.startswith('• ') and level == 0:\n",
        "                if current_chunk:\n",
        "                    chunks.append(current_chunk)\n",
        "                    current_chunk = []\n",
        "                    current_height = 0\n",
        "                    point_count = 0\n",
        "\n",
        "            # Handle large code blocks\n",
        "            if content_type == 'code':\n",
        "                code_lines = content.split('\\n')\n",
        "                if len(code_lines) > self.MAX_CODE_LINES_PER_SLIDE:\n",
        "                    if current_chunk:\n",
        "                        chunks.append(current_chunk)\n",
        "                        current_chunk = []\n",
        "\n",
        "                    for j in range(0, len(code_lines), self.MAX_CODE_LINES_PER_SLIDE):\n",
        "                        code_chunk = code_lines[j:j + self.MAX_CODE_LINES_PER_SLIDE]\n",
        "                        chunks.append([('\\n'.join(code_chunk), 0, 'code_continued')])\n",
        "\n",
        "                    current_chunk = []\n",
        "                    current_height = 0\n",
        "                    point_count = 0\n",
        "                    i += 1\n",
        "                    continue\n",
        "\n",
        "            # Start new slide if current one is full\n",
        "            if (point_count >= self.MAX_POINTS_PER_SLIDE and level > 0) or \\\n",
        "               (current_height + line_height > Inches(5)):\n",
        "                if current_chunk:\n",
        "                    chunks.append(current_chunk)\n",
        "                    current_chunk = []\n",
        "                    current_height = 0\n",
        "                    point_count = 0\n",
        "\n",
        "            current_chunk.append(line)\n",
        "            current_height += line_height\n",
        "            if level > 0:\n",
        "                point_count += 1\n",
        "\n",
        "            i += 1\n",
        "\n",
        "        if current_chunk:\n",
        "            chunks.append(current_chunk)\n",
        "\n",
        "        return chunks\n",
        "\n",
        "    def calculate_line_height(self, line):\n",
        "        \"\"\"Calculate height needed for a line of content\"\"\"\n",
        "        content, level, content_type = line\n",
        "\n",
        "        if content_type in ['code', 'code_continued']:\n",
        "            num_lines = len(content.split('\\n'))\n",
        "            return Inches(0.25) * num_lines + self.CODE_BLOCK_SPACING\n",
        "        elif content_type == 'equation':\n",
        "            return self.EQUATION_SPACING\n",
        "        else:\n",
        "            base_height = self.BULLET_SPACING\n",
        "            wrapped_lines = len(content) // 80 + 1\n",
        "            return base_height * wrapped_lines\n",
        "\n",
        "    def process_content_lines(self, content):\n",
        "        \"\"\"Process content into structured lines with type information\"\"\"\n",
        "        processed_lines = []\n",
        "        code_block = []\n",
        "        in_code = False\n",
        "\n",
        "        for line in content.split('\\n'):\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "\n",
        "            if line.startswith('```'):\n",
        "                if in_code:\n",
        "                    processed_lines.append(('\\n'.join(code_block), 0, 'code'))\n",
        "                    code_block = []\n",
        "                    in_code = False\n",
        "                else:\n",
        "                    in_code = True\n",
        "                continue\n",
        "\n",
        "            if in_code:\n",
        "                code_block.append(line)\n",
        "                continue\n",
        "\n",
        "            if '$' in line:\n",
        "                eq = re.search(r'\\$(.*?)\\$', line).group(1)\n",
        "                processed_lines.append((eq, 0, 'equation'))\n",
        "                continue\n",
        "\n",
        "            # Handle bullet points and subheadings\n",
        "            if line.startswith('• '):\n",
        "                text = line[2:].strip()\n",
        "                if text.isupper() or text.endswith(':'):\n",
        "                    # Subheading\n",
        "                    processed_lines.append((line, 0, 'subheading'))\n",
        "                else:\n",
        "                    # Regular bullet point\n",
        "                    processed_lines.append((text, 1, 'text'))\n",
        "            elif line.startswith('•#'):\n",
        "                # Sub-bullet\n",
        "                processed_lines.append((line[2:].strip(), 2, 'text'))\n",
        "            else:\n",
        "                # Regular text\n",
        "                processed_lines.append((line, 0, 'text'))\n",
        "\n",
        "        return processed_lines\n",
        "\n",
        "class LaTeXRenderer:\n",
        "    def __init__(self):\n",
        "        plt.rc('text', usetex=True)\n",
        "        plt.rc('font', family='serif')\n",
        "\n",
        "    def equation_to_image(self, equation, dpi=300):\n",
        "        \"\"\"Convert LaTeX equation to image\"\"\"\n",
        "        equation = equation.replace('\\_', '_')\n",
        "\n",
        "        fig = plt.figure(figsize=(10, 1))\n",
        "        plt.axis('off')\n",
        "        plt.text(0.5, 0.5, f'${equation}$',\n",
        "                fontsize=14,\n",
        "                horizontalalignment='center',\n",
        "                verticalalignment='center')\n",
        "\n",
        "        buf = io.BytesIO()\n",
        "        plt.savefig(buf, format='png', dpi=dpi, bbox_inches='tight', transparent=True)\n",
        "        plt.close(fig)\n",
        "\n",
        "        buf.seek(0)\n",
        "        return Image.open(buf)\n",
        "\n",
        "class SlideContentManager:\n",
        "    def __init__(self, slide):\n",
        "        self.slide = slide\n",
        "        self.current_top = Inches(2)\n",
        "        self.latex_renderer = LaTeXRenderer()\n",
        "\n",
        "    def add_content(self, content, level, content_type):\n",
        "        \"\"\"Add content to slide with proper spacing\"\"\"\n",
        "        if content_type in ['code', 'code_continued']:\n",
        "            height = self._add_code_block(content)\n",
        "            self.current_top += height + Inches(0.6)\n",
        "        elif content_type == 'equation':\n",
        "            success = self._add_equation(content)\n",
        "            if success:\n",
        "                self.current_top += Inches(0.8)\n",
        "        elif content_type == 'subheading':\n",
        "            self._add_subheading(content)\n",
        "            self.current_top += Inches(0.6)\n",
        "        else:\n",
        "            self._add_text_content(content, level)\n",
        "            self.current_top += Inches(0.4)\n",
        "\n",
        "    def _add_text_content(self, text, level):\n",
        "        \"\"\"Add text content with proper formatting\"\"\"\n",
        "        content_shape = self.slide.placeholders[1]\n",
        "        text_frame = content_shape.text_frame\n",
        "\n",
        "        paragraph = text_frame.add_paragraph()\n",
        "        paragraph.level = level\n",
        "\n",
        "        # Handle text with potential bold sections\n",
        "        parts = re.split(r'(\\*\\*.*?\\*\\*)', text)\n",
        "        for part in parts:\n",
        "            if part:  # Skip empty parts\n",
        "                run = paragraph.add_run()\n",
        "                if part.startswith('**') and part.endswith('**'):\n",
        "                    run.text = part.strip('*')\n",
        "                    run.font.bold = True\n",
        "                else:\n",
        "                    run.text = part\n",
        "                    run.font.bold = False\n",
        "                run.font.size = Pt(14)\n",
        "\n",
        "        if level == 2:\n",
        "            paragraph.indent = Inches(0.5)\n",
        "\n",
        "    def _add_subheading(self, text):\n",
        "        \"\"\"Add subheading with proper formatting\"\"\"\n",
        "        content_shape = self.slide.placeholders[1]\n",
        "        text_frame = content_shape.text_frame\n",
        "\n",
        "        paragraph = text_frame.add_paragraph()\n",
        "        run = paragraph.add_run()\n",
        "        run.text = text[2:].strip()  # Remove bullet point\n",
        "        run.font.bold = True\n",
        "        run.font.size = Pt(16)\n",
        "\n",
        "    def _add_code_block(self, code):\n",
        "        \"\"\"Add code block with proper spacing\"\"\"\n",
        "        left = Inches(1)\n",
        "        width = Inches(11)\n",
        "\n",
        "        line_height = Inches(0.3)\n",
        "        total_height = len(code.split('\\n')) * line_height + Inches(0.5)\n",
        "\n",
        "        textbox = self.slide.shapes.add_textbox(left, self.current_top, width, total_height)\n",
        "        text_frame = textbox.text_frame\n",
        "\n",
        "        paragraph = text_frame.add_paragraph()\n",
        "        run = paragraph.add_run()\n",
        "        run.text = code\n",
        "        run.font.name = 'Courier New'\n",
        "        run.font.size = Pt(11)\n",
        "\n",
        "        fill = textbox.fill\n",
        "        fill.solid()\n",
        "        fill.fore_color.rgb = RGBColor(245, 245, 245)\n",
        "\n",
        "        return total_height\n",
        "\n",
        "    def _add_equation(self, equation):\n",
        "        \"\"\"Add equation with proper spacing\"\"\"\n",
        "        try:\n",
        "            eq_image = self.latex_renderer.equation_to_image(equation)\n",
        "            img_buf = io.BytesIO()\n",
        "            eq_image.save(img_buf, format='PNG')\n",
        "            img_buf.seek(0)\n",
        "\n",
        "            left = Inches(1)\n",
        "            self.slide.shapes.add_picture(img_buf, left, self.current_top, height=Inches(0.8))\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"Error rendering equation: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "class SlideGenerator:\n",
        "    def __init__(self, presentation_title, template_path):\n",
        "        self.prs = Presentation(template_path)\n",
        "        self.content_distributor = ContentDistributor()\n",
        "        self.presentation_title = presentation_title\n",
        "\n",
        "    def _add_title_slide(self):\n",
        "        \"\"\"Create title slide\"\"\"\n",
        "        slide = self.prs.slides.add_slide(self.prs.slide_layouts[0])\n",
        "        title_shape = slide.shapes.title\n",
        "        title_shape.text = self.presentation_title\n",
        "\n",
        "        paragraph = title_shape.text_frame.paragraphs[0]\n",
        "        paragraph.alignment = PP_ALIGN.CENTER\n",
        "        run = paragraph.runs[0]\n",
        "        run.font.size = Pt(44)\n",
        "        run.font.bold = True\n",
        "        run.font.color.rgb = RGBColor(44, 62, 80)\n",
        "\n",
        "    def _create_content_slides(self, title, content_chunk, slide_number=1, total_slides=1):\n",
        "        \"\"\"Create a content slide\"\"\"\n",
        "        slide = self.prs.slides.add_slide(self.prs.slide_layouts[1])\n",
        "        content_manager = SlideContentManager(slide)\n",
        "\n",
        "        # Add slide title\n",
        "        title_shape = slide.shapes.title\n",
        "        clean_title = self._clean_title(title)\n",
        "\n",
        "        # Add continuation number for split slides\n",
        "        if total_slides > 1:\n",
        "            title_shape.text = f\"{clean_title} ({slide_number}/{total_slides})\"\n",
        "        else:\n",
        "            title_shape.text = clean_title\n",
        "\n",
        "        # Format title\n",
        "        title_run = title_shape.text_frame.paragraphs[0].runs[0]\n",
        "        title_run.font.size = Pt(32)\n",
        "        title_run.font.bold = True\n",
        "\n",
        "        # Add content\n",
        "        for content, level, content_type in content_chunk:\n",
        "            content_manager.add_content(content, level, content_type)\n",
        "\n",
        "    def _clean_title(self, title):\n",
        "        \"\"\"Remove markdown formatting from title\"\"\"\n",
        "        return title.replace('**', '').strip()\n",
        "\n",
        "    def generate_presentation(self, content):\n",
        "        \"\"\"Generate presentation with properly distributed content\"\"\"\n",
        "        sections = re.split(r'##\\s+\\d+\\.\\s+', content)[1:]\n",
        "        self._add_title_slide()\n",
        "\n",
        "        for section in sections:\n",
        "            title_match = re.match(r'\\*\\*(.*?)\\*\\*', section)\n",
        "            if title_match:\n",
        "                title = title_match.group(1)\n",
        "                content = section[title_match.end():].strip()\n",
        "\n",
        "                # Distribute content across slides\n",
        "                chunks = self.content_distributor.distribute_content(content)\n",
        "                for i, chunk in enumerate(chunks, 1):\n",
        "                    self._create_content_slides(title, chunk, i, len(chunks))\n",
        "\n",
        "    def save(self):\n",
        "        \"\"\"Save presentation with query-based filename\"\"\"\n",
        "        filename = f\"{self.presentation_title.replace(' ', '_')}.pptx\"\n",
        "        self.prs.save(filename)\n",
        "        files.download(filename)\n",
        "\n",
        "def create_presentation(query, content, template_path):\n",
        "    \"\"\"Main function to create presentation\"\"\"\n",
        "    generator = SlideGenerator(query.upper(), template_path)\n",
        "    generator.generate_presentation(content)\n",
        "    generator.save()\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Please upload your PowerPoint template...\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    presentation_title = \"Understanding LSTM Networks\"\n",
        "    template_path = next(iter(uploaded.keys()))\n",
        "\n",
        "    with open('content.txt', 'r') as file:\n",
        "        content = file.read()\n",
        "\n",
        "    create_presentation(presentation_title, content, template_path)"
      ],
      "metadata": {
        "id": "qQBXQDzAJ9DH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2 python-pptx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTAtSUyplGTu",
        "outputId": "539f0ac2-6678-4a29-bc5b-a01578b3e220"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: python-pptx in /usr/local/lib/python3.11/dist-packages (1.0.2)\n",
            "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (11.1.0)\n",
            "Requirement already satisfied: XlsxWriter>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (3.2.2)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (5.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (4.12.2)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m225.3/232.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "########################### LATEX CODE USE THIS ####################################\n",
        "import os\n",
        "import re\n",
        "from pptx import Presentation\n",
        "from pptx.util import Inches, Pt\n",
        "from pptx.enum.text import PP_ALIGN\n",
        "from pptx.dml.color import RGBColor\n",
        "import PyPDF2\n",
        "\n",
        "def convert_to_tex(content):\n",
        "    \"\"\"\n",
        "    Convert content to LaTeX with proper section hierarchy\n",
        "    \"\"\"\n",
        "    tex_content = \"\"\"\\\\documentclass{article}\n",
        "\\\\usepackage{amsmath}\n",
        "\\\\usepackage{listings}\n",
        "\\\\usepackage{xcolor}\n",
        "\\\\usepackage{enumitem}\n",
        "\\\\usepackage{titlesec}\n",
        "\\\\usepackage{geometry}\n",
        "\n",
        "\\\\geometry{\n",
        "    a4paper,\n",
        "    left=1in,\n",
        "    right=1in,\n",
        "    top=1in,\n",
        "    bottom=1in\n",
        "}\n",
        "\n",
        "% Format section titles\n",
        "\\\\titleformat{\\\\section}\n",
        "  {\\\\Large\\\\bfseries}  % format\n",
        "  {\\\\thesection.}      % label\n",
        "  {1em}                % sep\n",
        "  {}                   % before-code\n",
        "  []                   % after-code\n",
        "\n",
        "% Format subsection titles\n",
        "\\\\titleformat{\\\\subsection}\n",
        "  {\\\\large\\\\bfseries}   % format\n",
        "  {}                    % label\n",
        "  {0em}                % sep\n",
        "  {}                   % before-code\n",
        "  []                   % after-code\n",
        "\n",
        "% Code listing settings\n",
        "\\\\lstset{\n",
        "    backgroundcolor=\\\\color{gray!10},\n",
        "    basicstyle=\\\\ttfamily\\\\small,\n",
        "    breaklines=true,\n",
        "    frame=single,\n",
        "    numbers=left,\n",
        "    numberstyle=\\\\tiny,\n",
        "    keywordstyle=\\\\color{blue},\n",
        "    commentstyle=\\\\color{green!60!black},\n",
        "    stringstyle=\\\\color{red}\n",
        "}\n",
        "\n",
        "\\\\begin{document}\n",
        "\\\\pagestyle{plain}\n",
        "\"\"\"\n",
        "    sections = content.split(\"1.--\\n\\n\")\n",
        "    current_section = None\n",
        "\n",
        "    for section in sections:\n",
        "        if not section.strip():\n",
        "            continue\n",
        "\n",
        "        # Process main section headers (##)\n",
        "        if \"## \" in section:\n",
        "            title = re.search(r\"## \\d+\\. \\*\\*(.*?)\\*\\*\", section)\n",
        "            if title:\n",
        "                section_title = title.group(1).strip()\n",
        "                tex_content += f\"\\\\section{{{section_title}}}\\n\\n\"\n",
        "                section = re.sub(r\"## \\d+\\. \\*\\*.*?\\*\\*\\n\", \"\", section)\n",
        "\n",
        "        paragraphs = section.split(\"\\n\")\n",
        "        in_itemize = False\n",
        "        in_paragraph = False\n",
        "        in_code_block = False\n",
        "\n",
        "        for paragraph in paragraphs:\n",
        "            paragraph = paragraph.strip()\n",
        "            if not paragraph:\n",
        "                if in_itemize:\n",
        "                    tex_content += \"\\\\end{itemize}\\n\"\n",
        "                    in_itemize = False\n",
        "                if in_paragraph:\n",
        "                    tex_content += \"\\n\\n\"\n",
        "                    in_paragraph = False\n",
        "                continue\n",
        "\n",
        "            # Handle different content types\n",
        "            if paragraph.startswith(\"```python\"):\n",
        "                if in_itemize:\n",
        "                    tex_content += \"\\\\end{itemize}\\n\"\n",
        "                    in_itemize = False\n",
        "                in_code_block = True\n",
        "                tex_content += \"\\\\begin{lstlisting}[language=Python]\\n\"\n",
        "            elif paragraph.startswith(\"```\") and in_code_block:\n",
        "                in_code_block = False\n",
        "                tex_content += \"\\\\end{lstlisting}\\n\\n\"\n",
        "            elif in_code_block:\n",
        "                tex_content += paragraph + \"\\n\"\n",
        "            elif paragraph.startswith(\"• \"):\n",
        "                if any(keyword in paragraph.lower() for keyword in\n",
        "                    [\"elements\", \"principles\", \"management\", \"handling\", \"practices\",\n",
        "                     \"cases\", \"patterns\", \"metrics\", \"approaches\", \"strategies\"]):\n",
        "                    if in_itemize:\n",
        "                        tex_content += \"\\\\end{itemize}\\n\"\n",
        "                        in_itemize = False\n",
        "                    tex_content += f\"\\\\subsection{{{paragraph[2:]}}}\\n\\n\"\n",
        "                else:\n",
        "                    if not in_itemize:\n",
        "                        tex_content += \"\\\\begin{itemize}\\n\"\n",
        "                        in_itemize = True\n",
        "                    tex_content += f\"\\\\item {paragraph[2:]}\\n\"\n",
        "            elif paragraph.startswith(\"•# \"):\n",
        "                if in_itemize:\n",
        "                    tex_content += \"\\\\end{itemize}\\n\"\n",
        "                    in_itemize = False\n",
        "                tex_content += f\"\\\\subsection{{{paragraph[3:]}}}\\n\\n\"\n",
        "            elif re.match(r'^\\d+\\.\\s', paragraph):\n",
        "                if not in_itemize:\n",
        "                    tex_content += \"\\\\begin{itemize}\\n\"\n",
        "                    in_itemize = True\n",
        "                paragraph = re.sub(r'^\\d+\\.\\s', '', paragraph)\n",
        "                tex_content += f\"\\\\item {paragraph}\\n\"\n",
        "            else:\n",
        "                if in_itemize:\n",
        "                    tex_content += \"\\\\end{itemize}\\n\"\n",
        "                    in_itemize = False\n",
        "                # Handle equations and regular text\n",
        "                if \"$\" in paragraph:\n",
        "                    tex_content += paragraph + \"\\n\\n\"\n",
        "                else:\n",
        "                    if not paragraph.startswith(\"\\\\\"):\n",
        "                        if not in_paragraph:\n",
        "                            in_paragraph = True\n",
        "                        tex_content += paragraph + \" \"\n",
        "\n",
        "        if in_itemize:\n",
        "            tex_content += \"\\\\end{itemize}\\n\"\n",
        "        if in_paragraph:\n",
        "            tex_content += \"\\n\\n\"\n",
        "\n",
        "    tex_content += \"\\\\end{document}\"\n",
        "    return tex_content\n",
        "\n",
        "def create_tex_and_compile(tex_content, filename=\"output\"):\n",
        "    \"\"\"Create and compile LaTeX file\"\"\"\n",
        "    with open(f\"{filename}.tex\", \"w\", encoding='utf-8') as f:\n",
        "        f.write(tex_content)\n",
        "\n",
        "    os.system(f\"pdflatex -interaction=nonstopmode {filename}.tex\")\n",
        "    return f\"{filename}.pdf\"\n",
        "\n",
        "def split_content_into_slides(lines, max_points=3):\n",
        "    \"\"\"Split content into slides with specific heading and subheading handling\"\"\"\n",
        "    slides = []\n",
        "    current_slide = {\"title\": \"\", \"subtitle\": \"\", \"content\": [], \"type\": \"normal\"}\n",
        "    content_count = 0\n",
        "    paragraph_content = []\n",
        "\n",
        "    def create_new_slide(title, subtitle=\"\", slide_type=\"normal\"):\n",
        "        return {\n",
        "            \"title\": title,\n",
        "            \"subtitle\": subtitle,\n",
        "            \"content\": [],\n",
        "            \"type\": slide_type\n",
        "        }\n",
        "\n",
        "    def add_current_slide():\n",
        "        if current_slide[\"content\"]:\n",
        "            slides.append(current_slide.copy())\n",
        "\n",
        "    def clean_title(title):\n",
        "        \"\"\"Clean heading/subheading text\"\"\"\n",
        "        return title.replace(\"•\", \"\").replace(\"**\", \"\").strip()\n",
        "\n",
        "    def is_main_heading(line):\n",
        "        \"\"\"Check if line is a main heading\"\"\"\n",
        "        return bool(re.match(r'^##\\s+\\d+\\.\\s+\\*\\*.*?\\*\\*$', line))\n",
        "\n",
        "    def is_subheading(line):\n",
        "        \"\"\"Check if line matches subheading patterns\"\"\"\n",
        "        subheading_patterns = [\n",
        "            \"Core Definition and Purpose\",\n",
        "            \"Key Principles\",\n",
        "            \"Primary Elements and Their Role\",\n",
        "            \"Relationships and Interactions\"\n",
        "        ]\n",
        "        # Remove bullet point if present\n",
        "        clean_line = line.replace(\"• \", \"\").strip()\n",
        "        return any(pattern in clean_line for pattern in subheading_patterns)\n",
        "\n",
        "    current_main_heading = \"\"\n",
        "\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "\n",
        "        # Handle main headings (e.g., \"## 1. **Concept Overview**\")\n",
        "        if is_main_heading(line):\n",
        "            if current_slide[\"content\"]:\n",
        "                add_current_slide()\n",
        "\n",
        "            # Extract title from between ** markers\n",
        "            title_match = re.search(r'\\*\\*(.*?)\\*\\*', line)\n",
        "            if title_match:\n",
        "                current_main_heading = title_match.group(1).strip()\n",
        "                current_slide = create_new_slide(current_main_heading)\n",
        "                content_count = 0\n",
        "\n",
        "        # Handle subheadings\n",
        "        elif is_subheading(line):\n",
        "            if current_slide[\"content\"]:\n",
        "                add_current_slide()\n",
        "\n",
        "            # Clean subheading text and create new slide\n",
        "            clean_subheading = clean_title(line)\n",
        "            current_slide = create_new_slide(\n",
        "                current_main_heading,  # Keep main heading as title\n",
        "                clean_subheading      # Use subheading as subtitle\n",
        "            )\n",
        "            content_count = 0\n",
        "\n",
        "        # Handle bullet points\n",
        "        elif line.startswith(\"• \") or line.startswith(\"- \"):\n",
        "            if content_count >= max_points:\n",
        "                add_current_slide()\n",
        "                # Maintain same heading and subheading\n",
        "                current_slide = create_new_slide(\n",
        "                    current_slide[\"title\"],\n",
        "                    current_slide[\"subtitle\"] + \" (continued)\" if current_slide[\"subtitle\"] else \"\"\n",
        "                )\n",
        "                content_count = 0\n",
        "\n",
        "            current_slide[\"content\"].append({\n",
        "                \"type\": \"bullet\",\n",
        "                \"text\": line[2:].strip()\n",
        "            })\n",
        "            content_count += 1\n",
        "\n",
        "        # Handle regular paragraphs\n",
        "        else:\n",
        "            if content_count >= 1:  # Start new slide for paragraphs\n",
        "                add_current_slide()\n",
        "                current_slide = create_new_slide(\n",
        "                    current_slide[\"title\"],\n",
        "                    current_slide[\"subtitle\"]\n",
        "                )\n",
        "                content_count = 0\n",
        "\n",
        "            current_slide[\"content\"].append({\n",
        "                \"type\": \"paragraph\",\n",
        "                \"text\": line\n",
        "            })\n",
        "            content_count += 1\n",
        "\n",
        "    # Add any remaining content\n",
        "    if current_slide[\"content\"]:\n",
        "        add_current_slide()\n",
        "\n",
        "    return slides\n",
        "\n",
        "def create_presentation(slides, output_filename=\"presentation.pptx\"):\n",
        "    \"\"\"Create PowerPoint presentation with enhanced formatting\"\"\"\n",
        "    prs = Presentation()\n",
        "\n",
        "    # Set slide dimensions to 16:9\n",
        "    prs.slide_width = Inches(13.333)\n",
        "    prs.slide_height = Inches(7.5)\n",
        "\n",
        "    # Create title slide layout\n",
        "    title_slide_layout = prs.slide_layouts[0]\n",
        "    content_slide_layout = prs.slide_layouts[1]\n",
        "\n",
        "    for slide_num, slide_content in enumerate(slides, 1):\n",
        "        slide = prs.slides.add_slide(content_slide_layout)\n",
        "\n",
        "        # Add title\n",
        "        title = slide.shapes.title\n",
        "        title.text = slide_content[\"title\"]\n",
        "        title_tf = title.text_frame.paragraphs[0]\n",
        "        title_tf.font.size = Pt(40)\n",
        "        title_tf.font.bold = True\n",
        "        title_tf.font.color.rgb = RGBColor(0, 51, 102)\n",
        "\n",
        "        # Add content\n",
        "        content_shape = slide.shapes.placeholders[1]\n",
        "        tf = content_shape.text_frame\n",
        "        tf.word_wrap = True\n",
        "\n",
        "        # Add subtitle if exists\n",
        "        if slide_content[\"subtitle\"]:\n",
        "            subtitle = tf.add_paragraph()\n",
        "            subtitle.text = slide_content[\"subtitle\"]\n",
        "            subtitle.font.bold = True\n",
        "            subtitle.font.size = Pt(32)\n",
        "            subtitle.font.color.rgb = RGBColor(51, 51, 51)\n",
        "            subtitle.space_before = Pt(20)\n",
        "            subtitle.space_after = Pt(20)\n",
        "\n",
        "        # Add content with proper spacing\n",
        "        for content_item in slide_content[\"content\"]:\n",
        "            p = tf.add_paragraph()\n",
        "\n",
        "            if content_item[\"type\"] == \"bullet\":\n",
        "                p.text = \"• \" + content_item[\"text\"]  # Add bullet point character\n",
        "                p.level = 1\n",
        "                p.font.size = Pt(24)\n",
        "                p.space_before = Pt(12)\n",
        "                p.space_after = Pt(12)\n",
        "            elif content_item[\"type\"] == \"paragraph\":\n",
        "                p.text = content_item[\"text\"]\n",
        "                p.font.size = Pt(24)\n",
        "                p.space_before = Pt(12)\n",
        "                p.space_after = Pt(12)\n",
        "\n",
        "        # Add page number\n",
        "        page_number = slide.shapes.add_textbox(\n",
        "            Inches(12.33), Inches(6.9), Inches(0.5), Inches(0.3))\n",
        "        page_number.text_frame.text = str(slide_num)\n",
        "        page_number.text_frame.paragraphs[0].alignment = PP_ALIGN.RIGHT\n",
        "\n",
        "    prs.save(output_filename)\n",
        "    return output_filename\n",
        "\n",
        "def run_pipeline(content):\n",
        "    \"\"\"Complete pipeline from content to PDF and PPTX\"\"\"\n",
        "    # Convert to TeX\n",
        "    tex_content = convert_to_tex(content)\n",
        "    print(\"TeX content created.\")\n",
        "\n",
        "    # Create and compile PDF\n",
        "    pdf_path = create_tex_and_compile(tex_content)\n",
        "    print(\"PDF compiled.\")\n",
        "\n",
        "    # Extract and format content for slides\n",
        "    lines = content.split('\\n')\n",
        "    slides = split_content_into_slides(lines)\n",
        "    print(\"Slides content organized.\")\n",
        "\n",
        "    # Create presentation\n",
        "    pptx_path = create_presentation(slides)\n",
        "    print(\"PowerPoint presentation created.\")\n",
        "\n",
        "    return pdf_path, pptx_path\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to run the conversion process\"\"\"\n",
        "    try:\n",
        "        # Read the content\n",
        "        with open('content.txt', 'r', encoding='utf-8') as file:\n",
        "            content = file.read()\n",
        "\n",
        "        # Run the pipeline\n",
        "        pdf_path, pptx_path = run_pipeline(content)\n",
        "        print(f\"\\nSuccessfully generated files:\")\n",
        "        print(f\"PDF: {pdf_path}\")\n",
        "        print(f\"Presentation: {pptx_path}\")\n",
        "\n",
        "        # Verify generated files\n",
        "        if os.path.exists(pdf_path) and os.path.exists(pptx_path):\n",
        "            print(\"\\nVerification successful - both files were created.\")\n",
        "            print(f\"PDF size: {os.path.getsize(pdf_path):,} bytes\")\n",
        "            print(f\"PPTX size: {os.path.getsize(pptx_path):,} bytes\")\n",
        "        else:\n",
        "            missing = []\n",
        "            if not os.path.exists(pdf_path):\n",
        "                missing.append(\"PDF\")\n",
        "            if not os.path.exists(pptx_path):\n",
        "                missing.append(\"PPTX\")\n",
        "            print(f\"\\nWarning: The following files were not created: {', '.join(missing)}\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(\"Error: content.txt file not found. Please ensure the file exists in the current directory.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred during conversion: {str(e)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiD_bcI-hIng",
        "outputId": "889c8a94-4fed-44cc-b1f3-2d629d8b1168"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TeX content created.\n",
            "PDF compiled.\n",
            "Slides content organized.\n",
            "PowerPoint presentation created.\n",
            "\n",
            "Successfully generated files:\n",
            "PDF: output.pdf\n",
            "Presentation: presentation.pptx\n",
            "\n",
            "Verification successful - both files were created.\n",
            "PDF size: 71,737 bytes\n",
            "PPTX size: 121,462 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ALvgwde2hMZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "from typing import Dict, List, Union\n",
        "\n",
        "# API Configuration\n",
        "HUGGINGFACE_API_TOKEN = \"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\"\n",
        "MODEL_NAME = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
        "HUGGINGFACE_API_URL = f\"https://api-inference.huggingface.co/models/{MODEL_NAME}\"\n",
        "HEADERS = {\n",
        "    \"Authorization\": f\"Bearer {HUGGINGFACE_API_TOKEN}\"\n",
        "}\n",
        "\n",
        "class QuizGenerator:\n",
        "    def read_context_file(self, file_path: str) -> str:\n",
        "        \"\"\"Read content from the context file.\"\"\"\n",
        "        try:\n",
        "            with open(file_path, 'r', encoding='utf-8') as file:\n",
        "                return file.read()\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"Error reading file: {str(e)}\")\n",
        "\n",
        "    def query_huggingface_api(self, prompt: str, max_length: int = 30000) -> Dict:\n",
        "        \"\"\"Query the Hugging Face API with the specified configuration.\"\"\"\n",
        "        payload = {\n",
        "            \"inputs\": prompt,\n",
        "            \"parameters\": {\n",
        "                \"max_new_tokens\": max_length,\n",
        "                \"temperature\": 0.7,\n",
        "                \"top_p\": 0.9,\n",
        "                \"top_k\": 40,\n",
        "                \"repetition_penalty\": 1.1,\n",
        "                \"do_sample\": True,\n",
        "                \"stop\": [\"<|endoftext|>\"]\n",
        "            }\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            response = requests.post(\n",
        "                HUGGINGFACE_API_URL,\n",
        "                headers=HEADERS,\n",
        "                json=payload,\n",
        "                timeout=60\n",
        "            )\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                return response.json()\n",
        "            else:\n",
        "                raise Exception(\n",
        "                    f\"Request failed with status code {response.status_code}: {response.text}\"\n",
        "                )\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            raise Exception(f\"API request failed: {str(e)}\")\n",
        "\n",
        "    def generate_quiz_prompt(self, content: str) -> str:\n",
        "        \"\"\"Generate a structured prompt for the Mistral model.\"\"\"\n",
        "        return f\"\"\"<s>[INST] You are a quiz generation expert. Based on the following content, create a comprehensive quiz with the following requirements:\n",
        "\n",
        "1. Multiple Choice Questions (10 total):\n",
        "   - 4 Easy questions (basic recall)\n",
        "   - 3 Medium questions (concept application)\n",
        "   - 3 Hard questions (analysis)\n",
        "\n",
        "2. Fill in the Blanks (10 total):\n",
        "   - 4 Easy questions\n",
        "   - 3 Medium questions\n",
        "   - 3 Hard questions\n",
        "\n",
        "3. Short Answer Questions (15 total):\n",
        "   - 5 Easy questions\n",
        "   - 5 Medium questions\n",
        "   - 5 Hard questions\n",
        "\n",
        "Content to create questions from:\n",
        "{content}\n",
        "\n",
        "Please format your response exactly as shown below:\n",
        "\n",
        "=== MULTIPLE CHOICE QUESTIONS ===\n",
        "[Difficulty: Easy/Medium/Hard]\n",
        "Q1. Question text\n",
        "A) Option A\n",
        "B) Option B\n",
        "C) Option C\n",
        "D) Option D\n",
        "Correct: [Letter]\n",
        "Explanation: Brief explanation\n",
        "\n",
        "=== FILL IN THE BLANKS ===\n",
        "[Difficulty: Easy/Medium/Hard]\n",
        "Q1. Sentence with _____ to fill\n",
        "Answer: Correct answer\n",
        "Explanation: Brief explanation\n",
        "\n",
        "=== SHORT ANSWER QUESTIONS ===\n",
        "[Difficulty: Easy/Medium/Hard]\n",
        "Q1. Question text\n",
        "Answer: Model answer (1-2 sentences)\n",
        "Key Points: Main concepts to check in answer\n",
        "\n",
        "Generate the quiz now.[/INST]</s>\"\"\"\n",
        "\n",
        "    def parse_quiz_response(self, response: List[Dict]) -> Dict:\n",
        "        \"\"\"Parse the Mistral model's response into structured format.\"\"\"\n",
        "        # Extract the text from the response\n",
        "        if isinstance(response, list) and len(response) > 0:\n",
        "            quiz_text = response[0].get('generated_text', '')\n",
        "        else:\n",
        "            raise Exception(\"Invalid response format from API\")\n",
        "\n",
        "        # Initialize structured quiz dictionary\n",
        "        structured_quiz = {\n",
        "            \"multiple_choice\": [],\n",
        "            \"fill_in_blanks\": [],\n",
        "            \"short_answer\": []\n",
        "        }\n",
        "\n",
        "        # Split the text into sections\n",
        "        sections = quiz_text.split(\"===\")\n",
        "\n",
        "        def parse_difficulty(question_text: str) -> str:\n",
        "            \"\"\"Extract difficulty level from question text.\"\"\"\n",
        "            if \"[Difficulty:\" in question_text:\n",
        "                difficulty = question_text.split(\"[Difficulty:\")[1].split(\"]\")[0].strip()\n",
        "                return difficulty.lower()\n",
        "            return \"medium\"  # default difficulty\n",
        "\n",
        "        def parse_multiple_choice(section: str) -> List[Dict]:\n",
        "            \"\"\"Parse multiple choice questions section.\"\"\"\n",
        "            questions = []\n",
        "            current_question = {}\n",
        "\n",
        "            # Split into individual questions\n",
        "            question_blocks = section.split(\"\\n\\n\")\n",
        "\n",
        "            for block in question_blocks:\n",
        "                if not block.strip() or \"MULTIPLE CHOICE QUESTIONS\" in block:\n",
        "                    continue\n",
        "\n",
        "                lines = block.strip().split(\"\\n\")\n",
        "                current_question = {\n",
        "                    \"type\": \"multiple_choice\",\n",
        "                    \"difficulty\": parse_difficulty(block),\n",
        "                    \"options\": [],\n",
        "                    \"explanation\": \"\"\n",
        "                }\n",
        "\n",
        "                for line in lines:\n",
        "                    line = line.strip()\n",
        "                    if line.startswith(\"Q\"):\n",
        "                        current_question[\"question\"] = line.split(\".\", 1)[1].strip()\n",
        "                    elif line.startswith((\"A)\", \"B)\", \"C)\", \"D)\")):\n",
        "                        current_question[\"options\"].append({\n",
        "                            \"label\": line[0],\n",
        "                            \"text\": line[3:].strip()\n",
        "                        })\n",
        "                    elif line.startswith(\"Correct:\"):\n",
        "                        current_question[\"correct_answer\"] = line.split(\":\", 1)[1].strip()\n",
        "                    elif line.startswith(\"Explanation:\"):\n",
        "                        current_question[\"explanation\"] = line.split(\":\", 1)[1].strip()\n",
        "\n",
        "                if current_question.get(\"question\"):\n",
        "                    questions.append(current_question)\n",
        "\n",
        "            return questions\n",
        "\n",
        "        def parse_fill_in_blanks(section: str) -> List[Dict]:\n",
        "            \"\"\"Parse fill in the blanks section.\"\"\"\n",
        "            questions = []\n",
        "            question_blocks = section.split(\"\\n\\n\")\n",
        "\n",
        "            for block in question_blocks:\n",
        "                if not block.strip() or \"FILL IN THE BLANKS\" in block:\n",
        "                    continue\n",
        "\n",
        "                lines = block.strip().split(\"\\n\")\n",
        "                current_question = {\n",
        "                    \"type\": \"fill_in_blanks\",\n",
        "                    \"difficulty\": parse_difficulty(block),\n",
        "                    \"explanation\": \"\"\n",
        "                }\n",
        "\n",
        "                for line in lines:\n",
        "                    line = line.strip()\n",
        "                    if line.startswith(\"Q\"):\n",
        "                        current_question[\"question\"] = line.split(\".\", 1)[1].strip()\n",
        "                    elif line.startswith(\"Answer:\"):\n",
        "                        current_question[\"answer\"] = line.split(\":\", 1)[1].strip()\n",
        "                    elif line.startswith(\"Explanation:\"):\n",
        "                        current_question[\"explanation\"] = line.split(\":\", 1)[1].strip()\n",
        "\n",
        "                if current_question.get(\"question\"):\n",
        "                    questions.append(current_question)\n",
        "\n",
        "            return questions\n",
        "\n",
        "        def parse_short_answer(section: str) -> List[Dict]:\n",
        "            \"\"\"Parse short answer questions section.\"\"\"\n",
        "            questions = []\n",
        "            question_blocks = section.split(\"\\n\\n\")\n",
        "\n",
        "            for block in question_blocks:\n",
        "                if not block.strip() or \"SHORT ANSWER QUESTIONS\" in block:\n",
        "                    continue\n",
        "\n",
        "                lines = block.strip().split(\"\\n\")\n",
        "                current_question = {\n",
        "                    \"type\": \"short_answer\",\n",
        "                    \"difficulty\": parse_difficulty(block),\n",
        "                    \"key_points\": []\n",
        "                }\n",
        "\n",
        "                for line in lines:\n",
        "                    line = line.strip()\n",
        "                    if line.startswith(\"Q\"):\n",
        "                        current_question[\"question\"] = line.split(\".\", 1)[1].strip()\n",
        "                    elif line.startswith(\"Answer:\"):\n",
        "                        current_question[\"answer\"] = line.split(\":\", 1)[1].strip()\n",
        "                    elif line.startswith(\"Key Points:\"):\n",
        "                        # Split key points if they're comma-separated\n",
        "                        key_points = line.split(\":\", 1)[1].strip()\n",
        "                        current_question[\"key_points\"] = [\n",
        "                            point.strip()\n",
        "                            for point in key_points.split(\",\")\n",
        "                        ]\n",
        "\n",
        "                if current_question.get(\"question\"):\n",
        "                    questions.append(current_question)\n",
        "\n",
        "            return questions\n",
        "\n",
        "        # Parse each section\n",
        "        for section in sections:\n",
        "            section = section.strip()\n",
        "            if \"MULTIPLE CHOICE QUESTIONS\" in section:\n",
        "                structured_quiz[\"multiple_choice\"] = parse_multiple_choice(section)\n",
        "            elif \"FILL IN THE BLANKS\" in section:\n",
        "                structured_quiz[\"fill_in_blanks\"] = parse_fill_in_blanks(section)\n",
        "            elif \"SHORT ANSWER QUESTIONS\" in section:\n",
        "                structured_quiz[\"short_answer\"] = parse_short_answer(section)\n",
        "\n",
        "        # Add metadata and statistics\n",
        "        quiz_metadata = {\n",
        "            \"total_questions\": sum(len(questions) for questions in structured_quiz.values()),\n",
        "            \"question_types\": {\n",
        "                \"multiple_choice\": len(structured_quiz[\"multiple_choice\"]),\n",
        "                \"fill_in_blanks\": len(structured_quiz[\"fill_in_blanks\"]),\n",
        "                \"short_answer\": len(structured_quiz[\"short_answer\"])\n",
        "            },\n",
        "            \"difficulty_distribution\": {\n",
        "                \"easy\": sum(1 for q in (structured_quiz[\"multiple_choice\"] +\n",
        "                                      structured_quiz[\"fill_in_blanks\"] +\n",
        "                                      structured_quiz[\"short_answer\"])\n",
        "                         if q[\"difficulty\"] == \"easy\"),\n",
        "                \"medium\": sum(1 for q in (structured_quiz[\"multiple_choice\"] +\n",
        "                                        structured_quiz[\"fill_in_blanks\"] +\n",
        "                                        structured_quiz[\"short_answer\"])\n",
        "                         if q[\"difficulty\"] == \"medium\"),\n",
        "                \"hard\": sum(1 for q in (structured_quiz[\"multiple_choice\"] +\n",
        "                                      structured_quiz[\"fill_in_blanks\"] +\n",
        "                                      structured_quiz[\"short_answer\"])\n",
        "                         if q[\"difficulty\"] == \"hard\")\n",
        "            }\n",
        "        }\n",
        "\n",
        "        return {\n",
        "            \"metadata\": quiz_metadata,\n",
        "            \"quiz\": structured_quiz,\n",
        "            \"raw_response\": quiz_text\n",
        "        }\n",
        "\n",
        "    def generate_quiz(self, context_file_path: str) -> Dict:\n",
        "        \"\"\"Main method to generate a complete quiz.\"\"\"\n",
        "        try:\n",
        "            # Read the context file\n",
        "            content = self.read_context_file(context_file_path)\n",
        "\n",
        "            # Generate the prompt\n",
        "            prompt = self.generate_quiz_prompt(content)\n",
        "\n",
        "            # Query the API\n",
        "            response = self.query_huggingface_api(prompt)\n",
        "\n",
        "            # Parse the response\n",
        "            quiz = self.parse_quiz_response(response)\n",
        "\n",
        "            return quiz\n",
        "\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"Quiz generation failed: {str(e)}\")\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        # Initialize quiz generator\n",
        "        quiz_gen = QuizGenerator()\n",
        "\n",
        "        # Generate quiz\n",
        "        quiz = quiz_gen.generate_quiz(\"content.txt\")\n",
        "\n",
        "        # Save the generated quiz\n",
        "        with open('generated_quiz.json', 'w', encoding='utf-8') as f:\n",
        "            json.dump(quiz, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "        print(\"Quiz generated successfully and saved to 'generated_quiz.json'\")\n",
        "\n",
        "        # Print summary statistics\n",
        "        print(\"\\nQuiz Statistics:\")\n",
        "        print(f\"Total Questions: {quiz['metadata']['total_questions']}\")\n",
        "        print(\"\\nQuestion Types:\")\n",
        "        for qtype, count in quiz['metadata']['question_types'].items():\n",
        "            print(f\"- {qtype}: {count}\")\n",
        "        print(\"\\nDifficulty Distribution:\")\n",
        "        for diff, count in quiz['metadata']['difficulty_distribution'].items():\n",
        "            print(f\"- {diff}: {count}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {str(e)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "-PIw_79Nngpi",
        "outputId": "d390c9ed-927d-4173-f9b7-8a0b692be6d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quiz generated successfully and saved to 'generated_quiz.json'\n",
            "\n",
            "Quiz Statistics:\n",
            "Total Questions: 0\n",
            "\n",
            "Question Types:\n",
            "- multiple_choice: 0\n",
            "- fill_in_blanks: 0\n",
            "- short_answer: 0\n",
            "\n",
            "Difficulty Distribution:\n",
            "- easy: 0\n",
            "- medium: 0\n",
            "- hard: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import time\n",
        "import os\n",
        "from typing import Dict, List, Union\n",
        "from requests.adapters import HTTPAdapter\n",
        "from urllib3.util.retry import Retry\n",
        "\n",
        "# API Configuration\n",
        "HUGGINGFACE_API_TOKEN = \"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\"\n",
        "MODEL_NAME = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
        "HUGGINGFACE_API_URL = f\"https://api-inference.huggingface.co/models/{MODEL_NAME}\"\n",
        "HEADERS = {\n",
        "    \"Authorization\": f\"Bearer {HUGGINGFACE_API_TOKEN}\"\n",
        "}\n",
        "\n",
        "class QuizGenerator:\n",
        "    def __init__(self, debug=True):\n",
        "        \"\"\"Initialize with debug option.\"\"\"\n",
        "        self.debug = debug\n",
        "        self.session = requests.Session()\n",
        "\n",
        "        retries = Retry(\n",
        "            total=5,\n",
        "            backoff_factor=1,\n",
        "            status_forcelist=[408, 429, 500, 502, 503, 504]\n",
        "        )\n",
        "\n",
        "        adapter = HTTPAdapter(max_retries=retries)\n",
        "        self.session.mount('https://', adapter)\n",
        "\n",
        "    def read_context_file(self, file_path: str) -> str:\n",
        "        \"\"\"Read content from the context file with proper error handling.\"\"\"\n",
        "        try:\n",
        "            if not os.path.exists(file_path):\n",
        "                raise FileNotFoundError(f\"Content file not found: {file_path}\")\n",
        "\n",
        "            if not os.access(file_path, os.R_OK):\n",
        "                raise PermissionError(f\"Cannot read content file: {file_path}\")\n",
        "\n",
        "            with open(file_path, 'r', encoding='utf-8') as file:\n",
        "                content = file.read()\n",
        "\n",
        "            if not content.strip():\n",
        "                raise ValueError(f\"Content file is empty: {file_path}\")\n",
        "\n",
        "            if self.debug:\n",
        "                print(f\"Successfully read {len(content)} characters from {file_path}\")\n",
        "\n",
        "            # Clean up content\n",
        "            content = content.replace('\\ufeff', '').replace('\\r\\n', '\\n')\n",
        "\n",
        "            return content\n",
        "\n",
        "        except UnicodeDecodeError:\n",
        "            raise Exception(f\"File encoding error. Please ensure {file_path} is saved in UTF-8 format.\")\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"Error reading content file: {str(e)}\")\n",
        "\n",
        "    def generate_quiz_prompt(self, content: str) -> str:\n",
        "        \"\"\"Generate a structured prompt for the quiz.\"\"\"\n",
        "        return f\"\"\"<s>[INST] You are a technical quiz generation expert. Based on the provided technical content, create a comprehensive assessment that tests understanding at different levels. Generate the following:\n",
        "\n",
        "1. Multiple Choice Questions (10 total):\n",
        "   - 4 Easy questions: Test basic terminology and concept recall\n",
        "   - 3 Medium questions: Test understanding of relationships and principles\n",
        "   - 3 Hard questions: Test advanced concepts and technical analysis\n",
        "\n",
        "2. Fill in the Blanks (10 total):\n",
        "   - 4 Easy questions: Basic terminology and definitions\n",
        "   - 3 Medium questions: Technical relationships and components\n",
        "   - 3 Hard questions: Complex technical concepts and implementations\n",
        "\n",
        "3. Short Answer Questions (15 total):\n",
        "   - 5 Easy questions: Basic concept explanation\n",
        "   - 5 Medium questions: Understanding mechanisms and relationships\n",
        "   - 5 Hard questions: Technical analysis and practical applications\n",
        "\n",
        "Content to create questions from:\n",
        "{content}\n",
        "\n",
        "Format your response EXACTLY as follows:\n",
        "\n",
        "=== MULTIPLE CHOICE QUESTIONS ===\n",
        "[Difficulty: Easy/Medium/Hard]\n",
        "Q1. Question text\n",
        "A) Option A\n",
        "B) Option B\n",
        "C) Option C\n",
        "D) Option D\n",
        "Correct: [Letter]\n",
        "Explanation: Brief explanation\n",
        "\n",
        "=== FILL IN THE BLANKS ===\n",
        "[Difficulty: Easy/Medium/Hard]\n",
        "Q1. Sentence with _____ to fill\n",
        "Answer: Correct answer\n",
        "Explanation: Brief explanation\n",
        "\n",
        "=== SHORT ANSWER QUESTIONS ===\n",
        "[Difficulty: Easy/Medium/Hard]\n",
        "Q1. Question text\n",
        "Answer: Model answer (1-2 sentences)\n",
        "Key Points: Key point 1, Key point 2\n",
        "\n",
        "Ensure questions:\n",
        "- Cover different aspects of the content\n",
        "- Are technically accurate\n",
        "- Have clear, unambiguous answers\n",
        "- Progress in difficulty appropriately\n",
        "- Test both theoretical knowledge and practical understanding\n",
        "[/INST]</s>\"\"\"\n",
        "\n",
        "    def query_huggingface_api(self, prompt: str, max_length: int = 30000) -> Dict:\n",
        "        \"\"\"Query the Hugging Face API with proper error handling.\"\"\"\n",
        "        payload = {\n",
        "            \"inputs\": prompt,\n",
        "            \"parameters\": {\n",
        "                \"max_new_tokens\": max_length,\n",
        "                \"temperature\": 0.7,\n",
        "                \"top_p\": 0.9,\n",
        "                \"top_k\": 40,\n",
        "                \"repetition_penalty\": 1.1,\n",
        "                \"do_sample\": True,\n",
        "                \"stop\": [\"<|endoftext|>\"]\n",
        "            }\n",
        "        }\n",
        "\n",
        "        max_retries = 3\n",
        "        current_timeout = 90\n",
        "\n",
        "        for attempt in range(max_retries):\n",
        "            try:\n",
        "                print(f\"\\nAttempt {attempt + 1} of {max_retries} (timeout: {current_timeout}s)\")\n",
        "\n",
        "                response = self.session.post(\n",
        "                    HUGGINGFACE_API_URL,\n",
        "                    headers=HEADERS,\n",
        "                    json=payload,\n",
        "                    timeout=current_timeout\n",
        "                )\n",
        "\n",
        "                if self.debug:\n",
        "                    print(f\"Response status code: {response.status_code}\")\n",
        "\n",
        "                if response.status_code == 200:\n",
        "                    return response.json()\n",
        "                elif response.status_code == 503:\n",
        "                    print(\"Model is loading, waiting...\")\n",
        "                    time.sleep(20)\n",
        "                else:\n",
        "                    response.raise_for_status()\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Attempt {attempt + 1} failed: {str(e)}\")\n",
        "                if attempt < max_retries - 1:\n",
        "                    wait_time = (attempt + 1) * 5\n",
        "                    current_timeout *= 2\n",
        "                    print(f\"Waiting {wait_time} seconds before retry...\")\n",
        "                    time.sleep(wait_time)\n",
        "                else:\n",
        "                    raise\n",
        "\n",
        "        raise Exception(\"Failed to get valid response after all retries\")\n",
        "\n",
        "    def parse_quiz_response(self, response: List[Dict]) -> Dict:\n",
        "        \"\"\"Parse the API response into structured format.\"\"\"\n",
        "        try:\n",
        "            # Extract text from response\n",
        "            if isinstance(response, list):\n",
        "                quiz_text = response[0].get('generated_text', '')\n",
        "            else:\n",
        "                quiz_text = response.get('generated_text', '')\n",
        "\n",
        "            if not quiz_text:\n",
        "                raise ValueError(\"No generated text in API response\")\n",
        "\n",
        "            # Initialize structured quiz\n",
        "            structured_quiz = {\n",
        "                \"multiple_choice\": [],\n",
        "                \"fill_in_blanks\": [],\n",
        "                \"short_answer\": []\n",
        "            }\n",
        "\n",
        "            # Split into main sections (Multiple Choice, Fill in Blanks, Short Answer)\n",
        "            main_sections = quiz_text.split(\"\\n\\n1. \")[1:]  # Skip any text before first section\n",
        "            if not main_sections:\n",
        "                main_sections = quiz_text.split(\"\\n1. \")[1:]\n",
        "\n",
        "            current_section_type = None\n",
        "            current_difficulty = None\n",
        "            current_question = None\n",
        "\n",
        "            for line in quiz_text.split('\\n'):\n",
        "                line = line.strip()\n",
        "                if not line:\n",
        "                    continue\n",
        "\n",
        "                # Determine section type\n",
        "                if \"1. Multiple Choice Questions\" in line:\n",
        "                    current_section_type = \"multiple_choice\"\n",
        "                    continue\n",
        "                elif \"2. Fill in the Blanks\" in line:\n",
        "                    current_section_type = \"fill_in_blanks\"\n",
        "                    continue\n",
        "                elif \"3. Short Answer Questions\" in line:\n",
        "                    current_section_type = \"short_answer\"\n",
        "                    continue\n",
        "\n",
        "                # Check for difficulty headers\n",
        "                if \"**Easy Questions**\" in line:\n",
        "                    current_difficulty = \"easy\"\n",
        "                    continue\n",
        "                elif \"**Medium Questions**\" in line:\n",
        "                    current_difficulty = \"medium\"\n",
        "                    continue\n",
        "                elif \"**Hard Questions**\" in line:\n",
        "                    current_difficulty = \"hard\"\n",
        "                    continue\n",
        "\n",
        "                # Parse Multiple Choice Questions\n",
        "                if current_section_type == \"multiple_choice\":\n",
        "                    if line.startswith('Q'):\n",
        "                        if current_question:\n",
        "                            structured_quiz[\"multiple_choice\"].append(current_question)\n",
        "                        current_question = {\n",
        "                            \"type\": \"multiple_choice\",\n",
        "                            \"difficulty\": current_difficulty,\n",
        "                            \"question\": line.split('.', 1)[1].strip(),\n",
        "                            \"options\": [],\n",
        "                            \"correct_answer\": \"\",\n",
        "                            \"explanation\": \"\"\n",
        "                        }\n",
        "                    elif line.startswith(('A)', 'B)', 'C)', 'D)')):\n",
        "                        if current_question:\n",
        "                            current_question[\"options\"].append({\n",
        "                                \"label\": line[0],\n",
        "                                \"text\": line[2:].strip()\n",
        "                            })\n",
        "                    elif line.startswith('Answer:'):\n",
        "                        if current_question:\n",
        "                            current_question[\"correct_answer\"] = line.split(':', 1)[1].strip()\n",
        "                    elif line.startswith('Explanation:'):\n",
        "                        if current_question:\n",
        "                            current_question[\"explanation\"] = line.split(':', 1)[1].strip()\n",
        "                            structured_quiz[\"multiple_choice\"].append(current_question)\n",
        "                            current_question = None\n",
        "\n",
        "                # Parse Fill in the Blanks\n",
        "                elif current_section_type == \"fill_in_blanks\":\n",
        "                    if line.startswith('Q'):\n",
        "                        if current_question:\n",
        "                            structured_quiz[\"fill_in_blanks\"].append(current_question)\n",
        "                        current_question = {\n",
        "                            \"type\": \"fill_in_blanks\",\n",
        "                            \"difficulty\": current_difficulty,\n",
        "                            \"question\": line.split('.', 1)[1].strip(),\n",
        "                            \"answer\": \"\",\n",
        "                            \"explanation\": \"\"\n",
        "                        }\n",
        "                    elif line.startswith('Answer:'):\n",
        "                        if current_question:\n",
        "                            current_question[\"answer\"] = line.split(':', 1)[1].strip()\n",
        "                    elif line.startswith('Explanation:'):\n",
        "                        if current_question:\n",
        "                            current_question[\"explanation\"] = line.split(':', 1)[1].strip()\n",
        "                            structured_quiz[\"fill_in_blanks\"].append(current_question)\n",
        "                            current_question = None\n",
        "\n",
        "                # Parse Short Answer Questions\n",
        "                elif current_section_type == \"short_answer\":\n",
        "                    if line.startswith('Q'):\n",
        "                        if current_question:\n",
        "                            structured_quiz[\"short_answer\"].append(current_question)\n",
        "                        current_question = {\n",
        "                            \"type\": \"short_answer\",\n",
        "                            \"difficulty\": current_difficulty,\n",
        "                            \"question\": line.split('.', 1)[1].strip(),\n",
        "                            \"answer\": \"\",\n",
        "                            \"explanation\": \"\"\n",
        "                        }\n",
        "                    elif line.startswith('Answer:'):\n",
        "                        if current_question:\n",
        "                            current_question[\"answer\"] = line.split(':', 1)[1].strip()\n",
        "                            structured_quiz[\"short_answer\"].append(current_question)\n",
        "                            current_question = None\n",
        "\n",
        "            # Add the last question if it exists\n",
        "            if current_question:\n",
        "                if current_section_type == \"multiple_choice\":\n",
        "                    structured_quiz[\"multiple_choice\"].append(current_question)\n",
        "                elif current_section_type == \"fill_in_blanks\":\n",
        "                    structured_quiz[\"fill_in_blanks\"].append(current_question)\n",
        "                elif current_section_type == \"short_answer\":\n",
        "                    structured_quiz[\"short_answer\"].append(current_question)\n",
        "\n",
        "            # Calculate metadata\n",
        "            quiz_metadata = self._calculate_metadata(structured_quiz)\n",
        "\n",
        "            return {\n",
        "                \"metadata\": quiz_metadata,\n",
        "                \"quiz\": structured_quiz,\n",
        "                \"raw_response\": quiz_text\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error parsing quiz response: {str(e)}\")\n",
        "            if self.debug:\n",
        "                print(\"\\nFull response for debugging:\")\n",
        "                print(quiz_text[:500] + \"...\" if len(quiz_text) > 500 else quiz_text)\n",
        "            raise\n",
        "\n",
        "    def _calculate_metadata(self, quiz: Dict) -> Dict:\n",
        "        \"\"\"Calculate quiz metadata.\"\"\"\n",
        "        try:\n",
        "            total_questions = sum(len(questions) for questions in quiz.values())\n",
        "\n",
        "            return {\n",
        "                \"total_questions\": total_questions,\n",
        "                \"question_types\": {\n",
        "                    qtype: len(questions)\n",
        "                    for qtype, questions in quiz.items()\n",
        "                },\n",
        "                \"difficulty_distribution\": {\n",
        "                    level: sum(\n",
        "                        1 for questions in quiz.values()\n",
        "                        for q in questions\n",
        "                        if q.get(\"difficulty\") == level\n",
        "                    )\n",
        "                    for level in [\"easy\", \"medium\", \"hard\"]\n",
        "                },\n",
        "                \"generation_timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "            }\n",
        "        except Exception as e:\n",
        "            print(f\"Error calculating metadata: {str(e)}\")\n",
        "            return {\n",
        "                \"total_questions\": 0,\n",
        "                \"question_types\": {\n",
        "                    \"multiple_choice\": 0,\n",
        "                    \"fill_in_blanks\": 0,\n",
        "                    \"short_answer\": 0\n",
        "                },\n",
        "                \"difficulty_distribution\": {\n",
        "                    \"easy\": 0,\n",
        "                    \"medium\": 0,\n",
        "                    \"hard\": 0\n",
        "                },\n",
        "                \"generation_timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "            }\n",
        "    def generate_quiz(self, context_file_path: str) -> Dict:\n",
        "        \"\"\"Generate a complete quiz with error handling.\"\"\"\n",
        "        try:\n",
        "            content = self.read_context_file(context_file_path)\n",
        "            if self.debug:\n",
        "                print(f\"\\nRead {len(content)} characters from {context_file_path}\")\n",
        "\n",
        "            prompt = self.generate_quiz_prompt(content)\n",
        "\n",
        "            response = self.query_huggingface_api(prompt)\n",
        "\n",
        "            return self.parse_quiz_response(response)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Quiz generation failed: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        print(\"Starting quiz generation...\")\n",
        "\n",
        "        if not os.path.exists(\"content.txt\"):\n",
        "            print(\"Error: content.txt file not found!\")\n",
        "            print(\"\\nPlease create a content.txt file with your technical content.\")\n",
        "            print(\"The content can be about any computer science or technical topic.\")\n",
        "            print(\"\\nFile requirements:\")\n",
        "            print(\"1. Save as 'content.txt' in the same directory as this script\")\n",
        "            print(\"2. Use UTF-8 encoding\")\n",
        "            print(\"3. Include sufficient content for meaningful questions\")\n",
        "            return\n",
        "\n",
        "        quiz_gen = QuizGenerator(debug=True)\n",
        "\n",
        "        print(\"\\nReading content and generating quiz...\")\n",
        "        print(\"This may take a few minutes depending on the content length.\")\n",
        "        quiz = quiz_gen.generate_quiz(\"content.txt\")\n",
        "\n",
        "        # Create output directory\n",
        "        output_dir = \"quiz_output\"\n",
        "        if not os.path.exists(output_dir):\n",
        "            os.makedirs(output_dir)\n",
        "\n",
        "        # Save outputs\n",
        "        print(\"\\nSaving quiz files...\")\n",
        "\n",
        "        # Save raw response\n",
        "        raw_path = os.path.join(output_dir, 'quiz_raw.txt')\n",
        "        with open(raw_path, 'w', encoding='utf-8') as f:\n",
        "            f.write(quiz['raw_response'])\n",
        "\n",
        "        # Save structured quiz\n",
        "        json_path = os.path.join(output_dir, 'generated_quiz.json')\n",
        "        with open(json_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(quiz, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "        print(\"\\nQuiz generation completed successfully!\")\n",
        "        print(f\"\\nOutput files (in {output_dir}/):\")\n",
        "        print(\"- generated_quiz.json (structured quiz data)\")\n",
        "        print(\"- quiz_raw.txt (raw quiz text)\")\n",
        "\n",
        "        # Print quiz statistics\n",
        "        print(\"\\nQuiz Statistics:\")\n",
        "        print(f\"Total Questions: {quiz['metadata']['total_questions']}\")\n",
        "        print(\"\\nQuestion Types:\")\n",
        "        for qtype, count in quiz['metadata']['question_types'].items():\n",
        "            print(f\"- {qtype}: {count}\")\n",
        "        print(\"\\nDifficulty Distribution:\")\n",
        "        for diff, count in quiz['metadata']['difficulty_distribution'].items():\n",
        "            print(f\"- {diff}: {count}\")\n",
        "\n",
        "        print(\"\\nYou can find your quiz in the following files:\")\n",
        "        print(f\"1. {raw_path} - Contains the raw quiz text\")\n",
        "        print(f\"2. {json_path} - Contains the structured quiz data\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError: {str(e)}\")\n",
        "        print(\"\\nTroubleshooting tips:\")\n",
        "        print(\"1. Check that content.txt exists and is readable\")\n",
        "        print(\"2. Verify the content.txt has enough text to generate questions\")\n",
        "        print(\"3. Ensure content.txt is saved with UTF-8 encoding\")\n",
        "        print(\"4. Try running the script again (API might be temporarily busy)\")\n",
        "        print(\"5. Check your internet connection\")\n",
        "        print(\"\\nFor more details, check:\")\n",
        "        print(\"- The error message above\")\n",
        "        print(\"- quiz_raw.txt file (if created)\")\n",
        "        print(\"- generated_quiz.json file (if created)\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "8wARo_hzngcr",
        "outputId": "32b56dd4-8fb2-4f77-e4f3-5aebe74f4aab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting quiz generation...\n",
            "\n",
            "Reading content and generating quiz...\n",
            "This may take a few minutes depending on the content length.\n",
            "Successfully read 10101 characters from content.txt\n",
            "\n",
            "Read 10101 characters from content.txt\n",
            "\n",
            "Attempt 1 of 3 (timeout: 90s)\n",
            "Response status code: 200\n",
            "\n",
            "Saving quiz files...\n",
            "\n",
            "Quiz generation completed successfully!\n",
            "\n",
            "Output files (in quiz_output/):\n",
            "- generated_quiz.json (structured quiz data)\n",
            "- quiz_raw.txt (raw quiz text)\n",
            "\n",
            "Quiz Statistics:\n",
            "Total Questions: 35\n",
            "\n",
            "Question Types:\n",
            "- multiple_choice: 11\n",
            "- fill_in_blanks: 9\n",
            "- short_answer: 15\n",
            "\n",
            "Difficulty Distribution:\n",
            "- easy: 14\n",
            "- medium: 9\n",
            "- hard: 9\n",
            "\n",
            "You can find your quiz in the following files:\n",
            "1. quiz_output/quiz_raw.txt - Contains the raw quiz text\n",
            "2. quiz_output/generated_quiz.json - Contains the structured quiz data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EDOb9AHjsTV-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}