{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4234c6cd0c6d40568fad29ff687b58c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_316805a02e1047ed84984e1eb84eaf72",
              "IPY_MODEL_2c7c4631cf7f4a89a1334269801c54e1",
              "IPY_MODEL_f21958c81dd84aa7be05a9d0bfad65a2"
            ],
            "layout": "IPY_MODEL_c4e5358638284bc1953584556b7c05e1"
          }
        },
        "316805a02e1047ed84984e1eb84eaf72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c15b253fa8de4d24b593e75cfda58ee7",
            "placeholder": "​",
            "style": "IPY_MODEL_73b94ab484ca4fba94622c102b828395",
            "value": "modules.json: 100%"
          }
        },
        "2c7c4631cf7f4a89a1334269801c54e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb92dee048cc427aaa439ce0182bf7ab",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_71ca27dc9c1c4f61aea171d5b893e633",
            "value": 349
          }
        },
        "f21958c81dd84aa7be05a9d0bfad65a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35e02812705141e6868d3f3d6833c6d4",
            "placeholder": "​",
            "style": "IPY_MODEL_969cdd6d67e64952a4ab591ea5625b9d",
            "value": " 349/349 [00:00&lt;00:00, 35.3kB/s]"
          }
        },
        "c4e5358638284bc1953584556b7c05e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c15b253fa8de4d24b593e75cfda58ee7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73b94ab484ca4fba94622c102b828395": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb92dee048cc427aaa439ce0182bf7ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71ca27dc9c1c4f61aea171d5b893e633": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "35e02812705141e6868d3f3d6833c6d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "969cdd6d67e64952a4ab591ea5625b9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eca302a0fee44c499174dea1bce779a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_344f439b4c75418faddec798a32d2c6c",
              "IPY_MODEL_3d0f3b3d01114aee92c2547d06b36079",
              "IPY_MODEL_6a8d0339b02a4cf2904092bf926889bc"
            ],
            "layout": "IPY_MODEL_1cbe2a466c9146d0aa0844415d44dbf0"
          }
        },
        "344f439b4c75418faddec798a32d2c6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_035c578596514260a18e0148a25a60dc",
            "placeholder": "​",
            "style": "IPY_MODEL_0a6f76b1664948d29de43b4ae53a8a63",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "3d0f3b3d01114aee92c2547d06b36079": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e10a53fa4e14ed4ad7ae32f5040defa",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ee20dee0e2734fb49bbea4a7ae6f8708",
            "value": 116
          }
        },
        "6a8d0339b02a4cf2904092bf926889bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_241e667277a54ed0b192da9423910022",
            "placeholder": "​",
            "style": "IPY_MODEL_e1dc9dab0247485ca6f503d4e2f414d4",
            "value": " 116/116 [00:00&lt;00:00, 10.9kB/s]"
          }
        },
        "1cbe2a466c9146d0aa0844415d44dbf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "035c578596514260a18e0148a25a60dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a6f76b1664948d29de43b4ae53a8a63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e10a53fa4e14ed4ad7ae32f5040defa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee20dee0e2734fb49bbea4a7ae6f8708": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "241e667277a54ed0b192da9423910022": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1dc9dab0247485ca6f503d4e2f414d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2c68a0ed8a0464886b03e98bdd3f459": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1d1846df4b5944e7895632512ff72638",
              "IPY_MODEL_ff71888d67014445a0e8479618d7dc6e",
              "IPY_MODEL_097b9136665e448a81304032397226bd"
            ],
            "layout": "IPY_MODEL_bbdd720d40da484aaba8ff642bee352d"
          }
        },
        "1d1846df4b5944e7895632512ff72638": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a867fe9102d40b2bbcfafe98b76080e",
            "placeholder": "​",
            "style": "IPY_MODEL_505e1d4b3657448abf5d62455c0f50d9",
            "value": "README.md: 100%"
          }
        },
        "ff71888d67014445a0e8479618d7dc6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06d035a828634e47884878a15392da2c",
            "max": 10454,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_97c12f660795478d8f9a2017650df371",
            "value": 10454
          }
        },
        "097b9136665e448a81304032397226bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_375e63762a794ec69371b51694cfcba9",
            "placeholder": "​",
            "style": "IPY_MODEL_6c9439846d5c428985640eeb9af3f8d7",
            "value": " 10.5k/10.5k [00:00&lt;00:00, 765kB/s]"
          }
        },
        "bbdd720d40da484aaba8ff642bee352d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a867fe9102d40b2bbcfafe98b76080e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "505e1d4b3657448abf5d62455c0f50d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06d035a828634e47884878a15392da2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97c12f660795478d8f9a2017650df371": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "375e63762a794ec69371b51694cfcba9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c9439846d5c428985640eeb9af3f8d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f1b0089f1cd420487cd3b249f36abd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e6588d1dec0a4ee2ac479161572514c9",
              "IPY_MODEL_8c26c68e6daa4be79363efbc5ca66230",
              "IPY_MODEL_a0473a803db24c26ba3fcf61dcb84238"
            ],
            "layout": "IPY_MODEL_bfd971d1b6c246bf84a94cbf39787fb6"
          }
        },
        "e6588d1dec0a4ee2ac479161572514c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_537027c027ec413abc13abb973aaa89b",
            "placeholder": "​",
            "style": "IPY_MODEL_2029f02d01714a97957eed666a7128a5",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "8c26c68e6daa4be79363efbc5ca66230": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d429351a50a4e5cbc33e014572125e7",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9c265131833e42229dd941ec476dea1c",
            "value": 53
          }
        },
        "a0473a803db24c26ba3fcf61dcb84238": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09e8a09367e04e05ac3781bf8faabc19",
            "placeholder": "​",
            "style": "IPY_MODEL_8f9a6137ebb94a0c91aefba9e8985138",
            "value": " 53.0/53.0 [00:00&lt;00:00, 4.23kB/s]"
          }
        },
        "bfd971d1b6c246bf84a94cbf39787fb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "537027c027ec413abc13abb973aaa89b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2029f02d01714a97957eed666a7128a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d429351a50a4e5cbc33e014572125e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c265131833e42229dd941ec476dea1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "09e8a09367e04e05ac3781bf8faabc19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f9a6137ebb94a0c91aefba9e8985138": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e695fa8807f45daaac2b850cdab7b1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5ffdecd5620544b2a2039638124b501a",
              "IPY_MODEL_b33254ef8753493e8f90510a3efe33e4",
              "IPY_MODEL_1dc2fa19baa045ab93554f5bdcd36832"
            ],
            "layout": "IPY_MODEL_c36303debc5c414596f00f8c873dc67c"
          }
        },
        "5ffdecd5620544b2a2039638124b501a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_447016c6b96f4f30a6b1b7ec4b878675",
            "placeholder": "​",
            "style": "IPY_MODEL_f6417c2fe365422abc853e5920df7f4e",
            "value": "config.json: 100%"
          }
        },
        "b33254ef8753493e8f90510a3efe33e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0068ba64c8944f4c8c92712ccad243a1",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_47bd2b7e3e87414ebcc49fde4f6bba17",
            "value": 612
          }
        },
        "1dc2fa19baa045ab93554f5bdcd36832": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b79fb0c2d0c84bc185db096a429dd6d1",
            "placeholder": "​",
            "style": "IPY_MODEL_ee39a8ceca144081b2bf082d5296f99a",
            "value": " 612/612 [00:00&lt;00:00, 48.1kB/s]"
          }
        },
        "c36303debc5c414596f00f8c873dc67c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "447016c6b96f4f30a6b1b7ec4b878675": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6417c2fe365422abc853e5920df7f4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0068ba64c8944f4c8c92712ccad243a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47bd2b7e3e87414ebcc49fde4f6bba17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b79fb0c2d0c84bc185db096a429dd6d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee39a8ceca144081b2bf082d5296f99a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1344373cdfa04b4f9cade3b720b324ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_10bf73837d994d5f917d7921eae4afe4",
              "IPY_MODEL_f15a8d76752246c080fe0736eec06e1d",
              "IPY_MODEL_55820bbb24d043c1b03bae365de8119c"
            ],
            "layout": "IPY_MODEL_e6baa75012194baf8ded248537f54f2d"
          }
        },
        "10bf73837d994d5f917d7921eae4afe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_547652ccfced4ac291caaa4e29810a90",
            "placeholder": "​",
            "style": "IPY_MODEL_8df8806b7b7d468390edd73e6ac1e692",
            "value": "model.safetensors: 100%"
          }
        },
        "f15a8d76752246c080fe0736eec06e1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_745fdf8d04a44a819ef20764bb039c71",
            "max": 90868376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eb5ac0c0a86144168ee06dd7385c8f9c",
            "value": 90868376
          }
        },
        "55820bbb24d043c1b03bae365de8119c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6943770646a40ae845440f136bdbd44",
            "placeholder": "​",
            "style": "IPY_MODEL_acb6d5f629684f5d9b9790f2e54fa419",
            "value": " 90.9M/90.9M [00:00&lt;00:00, 171MB/s]"
          }
        },
        "e6baa75012194baf8ded248537f54f2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "547652ccfced4ac291caaa4e29810a90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8df8806b7b7d468390edd73e6ac1e692": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "745fdf8d04a44a819ef20764bb039c71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb5ac0c0a86144168ee06dd7385c8f9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c6943770646a40ae845440f136bdbd44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acb6d5f629684f5d9b9790f2e54fa419": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13b73b47f8114f158ca1f0fbd3e72338": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_21393cac609d4ef399bf7e6c418244a6",
              "IPY_MODEL_e2f10c8e83d84d7abea832d317c5c7a7",
              "IPY_MODEL_9b516f66342a4ab3ac8e7f7397e2ab1d"
            ],
            "layout": "IPY_MODEL_496fb78999084bdaaf31b00c0ff51a2c"
          }
        },
        "21393cac609d4ef399bf7e6c418244a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3d574c178eb4045949c8ade537b1782",
            "placeholder": "​",
            "style": "IPY_MODEL_8fb2db8051ba45a381890855eb9b9623",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "e2f10c8e83d84d7abea832d317c5c7a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c700b0b7fb44d8e95d7c7391b91b181",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_557d08429b444ac1a150eeb626a6abf1",
            "value": 350
          }
        },
        "9b516f66342a4ab3ac8e7f7397e2ab1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57bc9d3523b84d0385c7f7b96349f9f8",
            "placeholder": "​",
            "style": "IPY_MODEL_e14badf67c864812a9baa744223a08ec",
            "value": " 350/350 [00:00&lt;00:00, 34.8kB/s]"
          }
        },
        "496fb78999084bdaaf31b00c0ff51a2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3d574c178eb4045949c8ade537b1782": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fb2db8051ba45a381890855eb9b9623": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c700b0b7fb44d8e95d7c7391b91b181": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "557d08429b444ac1a150eeb626a6abf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "57bc9d3523b84d0385c7f7b96349f9f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e14badf67c864812a9baa744223a08ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8fd174d145df401f80de75c6ad04dd40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e951cd8965d443fa88c31004d27bc0bf",
              "IPY_MODEL_6927b71703c045b99d1d2e137cd8fcc1",
              "IPY_MODEL_c93975fd56064feb921fd55810424be5"
            ],
            "layout": "IPY_MODEL_4fa96f28676541a2a89d81a80500edba"
          }
        },
        "e951cd8965d443fa88c31004d27bc0bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b4684684b9d4afdbfb005c036d6a754",
            "placeholder": "​",
            "style": "IPY_MODEL_a62c5e3774a5462e89a290094d51416e",
            "value": "vocab.txt: 100%"
          }
        },
        "6927b71703c045b99d1d2e137cd8fcc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8ab76bc65ed4ab0946eef75e5568918",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bcf5d7427d7d497eac9f61303050488b",
            "value": 231508
          }
        },
        "c93975fd56064feb921fd55810424be5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ab34d1f44fd47b8b3b523adb3c52c3f",
            "placeholder": "​",
            "style": "IPY_MODEL_acfab42c5120421280c49b0b8bdfee9c",
            "value": " 232k/232k [00:00&lt;00:00, 3.00MB/s]"
          }
        },
        "4fa96f28676541a2a89d81a80500edba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b4684684b9d4afdbfb005c036d6a754": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a62c5e3774a5462e89a290094d51416e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8ab76bc65ed4ab0946eef75e5568918": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcf5d7427d7d497eac9f61303050488b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ab34d1f44fd47b8b3b523adb3c52c3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acfab42c5120421280c49b0b8bdfee9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7331459203c84a5da79c6d8d5fbff1ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bf6b6742d7664513aee1d4c4e28a8496",
              "IPY_MODEL_586bf0bf4434442ba1bac191475afbc3",
              "IPY_MODEL_f0ac54fefbbd464c9a145d7d17877816"
            ],
            "layout": "IPY_MODEL_aa1d3bb8d05d418b95f2e31c463918c7"
          }
        },
        "bf6b6742d7664513aee1d4c4e28a8496": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdaabe5a8cad4c4ba15fc6f811fc8e8d",
            "placeholder": "​",
            "style": "IPY_MODEL_a8debba1da5447dab24c48f027ed8e33",
            "value": "tokenizer.json: 100%"
          }
        },
        "586bf0bf4434442ba1bac191475afbc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7727e978e0fa4d3aa116bc4db836d9d4",
            "max": 466247,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_398a1b16345b4bbe92715cb37fd9750b",
            "value": 466247
          }
        },
        "f0ac54fefbbd464c9a145d7d17877816": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40f7a64eb52142528509ecb146e44061",
            "placeholder": "​",
            "style": "IPY_MODEL_32bd05adc844440fa77ef818b3a69086",
            "value": " 466k/466k [00:00&lt;00:00, 3.14MB/s]"
          }
        },
        "aa1d3bb8d05d418b95f2e31c463918c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdaabe5a8cad4c4ba15fc6f811fc8e8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8debba1da5447dab24c48f027ed8e33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7727e978e0fa4d3aa116bc4db836d9d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "398a1b16345b4bbe92715cb37fd9750b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "40f7a64eb52142528509ecb146e44061": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32bd05adc844440fa77ef818b3a69086": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eecabbef92a24a7881d8bbb4711b63fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a80be735e0424f8082b944f53a9820a0",
              "IPY_MODEL_e4e2744f07a5488a9b43eba59e975b3b",
              "IPY_MODEL_33f1b4b1661f438fb7591031355e7224"
            ],
            "layout": "IPY_MODEL_36350473be284f78b89eb340c31c4a3e"
          }
        },
        "a80be735e0424f8082b944f53a9820a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f42a48f33b442d6b17226f47cec384d",
            "placeholder": "​",
            "style": "IPY_MODEL_d891806b12934b4eac8eed19073094f0",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "e4e2744f07a5488a9b43eba59e975b3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2012e6abf20246ef89ee4b7697ed785f",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e9e1590fb07b49c7ad2454f94d01c8f6",
            "value": 112
          }
        },
        "33f1b4b1661f438fb7591031355e7224": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fcdee9a452ad4db2857657e612a18af6",
            "placeholder": "​",
            "style": "IPY_MODEL_8dee61ab3dfe46e8ad375e9ea2be2d21",
            "value": " 112/112 [00:00&lt;00:00, 8.67kB/s]"
          }
        },
        "36350473be284f78b89eb340c31c4a3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f42a48f33b442d6b17226f47cec384d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d891806b12934b4eac8eed19073094f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2012e6abf20246ef89ee4b7697ed785f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9e1590fb07b49c7ad2454f94d01c8f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fcdee9a452ad4db2857657e612a18af6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8dee61ab3dfe46e8ad375e9ea2be2d21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38bd37eef8c3473f8d16516b10686d83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_63f8554c18824e1bbd5e133bd7dfe275",
              "IPY_MODEL_3096e7e15ebe41eba562ed2531d35b2a",
              "IPY_MODEL_ace7aed23f0b45f8aef5a7012f971cfe"
            ],
            "layout": "IPY_MODEL_9a2880240bb948b59628627f3bbde9be"
          }
        },
        "63f8554c18824e1bbd5e133bd7dfe275": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cf8dd32783e4b76876cdd0e950b90a2",
            "placeholder": "​",
            "style": "IPY_MODEL_bea3a76f06b84e509b09e24fb48e19dc",
            "value": "config.json: 100%"
          }
        },
        "3096e7e15ebe41eba562ed2531d35b2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ada06ba1d0124e4bab5e9202617a14f3",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_55f0443bc2624f08931439b42b8db02b",
            "value": 190
          }
        },
        "ace7aed23f0b45f8aef5a7012f971cfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca43127ef6d04617ac1d6aa8f345c002",
            "placeholder": "​",
            "style": "IPY_MODEL_437c05084ed54d349f3b3b2112e5befd",
            "value": " 190/190 [00:00&lt;00:00, 19.4kB/s]"
          }
        },
        "9a2880240bb948b59628627f3bbde9be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cf8dd32783e4b76876cdd0e950b90a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bea3a76f06b84e509b09e24fb48e19dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ada06ba1d0124e4bab5e9202617a14f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55f0443bc2624f08931439b42b8db02b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ca43127ef6d04617ac1d6aa8f345c002": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "437c05084ed54d349f3b3b2112e5befd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4234c6cd0c6d40568fad29ff687b58c5",
            "316805a02e1047ed84984e1eb84eaf72",
            "2c7c4631cf7f4a89a1334269801c54e1",
            "f21958c81dd84aa7be05a9d0bfad65a2",
            "c4e5358638284bc1953584556b7c05e1",
            "c15b253fa8de4d24b593e75cfda58ee7",
            "73b94ab484ca4fba94622c102b828395",
            "fb92dee048cc427aaa439ce0182bf7ab",
            "71ca27dc9c1c4f61aea171d5b893e633",
            "35e02812705141e6868d3f3d6833c6d4",
            "969cdd6d67e64952a4ab591ea5625b9d",
            "eca302a0fee44c499174dea1bce779a9",
            "344f439b4c75418faddec798a32d2c6c",
            "3d0f3b3d01114aee92c2547d06b36079",
            "6a8d0339b02a4cf2904092bf926889bc",
            "1cbe2a466c9146d0aa0844415d44dbf0",
            "035c578596514260a18e0148a25a60dc",
            "0a6f76b1664948d29de43b4ae53a8a63",
            "4e10a53fa4e14ed4ad7ae32f5040defa",
            "ee20dee0e2734fb49bbea4a7ae6f8708",
            "241e667277a54ed0b192da9423910022",
            "e1dc9dab0247485ca6f503d4e2f414d4",
            "a2c68a0ed8a0464886b03e98bdd3f459",
            "1d1846df4b5944e7895632512ff72638",
            "ff71888d67014445a0e8479618d7dc6e",
            "097b9136665e448a81304032397226bd",
            "bbdd720d40da484aaba8ff642bee352d",
            "3a867fe9102d40b2bbcfafe98b76080e",
            "505e1d4b3657448abf5d62455c0f50d9",
            "06d035a828634e47884878a15392da2c",
            "97c12f660795478d8f9a2017650df371",
            "375e63762a794ec69371b51694cfcba9",
            "6c9439846d5c428985640eeb9af3f8d7",
            "1f1b0089f1cd420487cd3b249f36abd0",
            "e6588d1dec0a4ee2ac479161572514c9",
            "8c26c68e6daa4be79363efbc5ca66230",
            "a0473a803db24c26ba3fcf61dcb84238",
            "bfd971d1b6c246bf84a94cbf39787fb6",
            "537027c027ec413abc13abb973aaa89b",
            "2029f02d01714a97957eed666a7128a5",
            "9d429351a50a4e5cbc33e014572125e7",
            "9c265131833e42229dd941ec476dea1c",
            "09e8a09367e04e05ac3781bf8faabc19",
            "8f9a6137ebb94a0c91aefba9e8985138",
            "5e695fa8807f45daaac2b850cdab7b1e",
            "5ffdecd5620544b2a2039638124b501a",
            "b33254ef8753493e8f90510a3efe33e4",
            "1dc2fa19baa045ab93554f5bdcd36832",
            "c36303debc5c414596f00f8c873dc67c",
            "447016c6b96f4f30a6b1b7ec4b878675",
            "f6417c2fe365422abc853e5920df7f4e",
            "0068ba64c8944f4c8c92712ccad243a1",
            "47bd2b7e3e87414ebcc49fde4f6bba17",
            "b79fb0c2d0c84bc185db096a429dd6d1",
            "ee39a8ceca144081b2bf082d5296f99a",
            "1344373cdfa04b4f9cade3b720b324ad",
            "10bf73837d994d5f917d7921eae4afe4",
            "f15a8d76752246c080fe0736eec06e1d",
            "55820bbb24d043c1b03bae365de8119c",
            "e6baa75012194baf8ded248537f54f2d",
            "547652ccfced4ac291caaa4e29810a90",
            "8df8806b7b7d468390edd73e6ac1e692",
            "745fdf8d04a44a819ef20764bb039c71",
            "eb5ac0c0a86144168ee06dd7385c8f9c",
            "c6943770646a40ae845440f136bdbd44",
            "acb6d5f629684f5d9b9790f2e54fa419",
            "13b73b47f8114f158ca1f0fbd3e72338",
            "21393cac609d4ef399bf7e6c418244a6",
            "e2f10c8e83d84d7abea832d317c5c7a7",
            "9b516f66342a4ab3ac8e7f7397e2ab1d",
            "496fb78999084bdaaf31b00c0ff51a2c",
            "d3d574c178eb4045949c8ade537b1782",
            "8fb2db8051ba45a381890855eb9b9623",
            "6c700b0b7fb44d8e95d7c7391b91b181",
            "557d08429b444ac1a150eeb626a6abf1",
            "57bc9d3523b84d0385c7f7b96349f9f8",
            "e14badf67c864812a9baa744223a08ec",
            "8fd174d145df401f80de75c6ad04dd40",
            "e951cd8965d443fa88c31004d27bc0bf",
            "6927b71703c045b99d1d2e137cd8fcc1",
            "c93975fd56064feb921fd55810424be5",
            "4fa96f28676541a2a89d81a80500edba",
            "3b4684684b9d4afdbfb005c036d6a754",
            "a62c5e3774a5462e89a290094d51416e",
            "f8ab76bc65ed4ab0946eef75e5568918",
            "bcf5d7427d7d497eac9f61303050488b",
            "5ab34d1f44fd47b8b3b523adb3c52c3f",
            "acfab42c5120421280c49b0b8bdfee9c",
            "7331459203c84a5da79c6d8d5fbff1ff",
            "bf6b6742d7664513aee1d4c4e28a8496",
            "586bf0bf4434442ba1bac191475afbc3",
            "f0ac54fefbbd464c9a145d7d17877816",
            "aa1d3bb8d05d418b95f2e31c463918c7",
            "fdaabe5a8cad4c4ba15fc6f811fc8e8d",
            "a8debba1da5447dab24c48f027ed8e33",
            "7727e978e0fa4d3aa116bc4db836d9d4",
            "398a1b16345b4bbe92715cb37fd9750b",
            "40f7a64eb52142528509ecb146e44061",
            "32bd05adc844440fa77ef818b3a69086",
            "eecabbef92a24a7881d8bbb4711b63fd",
            "a80be735e0424f8082b944f53a9820a0",
            "e4e2744f07a5488a9b43eba59e975b3b",
            "33f1b4b1661f438fb7591031355e7224",
            "36350473be284f78b89eb340c31c4a3e",
            "8f42a48f33b442d6b17226f47cec384d",
            "d891806b12934b4eac8eed19073094f0",
            "2012e6abf20246ef89ee4b7697ed785f",
            "e9e1590fb07b49c7ad2454f94d01c8f6",
            "fcdee9a452ad4db2857657e612a18af6",
            "8dee61ab3dfe46e8ad375e9ea2be2d21",
            "38bd37eef8c3473f8d16516b10686d83",
            "63f8554c18824e1bbd5e133bd7dfe275",
            "3096e7e15ebe41eba562ed2531d35b2a",
            "ace7aed23f0b45f8aef5a7012f971cfe",
            "9a2880240bb948b59628627f3bbde9be",
            "0cf8dd32783e4b76876cdd0e950b90a2",
            "bea3a76f06b84e509b09e24fb48e19dc",
            "ada06ba1d0124e4bab5e9202617a14f3",
            "55f0443bc2624f08931439b42b8db02b",
            "ca43127ef6d04617ac1d6aa8f345c002",
            "437c05084ed54d349f3b3b2112e5befd"
          ]
        },
        "id": "PdnyXBOLlwUr",
        "outputId": "4808504e-f771-4afd-d3da-539e1c2b33bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m599.1/599.1 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m108.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m90.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 29 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 696 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.6 [186 kB]\n",
            "Fetched 186 kB in 1s (184 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 126209 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.6_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.6) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.6) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 29 not upgraded.\n",
            "Need to get 4,816 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Fetched 4,816 kB in 2s (2,853 kB/s)\n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 126239 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Collecting python-pptx\n",
            "  Downloading python_pptx-1.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (11.1.0)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx)\n",
            "  Downloading XlsxWriter-3.2.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (5.3.1)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (4.12.2)\n",
            "Downloading python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading XlsxWriter-3.2.2-py3-none-any.whl (165 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.1/165.1 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: XlsxWriter, python-pptx\n",
            "Successfully installed XlsxWriter-3.2.2 python-pptx-1.0.2\n",
            "Collecting gensim==3.8.3\n",
            "  Downloading gensim-3.8.3.tar.gz (23.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.4/23.4 MB\u001b[0m \u001b[31m91.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.11/dist-packages (from gensim==3.8.3) (2.0.2)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.11/dist-packages (from gensim==3.8.3) (1.14.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from gensim==3.8.3) (1.17.0)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim==3.8.3) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart_open>=1.8.1->gensim==3.8.3) (1.17.2)\n",
            "Building wheels for collected packages: gensim\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for gensim (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for gensim\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for gensim\n",
            "Failed to build gensim\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (gensim)\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting keybert\n",
            "  Downloading keybert-0.9.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from keybert) (2.0.2)\n",
            "Requirement already satisfied: rich>=10.4.0 in /usr/local/lib/python3.11/dist-packages (from keybert) (13.9.4)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.11/dist-packages (from keybert) (1.6.1)\n",
            "Requirement already satisfied: sentence-transformers>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from keybert) (3.4.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.4.0->keybert) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.4.0->keybert) (2.18.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.2->keybert) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.2->keybert) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.2->keybert) (3.6.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.3.8->keybert) (4.50.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.3.8->keybert) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.3.8->keybert) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.3.8->keybert) (0.29.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=0.3.8->keybert) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (4.12.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.4.0->keybert) (0.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (0.5.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.3.8->keybert) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (2025.1.31)\n",
            "Downloading keybert-0.9.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.4/41.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: keybert\n",
            "Successfully installed keybert-0.9.0\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Collecting google_images_download\n",
            "  Downloading google_images_download-2.8.0.tar.gz (14 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting selenium (from google_images_download)\n",
            "  Downloading selenium-4.30.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium->google_images_download) (2.3.0)\n",
            "Collecting trio~=0.17 (from selenium->google_images_download)\n",
            "  Downloading trio-0.29.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting trio-websocket~=0.9 (from selenium->google_images_download)\n",
            "  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.11/dist-packages (from selenium->google_images_download) (2025.1.31)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.11/dist-packages (from selenium->google_images_download) (4.12.2)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.11/dist-packages (from selenium->google_images_download) (1.8.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium->google_images_download) (25.3.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium->google_images_download) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium->google_images_download) (3.10)\n",
            "Collecting outcome (from trio~=0.17->selenium->google_images_download)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium->google_images_download) (1.3.1)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium->google_images_download)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium->google_images_download) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium->google_images_download) (0.14.0)\n",
            "Downloading selenium-4.30.0-py3-none-any.whl (9.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio-0.29.0-py3-none-any.whl (492 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m492.9/492.9 kB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
            "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: google_images_download\n",
            "  Building wheel for google_images_download (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google_images_download: filename=google_images_download-2.8.0-py2.py3-none-any.whl size=14537 sha256=2e997d99116dfdbd8d22df2ba180ad319b827a4cf0b1e2d26ddb2e2f6256623b\n",
            "  Stored in directory: /root/.cache/pip/wheels/dc/83/37/7303b15f3e8a5bfbd5c7ebbfe13f0c666ada6f8efecc6d77ec\n",
            "Successfully built google_images_download\n",
            "Installing collected packages: wsproto, outcome, trio, trio-websocket, selenium, google_images_download\n",
            "Successfully installed google_images_download-2.8.0 outcome-1.3.0.post0 selenium-4.30.0 trio-0.29.0 trio-websocket-0.12.2 wsproto-1.2.0\n",
            "Collecting google-search-results\n",
            "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from google-search-results) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (2025.1.31)\n",
            "Building wheels for collected packages: google-search-results\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32009 sha256=51e0027952ccb3966e8a487b8de3a681a4433cf49c49c53d5d1d7a849180a652\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/42/3e/aeb691b02cb7175ec70e2da04b5658d4739d2b41e5f73cd06f\n",
            "Successfully built google-search-results\n",
            "Installing collected packages: google-search-results\n",
            "Successfully installed google-search-results-2.4.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4234c6cd0c6d40568fad29ff687b58c5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eca302a0fee44c499174dea1bce779a9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a2c68a0ed8a0464886b03e98bdd3f459"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1f1b0089f1cd420487cd3b249f36abd0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5e695fa8807f45daaac2b850cdab7b1e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1344373cdfa04b4f9cade3b720b324ad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "13b73b47f8114f158ca1f0fbd3e72338"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8fd174d145df401f80de75c6ad04dd40"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7331459203c84a5da79c6d8d5fbff1ff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eecabbef92a24a7881d8bbb4711b63fd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "38bd37eef8c3473f8d16516b10686d83"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "<ipython-input-1-dbd0b3b5e446>:36: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.20.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.27.2)\n",
            "Downloading groq-0.20.0-py3-none-any.whl (124 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/124.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.9/124.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-0.20.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade langchain openai  -q\n",
        "!pip install sentence_transformers -q\n",
        "!apt-get install poppler-utils\n",
        "!apt-get install -y tesseract-ocr\n",
        "!pip install -U langchain-community -q\n",
        "!pip install pillow\n",
        "!pip install requests\n",
        "!pip install python-pptx\n",
        "!pip install gensim==3.8.3\n",
        "!pip install keybert\n",
        "!pip install requests Pillow\n",
        "!pip install google_images_download\n",
        "!pip install google-search-results\n",
        "from pptx import Presentation\n",
        "from pptx.util import Pt, Inches\n",
        "from PIL import Image\n",
        "import random\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "from io import BytesIO\n",
        "import requests\n",
        "# Download necessary NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Initialize KeyBERT\n",
        "from keybert import KeyBERT\n",
        "kw_model = KeyBERT()\n",
        "\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "from langchain.embeddings import SentenceTransformerEmbeddings\n",
        "embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "!pip install pinecone-client -q\n",
        "!pip install groq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall pinecone-client -y"
      ],
      "metadata": {
        "id": "HhiphItSDaPU",
        "outputId": "d0d4f078-b7c3-4396-d8eb-d8b3e3c68ccc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: pinecone-client 6.0.0\n",
            "Uninstalling pinecone-client-6.0.0:\n",
            "  Successfully uninstalled pinecone-client-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-pinecone\n"
      ],
      "metadata": {
        "id": "20y3YwHdDeOp",
        "outputId": "306acd91-eeac-40b7-f3df-0914fbd9794f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-pinecone\n",
            "  Downloading langchain_pinecone-0.2.3-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.34 in /usr/local/lib/python3.11/dist-packages (from langchain-pinecone) (0.3.47)\n",
            "Collecting pinecone<6.0.0,>=5.4.0 (from langchain-pinecone)\n",
            "  Downloading pinecone-5.4.2-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting aiohttp<3.11,>=3.10 (from langchain-pinecone)\n",
            "  Downloading aiohttp-3.10.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting numpy<2.0.0,>=1.26.4 (from langchain-pinecone)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-tests<1.0.0,>=0.3.7 (from langchain-pinecone)\n",
            "  Downloading langchain_tests-0.3.17-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<3.11,>=3.10->langchain-pinecone) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<3.11,>=3.10->langchain-pinecone) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<3.11,>=3.10->langchain-pinecone) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<3.11,>=3.10->langchain-pinecone) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<3.11,>=3.10->langchain-pinecone) (6.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<3.11,>=3.10->langchain-pinecone) (1.18.3)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (0.3.18)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (4.12.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (2.10.6)\n",
            "Collecting langchain-core<1.0.0,>=0.3.34 (from langchain-pinecone)\n",
            "  Downloading langchain_core-0.3.49-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: pytest<9,>=7 in /usr/local/lib/python3.11/dist-packages (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (8.3.5)\n",
            "Collecting pytest-asyncio<1,>=0.20 (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone)\n",
            "  Downloading pytest_asyncio-0.26.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (0.28.1)\n",
            "Collecting syrupy<5,>=4 (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone)\n",
            "  Downloading syrupy-4.9.1-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting pytest-socket<1,>=0.6.0 (from langchain-tests<1.0.0,>=0.3.7->langchain-pinecone)\n",
            "  Downloading pytest_socket-0.7.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.11/dist-packages (from pinecone<6.0.0,>=5.4.0->langchain-pinecone) (2025.1.31)\n",
            "Collecting pinecone-plugin-inference<4.0.0,>=2.0.0 (from pinecone<6.0.0,>=5.4.0->langchain-pinecone)\n",
            "  Downloading pinecone_plugin_inference-3.1.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from pinecone<6.0.0,>=5.4.0->langchain-pinecone) (0.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from pinecone<6.0.0,>=5.4.0->langchain-pinecone) (2.8.2)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.11/dist-packages (from pinecone<6.0.0,>=5.4.0->langchain-pinecone) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from pinecone<6.0.0,>=5.4.0->langchain-pinecone) (2.3.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (3.10.15)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (2.27.2)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest<9,>=7->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (2.1.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest<9,>=7->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (1.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.5.3->pinecone<6.0.0,>=5.4.0->langchain-pinecone) (1.17.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.12.0->aiohttp<3.11,>=3.10->langchain-pinecone) (0.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.34->langchain-pinecone) (3.4.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.25.0->langchain-tests<1.0.0,>=0.3.7->langchain-pinecone) (1.3.1)\n",
            "Downloading langchain_pinecone-0.2.3-py3-none-any.whl (11 kB)\n",
            "Downloading aiohttp-3.10.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_tests-0.3.17-py3-none-any.whl (39 kB)\n",
            "Downloading langchain_core-0.3.49-py3-none-any.whl (420 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m420.1/420.1 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone-5.4.2-py3-none-any.whl (427 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.3/427.3 kB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pinecone_plugin_inference-3.1.0-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytest_asyncio-0.26.0-py3-none-any.whl (19 kB)\n",
            "Downloading pytest_socket-0.7.0-py3-none-any.whl (6.8 kB)\n",
            "Downloading syrupy-4.9.1-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.2/52.2 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pinecone-plugin-inference, numpy, syrupy, pytest-socket, pytest-asyncio, pinecone, aiohttp, langchain-core, langchain-tests, langchain-pinecone\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: aiohttp\n",
            "    Found existing installation: aiohttp 3.11.14\n",
            "    Uninstalling aiohttp-3.11.14:\n",
            "      Successfully uninstalled aiohttp-3.11.14\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.47\n",
            "    Uninstalling langchain-core-0.3.47:\n",
            "      Successfully uninstalled langchain-core-0.3.47\n",
            "Successfully installed aiohttp-3.10.11 langchain-core-0.3.49 langchain-pinecone-0.2.3 langchain-tests-0.3.17 numpy-1.26.4 pinecone-5.4.2 pinecone-plugin-inference-3.1.0 pytest-asyncio-0.26.0 pytest-socket-0.7.0 syrupy-4.9.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "import time\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "from langchain.embeddings import SentenceTransformerEmbeddings\n",
        "from langchain_pinecone import Pinecone as LangchainPinecone  # Correct import\n",
        "\n",
        "#074e0d9a-ab5e-48bf-8eae-9effae335521\n",
        "# Pinecone API key\n",
        "if not os.getenv(\"PINECONE_API_KEY\"):\n",
        "    os.environ[\"PINECONE_API_KEY\"] = getpass.getpass(\"Enter your Pinecone API key: \")\n",
        "\n",
        "pinecone_api_key = os.environ.get(\"PINECONE_API_KEY\")\n",
        "\n",
        "# Initialize Pinecone\n",
        "pc = Pinecone(api_key=pinecone_api_key)\n",
        "\n",
        "# Define your index name\n",
        "index_name = \"newdata\"  # Change if desired\n",
        "\n",
        "# Check for existing indexes\n",
        "existing_indexes = [index_info.name for index_info in pc.list_indexes()]\n",
        "\n",
        "# Create the index if it does not exist\n",
        "if index_name not in existing_indexes:\n",
        "    pc.create_index(\n",
        "        name=index_name,\n",
        "        dimension=384,  # Adjust this to match your embeddings' dimension\n",
        "        metric=\"cosine\",\n",
        "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
        "    )\n",
        "\n",
        "    # Wait until the index is ready\n",
        "    while not pc.describe_index(index_name).status[\"ready\"]:\n",
        "        print(\"Waiting for the index to be ready...\")\n",
        "        time.sleep(1)\n",
        "\n",
        "# Connect to the index as a Pinecone instance\n",
        "index = pc.Index(index_name)\n",
        "\n",
        "# Print connection success message\n",
        "print(f\"Successfully connected to the index: {index_name}\")\n",
        "\n",
        "# Define embeddings model\n",
        "embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Correct way to create LangChain Pinecone index\n",
        "langchain_index = LangchainPinecone(\n",
        "    index=index,  # Pass the correct Pinecone instance\n",
        "    embedding=embeddings,\n",
        "    text_key=\"text\"  # Required argument for storing/retrieving text\n",
        ")\n",
        "\n",
        "# Output verification\n",
        "print(f\"Successfully created or connected to the LangChain index: {langchain_index}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXOif7Tel1UO",
        "outputId": "f1cb3c72-a038-4ed7-f86b-aad4dd8e316d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your Pinecone API key: ··········\n",
            "Successfully connected to the index: newdata\n",
            "Successfully created or connected to the LangChain index: <langchain_pinecone.vectorstores.Pinecone object at 0x7d248887e850>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-5d1c91d973bc>:48: LangChainDeprecationWarning: The class `Pinecone` was deprecated in LangChain 0.0.3 and will be removed in 1.0.0. Use :class:`~PineconeVectorStore` instead.\n",
            "  langchain_index = LangchainPinecone(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_similar_docs(query, k=20, score=True):\n",
        "    if score:\n",
        "        similar_docs = langchain_index.similarity_search_with_score(query, k=k)  # Use langchain_index\n",
        "    else:\n",
        "        similar_docs = langchain_index.similarity_search(query, k=k)  # Use langchain_index\n",
        "    return similar_docs"
      ],
      "metadata": {
        "id": "uEB5pVkNl1Qw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###############################################  WITH GROQ #############################################################\n",
        "from groq import Groq\n",
        "import os\n",
        "\n",
        "class GroqClient:\n",
        "    def __init__(self, api_key):\n",
        "        self.client = Groq(api_key=api_key)\n",
        "\n",
        "    def get_completion(self, query, max_tokens=2500):\n",
        "        prompt = self._construct_prompt(query)\n",
        "\n",
        "        try:\n",
        "            chat_completion = self.client.chat.completions.create(\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"system\",\n",
        "                        \"content\": \"You are a helpful AI assistant specialized in providing detailed technical explanations.\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": prompt\n",
        "                    }\n",
        "                ],\n",
        "                model=\"deepseek-r1-distill-llama-70b\",\n",
        "                temperature=0.5,\n",
        "                max_tokens=max_tokens,\n",
        "                top_p=0.7,\n",
        "                stream=False\n",
        "            )\n",
        "            return chat_completion.choices[0].message.content\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"API request failed: {str(e)}\")\n",
        "\n",
        "    def _construct_prompt(self, query):\n",
        "        return f'''\n",
        "Question: {query}\n",
        "\n",
        "Provide a comprehensive explanation strictly following this structure. Always use \"##\" to introduce each section:\n",
        "\n",
        "## 1. *Concept Overview*\n",
        "  • Core definition and purpose\n",
        "  • Key principles\n",
        "  • Relationship to broader computing concepts\n",
        "\n",
        "## 2. *Technical Components*\n",
        "  • Primary elements and their roles\n",
        "  • Relationships and interactions\n",
        "  • Implementation details\n",
        "  • Core algorithms/procedures (if applicable)\n",
        "\n",
        "## 3. *Working Mechanism*\n",
        "  • Step-by-step operational flow\n",
        "  • Critical processes and transformations\n",
        "  • Resource management (if applicable)\n",
        "  • Exception handling (if applicable)\n",
        "\n",
        "## 4. *Implementation Example*\n",
        "  • Use case scenario\n",
        "  • Code implementation or technical design\n",
        "  • Step-by-step execution\n",
        "  • Output analysis\n",
        "\n",
        "## 5. *Best Practices*\n",
        "  • Design considerations\n",
        "  • Optimization techniques\n",
        "  • Common pitfalls\n",
        "  • Performance implications\n",
        "\n",
        "## 6. *Applications*\n",
        "  • Real-world use cases\n",
        "  • Industry applications\n",
        "  • Integration patterns\n",
        "  • Variations and alternatives\n",
        "\n",
        "## 7. *Evaluation*\n",
        "  • Performance metrics\n",
        "  • Testing approaches\n",
        "  • Debugging strategies\n",
        "  • Optimization opportunities\n",
        "\n",
        "## 8. *Practice Problems*\n",
        "  • Concept verification questions\n",
        "  • Implementation challenges\n",
        "  • Problem-solving scenarios\n",
        "  • Solutions with explanations\n",
        "\n",
        "### Format Requirements:\n",
        "- Always use \"##\" to introduce each section header. Avoid using any other format.\n",
        "- Use bullet points for clarity\n",
        "- Show all mathematical steps using proper equation formatting ($...$)\n",
        "- Include clear variable definitions after each equation\n",
        "- Write formulas using LaTeX formatting inside $...$\n",
        "- For matrices use: $\\begin{{bmatrix}} a & b \\\\ c & d \\end{{bmatrix}}$\n",
        "- For fractions use: $\\frac{{numerator}}{{denominator}}$\n",
        "- Use ■ for numbered equations and • for regular points\n",
        "- Demonstrate practical interpretation\n",
        "- Connect to real applications\n",
        "\n",
        "### Equation Guidelines:\n",
        "- Enclose equations in $...$ format\n",
        "- Use proper LaTeX notation for mathematical expressions\n",
        "- Use $\\sum$ for summations\n",
        "- Define each variable after presenting equations\n",
        "- Number important equations using ■\n",
        "- Show step-by-step derivations with clear explanations\n",
        "\n",
        "### Code Guidelines:\n",
        "- Use LaTeX verbatim environment for code blocks:\n",
        "  \\begin{{verbatim}}\n",
        "  code here\n",
        "  \\end{{verbatim}}\n",
        "\n",
        "- For inline code use \\texttt{{code}}\n",
        "- For syntax highlighting:\n",
        "  \\begin{{lstlisting}}[language=Python]\n",
        "  code here\n",
        "  \\end{{lstlisting}}\n",
        "- Include comments explaining code functionality\n",
        "- Show output examples where applicable\n",
        "'''\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # api_key = os.environ.get(\"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\")\n",
        "    # client = GroqClient(api_key)\n",
        "\n",
        "    os.environ[\"GROQ_API_KEY\"] = \"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\"\n",
        "    api_key = os.environ.get(\"GROQ_API_KEY\")\n",
        "    client = GroqClient(api_key)\n",
        "    query = \"Bubble sort\"\n",
        "    try:\n",
        "        answer = client.get_completion(query)\n",
        "        print(\"Answer:\", answer)\n",
        "    except Exception as e:\n",
        "        print(\"Error:\", str(e))"
      ],
      "metadata": {
        "id": "YnZ7IrkUd8MH",
        "outputId": "a13bd389-1eb7-4cd8-a92b-5ceff1380451",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: <think>\n",
            "Alright, so I need to explain the concept of bubble sort in a detailed and structured way. Let me start by recalling what bubble sort is. It's a sorting algorithm, right? I remember it's one of the simpler ones, often taught to beginners. The idea is that you repeatedly step through the list, compare adjacent elements, and swap them if they're in the wrong order. This process continues until no swaps are needed, meaning the list is sorted.\n",
            "\n",
            "First, I should outline the concept overview. I'll define bubble sort, its purpose, key principles, and how it relates to other computing concepts. It's important to mention that it's a comparison-based, in-place algorithm with a time complexity of O(n²), which makes it less efficient on large datasets but simple to implement.\n",
            "\n",
            "Next, the technical components. I need to break down the primary elements: the array to be sorted, the swapping mechanism, and the control structures like loops. I should explain how nested loops work here—one for each pass through the array and another for comparing elements. Also, I'll include the algorithm in pseudocode to make it clear.\n",
            "\n",
            "Moving on to the working mechanism, I'll describe the step-by-step process. Starting with the first element, compare it with the next, swap if necessary, and move to the next pair. Each pass pushes the largest unsorted element to its correct position. I should emphasize that each pass reduces the portion of the array that needs sorting.\n",
            "\n",
            "For the implementation example, I'll choose a simple array and walk through how bubble sort would sort it. Maybe an array like [64, 34, 25, 12, 22, 11, 90]. I'll show each pass, highlighting the swaps and the state of the array after each pass. This will help illustrate how the algorithm works practically.\n",
            "\n",
            "Best practices are next. I should mention that while bubble sort is simple, it's not efficient for large data. I'll talk about optimizations, like halting early if a pass completes without swaps, and using a variable to track the last swap position to reduce iterations. Also, I'll note that it's stable and works well for nearly sorted or small datasets.\n",
            "\n",
            "Applications would cover where bubble sort is actually used. It's not for large-scale sorting, but it's good for educational purposes, embedded systems with limited resources, or when simplicity is more important than speed. I can also mention that variations like cocktail shaker sort exist for bidirectional sorting.\n",
            "\n",
            "In the evaluation section, I'll discuss performance metrics like time and space complexity. Testing approaches might include comparing it against other algorithms. Debugging strategies could involve checking loop conditions and swap logic. Optimization opportunities would include the early termination and reducing the range of the inner loop.\n",
            "\n",
            "Finally, practice problems. I'll suggest verifying the concept by implementing bubble sort, then optimizing it. Problem-solving scenarios might involve modifying the algorithm for specific data types or constraints. Providing solutions with explanations will help reinforce understanding.\n",
            "\n",
            "I need to make sure each section is clear and follows the structure with \"##\" headers and bullet points. Including equations where necessary, like for time complexity, and using LaTeX for code blocks will make the explanation comprehensive and easy to follow. I'll also ensure that each part connects to real applications and provides practical insights, avoiding overly technical jargon where possible.\n",
            "\n",
            "Overall, the goal is to provide a thorough explanation that's accessible to someone learning about sorting algorithms for the first time, while also offering depth for those looking to understand optimization and application contexts.\n",
            "</think>\n",
            "\n",
            "## 1. *Concept Overview*\n",
            "  • **Core definition and purpose**: Bubble sort is a simple sorting algorithm that repeatedly steps through the list, compares adjacent elements, and swaps them if they are in the wrong order. Its primary purpose is to sort data in ascending or descending order.\n",
            "  • **Key principles**: It is a comparison-based, in-place sorting algorithm. The algorithm works by repeatedly swapping the adjacent elements if they are in the wrong order.\n",
            "  • **Relationship to broader computing concepts**: Bubble sort is one of the simplest sorting algorithms, often used for educational purposes. It is less efficient on large data sets compared to algorithms like quicksort or mergesort but is simple to implement.\n",
            "\n",
            "## 2. *Technical Components*\n",
            "  • **Primary elements and their roles**:\n",
            "    - **Array/List**: The data structure to be sorted.\n",
            "    - **Swap Mechanism**: Temporarily holds a value during the swap operation.\n",
            "    - **Control Structures**: Uses nested loops to control the sorting process.\n",
            "  • **Relationships and interactions**: The outer loop runs for each element, while the inner loop compares adjacent elements and swaps them if necessary.\n",
            "  • **Implementation details**: The algorithm consists of nested loops. The outer loop runs from the start to the end of the array, while the inner loop runs from the start to the unsorted portion of the array.\n",
            "  • **Core algorithms/procedures**:\n",
            "    ```\n",
            "    procedure bubbleSort(A)\n",
            "      n = length(A)\n",
            "      for i from 0 to n-1\n",
            "        swapped = false\n",
            "        for j from 0 to n-i-1\n",
            "          if A[j] > A[j+1]\n",
            "            swap(A[j], A[j+1])\n",
            "            swapped = true\n",
            "        end if\n",
            "        if not swapped\n",
            "          break\n",
            "        end if\n",
            "      end for\n",
            "    end procedure\n",
            "    ```\n",
            "\n",
            "## 3. *Working Mechanism*\n",
            "  • **Step-by-step operational flow**:\n",
            "    1. **Initialization**: Start with the entire array as unsorted.\n",
            "    2. **First Pass**: Compare the first and second elements. If they are in the wrong order, swap them. Move to the next pair and repeat until the end of the array. The largest element \"bubbles\" up to its correct position.\n",
            "    3. **Subsequent Passes**: Repeat the process, but after each pass, the portion of the array that is already sorted increases. If no swaps occur during a pass, the array is sorted, and the algorithm terminates early.\n",
            "  • **Critical processes and transformations**: Each pass ensures that the next largest element is moved to its correct position.\n",
            "  • **Resource management**: Bubble sort is an in-place sorting algorithm, requiring only a small amount of extra memory for the swap variable.\n",
            "  • **Exception handling**: The algorithm does not require explicit exception handling as it works on any array of comparable elements.\n",
            "\n",
            "## 4. *Implementation Example*\n",
            "  • **Use case scenario**: Suppose we have an array `[64, 34, 25, 12, 22, 11, 90]` that we want to sort in ascending order.\n",
            "  • **Code implementation**:\n",
            "    ```python\n",
            "    def bubble_sort(arr):\n",
            "        n = len(arr)\n",
            "        for i in range(n):\n",
            "            swapped = False\n",
            "            for j in range(0, n-i-1):\n",
            "                if arr[j] > arr[j+1]:\n",
            "                    arr[j], arr[j+1] = arr[j+1], arr[j]\n",
            "                    swapped = True\n",
            "            if not swapped:\n",
            "                break\n",
            "        return arr\n",
            "    ```\n",
            "  • **Step-by-step execution**:\n",
            "    1. **Pass 1**: Compare and swap elements until the largest element (90) moves to the end.\n",
            "    2. **Pass 2**: The second largest element (64) moves to its position.\n",
            "    3. **Pass 3**: Continue until the array is sorted.\n",
            "  • **Output analysis**: The sorted array is `[11, 12, 22, 25, 34, 64, 90]`.\n",
            "\n",
            "## 5. *Best Practices*\n",
            "  • **Design considerations**:\n",
            "    - Use bubble sort for small datasets or educational purposes.\n",
            "    - Avoid using bubble sort for large datasets due to its O(n²) time complexity.\n",
            "  • **Optimization techniques**:\n",
            "    - **Early Termination**: If a pass completes without any swaps, the array is already sorted, and the algorithm can terminate early.\n",
            "    - **Reducing Comparisons**: After each pass, the largest element is in its correct position, so the inner loop can avoid checking the last `i` elements.\n",
            "  • **Common pitfalls**:\n",
            "    - Implementing the inner loop incorrectly, leading to out-of-bounds errors.\n",
            "    - Forgetting to break early if no swaps occur, leading to unnecessary iterations.\n",
            "  • **Performance implications**: Bubble sort has a worst-case and average time complexity of O(n²), making it inefficient for large datasets.\n",
            "\n",
            "## 6. *Applications*\n",
            "  • **Real-world use cases**:\n",
            "    - Sorting small datasets where simplicity is more important than speed.\n",
            "    - Educational purposes to introduce sorting algorithms.\n",
            "    - Embedded systems with limited resources.\n",
            "  • **Industry applications**:\n",
            "    - Simple sorting tasks in embedded systems.\n",
            "    - Legacy code where bubble sort is already implemented and works adequately for the given constraints.\n",
            "  • **Integration patterns**:\n",
            "    - Often used as a teaching tool before introducing more complex sorting algorithms.\n",
            "    - Can be used as a subroutine in more complex sorting algorithms.\n",
            "  • **Variations and alternatives**:\n",
            "    - **Cocktail Shaker Sort**: A bidirectional version of bubble sort that sorts in both directions each pass.\n",
            "    - **Odd-Even Sort**: A parallel version of bubble sort.\n",
            "\n",
            "## 7. *Evaluation*\n",
            "  • **Performance metrics**:\n",
            "    - **Time Complexity**: O(n²) in the worst and average cases, O(n) in the best case (when the array is already sorted).\n",
            "    - **Space Complexity**: O(1) since it is an in-place sorting algorithm.\n",
            "  • **Testing approaches**:\n",
            "    - Test with arrays of different sizes.\n",
            "    - Test with already sorted and reverse-sorted arrays to check for early termination.\n",
            "    - Test with arrays containing duplicate elements.\n",
            "  • **Debugging strategies**:\n",
            "    - Check the loop conditions to ensure they cover the entire array.\n",
            "    - Verify that the swap operation is correctly implemented.\n",
            "    - Use print statements or a debugger to track the state of the array during each pass.\n",
            "  • **Optimization opportunities**:\n",
            "    - Implement early termination if no swaps occur during a pass.\n",
            "    - Reduce the range of the inner loop after each pass.\n",
            "\n",
            "## 8. *Practice Problems*\n",
            "  • **Concept verification questions**:\n",
            "    - What is the time complexity of bubble sort in the worst case?\n",
            "    - How does bubble sort handle duplicate elements?\n",
            "    - What is the space complexity of bubble sort?\n",
            "  • **Implementation challenges**:\n",
            "    - Implement bubble sort for a linked list.\n",
            "    - Implement a bidirectional version of bubble sort (cocktail shaker sort).\n",
            "    - Implement bubble sort with early termination.\n",
            "  • **Problem-solving scenarios**:\n",
            "    - Sort a list of strings using bubble sort.\n",
            "    - Sort a list of integers in descending order using bubble sort.\n",
            "  • **Solutions with explanations**:\n",
            "    - **Time Complexity**: The worst-case time complexity is O(n²). This is because in the worst case, the algorithm has to compare and swap every pair of elements.\n",
            "    - **Duplicate Elements**: Bubble sort handles duplicate elements naturally. If two adjacent elements are equal, they are not swapped, and the algorithm continues.\n",
            "    - **Space Complexity**: The space complexity is O(1) because bubble sort is an in-place sorting algorithm.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "syHExGdpU5dj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# **\n",
        "import os\n",
        "import requests\n",
        "\n",
        "# Set the Hugging Face API key directly inside the script\n",
        "HUGGINGFACE_API_TOKEN = \"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\"  # Replace with your actual API key\n",
        "\n",
        "# Define the model name\n",
        "model_name = \"mistralai/Mistral-7B-Instruct-v0.3\"  # Replace with your chosen model\n",
        "\n",
        "# Construct the API URL\n",
        "HUGGINGFACE_API_URL = f\"https://api-inference.huggingface.co/models/{model_name}\"\n",
        "\n",
        "# Set up the headers with the authorization token\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {HUGGINGFACE_API_TOKEN}\"\n",
        "}\n",
        "\n",
        "# Example query\n",
        "query = \"LSTM\"\n",
        "\n",
        "# Assuming you have a function `get_similar_docs` defined\n",
        "similar_docs = get_similar_docs(query)\n",
        "\n",
        "# Prepare the context from similar_docs\n",
        "context = \"\\n\\n\".join([doc[0].page_content for doc in similar_docs])\n",
        "\n",
        "prompt = f'''\n",
        "Context: {context}\n",
        "Question: {query}\n",
        "\n",
        "Provide a comprehensive explanation strictly following this structure. Always use \"##\" to introduce each section:\n",
        "\n",
        "## 1. *Concept Overview*\n",
        "  • Core definition and purpose\n",
        "  • Key principles\n",
        "  • Relationship to broader computing concepts\n",
        "\n",
        "## 2. *Technical Components*\n",
        "  • Primary elements and their roles\n",
        "  • Relationships and interactions\n",
        "  • Implementation details\n",
        "  • Core algorithms/procedures (if applicable)\n",
        "\n",
        "## 3. *Working Mechanism*\n",
        "  • Step-by-step operational flow\n",
        "  • Critical processes and transformations\n",
        "  • Resource management (if applicable)\n",
        "  • Exception handling (if applicable)\n",
        "\n",
        "## 4. *Implementation Example*\n",
        "  • Use case scenario\n",
        "  • Code implementation or technical design\n",
        "  • Step-by-step execution\n",
        "  • Output analysis\n",
        "\n",
        "## 5. *Best Practices*\n",
        "  • Design considerations\n",
        "  • Optimization techniques\n",
        "  • Common pitfalls\n",
        "  • Performance implications\n",
        "\n",
        "## 6. *Applications*\n",
        "  • Real-world use cases\n",
        "  • Industry applications\n",
        "  • Integration patterns\n",
        "  • Variations and alternatives\n",
        "\n",
        "## 7. *Evaluation*\n",
        "  • Performance metrics\n",
        "  • Testing approaches\n",
        "  • Debugging strategies\n",
        "  • Optimization opportunities\n",
        "\n",
        "## 8. *Practice Problems*\n",
        "  • Concept verification questions\n",
        "  • Implementation challenges\n",
        "  • Problem-solving scenarios\n",
        "  • Solutions with explanations\n",
        "\n",
        "### Format Requirements:\n",
        "- Always use \"##\" to introduce each section header. Avoid using any other format.\n",
        "- Use bullet points for clarity\n",
        "- Show all mathematical steps using proper equation formatting ($...$)\n",
        "- Include clear variable definitions after each equation\n",
        "- Write formulas using LaTeX formatting inside $...$\n",
        "- For matrices use: $\\begin{{bmatrix}} a & b \\\\ c & d \\end{{bmatrix}}$\n",
        "- For fractions use: $\\frac{{numerator}}{{denominator}}$\n",
        "- Use ■ for numbered equations and • for regular points\n",
        "- Demonstrate practical interpretation\n",
        "- Connect to real applications\n",
        "\n",
        "### Equation Guidelines:\n",
        "- Enclose equations in $...$ format\n",
        "- Use proper LaTeX notation for mathematical expressions\n",
        "- Use $\\sum$ for summations\n",
        "- Define each variable after presenting equations\n",
        "- Number important equations using ■\n",
        "- Show step-by-step derivations with clear explanations\n",
        "\n",
        "### Code Guidelines:\n",
        "- Use LaTeX verbatim environment for code blocks:\n",
        "  \\begin{{verbatim}}\n",
        "  code here\n",
        "  \\end{{verbatim}}\n",
        "\n",
        "- For inline code use \\texttt{{code}}\n",
        "- For syntax highlighting:\n",
        "  \\begin{{lstlisting}}[language=Python]\n",
        "  code here\n",
        "  \\end{{lstlisting}}\n",
        "- Include comments explaining code functionality\n",
        "- Show output examples where applicable\n",
        "'''\n",
        "\n",
        "\n",
        "# Function to query Hugging Face Inference API\n",
        "def query_huggingface_api(prompt, max_length=25000):\n",
        "    payload = {\n",
        "        \"inputs\": prompt,\n",
        "        \"parameters\": {\n",
        "            \"max_new_tokens\": max_length,\n",
        "            \"temperature\": 0.5,\n",
        "            \"top_p\": 0.7,\n",
        "            \"top_k\": 50,\n",
        "            \"repetition_penalty\": 1.1,\n",
        "            \"do_sample\": True,\n",
        "            \"stop\": [\"<|endoftext|>\"]\n",
        "        }\n",
        "     }\n",
        "\n",
        "    response = requests.post(\n",
        "        HUGGINGFACE_API_URL,\n",
        "        headers=headers,\n",
        "        json=payload\n",
        "    )\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        #print(response.json())\n",
        "        return response.json()\n",
        "    else:\n",
        "        raise Exception(\n",
        "            f\"Request failed with status code {response.status_code}: {response.text}\"\n",
        "        )\n",
        "\n",
        "# Function to extract answer from API response\n",
        "def extract_answer(api_response):\n",
        "    if isinstance(api_response, list) and len(api_response) > 0:\n",
        "        generated_text = api_response[0].get('generated_text', '')\n",
        "\n",
        "        answer = generated_text.split(\"Answer:\")[-1].strip() if \"Answer:\" in generated_text else generated_text.strip()\n",
        "        if len(answer) > 30000:\n",
        "            answer = answer[:30000] + \"...\"\n",
        "        return answer\n",
        "    else:\n",
        "        return \"No answer generated.\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Generate the answer using Hugging Face Inference API\n",
        "try:\n",
        "    api_response = query_huggingface_api(prompt, max_length=25000)\n",
        "    answer = extract_answer(api_response)\n",
        "    print(\"Answer:\", answer)\n",
        "except Exception as e:\n",
        "    print(\"Error:\", str(e))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bC1pi0QOl1OH",
        "outputId": "5b789d1a-270b-4d1d-c76d-e05f066d7965"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: Context: BIBLIOGRAPHY  Graves, . . Sequence transduction  recurrent neural networks.   . Graves, .  . Jaitly . Towards  speech recognition  recurrent neural networks.   , . . Graves, .  . Schmidhuber . Framewise phoneme classiﬁcation  bidirec tional   other neural network architectures. Neural Networks  , .\n",
            "\n",
            "  vector hmthis information  represented.   limitation   informa   attenuated  repeated application   squashing function . short memories LSTMs, described below,   variant    address  issue,   memory cells  propagate information through  sequence without applying  linearities Hochreiter  Schmidhuber, .  denominator  Equation .   computational bottleneck, because  involves\n",
            "\n",
            "Recurrent neural networks   introduced     language model  technique,  which  context  token  summarized   recurrentlyupdated vector, ,,   ,,..., wherexmis  vector embedding   token wmand  function gdeﬁnes  recur rence.  starting condition   additional parameter   model.   short  memory     complex recurrence,  which  memory   through \n",
            "\n",
            " . LANGUAGE MODELS              Figure .   short memory  architecture. Gates  shown  boxes  dotted edges.    language model,  hmwould    predict   wordwm.  gates  functions   input  previous hidden state.   computed  elementwise sigmoid activations,   , ensuring  their values\n",
            "\n",
            "BIBLIOGRAPHY  , .  . Bansal .  relation extraction using lstms  sequences   structures.   , . . , .  . Hinton . Three  graphical models  statistical language  elling.  Proceedings   International Conference  Machine Learning  , .  . , .  . . Hinton .  scalable hierarchical distributed language model.  Neural Information Processing Systems  , . .\n",
            "\n",
            "sentations  vector space.  Proceedings  International Conference  Learning Represen tations . Mikolov, ., . Deoras, . Povey, . Burget,  . Cernocky . Strategies  training large scale neural network language models.  Proceedings   Workshop  Automatic Speech Recognition  Understanding  , . . Mikolov, ., . Karaﬁ , . Burget, . Cernock ,  . Khudanpur . Recurrent neural network based language model.  INTERSPEECH , . .\n",
            "\n",
            ".. Convolutional Neural Networks  Sequence Labeling  disadvantage  recurrent neural networks    architecture requires iterating through  sequence  inputs  predictions  hidden vector hmmust   puted   previous hidden vector , before predicting   . These iterative computations  difﬁcult  parallelize,    exploit  speedups offered  graph  processing units   operations   matrix multiplication. Convolutional\n",
            "\n",
            " baseline   implemented   neural architecture, using  attention  anism .., which scores  similarity   query      source    ., .      encode  passage   query , using  bidirectional LSTMs  .. BiLSTM   . BiLSTM  . .  query  represented  vertically concatenating   states   right  right passes \n",
            "\n",
            ".. RECURRENT NEURAL NETWORK LANGUAGE MODELS  derivatives automatically,  cache   future .  important distinction   feedforward neural networks considered         computa  graph   ,  varies   length   input.  poses difﬁculties  toolkits   designed around static computation graphs,   TensorFlow Abadi  ., . .. Hyperparameters\n",
            "\n",
            " incorporating  inner product   approximation   likelihood    ,   possible  estimate  parameters  backpropagation.   Mikolov  .,  includes   approximations continuous words   skipgrams. .. Continuous words   recurrent neural network language models,    conditioned   recurrently updated state vector, which  based   representations going      \n",
            "\n",
            ".. RECURRENT NEURAL NETWORK LANGUAGE MODELS    sequence.  language models  deﬁned,  .  , . ,,...,  , . whereφis  matrix   embeddings , andxmdenotes  embedding   .  conversion  wmtoxmis sometimes known   lookup layer , because  simply lookup  embeddings      table  ...  Elman  deﬁnes  simple recurrent operation Elman, ,\n",
            "\n",
            "whereδ   indicator function, taking  value      record   identical   target  .  probability  copying record rfrom  source ,  product    probability   local attention.     model,  attention weights αmare computed   previous decoder state .  computation graph therefore remains  feedforward network,  recurrent paths      .\n",
            "\n",
            " operator  elementwise Hadamard product.    controlled      weights, which parametrize  previous hidden state ..,    current input .., ,   vector offset .., .  overall operation   infor mally summarized  ,   ,,,  ,representing   state after reading token .   outperforms standard recurrent neural networks across   range \n",
            "\n",
            " . APPLICATIONS  SEQUENCE LABELING   predict labels      ONSTART   character.  recent   employed neural network architectures.  example,   .      architecture,  described  .  construct  trellis,  which    scored according   hidden state   ,   transitions  scored according  learned transition weights.  scoring segmentation   computed  \n",
            "\n",
            "beginning   source   greatest impact   encoding ,  therefore impact  words   beginning   target sentence. Later     vanced encoding models,   neural attention ..,  eliminated    reversing  source sentence.  encoder  decoder   implemented   LSTMs ,  multiple layers  hidden states.  shown  Figure .,  hidden state ,  layeriis treated\n",
            "\n",
            "epochs batches   sentences, chosen   similar length    sentence   batch   roughly   amount    process gradi  clipping ..  ensure      gradient never exceeds  predeﬁned value. .. Neural attention  sequencesequence model discussed   previous section   radical depar   statistical machine translation,  which    phrase   target \n",
            "\n",
            "brenner  Blunsom     . ,  strong empirical results.  models  recurrent   utterance level,    complete utterance updates  hidden state.  recurrentconvolutional network  Kalchbrenner  Blunsom   convolu   obtain  representation   individual utterance, while   .    second level  recurrence,  individual words.  enables their method   \n",
            "\n",
            ".. NEURAL SEQUENCE LABELING   practice, numerical stability demands       domain, logαm    logsm,  logαm . logβm    logsm,  logβm . .  application   forward  backward probabilities  shown  Figure ..   forward  backward recurrences operate   trellis, which implies  space complexityO. Because  recurrences require computing    Kterms \n",
            "\n",
            "tentional encoderdecoder translation model discussed  ..   ., .  longer sentence  encoded   sequence  vectors,    token.  decoder  computes attention  these vectors  updating   recurrent state.    generation,    useful  augment  encoderdecoder model   ability   words directly   source.   .  train  model \n",
            "\n",
            " Morphology  Syntax , Volume   Synthesis Lectures  Human Language Technolo . Morgan  Claypool Publishers. Bengio, ., . Vinyals, . Jaitly,  . Shazeer . Scheduled sampling  sequence prediction  recurrent neural networks.   , . . Bengio, ., . Ducharme,  . Vincent,  . Janvin .  neural probabilistic language model.  Journal  Machine Learning Research  , .\n",
            "Question: LSTM\n",
            "\n",
            "Provide a comprehensive explanation strictly following this structure. Always use \"##\" to introduce each section:\n",
            "\n",
            "## 1. *Concept Overview*\n",
            "  • Core definition and purpose\n",
            "  • Key principles\n",
            "  • Relationship to broader computing concepts\n",
            "\n",
            "## 2. *Technical Components*\n",
            "  • Primary elements and their roles\n",
            "  • Relationships and interactions\n",
            "  • Implementation details\n",
            "  • Core algorithms/procedures (if applicable)\n",
            "\n",
            "## 3. *Working Mechanism*\n",
            "  • Step-by-step operational flow\n",
            "  • Critical processes and transformations\n",
            "  • Resource management (if applicable)\n",
            "  • Exception handling (if applicable)\n",
            "\n",
            "## 4. *Implementation Example*\n",
            "  • Use case scenario\n",
            "  • Code implementation or technical design\n",
            "  • Step-by-step execution\n",
            "  • Output analysis\n",
            "\n",
            "## 5. *Best Practices*\n",
            "  • Design considerations\n",
            "  • Optimization techniques\n",
            "  • Common pitfalls\n",
            "  • Performance implications\n",
            "\n",
            "## 6. *Applications*\n",
            "  • Real-world use cases\n",
            "  • Industry applications\n",
            "  • Integration patterns\n",
            "  • Variations and alternatives\n",
            "\n",
            "## 7. *Evaluation*\n",
            "  • Performance metrics\n",
            "  • Testing approaches\n",
            "  • Debugging strategies\n",
            "  • Optimization opportunities\n",
            "\n",
            "## 8. *Practice Problems*\n",
            "  • Concept verification questions\n",
            "  • Implementation challenges\n",
            "  • Problem-solving scenarios\n",
            "  • Solutions with explanations\n",
            "\n",
            "### Format Requirements:\n",
            "- Always use \"##\" to introduce each section header. Avoid using any other format.\n",
            "- Use bullet points for clarity\n",
            "- Show all mathematical steps using proper equation formatting ($...$)\n",
            "- Include clear variable definitions after each equation\n",
            "- Write formulas using LaTeX formatting inside $...$\n",
            "- For matrices use: $\begin{bmatrix} a & b \\ c & d \\end{bmatrix}$\n",
            "- For fractions use: $\frac{numerator}{denominator}$\n",
            "- Use ■ for numbered equations and • for regular points\n",
            "- Demonstrate practical interpretation\n",
            "- Connect to real applications\n",
            "\n",
            "### Equation Guidelines:\n",
            "- Enclose equations in $...$ format\n",
            "- Use proper LaTeX notation for mathematical expressions\n",
            "- Use $\\sum$ for summations\n",
            "- Define each variable after presenting equations\n",
            "- Number important equations using ■\n",
            "- Show step-by-step derivations with clear explanations\n",
            "\n",
            "### Code Guidelines:\n",
            "- Use LaTeX verbatim environment for code blocks:\n",
            "  \begin{verbatim}\n",
            "  code here\n",
            "  \\end{verbatim}\n",
            "\n",
            "- For inline code use \texttt{code}\n",
            "- For syntax highlighting:\n",
            "  \begin{lstlisting}[language=Python]\n",
            "  code here\n",
            "  \\end{lstlisting}\n",
            "- Include comments explaining code functionality\n",
            "- Show output examples where applicable\n",
            "\n",
            "## 1. *Concept Overview*\n",
            "**Core definition and purpose:** Long Short-Term Memory (LSTM) is a type of recurrent neural network (RNN) that addresses the vanishing gradient problem by introducing a memory cell and three types of gates: input gate, forget gate, and output gate. The primary goal of LSTM is to maintain relevant information over long periods during sequential data processing.\n",
            "\n",
            "**Key principles:** LSTM uses a memory cell to store information, allowing it to retain crucial data throughout the entire sequence. The gates control the flow of information into and out of the memory cell, enabling LSTM to selectively focus on relevant information while ignoring irrelevant data. This mechanism allows LSTM to handle long-term dependencies effectively.\n",
            "\n",
            "**Relationship to broader computing concepts:** LSTM belongs to the family of artificial neural networks (ANNs), which are inspired by biological neurons and their interconnections. It extends traditional RNNs by incorporating memory mechanisms, making it more suitable for tasks involving long-term dependencies such as language modeling, speech recognition, and machine translation.\n",
            "\n",
            "## 2. *Technical Components*\n",
            "**Primary elements and their roles:**\n",
            "\n",
            "- **Memory Cell**: A central component that stores information over time.\n",
            "- **Input Gate**: Controls the flow of new information into the memory cell.\n",
            "- **Forget Gate**: Determines what information should be forgotten from the memory cell.\n",
            "- **Output Gate**: Decides what information should be released from the memory cell.\n",
            "- **Cell State**: Represents the current state of the memory cell.\n",
            "- **Hidden State**: Represents the internal state of the LSTM at a specific time step.\n",
            "\n",
            "**Relationships and interactions:** The interaction between these components determines how information flows through the LSTM. At each time step, the input gate decides whether to update the cell state, the forget gate determines what part of the existing cell state to keep, and the output gate decides what part of the updated cell state to release as the hidden state.\n",
            "\n",
            "**Implementation details:** LSTM is typically implemented using a sigmoid activation function for the gates and a hyperbolic tangent (tanh) activation function for the cell state. The cell state is updated by adding the new candidate cell state, which is a weighted combination of the input, the old cell state, and the forget gate's output.\n",
            "\n",
            "**Core algorithms/procedures:** The LSTM algorithm consists of four main steps:\n",
            "\n",
            "1. Input Gate: Calculate the input gate's activation using the input, hidden state, and previous cell state.\n",
            "2. Forget Gate: Calculate the forget gate's activation using the input, hidden state, and previous cell state.\n",
            "3. New Candidate Cell State: Calculate the new candidate cell state using the input, forget gate's output, and tanh activation of the new candidate cell state.\n",
            "4. Output Gate: Calculate the output gate's activation using the new candidate cell state, hidden state, and previous cell state.\n",
            "\n",
            "## 3. *Working Mechanism*\n",
            "**Step-by-step operational flow:**\n",
            "\n",
            "1. At each time step, the LSTM receives an input vector xm.\n",
            "2. The input gate calculates its activation i\\_tmusing the input vector, hidden state h\\_(t-1), and previous cell state c\\_(t-1).\n",
            "3. The forget gate calculates its activation f\\_tmusing the same inputs as the input gate.\n",
            "4. The new candidate cell state c\\_tmis calculated using the input vector, forget gate's output ft, and tanh activation of the new candidate cell state.\n",
            "5. The output gate calculates its activation o\\_tmusing the new candidate cell state, hidden state h\\_(t-1), and previous cell state c\\_(t-1).\n",
            "6. The cell state c\\_(t) is updated by multiplying the input gate's output it, forget gate's output ft, and the output gate's output ot, then adding the new candidate cell state c\\_tm.\n",
            "7. The hidden state h\\_(t) is calculated by multiplying the output gate's output ot with the tanh activation of the cell state c\\_(t).\n",
            "\n",
            "**Critical processes and transformations:** The LSTM's critical processes involve controlling the flow of information into and out of the memory cell via the input, forget, and output gates. The memory cell stores the relevant information, while the hidden state represents the internal state of the LSTM at a specific time step.\n",
            "\n",
            "**Resource management (if applicable):** LSTM does not have explicit resource management since it primarily focuses on processing sequential data. However, it requires memory resources to store the cell state and hidden state at each time step.\n",
            "\n",
            "**Exception handling (if applicable):** LSTM does not inherently handle exceptions like traditional programming languages. However, when implementing LSTM in software, common exception handling practices should be followed to manage errors and unexpected situations.\n",
            "\n",
            "## 4. *Implementation Example*\n",
            "**Use case scenario:** An example implementation of LSTM could be training a language model to predict the next word in a sentence given the preceding words.\n",
            "\n",
            "**Code implementation or technical design:** Here's a simplified Python implementation of an LSTM cell using the Keras library:\n",
            "\n",
            "```python\n",
            "from keras.layers import Input, LSTM, Dense\n",
            "\n",
            "inputs = Input(shape=(timesteps, num_features))\n",
            "lstm_layer = LSTM(num_units)\n",
            "hidden_state = lstm_layer(inputs)\n",
            "output = Dense(num_classes)(hidden_state)\n",
            "model = Model(inputs=inputs, outputs=output)\n",
            "```\n",
            "\n",
            "**Step-by-step execution:**\n",
            "\n",
            "1. Define the input shape and create an input layer.\n",
            "2. Create an LSTM layer with the desired number of units.\n",
            "3. Pass the input through the LSTM layer to get the hidden state.\n",
            "4. Create a dense layer with the desired number of output classes.\n",
            "5. Combine the input and output layers to create a model.\n",
            "\n",
            "**Output analysis:** After training the model, you can use it to make predictions on unseen data. For example, given the input sequence [word1, word2, word3], the model will output the predicted next word.\n",
            "\n",
            "## 5. *Best Practices*\n",
            "**Design considerations:** When designing an LSTM model, consider the following best practices:\n",
            "\n",
            "- Choose appropriate hyperparameters such as the number of LSTM units, learning rate, and dropout rate.\n",
            "- Experiment with different architectures, including stacking multiple LSTM layers or combining LSTM with other neural network architectures.\n",
            "- Regularize the model to prevent overfitting.\n",
            "\n",
            "**Optimization techniques:** To optimize LSTM performance, consider the following techniques:\n",
            "\n",
            "- Use efficient optimization algorithms such as Adam or RMSProp.\n",
            "- Apply batch normalization to improve stability and convergence.\n",
            "- Utilize gradient clipping to prevent exploding or vanishing gradients.\n",
            "\n",
            "**Common pitfalls:** Be aware of the following potential issues when working with LSTM:\n",
            "\n",
            "- Vanishing or exploding gradients due to long sequences or poorly chosen hyperparameters.\n",
            "- Overfitting due to insufficient regularization or lack of generalization.\n",
            "- Difficulty in parallelizing computations due to the recursive nature of LSTM.\n",
            "\n",
            "**Performance implications:** The performance of LSTM depends on several factors, including the size of the dataset, the complexity of the task, and the choice of hyperparameters. Training LSTM models can be computationally expensive, so it's essential to choose appropriate hardware and software configurations.\n",
            "\n",
            "## 6. *Applications*\n",
            "**Real-world use cases:** LSTM has been successfully applied in various domains, including:\n",
            "\n",
            "- Natural Language Processing (NLP): Text classification, sentiment analysis, machine translation, and language modeling.\n",
            "- Speech Recognition: Transcription of spoken language into written text.\n",
            "- Time Series Analysis: Predicting future trends based on historical data.\n",
            "\n",
            "**Industry applications:** LSTM is widely used in industries such as:\n",
            "\n",
            "- Artificial Intelligence (AI) and Machine Learning (ML) companies for developing intelligent systems.\n",
            "- Tech giants like Google, Microsoft, and Amazon for improving search engines, virtual assistants, and translation services.\n",
            "- Financial institutions for forecasting stock prices and market trends.\n",
            "\n",
            "**Integration patterns:** LSTM can be integrated into larger deep learning architectures, such as convolutional neural networks (CNNs) and transformers, to further enhance their capabilities.\n",
            "\n",
            "**Variations and alternatives:** There are several variations and alternatives to LSTM, including GRUs (Gated Recurrent Units), Echo State Networks, and Simple Recurrent Units (SRUs). Each has its unique strengths and weaknesses, and choosing the right one depends on the specific requirements of the task at hand.\n",
            "\n",
            "## 7. *Evaluation*\n",
            "**Performance metrics:** To evaluate LSTM performance, commonly used metrics include accuracy, loss, precision, recall, F1 score, and perplexity. The choice of metric depends on the specific task and the nature of the data.\n",
            "\n",
            "**Testing approaches:** Cross-validation, holdout sets, and bootstrap methods are popular testing approaches for evaluating LSTM performance.\n",
            "\n",
            "**Debugging strategies:** Debugging LSTM models can be challenging due to their complex nature. Strategies include visualizing the data, analyzing the gradients, and monitoring the loss and accuracy during training.\n",
            "\n",
            "**Optimization opportunities:** To optimize LSTM performance, consider techniques such as early stopping, learning rate scheduling, and data augmentation.\n",
            "\n",
            "## 8. *Practice Problems*\n",
            "**Concept verification questions:**\n",
            "\n",
            "1. What is the role of the memory cell in LSTM?\n",
            "2. Explain the difference between the input gate, forget gate, and output gate in LSTM.\n",
            "3. How does LSTM handle long-term dependencies compared to traditional RNNs?\n",
            "\n",
            "**Implementation challenges:**\n",
            "\n",
            "1. Implement an LSTM cell from scratch using PyTorch.\n",
            "2. Train an LSTM model to perform sentiment analysis on movie reviews.\n",
            "\n",
            "**Problem-solving scenarios:**\n",
            "\n",
            "1. You are given a sequence of numbers representing stock prices. Develop an LSTM model to predict the next price in the sequence.\n",
            "2. Given a corpus of news articles, develop an LSTM model to classify them as positive, negative, or neutral based on their sentiment.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_answer(text):\n",
        "   \"\"\"Extract the answer, removing everything before 'Show output examples where applicable'\"\"\"\n",
        "   # Find the index of the end section\n",
        "   start_index = text.find(\"</think>\")\n",
        "\n",
        "   if start_index == -1:\n",
        "       return text.strip()\n",
        "\n",
        "   return text[start_index + len(\"Show output examples where applicable\"):].strip()\n",
        "\n",
        "# Usage\n",
        "clean_answer = extract_answer(answer)\n",
        "print(clean_answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "T4s7bF8Fl1LR",
        "outputId": "2bea39f5-011f-4449-dd8d-3a108ef696ec"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "• **Core definition and purpose**: Bubble sort is a simple sorting algorithm that repeatedly steps through the list, compares adjacent elements, and swaps them if they are in the wrong order. Its primary purpose is to sort data in ascending or descending order.\n",
            "  • **Key principles**: It is a comparison-based, in-place sorting algorithm. The algorithm works by repeatedly swapping the adjacent elements if they are in the wrong order.\n",
            "  • **Relationship to broader computing concepts**: Bubble sort is one of the simplest sorting algorithms, often used for educational purposes. It is less efficient on large data sets compared to algorithms like quicksort or mergesort but is simple to implement.\n",
            "\n",
            "## 2. *Technical Components*\n",
            "  • **Primary elements and their roles**:\n",
            "    - **Array/List**: The data structure to be sorted.\n",
            "    - **Swap Mechanism**: Temporarily holds a value during the swap operation.\n",
            "    - **Control Structures**: Uses nested loops to control the sorting process.\n",
            "  • **Relationships and interactions**: The outer loop runs for each element, while the inner loop compares adjacent elements and swaps them if necessary.\n",
            "  • **Implementation details**: The algorithm consists of nested loops. The outer loop runs from the start to the end of the array, while the inner loop runs from the start to the unsorted portion of the array.\n",
            "  • **Core algorithms/procedures**:\n",
            "    ```\n",
            "    procedure bubbleSort(A)\n",
            "      n = length(A)\n",
            "      for i from 0 to n-1\n",
            "        swapped = false\n",
            "        for j from 0 to n-i-1\n",
            "          if A[j] > A[j+1]\n",
            "            swap(A[j], A[j+1])\n",
            "            swapped = true\n",
            "        end if\n",
            "        if not swapped\n",
            "          break\n",
            "        end if\n",
            "      end for\n",
            "    end procedure\n",
            "    ```\n",
            "\n",
            "## 3. *Working Mechanism*\n",
            "  • **Step-by-step operational flow**:\n",
            "    1. **Initialization**: Start with the entire array as unsorted.\n",
            "    2. **First Pass**: Compare the first and second elements. If they are in the wrong order, swap them. Move to the next pair and repeat until the end of the array. The largest element \"bubbles\" up to its correct position.\n",
            "    3. **Subsequent Passes**: Repeat the process, but after each pass, the portion of the array that is already sorted increases. If no swaps occur during a pass, the array is sorted, and the algorithm terminates early.\n",
            "  • **Critical processes and transformations**: Each pass ensures that the next largest element is moved to its correct position.\n",
            "  • **Resource management**: Bubble sort is an in-place sorting algorithm, requiring only a small amount of extra memory for the swap variable.\n",
            "  • **Exception handling**: The algorithm does not require explicit exception handling as it works on any array of comparable elements.\n",
            "\n",
            "## 4. *Implementation Example*\n",
            "  • **Use case scenario**: Suppose we have an array `[64, 34, 25, 12, 22, 11, 90]` that we want to sort in ascending order.\n",
            "  • **Code implementation**:\n",
            "    ```python\n",
            "    def bubble_sort(arr):\n",
            "        n = len(arr)\n",
            "        for i in range(n):\n",
            "            swapped = False\n",
            "            for j in range(0, n-i-1):\n",
            "                if arr[j] > arr[j+1]:\n",
            "                    arr[j], arr[j+1] = arr[j+1], arr[j]\n",
            "                    swapped = True\n",
            "            if not swapped:\n",
            "                break\n",
            "        return arr\n",
            "    ```\n",
            "  • **Step-by-step execution**:\n",
            "    1. **Pass 1**: Compare and swap elements until the largest element (90) moves to the end.\n",
            "    2. **Pass 2**: The second largest element (64) moves to its position.\n",
            "    3. **Pass 3**: Continue until the array is sorted.\n",
            "  • **Output analysis**: The sorted array is `[11, 12, 22, 25, 34, 64, 90]`.\n",
            "\n",
            "## 5. *Best Practices*\n",
            "  • **Design considerations**:\n",
            "    - Use bubble sort for small datasets or educational purposes.\n",
            "    - Avoid using bubble sort for large datasets due to its O(n²) time complexity.\n",
            "  • **Optimization techniques**:\n",
            "    - **Early Termination**: If a pass completes without any swaps, the array is already sorted, and the algorithm can terminate early.\n",
            "    - **Reducing Comparisons**: After each pass, the largest element is in its correct position, so the inner loop can avoid checking the last `i` elements.\n",
            "  • **Common pitfalls**:\n",
            "    - Implementing the inner loop incorrectly, leading to out-of-bounds errors.\n",
            "    - Forgetting to break early if no swaps occur, leading to unnecessary iterations.\n",
            "  • **Performance implications**: Bubble sort has a worst-case and average time complexity of O(n²), making it inefficient for large datasets.\n",
            "\n",
            "## 6. *Applications*\n",
            "  • **Real-world use cases**:\n",
            "    - Sorting small datasets where simplicity is more important than speed.\n",
            "    - Educational purposes to introduce sorting algorithms.\n",
            "    - Embedded systems with limited resources.\n",
            "  • **Industry applications**:\n",
            "    - Simple sorting tasks in embedded systems.\n",
            "    - Legacy code where bubble sort is already implemented and works adequately for the given constraints.\n",
            "  • **Integration patterns**:\n",
            "    - Often used as a teaching tool before introducing more complex sorting algorithms.\n",
            "    - Can be used as a subroutine in more complex sorting algorithms.\n",
            "  • **Variations and alternatives**:\n",
            "    - **Cocktail Shaker Sort**: A bidirectional version of bubble sort that sorts in both directions each pass.\n",
            "    - **Odd-Even Sort**: A parallel version of bubble sort.\n",
            "\n",
            "## 7. *Evaluation*\n",
            "  • **Performance metrics**:\n",
            "    - **Time Complexity**: O(n²) in the worst and average cases, O(n) in the best case (when the array is already sorted).\n",
            "    - **Space Complexity**: O(1) since it is an in-place sorting algorithm.\n",
            "  • **Testing approaches**:\n",
            "    - Test with arrays of different sizes.\n",
            "    - Test with already sorted and reverse-sorted arrays to check for early termination.\n",
            "    - Test with arrays containing duplicate elements.\n",
            "  • **Debugging strategies**:\n",
            "    - Check the loop conditions to ensure they cover the entire array.\n",
            "    - Verify that the swap operation is correctly implemented.\n",
            "    - Use print statements or a debugger to track the state of the array during each pass.\n",
            "  • **Optimization opportunities**:\n",
            "    - Implement early termination if no swaps occur during a pass.\n",
            "    - Reduce the range of the inner loop after each pass.\n",
            "\n",
            "## 8. *Practice Problems*\n",
            "  • **Concept verification questions**:\n",
            "    - What is the time complexity of bubble sort in the worst case?\n",
            "    - How does bubble sort handle duplicate elements?\n",
            "    - What is the space complexity of bubble sort?\n",
            "  • **Implementation challenges**:\n",
            "    - Implement bubble sort for a linked list.\n",
            "    - Implement a bidirectional version of bubble sort (cocktail shaker sort).\n",
            "    - Implement bubble sort with early termination.\n",
            "  • **Problem-solving scenarios**:\n",
            "    - Sort a list of strings using bubble sort.\n",
            "    - Sort a list of integers in descending order using bubble sort.\n",
            "  • **Solutions with explanations**:\n",
            "    - **Time Complexity**: The worst-case time complexity is O(n²). This is because in the worst case, the algorithm has to compare and swap every pair of elements.\n",
            "    - **Duplicate Elements**: Bubble sort handles duplicate elements naturally. If two adjacent elements are equal, they are not swapped, and the algorithm continues.\n",
            "    - **Space Complexity**: The space complexity is O(1) because bubble sort is an in-place sorting algorithm.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def format_text(text):\n",
        "    \"\"\"\n",
        "    Format text with the following rules:\n",
        "    1. Change single asterisks to double asterisks\n",
        "    2. Convert '###' to bullet points\n",
        "    3. Convert dashes to numbered lists, resetting numbers after each bullet point\n",
        "\n",
        "    Args:\n",
        "        text (str): Input text to be formatted\n",
        "    Returns:\n",
        "        str: Formatted text\n",
        "    \"\"\"\n",
        "    # Split text into lines for processing\n",
        "    lines = text.split('\\n')\n",
        "    formatted_lines = []\n",
        "\n",
        "    # Initialize counters for each indentation level\n",
        "    number_counters = {}\n",
        "    current_indent = 0\n",
        "\n",
        "    for i, line in enumerate(lines):\n",
        "        # Skip empty lines but preserve them\n",
        "        if not line.strip():\n",
        "            formatted_lines.append(line)\n",
        "            continue\n",
        "\n",
        "        # Handle single asterisks to double asterisks\n",
        "        # Use negative lookbehind and lookahead to avoid modifying double asterisks\n",
        "        line = re.sub(r'(?<![\\*])\\*(?![\\*])([^\\*]+)(?<![\\*])\\*(?![\\*])', r'**\\1**', line)\n",
        "\n",
        "        # Get the indentation level of the current line\n",
        "        indent = len(line) - len(line.lstrip())\n",
        "\n",
        "        # Convert ### to bullet points\n",
        "        if line.strip().startswith('###'):\n",
        "            # When we encounter a bullet point, reset all numbering counters\n",
        "            number_counters = {}\n",
        "            line = line.replace('###', '•')\n",
        "            current_indent = indent\n",
        "\n",
        "        # Handle numbered lists (lines starting with dash)\n",
        "        elif line.strip().startswith('-'):\n",
        "            # Reset counters for deeper indentation levels when indent changes\n",
        "            if indent > current_indent:\n",
        "                # Keep only counters for less indented levels\n",
        "                number_counters = {k: v for k, v in number_counters.items() if k < indent}\n",
        "\n",
        "            # Initialize or increment counter for this indentation level\n",
        "            if indent not in number_counters:\n",
        "                number_counters[indent] = 1\n",
        "            else:\n",
        "                number_counters[indent] += 1\n",
        "\n",
        "            # Replace dash with the current number for this indentation level\n",
        "            line = re.sub(r'^\\s*-', f\"{' ' * indent}{number_counters[indent]}.\", line, 1)\n",
        "            current_indent = indent\n",
        "        else:\n",
        "            # For non-list lines, keep track of the current indentation\n",
        "            current_indent = indent\n",
        "\n",
        "        formatted_lines.append(line)\n",
        "\n",
        "    return '\\n'.join(formatted_lines)\n",
        "\n",
        "def process_file(input_text):\n",
        "    \"\"\"\n",
        "    Process the entire file and apply formatting\n",
        "\n",
        "    Args:\n",
        "        input_text (str): Content of the input file\n",
        "    Returns:\n",
        "        str: Formatted content\n",
        "    \"\"\"\n",
        "    # Format the text\n",
        "    formatted_text = format_text(input_text)\n",
        "    return formatted_text\n",
        "\n",
        "# Example usage demonstrating the reset behavior\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "\n",
        "    # Process and print the sample text\n",
        "    result = process_file(clean_answer)\n",
        "    print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "l-RRDvGul1FY",
        "outputId": "3053a416-7c8e-4857-abcc-404e6145676d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "• **Core definition and purpose**: Bubble sort is a simple sorting algorithm that repeatedly steps through the list, compares adjacent elements, and swaps them if they are in the wrong order. Its primary purpose is to sort data in ascending or descending order.\n",
            "  • **Key principles**: It is a comparison-based, in-place sorting algorithm. The algorithm works by repeatedly swapping the adjacent elements if they are in the wrong order.\n",
            "  • **Relationship to broader computing concepts**: Bubble sort is one of the simplest sorting algorithms, often used for educational purposes. It is less efficient on large data sets compared to algorithms like quicksort or mergesort but is simple to implement.\n",
            "\n",
            "## 2. **Technical Components**\n",
            "  • **Primary elements and their roles**:\n",
            "    1. **Array/List**: The data structure to be sorted.\n",
            "    2. **Swap Mechanism**: Temporarily holds a value during the swap operation.\n",
            "    3. **Control Structures**: Uses nested loops to control the sorting process.\n",
            "  • **Relationships and interactions**: The outer loop runs for each element, while the inner loop compares adjacent elements and swaps them if necessary.\n",
            "  • **Implementation details**: The algorithm consists of nested loops. The outer loop runs from the start to the end of the array, while the inner loop runs from the start to the unsorted portion of the array.\n",
            "  • **Core algorithms/procedures**:\n",
            "    ```\n",
            "    procedure bubbleSort(A)\n",
            "      n = length(A)\n",
            "      for i from 0 to n-1\n",
            "        swapped = false\n",
            "        for j from 0 to n-i-1\n",
            "          if A[j] > A[j+1]\n",
            "            swap(A[j], A[j+1])\n",
            "            swapped = true\n",
            "        end if\n",
            "        if not swapped\n",
            "          break\n",
            "        end if\n",
            "      end for\n",
            "    end procedure\n",
            "    ```\n",
            "\n",
            "## 3. **Working Mechanism**\n",
            "  • **Step-by-step operational flow**:\n",
            "    1. **Initialization**: Start with the entire array as unsorted.\n",
            "    2. **First Pass**: Compare the first and second elements. If they are in the wrong order, swap them. Move to the next pair and repeat until the end of the array. The largest element \"bubbles\" up to its correct position.\n",
            "    3. **Subsequent Passes**: Repeat the process, but after each pass, the portion of the array that is already sorted increases. If no swaps occur during a pass, the array is sorted, and the algorithm terminates early.\n",
            "  • **Critical processes and transformations**: Each pass ensures that the next largest element is moved to its correct position.\n",
            "  • **Resource management**: Bubble sort is an in-place sorting algorithm, requiring only a small amount of extra memory for the swap variable.\n",
            "  • **Exception handling**: The algorithm does not require explicit exception handling as it works on any array of comparable elements.\n",
            "\n",
            "## 4. **Implementation Example**\n",
            "  • **Use case scenario**: Suppose we have an array `[64, 34, 25, 12, 22, 11, 90]` that we want to sort in ascending order.\n",
            "  • **Code implementation**:\n",
            "    ```python\n",
            "    def bubble_sort(arr):\n",
            "        n = len(arr)\n",
            "        for i in range(n):\n",
            "            swapped = False\n",
            "            for j in range(0, n-i-1):\n",
            "                if arr[j] > arr[j+1]:\n",
            "                    arr[j], arr[j+1] = arr[j+1], arr[j]\n",
            "                    swapped = True\n",
            "            if not swapped:\n",
            "                break\n",
            "        return arr\n",
            "    ```\n",
            "  • **Step-by-step execution**:\n",
            "    1. **Pass 1**: Compare and swap elements until the largest element (90) moves to the end.\n",
            "    2. **Pass 2**: The second largest element (64) moves to its position.\n",
            "    3. **Pass 3**: Continue until the array is sorted.\n",
            "  • **Output analysis**: The sorted array is `[11, 12, 22, 25, 34, 64, 90]`.\n",
            "\n",
            "## 5. **Best Practices**\n",
            "  • **Design considerations**:\n",
            "    1. Use bubble sort for small datasets or educational purposes.\n",
            "    2. Avoid using bubble sort for large datasets due to its O(n²) time complexity.\n",
            "  • **Optimization techniques**:\n",
            "    1. **Early Termination**: If a pass completes without any swaps, the array is already sorted, and the algorithm can terminate early.\n",
            "    2. **Reducing Comparisons**: After each pass, the largest element is in its correct position, so the inner loop can avoid checking the last `i` elements.\n",
            "  • **Common pitfalls**:\n",
            "    1. Implementing the inner loop incorrectly, leading to out-of-bounds errors.\n",
            "    2. Forgetting to break early if no swaps occur, leading to unnecessary iterations.\n",
            "  • **Performance implications**: Bubble sort has a worst-case and average time complexity of O(n²), making it inefficient for large datasets.\n",
            "\n",
            "## 6. **Applications**\n",
            "  • **Real-world use cases**:\n",
            "    1. Sorting small datasets where simplicity is more important than speed.\n",
            "    2. Educational purposes to introduce sorting algorithms.\n",
            "    3. Embedded systems with limited resources.\n",
            "  • **Industry applications**:\n",
            "    1. Simple sorting tasks in embedded systems.\n",
            "    2. Legacy code where bubble sort is already implemented and works adequately for the given constraints.\n",
            "  • **Integration patterns**:\n",
            "    1. Often used as a teaching tool before introducing more complex sorting algorithms.\n",
            "    2. Can be used as a subroutine in more complex sorting algorithms.\n",
            "  • **Variations and alternatives**:\n",
            "    1. **Cocktail Shaker Sort**: A bidirectional version of bubble sort that sorts in both directions each pass.\n",
            "    2. **Odd-Even Sort**: A parallel version of bubble sort.\n",
            "\n",
            "## 7. **Evaluation**\n",
            "  • **Performance metrics**:\n",
            "    1. **Time Complexity**: O(n²) in the worst and average cases, O(n) in the best case (when the array is already sorted).\n",
            "    2. **Space Complexity**: O(1) since it is an in-place sorting algorithm.\n",
            "  • **Testing approaches**:\n",
            "    1. Test with arrays of different sizes.\n",
            "    2. Test with already sorted and reverse-sorted arrays to check for early termination.\n",
            "    3. Test with arrays containing duplicate elements.\n",
            "  • **Debugging strategies**:\n",
            "    1. Check the loop conditions to ensure they cover the entire array.\n",
            "    2. Verify that the swap operation is correctly implemented.\n",
            "    3. Use print statements or a debugger to track the state of the array during each pass.\n",
            "  • **Optimization opportunities**:\n",
            "    1. Implement early termination if no swaps occur during a pass.\n",
            "    2. Reduce the range of the inner loop after each pass.\n",
            "\n",
            "## 8. **Practice Problems**\n",
            "  • **Concept verification questions**:\n",
            "    1. What is the time complexity of bubble sort in the worst case?\n",
            "    2. How does bubble sort handle duplicate elements?\n",
            "    3. What is the space complexity of bubble sort?\n",
            "  • **Implementation challenges**:\n",
            "    1. Implement bubble sort for a linked list.\n",
            "    2. Implement a bidirectional version of bubble sort (cocktail shaker sort).\n",
            "    3. Implement bubble sort with early termination.\n",
            "  • **Problem-solving scenarios**:\n",
            "    1. Sort a list of strings using bubble sort.\n",
            "    2. Sort a list of integers in descending order using bubble sort.\n",
            "  • **Solutions with explanations**:\n",
            "    1. **Time Complexity**: The worst-case time complexity is O(n²). This is because in the worst case, the algorithm has to compare and swap every pair of elements.\n",
            "    2. **Duplicate Elements**: Bubble sort handles duplicate elements naturally. If two adjacent elements are equal, they are not swapped, and the algorithm continues.\n",
            "    3. **Space Complexity**: The space complexity is O(1) because bubble sort is an in-place sorting algorithm.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write the content to a text file\n",
        "file_path = \"content.txt\"\n",
        "with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
        "    file.write(result)\n"
      ],
      "metadata": {
        "id": "F_5Sj2r6l07e"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get install -y texlive-latex-base texlive-fonts-recommended texlive-fonts-extra texlive-latex-extra dvipng cm-super\n",
        "!pip install python-pptx Pillow matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "GCtBa5Ssmy6s",
        "outputId": "f7c570aa-3c3a-48db-d28e-95bbbc2096dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.81)] [1 InRelease 12.7 kB/129 kB 10%] [Connected t\r                                                                                                    \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:8 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,229 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,604 kB]\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,651 kB]\n",
            "Hit:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,654 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,906 kB]\n",
            "Get:16 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [57.8 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,522 kB]\n",
            "Fetched 20.0 MB in 3s (6,278 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  cm-super-minimal dvisvgm fonts-adf-accanthis fonts-adf-berenis fonts-adf-gillius\n",
            "  fonts-adf-universalis fonts-cabin fonts-cantarell fonts-comfortaa fonts-croscore\n",
            "  fonts-crosextra-caladea fonts-crosextra-carlito fonts-dejavu-core fonts-dejavu-extra\n",
            "  fonts-droid-fallback fonts-ebgaramond fonts-ebgaramond-extra fonts-font-awesome\n",
            "  fonts-freefont-otf fonts-freefont-ttf fonts-gfs-artemisia fonts-gfs-complutum fonts-gfs-didot\n",
            "  fonts-gfs-neohellenic fonts-gfs-olga fonts-gfs-solomos fonts-go fonts-junicode fonts-lato\n",
            "  fonts-linuxlibertine fonts-lmodern fonts-lobster fonts-lobstertwo fonts-noto-color-emoji\n",
            "  fonts-noto-core fonts-noto-mono fonts-oflb-asana-math fonts-open-sans fonts-roboto-unhinted\n",
            "  fonts-sil-charis fonts-sil-gentium fonts-sil-gentium-basic fonts-sil-gentiumplus\n",
            "  fonts-sil-gentiumplus-compact fonts-stix fonts-texgyre fonts-urw-base35 ghostscript\n",
            "  libapache-pom-java libcommons-logging-java libcommons-parent-java libfontbox-java libfontenc1\n",
            "  libgs9 libgs9-common libidn12 libijs-0.35 libjbig2dec0 libkpathsea6 libpdfbox-java libptexenc1\n",
            "  libruby3.0 libsynctex2 libteckit0 libtexlua53 libtexluajit2 libwoff1 libzzip-0-13 lmodern\n",
            "  pfb2t1c2pfb poppler-data preview-latex-style rake ruby ruby-net-telnet ruby-rubygems ruby-webrick\n",
            "  ruby-xmlrpc ruby3.0 rubygems-integration t1utils tex-common tex-gyre texlive-base\n",
            "  texlive-binaries texlive-fonts-extra-links texlive-latex-recommended texlive-pictures\n",
            "  texlive-plain-generic tipa xfonts-encodings xfonts-utils\n",
            "Suggested packages:\n",
            "  fonts-noto fontforge ghostscript-x libavalon-framework-java libcommons-logging-java-doc\n",
            "  libexcalibur-logkit-java liblog4j1.2-java fonts-japanese-mincho | fonts-ipafont-mincho\n",
            "  fonts-japanese-gothic | fonts-ipafont-gothic fonts-arphic-ukai fonts-arphic-uming fonts-nanum ri\n",
            "  ruby-dev bundler debhelper perl-tk xpdf | pdf-viewer xzdec texlive-fonts-extra-doc\n",
            "  texlive-fonts-recommended-doc texlive-latex-base-doc python3-pygments icc-profiles\n",
            "  libfile-which-perl libspreadsheet-parseexcel-perl texlive-latex-extra-doc\n",
            "  texlive-latex-recommended-doc texlive-luatex texlive-pstricks dot2tex prerex texlive-pictures-doc\n",
            "  vprerex default-jre-headless tipa-doc\n",
            "The following NEW packages will be installed:\n",
            "  cm-super cm-super-minimal dvipng dvisvgm fonts-adf-accanthis fonts-adf-berenis fonts-adf-gillius\n",
            "  fonts-adf-universalis fonts-cabin fonts-cantarell fonts-comfortaa fonts-croscore\n",
            "  fonts-crosextra-caladea fonts-crosextra-carlito fonts-dejavu-core fonts-dejavu-extra\n",
            "  fonts-droid-fallback fonts-ebgaramond fonts-ebgaramond-extra fonts-font-awesome\n",
            "  fonts-freefont-otf fonts-freefont-ttf fonts-gfs-artemisia fonts-gfs-complutum fonts-gfs-didot\n",
            "  fonts-gfs-neohellenic fonts-gfs-olga fonts-gfs-solomos fonts-go fonts-junicode fonts-lato\n",
            "  fonts-linuxlibertine fonts-lmodern fonts-lobster fonts-lobstertwo fonts-noto-color-emoji\n",
            "  fonts-noto-core fonts-noto-mono fonts-oflb-asana-math fonts-open-sans fonts-roboto-unhinted\n",
            "  fonts-sil-charis fonts-sil-gentium fonts-sil-gentium-basic fonts-sil-gentiumplus\n",
            "  fonts-sil-gentiumplus-compact fonts-stix fonts-texgyre fonts-urw-base35 ghostscript\n",
            "  libapache-pom-java libcommons-logging-java libcommons-parent-java libfontbox-java libfontenc1\n",
            "  libgs9 libgs9-common libidn12 libijs-0.35 libjbig2dec0 libkpathsea6 libpdfbox-java libptexenc1\n",
            "  libruby3.0 libsynctex2 libteckit0 libtexlua53 libtexluajit2 libwoff1 libzzip-0-13 lmodern\n",
            "  pfb2t1c2pfb poppler-data preview-latex-style rake ruby ruby-net-telnet ruby-rubygems ruby-webrick\n",
            "  ruby-xmlrpc ruby3.0 rubygems-integration t1utils tex-common tex-gyre texlive-base\n",
            "  texlive-binaries texlive-fonts-extra texlive-fonts-extra-links texlive-fonts-recommended\n",
            "  texlive-latex-base texlive-latex-extra texlive-latex-recommended texlive-pictures\n",
            "  texlive-plain-generic tipa xfonts-encodings xfonts-utils\n",
            "0 upgraded, 98 newly installed, 0 to remove and 21 not upgraded.\n",
            "Need to get 738 MB of archives.\n",
            "After this operation, 2,147 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-droid-fallback all 1:6.0.1r16-1.1build1 [1,805 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-lato all 2.0-2.1 [2,696 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 poppler-data all 0.4.11-1 [2,171 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tex-common all 6.17 [33.7 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libkpathsea6 amd64 2021.20210626.59705-1ubuntu0.2 [60.4 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libptexenc1 amd64 2021.20210626.59705-1ubuntu0.2 [39.1 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libsynctex2 amd64 2021.20210626.59705-1ubuntu0.2 [55.6 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libtexlua53 amd64 2021.20210626.59705-1ubuntu0.2 [120 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libtexluajit2 amd64 2021.20210626.59705-1ubuntu0.2 [267 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 t1utils amd64 1.41-4build2 [61.3 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libteckit0 amd64 2.5.11+ds1-1 [421 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libzzip-0-13 amd64 0.13.72+dfsg.1-1.1 [27.0 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 texlive-binaries amd64 2021.20210626.59705-1ubuntu0.2 [9,860 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-base all 2021.20220204-1 [21.0 MB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-lmodern all 2.004.5-6.1 [4,532 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-latex-base all 2021.20220204-1 [1,128 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-latex-recommended all 2021.20220204-1 [14.4 MB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy/universe amd64 cm-super-minimal all 0.3.4-17 [5,777 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy/universe amd64 pfb2t1c2pfb amd64 0.3-11 [9,342 B]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy/universe amd64 cm-super all 0.3.4-17 [20.2 MB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-urw-base35 all 20200910-1 [6,367 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgs9-common all 9.55.0~dfsg1-0ubuntu5.10 [752 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libidn12 amd64 1.38-4ubuntu1 [60.0 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy/main amd64 libijs-0.35 amd64 0.35-15build2 [16.5 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjbig2dec0 amd64 0.19-3build2 [64.7 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgs9 amd64 9.55.0~dfsg1-0ubuntu5.10 [5,031 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ghostscript amd64 9.55.0~dfsg1-0ubuntu5.10 [49.4 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu jammy/universe amd64 dvipng amd64 1.15-1.1 [78.9 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwoff1 amd64 1.0.2-1build4 [45.2 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu jammy/universe amd64 dvisvgm amd64 2.13.1-1 [1,221 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-adf-accanthis all 0.20190904-2 [203 kB]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-adf-berenis all 0.20190904-2 [313 kB]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-adf-gillius all 0.20190904-2 [190 kB]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-adf-universalis all 0.20190904-2 [112 kB]\n",
            "Get:35 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-cabin all 1.5-3 [141 kB]\n",
            "Get:36 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-cantarell all 0.303-2 [286 kB]\n",
            "Get:37 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-comfortaa all 3.001-3 [129 kB]\n",
            "Get:38 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-croscore all 20201225-1build1 [1,572 kB]\n",
            "Get:39 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-crosextra-caladea all 20130214-2.1 [82.4 kB]\n",
            "Get:40 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-crosextra-carlito all 20130920-1.1 [743 kB]\n",
            "Get:41 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-core all 2.37-2build1 [1,041 kB]\n",
            "Get:42 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-dejavu-extra all 2.37-2build1 [2,041 kB]\n",
            "Get:43 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-ebgaramond all 0.016+git20210310.42d4f9f2-1 [512 kB]\n",
            "Get:44 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-ebgaramond-extra all 0.016+git20210310.42d4f9f2-1 [2,233 kB]\n",
            "Get:45 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-font-awesome all 5.0.10+really4.7.0~dfsg-4.1 [516 kB]\n",
            "Get:46 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-freefont-otf all 20120503-10build1 [3,054 kB]\n",
            "Get:47 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-freefont-ttf all 20120503-10build1 [2,388 kB]\n",
            "Get:48 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-gfs-artemisia all 1.1-6 [260 kB]\n",
            "Get:49 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-gfs-complutum all 1.1-7 [41.8 kB]\n",
            "Get:50 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-gfs-didot all 1.1-7 [278 kB]\n",
            "Get:51 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-gfs-neohellenic all 1.1-7 [215 kB]\n",
            "Get:52 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-gfs-olga all 1.1-6 [33.5 kB]\n",
            "Get:53 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-gfs-solomos all 1.1-6 [40.9 kB]\n",
            "Get:54 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-go all 0~20170330-1 [369 kB]\n",
            "Get:55 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-junicode all 1.002-2 [828 kB]\n",
            "Get:56 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-linuxlibertine all 5.3.0-6 [1,627 kB]\n",
            "Get:57 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-lobster all 2.0-2.1 [38.9 kB]\n",
            "Get:58 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-lobstertwo all 2.0-2.1 [93.3 kB]\n",
            "Get:59 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 fonts-noto-color-emoji all 2.042-0ubuntu0.22.04.1 [9,944 kB]\n",
            "Get:60 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-noto-core all 20201225-1build1 [12.2 MB]\n",
            "Get:61 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-noto-mono all 20201225-1build1 [397 kB]\n",
            "Get:62 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-oflb-asana-math all 000.907-7build1 [245 kB]\n",
            "Get:63 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-open-sans all 1.11-2 [635 kB]\n",
            "Get:64 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-roboto-unhinted all 2:0~20170802-3 [2,376 kB]\n",
            "Get:65 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-sil-charis all 6.101-1 [3,973 kB]\n",
            "Get:66 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-sil-gentium all 20081126:1.03-4 [245 kB]\n",
            "Get:67 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-sil-gentium-basic all 1.102-1.1 [384 kB]\n",
            "Get:68 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-sil-gentiumplus all 6.101-1 [8,086 kB]\n",
            "Get:69 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-sil-gentiumplus-compact all 5.000-4 [1,514 kB]\n",
            "Get:70 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-texgyre all 20180621-3.1 [10.2 MB]\n",
            "Get:71 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libapache-pom-java all 18-1 [4,720 B]\n",
            "Get:72 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libcommons-parent-java all 43-1 [10.8 kB]\n",
            "Get:73 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libcommons-logging-java all 1.2-2 [60.3 kB]\n",
            "Get:74 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n",
            "Get:75 http://archive.ubuntu.com/ubuntu jammy/main amd64 rubygems-integration all 1.18 [5,336 B]\n",
            "Get:76 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ruby3.0 amd64 3.0.2-7ubuntu2.8 [50.1 kB]\n",
            "Get:77 http://archive.ubuntu.com/ubuntu jammy/main amd64 ruby-rubygems all 3.3.5-2 [228 kB]\n",
            "Get:78 http://archive.ubuntu.com/ubuntu jammy/main amd64 ruby amd64 1:3.0~exp1 [5,100 B]\n",
            "Get:79 http://archive.ubuntu.com/ubuntu jammy/main amd64 rake all 13.0.6-2 [61.7 kB]\n",
            "Get:80 http://archive.ubuntu.com/ubuntu jammy/main amd64 ruby-net-telnet all 0.1.1-2 [12.6 kB]\n",
            "Get:81 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ruby-webrick all 1.7.0-3ubuntu0.1 [52.1 kB]\n",
            "Get:82 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ruby-xmlrpc all 0.3.2-1ubuntu0.1 [24.9 kB]\n",
            "Get:83 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libruby3.0 amd64 3.0.2-7ubuntu2.8 [5,113 kB]\n",
            "Get:84 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]\n",
            "Get:85 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-utils amd64 1:7.7+6build2 [94.6 kB]\n",
            "Get:86 http://archive.ubuntu.com/ubuntu jammy/universe amd64 lmodern all 2.004.5-6.1 [9,471 kB]\n",
            "Get:87 http://archive.ubuntu.com/ubuntu jammy/universe amd64 preview-latex-style all 12.2-1ubuntu1 [185 kB]\n",
            "Get:88 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tex-gyre all 20180621-3.1 [6,209 kB]\n",
            "Get:89 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-fonts-extra all 2021.20220204-1 [484 MB]\n",
            "Get:90 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-stix all 1.1.1-4.1 [589 kB]\n",
            "Get:91 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-fonts-extra-links all 2021.20220204-1 [20.3 kB]\n",
            "Get:92 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-fonts-recommended all 2021.20220204-1 [4,972 kB]\n",
            "Get:93 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libfontbox-java all 1:1.8.16-2 [207 kB]\n",
            "Get:94 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libpdfbox-java all 1:1.8.16-2 [5,199 kB]\n",
            "Get:95 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-pictures all 2021.20220204-1 [8,720 kB]\n",
            "Get:96 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-latex-extra all 2021.20220204-1 [13.9 MB]\n",
            "Get:97 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-plain-generic all 2021.20220204-1 [27.5 MB]\n",
            "Get:98 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tipa all 2:1.3-21 [2,967 kB]\n",
            "Fetched 738 MB in 21s (34.6 MB/s)\n",
            "Extracting templates from packages: 100%\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package fonts-droid-fallback.\n",
            "(Reading database ... 125003 files and directories currently installed.)\n",
            "Preparing to unpack .../00-fonts-droid-fallback_1%3a6.0.1r16-1.1build1_all.deb ...\n",
            "Unpacking fonts-droid-fallback (1:6.0.1r16-1.1build1) ...\n",
            "Selecting previously unselected package fonts-lato.\n",
            "Preparing to unpack .../01-fonts-lato_2.0-2.1_all.deb ...\n",
            "Unpacking fonts-lato (2.0-2.1) ...\n",
            "Selecting previously unselected package poppler-data.\n",
            "Preparing to unpack .../02-poppler-data_0.4.11-1_all.deb ...\n",
            "Unpacking poppler-data (0.4.11-1) ...\n",
            "Selecting previously unselected package tex-common.\n",
            "Preparing to unpack .../03-tex-common_6.17_all.deb ...\n",
            "Unpacking tex-common (6.17) ...\n",
            "Selecting previously unselected package libkpathsea6:amd64.\n",
            "Preparing to unpack .../04-libkpathsea6_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking libkpathsea6:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Selecting previously unselected package libptexenc1:amd64.\n",
            "Preparing to unpack .../05-libptexenc1_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking libptexenc1:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Selecting previously unselected package libsynctex2:amd64.\n",
            "Preparing to unpack .../06-libsynctex2_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking libsynctex2:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Selecting previously unselected package libtexlua53:amd64.\n",
            "Preparing to unpack .../07-libtexlua53_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking libtexlua53:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Selecting previously unselected package libtexluajit2:amd64.\n",
            "Preparing to unpack .../08-libtexluajit2_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking libtexluajit2:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Selecting previously unselected package t1utils.\n",
            "Preparing to unpack .../09-t1utils_1.41-4build2_amd64.deb ...\n",
            "Unpacking t1utils (1.41-4build2) ...\n",
            "Selecting previously unselected package libteckit0:amd64.\n",
            "Preparing to unpack .../10-libteckit0_2.5.11+ds1-1_amd64.deb ...\n",
            "Unpacking libteckit0:amd64 (2.5.11+ds1-1) ...\n",
            "Selecting previously unselected package libzzip-0-13:amd64.\n",
            "Preparing to unpack .../11-libzzip-0-13_0.13.72+dfsg.1-1.1_amd64.deb ...\n",
            "Unpacking libzzip-0-13:amd64 (0.13.72+dfsg.1-1.1) ...\n",
            "Selecting previously unselected package texlive-binaries.\n",
            "Preparing to unpack .../12-texlive-binaries_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking texlive-binaries (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Selecting previously unselected package texlive-base.\n",
            "Preparing to unpack .../13-texlive-base_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-base (2021.20220204-1) ...\n",
            "Selecting previously unselected package fonts-lmodern.\n",
            "Preparing to unpack .../14-fonts-lmodern_2.004.5-6.1_all.deb ...\n",
            "Unpacking fonts-lmodern (2.004.5-6.1) ...\n",
            "Selecting previously unselected package texlive-latex-base.\n",
            "Preparing to unpack .../15-texlive-latex-base_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-latex-base (2021.20220204-1) ...\n",
            "Selecting previously unselected package texlive-latex-recommended.\n",
            "Preparing to unpack .../16-texlive-latex-recommended_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-latex-recommended (2021.20220204-1) ...\n",
            "Selecting previously unselected package cm-super-minimal.\n",
            "Preparing to unpack .../17-cm-super-minimal_0.3.4-17_all.deb ...\n",
            "Unpacking cm-super-minimal (0.3.4-17) ...\n",
            "Selecting previously unselected package pfb2t1c2pfb.\n",
            "Preparing to unpack .../18-pfb2t1c2pfb_0.3-11_amd64.deb ...\n",
            "Unpacking pfb2t1c2pfb (0.3-11) ...\n",
            "Selecting previously unselected package cm-super.\n",
            "Preparing to unpack .../19-cm-super_0.3.4-17_all.deb ...\n",
            "Unpacking cm-super (0.3.4-17) ...\n",
            "Selecting previously unselected package fonts-urw-base35.\n",
            "Preparing to unpack .../20-fonts-urw-base35_20200910-1_all.deb ...\n",
            "Unpacking fonts-urw-base35 (20200910-1) ...\n",
            "Selecting previously unselected package libgs9-common.\n",
            "Preparing to unpack .../21-libgs9-common_9.55.0~dfsg1-0ubuntu5.10_all.deb ...\n",
            "Unpacking libgs9-common (9.55.0~dfsg1-0ubuntu5.10) ...\n",
            "Selecting previously unselected package libidn12:amd64.\n",
            "Preparing to unpack .../22-libidn12_1.38-4ubuntu1_amd64.deb ...\n",
            "Unpacking libidn12:amd64 (1.38-4ubuntu1) ...\n",
            "Selecting previously unselected package libijs-0.35:amd64.\n",
            "Preparing to unpack .../23-libijs-0.35_0.35-15build2_amd64.deb ...\n",
            "Unpacking libijs-0.35:amd64 (0.35-15build2) ...\n",
            "Selecting previously unselected package libjbig2dec0:amd64.\n",
            "Preparing to unpack .../24-libjbig2dec0_0.19-3build2_amd64.deb ...\n",
            "Unpacking libjbig2dec0:amd64 (0.19-3build2) ...\n",
            "Selecting previously unselected package libgs9:amd64.\n",
            "Preparing to unpack .../25-libgs9_9.55.0~dfsg1-0ubuntu5.10_amd64.deb ...\n",
            "Unpacking libgs9:amd64 (9.55.0~dfsg1-0ubuntu5.10) ...\n",
            "Selecting previously unselected package ghostscript.\n",
            "Preparing to unpack .../26-ghostscript_9.55.0~dfsg1-0ubuntu5.10_amd64.deb ...\n",
            "Unpacking ghostscript (9.55.0~dfsg1-0ubuntu5.10) ...\n",
            "Selecting previously unselected package dvipng.\n",
            "Preparing to unpack .../27-dvipng_1.15-1.1_amd64.deb ...\n",
            "Unpacking dvipng (1.15-1.1) ...\n",
            "Selecting previously unselected package libwoff1:amd64.\n",
            "Preparing to unpack .../28-libwoff1_1.0.2-1build4_amd64.deb ...\n",
            "Unpacking libwoff1:amd64 (1.0.2-1build4) ...\n",
            "Selecting previously unselected package dvisvgm.\n",
            "Preparing to unpack .../29-dvisvgm_2.13.1-1_amd64.deb ...\n",
            "Unpacking dvisvgm (2.13.1-1) ...\n",
            "Selecting previously unselected package fonts-adf-accanthis.\n",
            "Preparing to unpack .../30-fonts-adf-accanthis_0.20190904-2_all.deb ...\n",
            "Unpacking fonts-adf-accanthis (0.20190904-2) ...\n",
            "Selecting previously unselected package fonts-adf-berenis.\n",
            "Preparing to unpack .../31-fonts-adf-berenis_0.20190904-2_all.deb ...\n",
            "Unpacking fonts-adf-berenis (0.20190904-2) ...\n",
            "Selecting previously unselected package fonts-adf-gillius.\n",
            "Preparing to unpack .../32-fonts-adf-gillius_0.20190904-2_all.deb ...\n",
            "Unpacking fonts-adf-gillius (0.20190904-2) ...\n",
            "Selecting previously unselected package fonts-adf-universalis.\n",
            "Preparing to unpack .../33-fonts-adf-universalis_0.20190904-2_all.deb ...\n",
            "Unpacking fonts-adf-universalis (0.20190904-2) ...\n",
            "Selecting previously unselected package fonts-cabin.\n",
            "Preparing to unpack .../34-fonts-cabin_1.5-3_all.deb ...\n",
            "Unpacking fonts-cabin (1.5-3) ...\n",
            "Selecting previously unselected package fonts-cantarell.\n",
            "Preparing to unpack .../35-fonts-cantarell_0.303-2_all.deb ...\n",
            "Unpacking fonts-cantarell (0.303-2) ...\n",
            "Selecting previously unselected package fonts-comfortaa.\n",
            "Preparing to unpack .../36-fonts-comfortaa_3.001-3_all.deb ...\n",
            "Unpacking fonts-comfortaa (3.001-3) ...\n",
            "Selecting previously unselected package fonts-croscore.\n",
            "Preparing to unpack .../37-fonts-croscore_20201225-1build1_all.deb ...\n",
            "Unpacking fonts-croscore (20201225-1build1) ...\n",
            "Selecting previously unselected package fonts-crosextra-caladea.\n",
            "Preparing to unpack .../38-fonts-crosextra-caladea_20130214-2.1_all.deb ...\n",
            "Unpacking fonts-crosextra-caladea (20130214-2.1) ...\n",
            "Selecting previously unselected package fonts-crosextra-carlito.\n",
            "Preparing to unpack .../39-fonts-crosextra-carlito_20130920-1.1_all.deb ...\n",
            "Unpacking fonts-crosextra-carlito (20130920-1.1) ...\n",
            "Selecting previously unselected package fonts-dejavu-core.\n",
            "Preparing to unpack .../40-fonts-dejavu-core_2.37-2build1_all.deb ...\n",
            "Unpacking fonts-dejavu-core (2.37-2build1) ...\n",
            "Selecting previously unselected package fonts-dejavu-extra.\n",
            "Preparing to unpack .../41-fonts-dejavu-extra_2.37-2build1_all.deb ...\n",
            "Unpacking fonts-dejavu-extra (2.37-2build1) ...\n",
            "Selecting previously unselected package fonts-ebgaramond.\n",
            "Preparing to unpack .../42-fonts-ebgaramond_0.016+git20210310.42d4f9f2-1_all.deb ...\n",
            "Unpacking fonts-ebgaramond (0.016+git20210310.42d4f9f2-1) ...\n",
            "Selecting previously unselected package fonts-ebgaramond-extra.\n",
            "Preparing to unpack .../43-fonts-ebgaramond-extra_0.016+git20210310.42d4f9f2-1_all.deb ...\n",
            "Unpacking fonts-ebgaramond-extra (0.016+git20210310.42d4f9f2-1) ...\n",
            "Selecting previously unselected package fonts-font-awesome.\n",
            "Preparing to unpack .../44-fonts-font-awesome_5.0.10+really4.7.0~dfsg-4.1_all.deb ...\n",
            "Unpacking fonts-font-awesome (5.0.10+really4.7.0~dfsg-4.1) ...\n",
            "Selecting previously unselected package fonts-freefont-otf.\n",
            "Preparing to unpack .../45-fonts-freefont-otf_20120503-10build1_all.deb ...\n",
            "Unpacking fonts-freefont-otf (20120503-10build1) ...\n",
            "Selecting previously unselected package fonts-freefont-ttf.\n",
            "Preparing to unpack .../46-fonts-freefont-ttf_20120503-10build1_all.deb ...\n",
            "Unpacking fonts-freefont-ttf (20120503-10build1) ...\n",
            "Selecting previously unselected package fonts-gfs-artemisia.\n",
            "Preparing to unpack .../47-fonts-gfs-artemisia_1.1-6_all.deb ...\n",
            "Unpacking fonts-gfs-artemisia (1.1-6) ...\n",
            "Selecting previously unselected package fonts-gfs-complutum.\n",
            "Preparing to unpack .../48-fonts-gfs-complutum_1.1-7_all.deb ...\n",
            "Unpacking fonts-gfs-complutum (1.1-7) ...\n",
            "Selecting previously unselected package fonts-gfs-didot.\n",
            "Preparing to unpack .../49-fonts-gfs-didot_1.1-7_all.deb ...\n",
            "Unpacking fonts-gfs-didot (1.1-7) ...\n",
            "Selecting previously unselected package fonts-gfs-neohellenic.\n",
            "Preparing to unpack .../50-fonts-gfs-neohellenic_1.1-7_all.deb ...\n",
            "Unpacking fonts-gfs-neohellenic (1.1-7) ...\n",
            "Selecting previously unselected package fonts-gfs-olga.\n",
            "Preparing to unpack .../51-fonts-gfs-olga_1.1-6_all.deb ...\n",
            "Unpacking fonts-gfs-olga (1.1-6) ...\n",
            "Selecting previously unselected package fonts-gfs-solomos.\n",
            "Preparing to unpack .../52-fonts-gfs-solomos_1.1-6_all.deb ...\n",
            "Unpacking fonts-gfs-solomos (1.1-6) ...\n",
            "Selecting previously unselected package fonts-go.\n",
            "Preparing to unpack .../53-fonts-go_0~20170330-1_all.deb ...\n",
            "Unpacking fonts-go (0~20170330-1) ...\n",
            "Selecting previously unselected package fonts-junicode.\n",
            "Preparing to unpack .../54-fonts-junicode_1.002-2_all.deb ...\n",
            "Unpacking fonts-junicode (1.002-2) ...\n",
            "Selecting previously unselected package fonts-linuxlibertine.\n",
            "Preparing to unpack .../55-fonts-linuxlibertine_5.3.0-6_all.deb ...\n",
            "Unpacking fonts-linuxlibertine (5.3.0-6) ...\n",
            "Selecting previously unselected package fonts-lobster.\n",
            "Preparing to unpack .../56-fonts-lobster_2.0-2.1_all.deb ...\n",
            "Unpacking fonts-lobster (2.0-2.1) ...\n",
            "Selecting previously unselected package fonts-lobstertwo.\n",
            "Preparing to unpack .../57-fonts-lobstertwo_2.0-2.1_all.deb ...\n",
            "Unpacking fonts-lobstertwo (2.0-2.1) ...\n",
            "Selecting previously unselected package fonts-noto-color-emoji.\n",
            "Preparing to unpack .../58-fonts-noto-color-emoji_2.042-0ubuntu0.22.04.1_all.deb ...\n",
            "Unpacking fonts-noto-color-emoji (2.042-0ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package fonts-noto-core.\n",
            "Preparing to unpack .../59-fonts-noto-core_20201225-1build1_all.deb ...\n",
            "Unpacking fonts-noto-core (20201225-1build1) ...\n",
            "Selecting previously unselected package fonts-noto-mono.\n",
            "Preparing to unpack .../60-fonts-noto-mono_20201225-1build1_all.deb ...\n",
            "Unpacking fonts-noto-mono (20201225-1build1) ...\n",
            "Selecting previously unselected package fonts-oflb-asana-math.\n",
            "Preparing to unpack .../61-fonts-oflb-asana-math_000.907-7build1_all.deb ...\n",
            "Unpacking fonts-oflb-asana-math (000.907-7build1) ...\n",
            "Selecting previously unselected package fonts-open-sans.\n",
            "Preparing to unpack .../62-fonts-open-sans_1.11-2_all.deb ...\n",
            "Unpacking fonts-open-sans (1.11-2) ...\n",
            "Selecting previously unselected package fonts-roboto-unhinted.\n",
            "Preparing to unpack .../63-fonts-roboto-unhinted_2%3a0~20170802-3_all.deb ...\n",
            "Unpacking fonts-roboto-unhinted (2:0~20170802-3) ...\n",
            "Selecting previously unselected package fonts-sil-charis.\n",
            "Preparing to unpack .../64-fonts-sil-charis_6.101-1_all.deb ...\n",
            "Unpacking fonts-sil-charis (6.101-1) ...\n",
            "Selecting previously unselected package fonts-sil-gentium.\n",
            "Preparing to unpack .../65-fonts-sil-gentium_20081126%3a1.03-4_all.deb ...\n",
            "Unpacking fonts-sil-gentium (20081126:1.03-4) ...\n",
            "Selecting previously unselected package fonts-sil-gentium-basic.\n",
            "Preparing to unpack .../66-fonts-sil-gentium-basic_1.102-1.1_all.deb ...\n",
            "Unpacking fonts-sil-gentium-basic (1.102-1.1) ...\n",
            "Selecting previously unselected package fonts-sil-gentiumplus.\n",
            "Preparing to unpack .../67-fonts-sil-gentiumplus_6.101-1_all.deb ...\n",
            "Unpacking fonts-sil-gentiumplus (6.101-1) ...\n",
            "Selecting previously unselected package fonts-sil-gentiumplus-compact.\n",
            "Preparing to unpack .../68-fonts-sil-gentiumplus-compact_5.000-4_all.deb ...\n",
            "Unpacking fonts-sil-gentiumplus-compact (5.000-4) ...\n",
            "Selecting previously unselected package fonts-texgyre.\n",
            "Preparing to unpack .../69-fonts-texgyre_20180621-3.1_all.deb ...\n",
            "Unpacking fonts-texgyre (20180621-3.1) ...\n",
            "Selecting previously unselected package libapache-pom-java.\n",
            "Preparing to unpack .../70-libapache-pom-java_18-1_all.deb ...\n",
            "Unpacking libapache-pom-java (18-1) ...\n",
            "Selecting previously unselected package libcommons-parent-java.\n",
            "Preparing to unpack .../71-libcommons-parent-java_43-1_all.deb ...\n",
            "Unpacking libcommons-parent-java (43-1) ...\n",
            "Selecting previously unselected package libcommons-logging-java.\n",
            "Preparing to unpack .../72-libcommons-logging-java_1.2-2_all.deb ...\n",
            "Unpacking libcommons-logging-java (1.2-2) ...\n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "Preparing to unpack .../73-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Selecting previously unselected package rubygems-integration.\n",
            "Preparing to unpack .../74-rubygems-integration_1.18_all.deb ...\n",
            "Unpacking rubygems-integration (1.18) ...\n",
            "Selecting previously unselected package ruby3.0.\n",
            "Preparing to unpack .../75-ruby3.0_3.0.2-7ubuntu2.8_amd64.deb ...\n",
            "Unpacking ruby3.0 (3.0.2-7ubuntu2.8) ...\n",
            "Selecting previously unselected package ruby-rubygems.\n",
            "Preparing to unpack .../76-ruby-rubygems_3.3.5-2_all.deb ...\n",
            "Unpacking ruby-rubygems (3.3.5-2) ...\n",
            "Selecting previously unselected package ruby.\n",
            "Preparing to unpack .../77-ruby_1%3a3.0~exp1_amd64.deb ...\n",
            "Unpacking ruby (1:3.0~exp1) ...\n",
            "Selecting previously unselected package rake.\n",
            "Preparing to unpack .../78-rake_13.0.6-2_all.deb ...\n",
            "Unpacking rake (13.0.6-2) ...\n",
            "Selecting previously unselected package ruby-net-telnet.\n",
            "Preparing to unpack .../79-ruby-net-telnet_0.1.1-2_all.deb ...\n",
            "Unpacking ruby-net-telnet (0.1.1-2) ...\n",
            "Selecting previously unselected package ruby-webrick.\n",
            "Preparing to unpack .../80-ruby-webrick_1.7.0-3ubuntu0.1_all.deb ...\n",
            "Unpacking ruby-webrick (1.7.0-3ubuntu0.1) ...\n",
            "Selecting previously unselected package ruby-xmlrpc.\n",
            "Preparing to unpack .../81-ruby-xmlrpc_0.3.2-1ubuntu0.1_all.deb ...\n",
            "Unpacking ruby-xmlrpc (0.3.2-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libruby3.0:amd64.\n",
            "Preparing to unpack .../82-libruby3.0_3.0.2-7ubuntu2.8_amd64.deb ...\n",
            "Unpacking libruby3.0:amd64 (3.0.2-7ubuntu2.8) ...\n",
            "Selecting previously unselected package xfonts-encodings.\n",
            "Preparing to unpack .../83-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\n",
            "Unpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Selecting previously unselected package xfonts-utils.\n",
            "Preparing to unpack .../84-xfonts-utils_1%3a7.7+6build2_amd64.deb ...\n",
            "Unpacking xfonts-utils (1:7.7+6build2) ...\n",
            "Selecting previously unselected package lmodern.\n",
            "Preparing to unpack .../85-lmodern_2.004.5-6.1_all.deb ...\n",
            "Unpacking lmodern (2.004.5-6.1) ...\n",
            "Selecting previously unselected package preview-latex-style.\n",
            "Preparing to unpack .../86-preview-latex-style_12.2-1ubuntu1_all.deb ...\n",
            "Unpacking preview-latex-style (12.2-1ubuntu1) ...\n",
            "Selecting previously unselected package tex-gyre.\n",
            "Preparing to unpack .../87-tex-gyre_20180621-3.1_all.deb ...\n",
            "Unpacking tex-gyre (20180621-3.1) ...\n",
            "Selecting previously unselected package texlive-fonts-extra.\n",
            "Preparing to unpack .../88-texlive-fonts-extra_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-fonts-extra (2021.20220204-1) ...\n",
            "Selecting previously unselected package fonts-stix.\n",
            "Preparing to unpack .../89-fonts-stix_1.1.1-4.1_all.deb ...\n",
            "Unpacking fonts-stix (1.1.1-4.1) ...\n",
            "Selecting previously unselected package texlive-fonts-extra-links.\n",
            "Preparing to unpack .../90-texlive-fonts-extra-links_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-fonts-extra-links (2021.20220204-1) ...\n",
            "Selecting previously unselected package texlive-fonts-recommended.\n",
            "Preparing to unpack .../91-texlive-fonts-recommended_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-fonts-recommended (2021.20220204-1) ...\n",
            "Selecting previously unselected package libfontbox-java.\n",
            "Preparing to unpack .../92-libfontbox-java_1%3a1.8.16-2_all.deb ...\n",
            "Unpacking libfontbox-java (1:1.8.16-2) ...\n",
            "Selecting previously unselected package libpdfbox-java.\n",
            "Preparing to unpack .../93-libpdfbox-java_1%3a1.8.16-2_all.deb ...\n",
            "Unpacking libpdfbox-java (1:1.8.16-2) ...\n",
            "Selecting previously unselected package texlive-pictures.\n",
            "Preparing to unpack .../94-texlive-pictures_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-pictures (2021.20220204-1) ...\n",
            "Selecting previously unselected package texlive-latex-extra.\n",
            "Preparing to unpack .../95-texlive-latex-extra_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-latex-extra (2021.20220204-1) ...\n",
            "Selecting previously unselected package texlive-plain-generic.\n",
            "Preparing to unpack .../96-texlive-plain-generic_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-plain-generic (2021.20220204-1) ...\n",
            "Selecting previously unselected package tipa.\n",
            "Preparing to unpack .../97-tipa_2%3a1.3-21_all.deb ...\n",
            "Unpacking tipa (2:1.3-21) ...\n",
            "Setting up pfb2t1c2pfb (0.3-11) ...\n",
            "Setting up fonts-gfs-didot (1.1-7) ...\n",
            "Setting up fonts-gfs-artemisia (1.1-6) ...\n",
            "Setting up fonts-sil-gentium-basic (1.102-1.1) ...\n",
            "Setting up fonts-cantarell (0.303-2) ...\n",
            "Setting up fonts-ebgaramond (0.016+git20210310.42d4f9f2-1) ...\n",
            "Setting up fonts-lato (2.0-2.1) ...\n",
            "Setting up fonts-junicode (1.002-2) ...\n",
            "Setting up fonts-noto-mono (20201225-1build1) ...\n",
            "Setting up libwoff1:amd64 (1.0.2-1build4) ...\n",
            "Setting up fonts-noto-color-emoji (2.042-0ubuntu0.22.04.1) ...\n",
            "Setting up libtexlua53:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Setting up fonts-adf-berenis (0.20190904-2) ...\n",
            "Setting up libijs-0.35:amd64 (0.35-15build2) ...\n",
            "Setting up libtexluajit2:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Setting up libfontbox-java (1:1.8.16-2) ...\n",
            "Setting up fonts-freefont-otf (20120503-10build1) ...\n",
            "Setting up fonts-freefont-ttf (20120503-10build1) ...\n",
            "Setting up fonts-gfs-solomos (1.1-6) ...\n",
            "Setting up fonts-comfortaa (3.001-3) ...\n",
            "Setting up rubygems-integration (1.18) ...\n",
            "Setting up libzzip-0-13:amd64 (0.13.72+dfsg.1-1.1) ...\n",
            "Setting up fonts-sil-gentiumplus-compact (5.000-4) ...\n",
            "Setting up fonts-roboto-unhinted (2:0~20170802-3) ...\n",
            "Setting up fonts-urw-base35 (20200910-1) ...\n",
            "Setting up fonts-open-sans (1.11-2) ...\n",
            "Setting up fonts-sil-gentiumplus (6.101-1) ...\n",
            "Setting up fonts-gfs-neohellenic (1.1-7) ...\n",
            "Setting up fonts-gfs-olga (1.1-6) ...\n",
            "Setting up fonts-oflb-asana-math (000.907-7build1) ...\n",
            "Setting up poppler-data (0.4.11-1) ...\n",
            "Setting up fonts-crosextra-carlito (20130920-1.1) ...\n",
            "Setting up fonts-adf-accanthis (0.20190904-2) ...\n",
            "Setting up tex-common (6.17) ...\n",
            "update-language: texlive-base not installed and configured, doing nothing!\n",
            "Setting up fonts-sil-gentium (20081126:1.03-4) ...\n",
            "Setting up fonts-adf-universalis (0.20190904-2) ...\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Setting up fonts-stix (1.1.1-4.1) ...\n",
            "Setting up fonts-sil-charis (6.101-1) ...\n",
            "Setting up libjbig2dec0:amd64 (0.19-3build2) ...\n",
            "Setting up fonts-go (0~20170330-1) ...\n",
            "Setting up libteckit0:amd64 (2.5.11+ds1-1) ...\n",
            "Setting up libapache-pom-java (18-1) ...\n",
            "Setting up ruby-net-telnet (0.1.1-2) ...\n",
            "Setting up fonts-cabin (1.5-3) ...\n",
            "Setting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Setting up t1utils (1.41-4build2) ...\n",
            "Setting up libidn12:amd64 (1.38-4ubuntu1) ...\n",
            "Setting up fonts-dejavu-core (2.37-2build1) ...\n",
            "Setting up fonts-texgyre (20180621-3.1) ...\n",
            "Setting up fonts-linuxlibertine (5.3.0-6) ...\n",
            "Setting up libkpathsea6:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Setting up fonts-croscore (20201225-1build1) ...\n",
            "Setting up ruby-webrick (1.7.0-3ubuntu0.1) ...\n",
            "Setting up fonts-dejavu-extra (2.37-2build1) ...\n",
            "Setting up fonts-gfs-complutum (1.1-7) ...\n",
            "Setting up fonts-crosextra-caladea (20130214-2.1) ...\n",
            "Setting up fonts-lmodern (2.004.5-6.1) ...\n",
            "Setting up fonts-ebgaramond-extra (0.016+git20210310.42d4f9f2-1) ...\n",
            "Setting up fonts-lobster (2.0-2.1) ...\n",
            "Setting up fonts-droid-fallback (1:6.0.1r16-1.1build1) ...\n",
            "Setting up fonts-adf-gillius (0.20190904-2) ...\n",
            "Setting up ruby-xmlrpc (0.3.2-1ubuntu0.1) ...\n",
            "Setting up fonts-noto-core (20201225-1build1) ...\n",
            "Setting up fonts-font-awesome (5.0.10+really4.7.0~dfsg-4.1) ...\n",
            "Setting up libsynctex2:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Setting up libgs9-common (9.55.0~dfsg1-0ubuntu5.10) ...\n",
            "Setting up libpdfbox-java (1:1.8.16-2) ...\n",
            "Setting up libgs9:amd64 (9.55.0~dfsg1-0ubuntu5.10) ...\n",
            "Setting up preview-latex-style (12.2-1ubuntu1) ...\n",
            "Setting up libcommons-parent-java (43-1) ...\n",
            "Setting up dvisvgm (2.13.1-1) ...\n",
            "Setting up libcommons-logging-java (1.2-2) ...\n",
            "Setting up ghostscript (9.55.0~dfsg1-0ubuntu5.10) ...\n",
            "Setting up xfonts-utils (1:7.7+6build2) ...\n",
            "Setting up fonts-lobstertwo (2.0-2.1) ...\n",
            "Setting up libptexenc1:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Setting up texlive-fonts-extra-links (2021.20220204-1) ...\n",
            "Setting up texlive-binaries (2021.20210626.59705-1ubuntu0.2) ...\n",
            "update-alternatives: using /usr/bin/xdvi-xaw to provide /usr/bin/xdvi.bin (xdvi.bin) in auto mode\n",
            "update-alternatives: using /usr/bin/bibtex.original to provide /usr/bin/bibtex (bibtex) in auto mode\n",
            "Setting up lmodern (2.004.5-6.1) ...\n",
            "Setting up texlive-base (2021.20220204-1) ...\n",
            "/usr/bin/ucfr\n",
            "/usr/bin/ucfr\n",
            "/usr/bin/ucfr\n",
            "/usr/bin/ucfr\n",
            "mktexlsr: Updating /var/lib/texmf/ls-R-TEXLIVEDIST... \n",
            "mktexlsr: Updating /var/lib/texmf/ls-R-TEXMFMAIN... \n",
            "mktexlsr: Updating /var/lib/texmf/ls-R... \n",
            "mktexlsr: Done.\n",
            "tl-paper: setting paper size for dvips to a4: /var/lib/texmf/dvips/config/config-paper.ps\n",
            "tl-paper: setting paper size for dvipdfmx to a4: /var/lib/texmf/dvipdfmx/dvipdfmx-paper.cfg\n",
            "tl-paper: setting paper size for xdvi to a4: /var/lib/texmf/xdvi/XDvi-paper\n",
            "tl-paper: setting paper size for pdftex to a4: /var/lib/texmf/tex/generic/tex-ini-files/pdftexconfig.tex\n",
            "Setting up tex-gyre (20180621-3.1) ...\n",
            "Setting up dvipng (1.15-1.1) ...\n",
            "Setting up texlive-plain-generic (2021.20220204-1) ...\n",
            "Setting up texlive-latex-base (2021.20220204-1) ...\n",
            "Setting up texlive-fonts-extra (2021.20220204-1) ...\n",
            "Setting up texlive-latex-recommended (2021.20220204-1) ...\n",
            "Setting up texlive-pictures (2021.20220204-1) ...\n",
            "Setting up texlive-fonts-recommended (2021.20220204-1) ...\n",
            "Setting up tipa (2:1.3-21) ...\n",
            "Setting up cm-super-minimal (0.3.4-17) ...\n",
            "Setting up texlive-latex-extra (2021.20220204-1) ...\n",
            "Setting up cm-super (0.3.4-17) ...\n",
            "Creating fonts. This may take some time... done.\n",
            "Setting up rake (13.0.6-2) ...\n",
            "Setting up libruby3.0:amd64 (3.0.2-7ubuntu2.8) ...\n",
            "Setting up ruby3.0 (3.0.2-7ubuntu2.8) ...\n",
            "Setting up ruby (1:3.0~exp1) ...\n",
            "Setting up ruby-rubygems (3.3.5-2) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "Processing triggers for tex-common (6.17) ...\n",
            "Running updmap-sys. This may take some time... done.\n",
            "Running mktexlsr /var/lib/texmf ... done.\n",
            "Building format(s) --all.\n",
            "\tThis may take some time... done.\n",
            "Requirement already satisfied: python-pptx in /usr/local/lib/python3.11/dist-packages (1.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: XlsxWriter>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (3.2.2)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (5.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (4.12.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.55.7)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "0QZmD5jwmyzU",
        "outputId": "9cf4b897-57b0-454e-8d02-25a45054e7ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload your PowerPoint template...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e177353c-157d-43c3-8fea-f3c48c4241cc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e177353c-157d-43c3-8fea-f3c48c4241cc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Crop.pptx to Crop (2).pptx\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e03f5b1c-bbea-4cbd-afc5-f61a70062d06\", \"UNDERSTANDING_LSTM_NETWORKS.pptx\", 50787)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_answer(api_response):\n",
        "    \"\"\"Extracts and validates keywords from the API response\"\"\"\n",
        "    try:\n",
        "        valid_suffixes = ['-visualization', '-diagram', '-illustration', '-example', '-steps']\n",
        "\n",
        "        # Handle different input types\n",
        "        if isinstance(api_response, list):\n",
        "            response_text = api_response[0].get('generated_text', '')\n",
        "        elif isinstance(api_response, dict):\n",
        "            response_text = api_response.get('generated_text', '')\n",
        "        else:\n",
        "            response_text = str(api_response)\n",
        "\n",
        "        # Look for the keywords section\n",
        "        if \"KEYWORDS (comma-separated):\" in response_text:\n",
        "            keywords_section = response_text.split(\"KEYWORDS (comma-separated):\")[-1].strip()\n",
        "            keyword_lines = [line.strip() for line in keywords_section.split('\\n') if line.strip()]\n",
        "\n",
        "            if not keyword_lines:\n",
        "                return []\n",
        "\n",
        "            # Take the first line of keywords\n",
        "            keywords = keyword_lines[0]\n",
        "\n",
        "            # Split and clean keywords\n",
        "            cleaned_keywords = []\n",
        "            for keyword in keywords.split(','):\n",
        "                keyword = keyword.strip()\n",
        "                if (keyword and\n",
        "                    '-' in keyword and\n",
        "                    any(keyword.endswith(suffix) for suffix in valid_suffixes) and\n",
        "                    keyword.count('-') >= 2):\n",
        "                    cleaned_keywords.append(keyword)\n",
        "\n",
        "            # Remove duplicates and limit to 7\n",
        "            cleaned_keywords = list(set(cleaned_keywords))[:7]\n",
        "\n",
        "            return cleaned_keywords if len(cleaned_keywords) >= 3 else []\n",
        "\n",
        "        return []\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting keywords: {str(e)}\")\n",
        "        return []"
      ],
      "metadata": {
        "id": "1k8UID7pLhmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####################################################################### IMAGE KEYWORD CODE ################################################################\n",
        "def create_image_keyword_prompt(content):\n",
        "    \"\"\"\n",
        "    Creates a prompt for generating image search keywords that works with any technical topic.\n",
        "\n",
        "    Args:\n",
        "        content (str): Technical content to analyze for image-searchable keywords\n",
        "\n",
        "    Returns:\n",
        "        str: Generic prompt that works with any technical content\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"You are a technical visualization expert. Extract specific image search keywords from the following content:\n",
        "\n",
        "{content}\n",
        "\n",
        "Your task: Generate 2-3 max most relevant image search keywords that would help find educational diagrams and technical visualizations related to the main concepts in this content.\n",
        "\n",
        "Focus on identifying keywords for:\n",
        "1. System/concept architecture diagrams\n",
        "2. Process flows and sequences\n",
        "3. Component interactions\n",
        "4. Implementation details\n",
        "5. Working mechanisms\n",
        "6. Step-by-step procedures\n",
        "7. Technical examples\n",
        "\n",
        "Keyword Generation Rules:\n",
        "1. Each keyword MUST use hyphens between words\n",
        "2. Each keyword MUST end with exactly ONE of these suffixes:\n",
        "   - -visualization\n",
        "   - -diagram\n",
        "   - -illustration\n",
        "   - -example\n",
        "   - -steps\n",
        "\n",
        "Key Requirements:\n",
        "- Use specific technical terms from the content\n",
        "- Include major concepts and processes\n",
        "- Avoid generic/non-specific terms\n",
        "- Keywords must directly relate to main topics\n",
        "- Each keyword should help find relevant technical diagrams\n",
        "\n",
        "Output Format:\n",
        "ONLY provide a comma-separated list of keywords. Example:\n",
        "concept-architecture-diagram, process-flow-visualization, component-interaction-illustration\n",
        "\n",
        "KEYWORDS (comma-separated):\"\"\"\n",
        "\n",
        "    return prompt\n",
        "\n",
        "# Modify the main function to work with your existing setup\n",
        "def main():\n",
        "    # Use your existing content and context\n",
        "    prompt = create_image_keyword_prompt(result)\n",
        "    #print(prompt)\n",
        "\n",
        "    # Use your existing API call function\n",
        "    api_response = query_huggingface_api(prompt, max_length=25000)\n",
        "\n",
        "    # Extract the keywords\n",
        "    image_keywords = extract_answer(api_response)\n",
        "\n",
        "    print(\"Generated Image Search Keywords:\")\n",
        "    print(image_keywords)\n",
        "\n",
        "    image_keywords = image_keywords[:3]\n",
        "    print(image_keywords)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMN77_iI56gh",
        "outputId": "99cf27f8-b864-405e-da66-5d25522897f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Image Search Keywords:\n",
            "['lstm-cell-diagram', 'lstm-working-mechanism-steps', 'input-gate-forget-gate-output-gate-illustration', 'long-short-term-memory-lstm-visualization', 'lstm-implementation-example']\n",
            "['lstm-cell-diagram', 'lstm-working-mechanism-steps', 'input-gate-forget-gate-output-gate-illustration']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import requests\n",
        "from pptx import Presentation\n",
        "from pptx.util import Inches, Pt\n",
        "from pptx.enum.text import PP_ALIGN\n",
        "from pptx.dml.color import RGBColor\n",
        "\n",
        "def scrape_images(keyword, num_images=4):\n",
        "    \"\"\"Scrape images from GeeksForGeeks using SERP API\"\"\"\n",
        "    api_key = \"df7729cfcc6f85cfea8e18cb9f13ce5180a3ea6e1c22e2e5f3de3ea16bd6e40b\"\n",
        "\n",
        "    params = {\n",
        "        \"engine\": \"google_images\",\n",
        "        \"q\": keyword,\n",
        "        \"google_domain\": \"google.com\",\n",
        "        \"gl\": \"us\",\n",
        "        \"hl\": \"en\",\n",
        "        \"api_key\": api_key,\n",
        "    }\n",
        "\n",
        "    response = requests.get(\"https://serpapi.com/search.json\", params=params)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        images = []\n",
        "\n",
        "        if \"images_results\" in data:\n",
        "            for image in data[\"images_results\"]:\n",
        "                if 'geeksforgeeks' in image.get('source', '').lower():\n",
        "                    images.append(image[\"original\"])\n",
        "                    if len(images) >= num_images:\n",
        "                        break\n",
        "            return images\n",
        "\n",
        "        return []\n",
        "    else:\n",
        "        print(f\"Failed to retrieve images. Status code: {response.status_code}\")\n",
        "        return []\n",
        "\n"
      ],
      "metadata": {
        "id": "hBj1ZMpP6C2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###############################################  WITH IMAGES #######################################\n",
        "import requests\n",
        "from pptx import Presentation\n",
        "from pptx.util import Inches, Pt\n",
        "from pptx.enum.text import PP_ALIGN, MSO_VERTICAL_ANCHOR\n",
        "from pptx.dml.color import RGBColor\n",
        "import re\n",
        "import io\n",
        "from PIL import Image\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class SlideContentManager:\n",
        "    def __init__(self, slide):\n",
        "        self.slide = slide\n",
        "        self.current_top = Inches(2)\n",
        "\n",
        "    def add_content(self, content, level, content_type):\n",
        "        \"\"\"Add content to slide with proper spacing\"\"\"\n",
        "        if content_type in ['code', 'code_continued']:\n",
        "            height = self._add_code_block(content)\n",
        "            self.current_top += height + Inches(0.6)\n",
        "        elif content_type == 'equation':\n",
        "            success = self._add_equation(content)\n",
        "            if success:\n",
        "                self.current_top += Inches(0.8)\n",
        "        elif content_type == 'subheading':\n",
        "            self._add_subheading(content)\n",
        "            self.current_top += Inches(0.6)\n",
        "        elif content_type == 'image':\n",
        "            self._add_image(content)\n",
        "            self.current_top += Inches(2)\n",
        "        else:\n",
        "            self._add_text_content(content, level)\n",
        "            self.current_top += Inches(0.4)\n",
        "\n",
        "    def _add_image(self, image_url):\n",
        "        \"\"\"Add an image to the slide, with optimized sizing and proper centering\"\"\"\n",
        "        try:\n",
        "            # Download the image\n",
        "            response = requests.get(image_url)\n",
        "            if response.status_code == 200:\n",
        "                # Open the image using Pillow\n",
        "                img_buf = io.BytesIO(response.content)\n",
        "                original_img = Image.open(img_buf)\n",
        "\n",
        "                # Convert image to RGB mode\n",
        "                img = original_img.convert('RGB')\n",
        "\n",
        "                # Define slide dimensions in inches (standard 16:9 ratio)\n",
        "                SLIDE_WIDTH_INCHES = 10\n",
        "                SLIDE_HEIGHT_INCHES = 5.625\n",
        "\n",
        "                # Get original image dimensions in pixels\n",
        "                img_width_pixels, img_height_pixels = img.size\n",
        "\n",
        "                # Convert to inches (assuming 96 DPI)\n",
        "                img_width_inches = img_width_pixels / 96\n",
        "                img_height_inches = img_height_pixels / 96\n",
        "\n",
        "                # Calculate maximum allowed dimensions (70% of slide)\n",
        "                max_width_inches = SLIDE_WIDTH_INCHES * 0.7\n",
        "                max_height_inches = SLIDE_HEIGHT_INCHES * 0.7\n",
        "\n",
        "                # Calculate scaling factor to fit within maximum dimensions\n",
        "                width_scale = max_width_inches / img_width_inches\n",
        "                height_scale = max_height_inches / img_height_inches\n",
        "                scale = min(width_scale, height_scale)\n",
        "\n",
        "                # Calculate final dimensions in inches\n",
        "                final_width_inches = img_width_inches * scale\n",
        "                final_height_inches = img_height_inches * scale\n",
        "\n",
        "                # Calculate centering positions in inches\n",
        "                left_inches = (SLIDE_WIDTH_INCHES - final_width_inches) / 2\n",
        "                top_inches = (SLIDE_HEIGHT_INCHES - final_height_inches) / 2\n",
        "\n",
        "                # Convert the image to the new size in pixels\n",
        "                new_width_pixels = int(final_width_inches * 96)\n",
        "                new_height_pixels = int(final_height_inches * 96)\n",
        "                img = img.resize((new_width_pixels, new_height_pixels), Image.LANCZOS)\n",
        "\n",
        "                # Save as PNG\n",
        "                png_buf = io.BytesIO()\n",
        "                img.save(png_buf, format='PNG')\n",
        "                png_buf.seek(0)\n",
        "\n",
        "                # Add image to slide using Inches for all measurements\n",
        "                self.slide.shapes.add_picture(\n",
        "                    png_buf,\n",
        "                    Inches(left_inches),\n",
        "                    Inches(top_inches),\n",
        "                    width=Inches(final_width_inches),\n",
        "                    height=Inches(final_height_inches)\n",
        "                )\n",
        "                print(f\"Successfully added image: {image_url}\")\n",
        "                return True\n",
        "            else:\n",
        "                print(f\"Failed to download image. Status code: {response.status_code}\")\n",
        "                return False\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing image {image_url}: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def _add_text_content(self, text, level):\n",
        "        \"\"\"Add text content with proper formatting\"\"\"\n",
        "        content_shape = self.slide.placeholders[1]\n",
        "        text_frame = content_shape.text_frame\n",
        "\n",
        "        paragraph = text_frame.add_paragraph()\n",
        "        paragraph.level = level\n",
        "\n",
        "        parts = re.split(r'(\\*\\*.*?\\*\\*)', text)\n",
        "        for part in parts:\n",
        "            if part:\n",
        "                run = paragraph.add_run()\n",
        "                if part.startswith('**') and part.endswith('**'):\n",
        "                    run.text = part.strip('*')\n",
        "                    run.font.bold = True\n",
        "                else:\n",
        "                    run.text = part\n",
        "                    run.font.bold = False\n",
        "                run.font.size = Pt(14)\n",
        "\n",
        "        if level == 2:\n",
        "            paragraph.indent = Inches(0.5)\n",
        "\n",
        "    def _add_subheading(self, text):\n",
        "        \"\"\"Add subheading with proper formatting\"\"\"\n",
        "        content_shape = self.slide.placeholders[1]\n",
        "        text_frame = content_shape.text_frame\n",
        "\n",
        "        paragraph = text_frame.add_paragraph()\n",
        "        run = paragraph.add_run()\n",
        "        run.text = text[2:].strip() if text.startswith('##') else text.strip()\n",
        "        run.font.bold = True\n",
        "        run.font.size = Pt(16)\n",
        "\n",
        "    def _add_code_block(self, code):\n",
        "        \"\"\"Add code block with proper spacing\"\"\"\n",
        "        left = Inches(1)\n",
        "        width = Inches(11)\n",
        "\n",
        "        line_height = Inches(0.3)\n",
        "        total_height = len(code.split('\\n')) * line_height + Inches(0.5)\n",
        "\n",
        "        textbox = self.slide.shapes.add_textbox(left, self.current_top, width, total_height)\n",
        "        text_frame = textbox.text_frame\n",
        "\n",
        "        paragraph = text_frame.add_paragraph()\n",
        "        run = paragraph.add_run()\n",
        "        run.text = code\n",
        "        run.font.name = 'Courier New'\n",
        "        run.font.size = Pt(11)\n",
        "\n",
        "        fill = textbox.fill\n",
        "        fill.solid()\n",
        "        fill.fore_color.rgb = RGBColor(245, 245, 245)\n",
        "\n",
        "        return total_height\n",
        "\n",
        "    def _add_equation(self, equation):\n",
        "        \"\"\"Add equation with proper spacing\"\"\"\n",
        "        try:\n",
        "            plt.rc('text', usetex=True)\n",
        "            plt.rc('font', family='serif')\n",
        "\n",
        "            fig = plt.figure(figsize=(10, 1))\n",
        "            plt.axis('off')\n",
        "            plt.text(0.5, 0.5, f'${equation}$',\n",
        "                    fontsize=14,\n",
        "                    horizontalalignment='center',\n",
        "                    verticalalignment='center')\n",
        "\n",
        "            buf = io.BytesIO()\n",
        "            plt.savefig(buf, format='png', dpi=300, bbox_inches='tight', transparent=True)\n",
        "            plt.close(fig)\n",
        "\n",
        "            buf.seek(0)\n",
        "            left = Inches(1)\n",
        "            self.slide.shapes.add_picture(buf, left, self.current_top, height=Inches(0.8))\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"Error rendering equation: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "class SlideGenerator:\n",
        "    def __init__(self, presentation_title, template_path):\n",
        "        self.prs = Presentation(template_path)\n",
        "        self.presentation_title = presentation_title\n",
        "        self.used_images = set()\n",
        "\n",
        "    def _add_title_slide(self):\n",
        "        \"\"\"Create title slide\"\"\"\n",
        "        slide = self.prs.slides.add_slide(self.prs.slide_layouts[0])\n",
        "        title_shape = slide.shapes.title\n",
        "        title_shape.text = self.presentation_title\n",
        "\n",
        "        paragraph = title_shape.text_frame.paragraphs[0]\n",
        "        paragraph.alignment = PP_ALIGN.CENTER\n",
        "        run = paragraph.runs[0]\n",
        "        run.font.size = Pt(44)\n",
        "        run.font.bold = True\n",
        "        run.font.color.rgb = RGBColor(44, 62, 80)\n",
        "\n",
        "    def _create_content_slides(self, title, content_chunk, slide_number=1, total_slides=1, image_keywords=None):\n",
        "        \"\"\"Create content slides with properly spaced images\"\"\"\n",
        "        # Create main content slide\n",
        "        slide = self.prs.slides.add_slide(self.prs.slide_layouts[1])\n",
        "        content_manager = SlideContentManager(slide)\n",
        "\n",
        "        # Add and format slide title\n",
        "        title_shape = slide.shapes.title\n",
        "        clean_title = self._clean_title(title)\n",
        "        title_shape.text = f\"{clean_title} ({slide_number}/{total_slides})\" if total_slides > 1 else clean_title\n",
        "        title_run = title_shape.text_frame.paragraphs[0].runs[0]\n",
        "        title_run.font.size = Pt(32)\n",
        "        title_run.font.bold = True\n",
        "\n",
        "        # Add content\n",
        "        full_content = ' '.join([content for content, _, _ in content_chunk])\n",
        "        for content, level, content_type in content_chunk:\n",
        "            content_manager.add_content(content, level, content_type)\n",
        "\n",
        "        # Handle images after content - STRICT limit to 3 images total\n",
        "        if image_keywords and slide_number == 1 and len(self.used_images) < 3:\n",
        "            for keyword in image_keywords[:3 - len(self.used_images)]:\n",
        "                if len(self.used_images) >= 3:  # Double-check limit\n",
        "                    break\n",
        "\n",
        "                try:\n",
        "                    # Create a new slide for the image\n",
        "                    img_slide = self.prs.slides.add_slide(self.prs.slide_layouts[1])\n",
        "                    img_content_manager = SlideContentManager(img_slide)\n",
        "\n",
        "                    # Set image slide title (smaller font)\n",
        "                    img_title_shape = img_slide.shapes.title\n",
        "                    img_title_shape.text = f\"{clean_title} - {keyword.replace('-', ' ').title()}\"\n",
        "                    img_title_run = img_title_shape.text_frame.paragraphs[0].runs[0]\n",
        "                    img_title_run.font.size = Pt(24)\n",
        "\n",
        "                    # Get and add image\n",
        "                    images = scrape_images(f\"{keyword} related to {full_content}\")\n",
        "                    if images and len(self.used_images) < 3:  # Re-check limit\n",
        "                        image_url = images[0]\n",
        "                        if image_url not in self.used_images:\n",
        "                            if img_content_manager._add_image(image_url):\n",
        "                                self.used_images.add(image_url)\n",
        "                                print(f\"Added image {len(self.used_images)}/3 for keyword: {keyword}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing image for keyword '{keyword}': {e}\")\n",
        "                    continue\n",
        "\n",
        "    def _clean_title(self, title):\n",
        "        \"\"\"Remove markdown formatting from title\"\"\"\n",
        "        return title.replace('**', '').strip()\n",
        "\n",
        "    def generate_presentation(self, content, image_keywords=None):\n",
        "        \"\"\"Generate presentation with content and properly distributed images\"\"\"\n",
        "        sections = re.split(r'##\\s+\\d+\\.\\s+', content)[1:]\n",
        "        self._add_title_slide()\n",
        "\n",
        "        for section in sections:\n",
        "            title_match = re.match(r'\\*\\*(.*?)\\*\\*', section)\n",
        "            if title_match:\n",
        "                title = title_match.group(1)\n",
        "                content = section[title_match.end():].strip()\n",
        "\n",
        "                # Distribute content across slides\n",
        "                chunks = self._distribute_content(content)\n",
        "                for i, chunk in enumerate(chunks, 1):\n",
        "                    self._create_content_slides(\n",
        "                        title,\n",
        "                        chunk,\n",
        "                        i,\n",
        "                        len(chunks),\n",
        "                        image_keywords if i == 1 else None\n",
        "                    )\n",
        "\n",
        "    def _distribute_content(self, content):\n",
        "        \"\"\"Distribute content into well-spaced chunks, keeping related content together\"\"\"\n",
        "        lines = content.split('\\n')\n",
        "        chunks = []\n",
        "        current_chunk = []\n",
        "\n",
        "        for i, line in enumerate(lines):\n",
        "            if line.strip():\n",
        "                # Identify if line is a bullet point or subheading\n",
        "                is_bullet = line.strip().startswith('■') or line.strip().startswith('•')\n",
        "                is_subheading = line.strip().startswith('##')\n",
        "\n",
        "                # Start new chunk if we find a bullet/subheading and already have content\n",
        "                if (is_bullet or is_subheading) and current_chunk:\n",
        "                    chunks.append(current_chunk)\n",
        "                    current_chunk = []\n",
        "\n",
        "                # Add the current line with appropriate type\n",
        "                content_type = 'subheading' if is_subheading else 'text'\n",
        "                level = 1 if is_bullet else 0\n",
        "                current_chunk.append((line.strip(), level, content_type))\n",
        "\n",
        "                # Look ahead to see if next line is related content\n",
        "                if i < len(lines) - 1:\n",
        "                    next_line = lines[i + 1].strip()\n",
        "                    if next_line and not (next_line.startswith('■') or next_line.startswith('•') or next_line.startswith('##')):\n",
        "                        continue\n",
        "\n",
        "            elif current_chunk:  # Empty line and we have content\n",
        "                chunks.append(current_chunk)\n",
        "                current_chunk = []\n",
        "\n",
        "        # Add the last chunk if it exists\n",
        "        if current_chunk:\n",
        "            chunks.append(current_chunk)\n",
        "\n",
        "        # If no chunks were created, return the content as a single chunk\n",
        "        if not chunks:\n",
        "            return [[(content.strip(), 0, 'text')]]\n",
        "\n",
        "        return chunks\n",
        "\n",
        "    def save(self):\n",
        "        \"\"\"Save presentation with query-based filename\"\"\"\n",
        "        filename = f\"{self.presentation_title.replace(' ', '_')}.pptx\"\n",
        "        self.prs.save(filename)\n",
        "        files.download(filename)\n",
        "\n",
        "\n",
        "def create_presentation(query, content, template_path, image_keywords=None):\n",
        "    \"\"\"Main function to create presentation\"\"\"\n",
        "    generator = SlideGenerator(query.upper(), template_path)\n",
        "    generator.generate_presentation(content, image_keywords)\n",
        "    generator.save()\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Please upload your PowerPoint template...\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    template_path = next(iter(uploaded.keys()))\n",
        "\n",
        "    with open('content.txt', 'r') as file:\n",
        "        content = file.read()\n",
        "\n",
        "    prompt = create_image_keyword_prompt(result)\n",
        "    api_response = query_huggingface_api(prompt, max_length=25000)\n",
        "    image_keywords = extract_answer(api_response)\n",
        "    image_keywords = image_keywords[:3]\n",
        "\n",
        "    print(\"Generated Image Search Keywords:\")\n",
        "    print(image_keywords)\n",
        "\n",
        "    # Create the presentation using the generated keywords\n",
        "    create_presentation(query, content, template_path, image_keywords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "4XEeX5DGKPog",
        "outputId": "0834cadb-e8e3-46d2-baf1-c9c6dc1d9fd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload your PowerPoint template...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4a2583f6-b04e-48e0-9a7a-13410d2c5aff\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4a2583f6-b04e-48e0-9a7a-13410d2c5aff\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Crop.pptx to Crop (5).pptx\n",
            "Generated Image Search Keywords:\n",
            "['lstm-cell-diagram', 'lstm-working-mechanism-steps', 'input-gate-forget-gate-output-gate-illustration']\n",
            "Successfully added image: https://media.geeksforgeeks.org/wp-content/uploads/newContent1.png\n",
            "Added image 1/3 for keyword: lstm-cell-diagram\n",
            "Successfully added image: https://media.geeksforgeeks.org/wp-content/uploads/20190702161054/unrolled2.png\n",
            "Added image 2/3 for keyword: input-gate-forget-gate-output-gate-illustration\n",
            "Successfully added image: https://media.geeksforgeeks.org/wp-content/uploads/20240208053129/lstm.webp\n",
            "Added image 3/3 for keyword: lstm-cell-diagram\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_77e57180-526c-465f-bcbd-d0e2ece68828\", \"LSTM.pptx\", 252419)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import requests\n",
        "# from pptx import Presentation\n",
        "# from pptx.util import Inches, Pt\n",
        "# from pptx.enum.text import PP_ALIGN, MSO_VERTICAL_ANCHOR\n",
        "# from pptx.dml.color import RGBColor\n",
        "# import re\n",
        "# import io\n",
        "# from PIL import Image\n",
        "# from google.colab import files\n",
        "\n",
        "# # Function to scrape images from GeeksForGeeks using SERP API\n",
        "# def scrape_images(keyword, num_images=2):\n",
        "#     \"\"\"Scrape images from GeeksForGeeks using SERP API\"\"\"\n",
        "#     api_key = \"41cf19594f02970e20e9362044f5605347e8e04ce0cf4a9614504c087d2bae2e\"\n",
        "\n",
        "#     params = {\n",
        "#         \"engine\": \"google_images\",\n",
        "#         \"q\": keyword,\n",
        "#         \"google_domain\": \"google.com\",\n",
        "#         \"gl\": \"us\",\n",
        "#         \"hl\": \"en\",\n",
        "#         \"api_key\": api_key,\n",
        "#     }\n",
        "\n",
        "#     response = requests.get(\"https://serpapi.com/search.json\", params=params)\n",
        "\n",
        "#     if response.status_code == 200:\n",
        "#         data = response.json()\n",
        "#         images = []\n",
        "\n",
        "#         if \"images_results\" in data:\n",
        "#             for image in data[\"images_results\"]:\n",
        "#                 if 'geeksforgeeks' in image.get('source', '').lower():\n",
        "#                     images.append(image[\"original\"])\n",
        "#                     if len(images) >= num_images:\n",
        "#                         break\n",
        "#             return images\n",
        "\n",
        "#         return []\n",
        "#     else:\n",
        "#         print(f\"Failed to retrieve images. Status code: {response.status_code}\")\n",
        "#         return []\n",
        "\n",
        "# # Function to generate image search keywords using a model\n",
        "# def create_image_keyword_prompt(content):\n",
        "#     \"\"\"Creates a prompt for generating image search keywords\"\"\"\n",
        "#     prompt = f\"\"\"You are a technical visualization expert. Extract specific image search keywords from the following content:\n",
        "\n",
        "# {content}\n",
        "\n",
        "# Your task: Generate 5-7 image search keywords that would help find educational diagrams and technical visualizations related to the main concepts in this content.\n",
        "\n",
        "# Focus on identifying keywords for:\n",
        "# 1. System/concept architecture diagrams\n",
        "# 2. Process flows and sequences\n",
        "# 3. Component interactions\n",
        "# 4. Implementation details\n",
        "# 5. Working mechanisms\n",
        "# 6. Step-by-step procedures\n",
        "# 7. Technical examples\n",
        "\n",
        "# Keyword Generation Rules:\n",
        "# 1. Each keyword MUST use hyphens between words\n",
        "# 2. Each keyword MUST end with exactly ONE of these suffixes:\n",
        "#    - -visualization\n",
        "#    - -diagram\n",
        "#    - -illustration\n",
        "#    - -example\n",
        "#    - -steps\n",
        "\n",
        "# Key Requirements:\n",
        "# - Use specific technical terms from the content\n",
        "# - Include major concepts and processes\n",
        "# - Avoid generic/non-specific terms\n",
        "# - Keywords must directly relate to main topics\n",
        "# - Each keyword should help find relevant technical diagrams\n",
        "\n",
        "# Output Format:\n",
        "# ONLY provide a comma-separated list of keywords. Example:\n",
        "# concept-architecture-diagram, process-flow-visualization, component-interaction-illustration\n",
        "\n",
        "# KEYWORDS (comma-separated):\"\"\"\n",
        "#     return prompt\n",
        "\n",
        "# # Function to extract and validate keywords from the model's response\n",
        "# def extract_answer(api_response):\n",
        "#     \"\"\"Extracts and validates keywords from the API response\"\"\"\n",
        "#     try:\n",
        "#         valid_suffixes = ['-visualization', '-diagram', '-illustration', '-example', '-steps']\n",
        "\n",
        "#         if isinstance(api_response, list):\n",
        "#             response_text = api_response[0].get('generated_text', '')\n",
        "#         elif isinstance(api_response, dict):\n",
        "#             response_text = api_response.get('generated_text', '')\n",
        "#         else:\n",
        "#             response_text = str(api_response)\n",
        "\n",
        "#         if \"KEYWORDS (comma-separated):\" not in response_text:\n",
        "#             return []\n",
        "\n",
        "#         keywords_section = response_text.split(\"KEYWORDS (comma-separated):\")[-1].strip()\n",
        "#         keyword_lines = [line.strip() for line in keywords_section.split('\\n') if line.strip()]\n",
        "#         if not keyword_lines:\n",
        "#             return []\n",
        "\n",
        "#         keywords = keyword_lines[0]\n",
        "#         cleaned_keywords = []\n",
        "\n",
        "#         for keyword in keywords.split(','):\n",
        "#             keyword = keyword.strip()\n",
        "#             if (keyword and\n",
        "#                 '-' in keyword and\n",
        "#                 any(keyword.endswith(suffix) for suffix in valid_suffixes) and\n",
        "#                 keyword.count('-') >= 2):\n",
        "#                 cleaned_keywords.append(keyword)\n",
        "\n",
        "#         cleaned_keywords = list(set(cleaned_keywords))  # Remove duplicates\n",
        "#         cleaned_keywords = cleaned_keywords[:7]\n",
        "\n",
        "#         return cleaned_keywords if len(cleaned_keywords) >= 3 else []\n",
        "\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error extracting keywords: {str(e)}\")\n",
        "#         return []\n",
        "\n",
        "# # Class to manage slide content and add images\n",
        "# class SlideContentManager:\n",
        "#     def __init__(self, slide):\n",
        "#         self.slide = slide\n",
        "#         self.current_top = Inches(2)\n",
        "\n",
        "#     def add_content(self, content, level, content_type):\n",
        "#         \"\"\"Add content to slide with proper spacing\"\"\"\n",
        "#         if content_type in ['code', 'code_continued']:\n",
        "#             height = self._add_code_block(content)\n",
        "#             self.current_top += height + Inches(0.6)\n",
        "#         elif content_type == 'equation':\n",
        "#             success = self._add_equation(content)\n",
        "#             if success:\n",
        "#                 self.current_top += Inches(0.8)\n",
        "#         elif content_type == 'subheading':\n",
        "#             self._add_subheading(content)\n",
        "#             self.current_top += Inches(0.6)\n",
        "#         elif content_type == 'image':\n",
        "#             self._add_image(content)\n",
        "#             self.current_top += Inches(2)  # Adjust spacing for images\n",
        "#         else:\n",
        "#             self._add_text_content(content, level)\n",
        "#             self.current_top += Inches(0.4)\n",
        "\n",
        "#     def _add_image(self, image_url):\n",
        "#         \"\"\"Add an image to the slide\"\"\"\n",
        "#         try:\n",
        "#             response = requests.get(image_url)\n",
        "#             if response.status_code == 200:\n",
        "#                 img_buf = io.BytesIO(response.content)\n",
        "#                 img = Image.open(img_buf)\n",
        "\n",
        "#                 # Resize image to fit slide\n",
        "#                 max_width = Inches(8)\n",
        "#                 max_height = Inches(4.5)\n",
        "#                 img.thumbnail((max_width, max_height), Image.ANTIALIAS)\n",
        "\n",
        "#                 # Save resized image to a buffer\n",
        "#                 resized_buf = io.BytesIO()\n",
        "#                 img.save(resized_buf, format='PNG')\n",
        "#                 resized_buf.seek(0)\n",
        "\n",
        "#                 # Add image to slide\n",
        "#                 left = (Inches(13.33) - img.width) / 2  # Center horizontally\n",
        "#                 self.slide.shapes.add_picture(resized_buf, left, self.current_top)\n",
        "#         except Exception as e:\n",
        "#             print(f\"Error adding image: {str(e)}\")\n",
        "\n",
        "#     def _add_text_content(self, text, level):\n",
        "#         \"\"\"Add text content with proper formatting\"\"\"\n",
        "#         content_shape = self.slide.placeholders[1]\n",
        "#         text_frame = content_shape.text_frame\n",
        "\n",
        "#         paragraph = text_frame.add_paragraph()\n",
        "#         paragraph.level = level\n",
        "\n",
        "#         # Handle text with potential bold sections\n",
        "#         parts = re.split(r'(\\*\\*.*?\\*\\*)', text)\n",
        "#         for part in parts:\n",
        "#             if part:  # Skip empty parts\n",
        "#                 run = paragraph.add_run()\n",
        "#                 if part.startswith('**') and part.endswith('**'):\n",
        "#                     run.text = part.strip('*')\n",
        "#                     run.font.bold = True\n",
        "#                 else:\n",
        "#                     run.text = part\n",
        "#                     run.font.bold = False\n",
        "#                 run.font.size = Pt(14)\n",
        "\n",
        "#         if level == 2:\n",
        "#             paragraph.indent = Inches(0.5)\n",
        "\n",
        "#     def _add_subheading(self, text):\n",
        "#         \"\"\"Add subheading with proper formatting\"\"\"\n",
        "#         content_shape = self.slide.placeholders[1]\n",
        "#         text_frame = content_shape.text_frame\n",
        "\n",
        "#         paragraph = text_frame.add_paragraph()\n",
        "#         run = paragraph.add_run()\n",
        "#         run.text = text[2:].strip()  # Remove bullet point\n",
        "#         run.font.bold = True\n",
        "#         run.font.size = Pt(16)\n",
        "\n",
        "#     def _add_code_block(self, code):\n",
        "#         \"\"\"Add code block with proper spacing\"\"\"\n",
        "#         left = Inches(1)\n",
        "#         width = Inches(11)\n",
        "\n",
        "#         line_height = Inches(0.3)\n",
        "#         total_height = len(code.split('\\n')) * line_height + Inches(0.5)\n",
        "\n",
        "#         textbox = self.slide.shapes.add_textbox(left, self.current_top, width, total_height)\n",
        "#         text_frame = textbox.text_frame\n",
        "\n",
        "#         paragraph = text_frame.add_paragraph()\n",
        "#         run = paragraph.add_run()\n",
        "#         run.text = code\n",
        "#         run.font.name = 'Courier New'\n",
        "#         run.font.size = Pt(11)\n",
        "\n",
        "#         fill = textbox.fill\n",
        "#         fill.solid()\n",
        "#         fill.fore_color.rgb = RGBColor(245, 245, 245)\n",
        "\n",
        "#         return total_height\n",
        "\n",
        "#     def _add_equation(self, equation):\n",
        "#         \"\"\"Add equation with proper spacing\"\"\"\n",
        "#         try:\n",
        "#             plt.rc('text', usetex=True)\n",
        "#             plt.rc('font', family='serif')\n",
        "\n",
        "#             fig = plt.figure(figsize=(10, 1))\n",
        "#             plt.axis('off')\n",
        "#             plt.text(0.5, 0.5, f'${equation}$',\n",
        "#                     fontsize=14,\n",
        "#                     horizontalalignment='center',\n",
        "#                     verticalalignment='center')\n",
        "\n",
        "#             buf = io.BytesIO()\n",
        "#             plt.savefig(buf, format='png', dpi=300, bbox_inches='tight', transparent=True)\n",
        "#             plt.close(fig)\n",
        "\n",
        "#             buf.seek(0)\n",
        "#             left = Inches(1)\n",
        "#             self.slide.shapes.add_picture(buf, left, self.current_top, height=Inches(0.8))\n",
        "#             return True\n",
        "#         except Exception as e:\n",
        "#             print(f\"Error rendering equation: {str(e)}\")\n",
        "#             return False\n",
        "\n",
        "# # Class to generate slides\n",
        "# class SlideGenerator:\n",
        "#     def __init__(self, presentation_title, template_path):\n",
        "#         self.prs = Presentation(template_path)\n",
        "#         self.presentation_title = presentation_title\n",
        "\n",
        "#     def _add_title_slide(self):\n",
        "#         \"\"\"Create title slide\"\"\"\n",
        "#         slide = self.prs.slides.add_slide(self.prs.slide_layouts[0])\n",
        "#         title_shape = slide.shapes.title\n",
        "#         title_shape.text = self.presentation_title\n",
        "\n",
        "#         paragraph = title_shape.text_frame.paragraphs[0]\n",
        "#         paragraph.alignment = PP_ALIGN.CENTER\n",
        "#         run = paragraph.runs[0]\n",
        "#         run.font.size = Pt(44)\n",
        "#         run.font.bold = True\n",
        "#         run.font.color.rgb = RGBColor(44, 62, 80)\n",
        "\n",
        "#     def _create_content_slides(self, title, content_chunk, slide_number=1, total_slides=1):\n",
        "#         \"\"\"Create a content slide\"\"\"\n",
        "#         slide = self.prs.slides.add_slide(self.prs.slide_layouts[1])\n",
        "#         content_manager = SlideContentManager(slide)\n",
        "\n",
        "#         # Add slide title\n",
        "#         title_shape = slide.shapes.title\n",
        "#         clean_title = self._clean_title(title)\n",
        "\n",
        "#         # Add continuation number for split slides\n",
        "#         if total_slides > 1:\n",
        "#             title_shape.text = f\"{clean_title} ({slide_number}/{total_slides})\"\n",
        "#         else:\n",
        "#             title_shape.text = clean_title\n",
        "\n",
        "#         # Format title\n",
        "#         title_run = title_shape.text_frame.paragraphs[0].runs[0]\n",
        "#         title_run.font.size = Pt(32)\n",
        "#         title_run.font.bold = True\n",
        "\n",
        "#         # Add content\n",
        "#         for content, level, content_type in content_chunk:\n",
        "#             content_manager.add_content(content, level, content_type)\n",
        "\n",
        "#         # Generate keywords and scrape images\n",
        "#         prompt = create_image_keyword_prompt(clean_title)\n",
        "#         keywords = extract_answer(prompt)  # Replace with actual model call if needed\n",
        "#         for keyword in keywords:\n",
        "#             images = scrape_images(keyword, num_images=1)\n",
        "#             for image_url in images:\n",
        "#                 content_manager.add_content(image_url, 0, 'image')\n",
        "\n",
        "#     def _clean_title(self, title):\n",
        "#         \"\"\"Remove markdown formatting from title\"\"\"\n",
        "#         return title.replace('**', '').strip()\n",
        "\n",
        "#     def generate_presentation(self, content):\n",
        "#         \"\"\"Generate presentation with properly distributed content\"\"\"\n",
        "#         sections = re.split(r'##\\s+\\d+\\.\\s+', content)[1:]\n",
        "#         self._add_title_slide()\n",
        "\n",
        "#         for section in sections:\n",
        "#             title_match = re.match(r'\\*\\*(.*?)\\*\\*', section)\n",
        "#             if title_match:\n",
        "#                 title = title_match.group(1)\n",
        "#                 content = section[title_match.end():].strip()\n",
        "\n",
        "#                 # Distribute content across slides\n",
        "#                 chunks = self._distribute_content(content)\n",
        "#                 for i, chunk in enumerate(chunks, 1):\n",
        "#                     self._create_content_slides(title, chunk, i, len(chunks))\n",
        "\n",
        "#     def _distribute_content(self, content):\n",
        "#         \"\"\"Distribute content into well-spaced chunks\"\"\"\n",
        "#         # Simplified distribution logic (can be expanded)\n",
        "#         lines = content.split('\\n')\n",
        "#         chunks = []\n",
        "#         current_chunk = []\n",
        "\n",
        "#         for line in lines:\n",
        "#             if line.strip():\n",
        "#                 current_chunk.append((line, 0, 'text'))\n",
        "#             else:\n",
        "#                 if current_chunk:\n",
        "#                     chunks.append(current_chunk)\n",
        "#                     current_chunk = []\n",
        "\n",
        "#         if current_chunk:\n",
        "#             chunks.append(current_chunk)\n",
        "\n",
        "#         return chunks\n",
        "\n",
        "#     def save(self):\n",
        "#         \"\"\"Save presentation with query-based filename\"\"\"\n",
        "#         filename = f\"{self.presentation_title.replace(' ', '_')}.pptx\"\n",
        "#         self.prs.save(filename)\n",
        "#         files.download(filename)\n",
        "\n",
        "# # Main function to create presentation\n",
        "# def create_presentation(query, content, template_path):\n",
        "#     \"\"\"Main function to create presentation\"\"\"\n",
        "#     generator = SlideGenerator(query.upper(), template_path)\n",
        "#     generator.generate_presentation(content)\n",
        "#     generator.save()\n",
        "\n",
        "# # Example usage\n",
        "# if __name__ == \"__main__\":\n",
        "#     print(\"Please upload your PowerPoint template...\")\n",
        "#     uploaded = files.upload()\n",
        "\n",
        "#     template_path = next(iter(uploaded.keys()))\n",
        "\n",
        "#     with open('content.txt', 'r') as file:\n",
        "#         content = file.read()\n",
        "\n",
        "#     create_presentation(query, content, template_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "EwyKh9uFwtZW",
        "outputId": "b7be45bd-c9d2-4465-b937-c0a32895d83a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload your PowerPoint template...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8b3c225d-24f1-4261-b91e-dbaf76cc56c4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8b3c225d-24f1-4261-b91e-dbaf76cc56c4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Crop.pptx to Crop (6).pptx\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c845cb5c-36a7-4cd5-b3a7-494252ef8b42\", \"LSTM.pptx\", 85260)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "aBET00wg4W2C",
        "outputId": "b3bfb163-8048-452c-8684-491ce0f43436"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload your PowerPoint template...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-dd60878f-7ffa-401f-b389-1a8f7240bc5c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-dd60878f-7ffa-401f-b389-1a8f7240bc5c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Crop.pptx to Crop (7).pptx\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_76fa8736-2422-481e-befd-6646596852a9\", \"LSTM.pptx\", 62492)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "################################################  WITHOUT IMAGES ################################3\n",
        "import matplotlib.pyplot as plt\n",
        "from pptx import Presentation\n",
        "from pptx.util import Inches, Pt\n",
        "from pptx.enum.text import PP_ALIGN, MSO_VERTICAL_ANCHOR\n",
        "from pptx.dml.color import RGBColor\n",
        "import re\n",
        "import io\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "import tempfile\n",
        "from google.colab import files\n",
        "\n",
        "class ContentDistributor:\n",
        "    def __init__(self):\n",
        "        self.MAX_POINTS_PER_SLIDE = 5\n",
        "        self.MAX_CODE_LINES_PER_SLIDE = 15\n",
        "        self.TITLE_MARGIN = Inches(0.5)\n",
        "        self.CONTENT_TOP_MARGIN = Inches(0.3)\n",
        "        self.BULLET_SPACING = Inches(0.4)\n",
        "        self.SUB_BULLET_INDENT = Inches(0.5)\n",
        "        self.EQUATION_SPACING = Inches(0.8)\n",
        "        self.CODE_BLOCK_SPACING = Inches(0.6)\n",
        "\n",
        "    def distribute_content(self, content):\n",
        "        \"\"\"Distribute content into well-spaced chunks\"\"\"\n",
        "        chunks = []\n",
        "        current_chunk = []\n",
        "        current_height = 0\n",
        "        point_count = 0\n",
        "\n",
        "        lines = self.process_content_lines(content)\n",
        "        i = 0\n",
        "        while i < len(lines):\n",
        "            line = lines[i]\n",
        "            content, level, content_type = line\n",
        "            line_height = self.calculate_line_height(line)\n",
        "\n",
        "            # Start new slide for subheadings\n",
        "            if content.startswith('• ') and level == 0:\n",
        "                if current_chunk:\n",
        "                    chunks.append(current_chunk)\n",
        "                    current_chunk = []\n",
        "                    current_height = 0\n",
        "                    point_count = 0\n",
        "\n",
        "            # Handle large code blocks\n",
        "            if content_type == 'code':\n",
        "                code_lines = content.split('\\n')\n",
        "                if len(code_lines) > self.MAX_CODE_LINES_PER_SLIDE:\n",
        "                    if current_chunk:\n",
        "                        chunks.append(current_chunk)\n",
        "                        current_chunk = []\n",
        "\n",
        "                    for j in range(0, len(code_lines), self.MAX_CODE_LINES_PER_SLIDE):\n",
        "                        code_chunk = code_lines[j:j + self.MAX_CODE_LINES_PER_SLIDE]\n",
        "                        chunks.append([('\\n'.join(code_chunk), 0, 'code_continued')])\n",
        "\n",
        "                    current_chunk = []\n",
        "                    current_height = 0\n",
        "                    point_count = 0\n",
        "                    i += 1\n",
        "                    continue\n",
        "\n",
        "            # Start new slide if current one is full\n",
        "            if (point_count >= self.MAX_POINTS_PER_SLIDE and level > 0) or \\\n",
        "               (current_height + line_height > Inches(5)):\n",
        "                if current_chunk:\n",
        "                    chunks.append(current_chunk)\n",
        "                    current_chunk = []\n",
        "                    current_height = 0\n",
        "                    point_count = 0\n",
        "\n",
        "            current_chunk.append(line)\n",
        "            current_height += line_height\n",
        "            if level > 0:\n",
        "                point_count += 1\n",
        "\n",
        "            i += 1\n",
        "\n",
        "        if current_chunk:\n",
        "            chunks.append(current_chunk)\n",
        "\n",
        "        return chunks\n",
        "\n",
        "    def calculate_line_height(self, line):\n",
        "        \"\"\"Calculate height needed for a line of content\"\"\"\n",
        "        content, level, content_type = line\n",
        "\n",
        "        if content_type in ['code', 'code_continued']:\n",
        "            num_lines = len(content.split('\\n'))\n",
        "            return Inches(0.25) * num_lines + self.CODE_BLOCK_SPACING\n",
        "        elif content_type == 'equation':\n",
        "            return self.EQUATION_SPACING\n",
        "        else:\n",
        "            base_height = self.BULLET_SPACING\n",
        "            wrapped_lines = len(content) // 80 + 1\n",
        "            return base_height * wrapped_lines\n",
        "\n",
        "    def process_content_lines(self, content):\n",
        "        \"\"\"Process content into structured lines with type information\"\"\"\n",
        "        processed_lines = []\n",
        "        code_block = []\n",
        "        in_code = False\n",
        "\n",
        "        for line in content.split('\\n'):\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "\n",
        "            if line.startswith('```'):\n",
        "                if in_code:\n",
        "                    processed_lines.append(('\\n'.join(code_block), 0, 'code'))\n",
        "                    code_block = []\n",
        "                    in_code = False\n",
        "                else:\n",
        "                    in_code = True\n",
        "                continue\n",
        "\n",
        "            if in_code:\n",
        "                code_block.append(line)\n",
        "                continue\n",
        "\n",
        "            if '$' in line:\n",
        "                eq = re.search(r'\\$(.*?)\\$', line).group(1)\n",
        "                processed_lines.append((eq, 0, 'equation'))\n",
        "                continue\n",
        "\n",
        "            # Handle bullet points and subheadings\n",
        "            if line.startswith('• '):\n",
        "                text = line[2:].strip()\n",
        "                if text.isupper() or text.endswith(':'):\n",
        "                    # Subheading\n",
        "                    processed_lines.append((line, 0, 'subheading'))\n",
        "                else:\n",
        "                    # Regular bullet point\n",
        "                    processed_lines.append((text, 1, 'text'))\n",
        "            elif line.startswith('•#'):\n",
        "                # Sub-bullet\n",
        "                processed_lines.append((line[2:].strip(), 2, 'text'))\n",
        "            else:\n",
        "                # Regular text\n",
        "                processed_lines.append((line, 0, 'text'))\n",
        "\n",
        "        return processed_lines\n",
        "\n",
        "class LaTeXRenderer:\n",
        "    def __init__(self):\n",
        "        plt.rc('text', usetex=True)\n",
        "        plt.rc('font', family='serif')\n",
        "\n",
        "    def equation_to_image(self, equation, dpi=300):\n",
        "        \"\"\"Convert LaTeX equation to image\"\"\"\n",
        "        equation = equation.replace('\\_', '_')\n",
        "\n",
        "        fig = plt.figure(figsize=(10, 1))\n",
        "        plt.axis('off')\n",
        "        plt.text(0.5, 0.5, f'${equation}$',\n",
        "                fontsize=14,\n",
        "                horizontalalignment='center',\n",
        "                verticalalignment='center')\n",
        "\n",
        "        buf = io.BytesIO()\n",
        "        plt.savefig(buf, format='png', dpi=dpi, bbox_inches='tight', transparent=True)\n",
        "        plt.close(fig)\n",
        "\n",
        "        buf.seek(0)\n",
        "        return Image.open(buf)\n",
        "\n",
        "class SlideContentManager:\n",
        "    def __init__(self, slide):\n",
        "        self.slide = slide\n",
        "        self.current_top = Inches(2)\n",
        "        self.latex_renderer = LaTeXRenderer()\n",
        "\n",
        "    def add_content(self, content, level, content_type):\n",
        "        \"\"\"Add content to slide with proper spacing\"\"\"\n",
        "        if content_type in ['code', 'code_continued']:\n",
        "            height = self._add_code_block(content)\n",
        "            self.current_top += height + Inches(0.6)\n",
        "        elif content_type == 'equation':\n",
        "            success = self._add_equation(content)\n",
        "            if success:\n",
        "                self.current_top += Inches(0.8)\n",
        "        elif content_type == 'subheading':\n",
        "            self._add_subheading(content)\n",
        "            self.current_top += Inches(0.6)\n",
        "        else:\n",
        "            self._add_text_content(content, level)\n",
        "            self.current_top += Inches(0.4)\n",
        "\n",
        "    def _add_text_content(self, text, level):\n",
        "        \"\"\"Add text content with proper formatting\"\"\"\n",
        "        content_shape = self.slide.placeholders[1]\n",
        "        text_frame = content_shape.text_frame\n",
        "\n",
        "        paragraph = text_frame.add_paragraph()\n",
        "        paragraph.level = level\n",
        "\n",
        "        # Handle text with potential bold sections\n",
        "        parts = re.split(r'(\\*\\*.*?\\*\\*)', text)\n",
        "        for part in parts:\n",
        "            if part:  # Skip empty parts\n",
        "                run = paragraph.add_run()\n",
        "                if part.startswith('**') and part.endswith('**'):\n",
        "                    run.text = part.strip('*')\n",
        "                    run.font.bold = True\n",
        "                else:\n",
        "                    run.text = part\n",
        "                    run.font.bold = False\n",
        "                run.font.size = Pt(14)\n",
        "\n",
        "        if level == 2:\n",
        "            paragraph.indent = Inches(0.5)\n",
        "\n",
        "    def _add_subheading(self, text):\n",
        "        \"\"\"Add subheading with proper formatting\"\"\"\n",
        "        content_shape = self.slide.placeholders[1]\n",
        "        text_frame = content_shape.text_frame\n",
        "\n",
        "        paragraph = text_frame.add_paragraph()\n",
        "        run = paragraph.add_run()\n",
        "        run.text = text[2:].strip()  # Remove bullet point\n",
        "        run.font.bold = True\n",
        "        run.font.size = Pt(16)\n",
        "\n",
        "    def _add_code_block(self, code):\n",
        "        \"\"\"Add code block with proper spacing\"\"\"\n",
        "        left = Inches(1)\n",
        "        width = Inches(11)\n",
        "\n",
        "        line_height = Inches(0.3)\n",
        "        total_height = len(code.split('\\n')) * line_height + Inches(0.5)\n",
        "\n",
        "        textbox = self.slide.shapes.add_textbox(left, self.current_top, width, total_height)\n",
        "        text_frame = textbox.text_frame\n",
        "\n",
        "        paragraph = text_frame.add_paragraph()\n",
        "        run = paragraph.add_run()\n",
        "        run.text = code\n",
        "        run.font.name = 'Courier New'\n",
        "        run.font.size = Pt(11)\n",
        "\n",
        "        fill = textbox.fill\n",
        "        fill.solid()\n",
        "        fill.fore_color.rgb = RGBColor(245, 245, 245)\n",
        "\n",
        "        return total_height\n",
        "\n",
        "    def _add_equation(self, equation):\n",
        "        \"\"\"Add equation with proper spacing\"\"\"\n",
        "        try:\n",
        "            eq_image = self.latex_renderer.equation_to_image(equation)\n",
        "            img_buf = io.BytesIO()\n",
        "            eq_image.save(img_buf, format='PNG')\n",
        "            img_buf.seek(0)\n",
        "\n",
        "            left = Inches(1)\n",
        "            self.slide.shapes.add_picture(img_buf, left, self.current_top, height=Inches(0.8))\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"Error rendering equation: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "class SlideGenerator:\n",
        "    def __init__(self, presentation_title, template_path):\n",
        "        self.prs = Presentation(template_path)\n",
        "        self.content_distributor = ContentDistributor()\n",
        "        self.presentation_title = presentation_title\n",
        "\n",
        "    def _add_title_slide(self):\n",
        "        \"\"\"Create title slide\"\"\"\n",
        "        slide = self.prs.slides.add_slide(self.prs.slide_layouts[0])\n",
        "        title_shape = slide.shapes.title\n",
        "        title_shape.text = self.presentation_title\n",
        "\n",
        "        paragraph = title_shape.text_frame.paragraphs[0]\n",
        "        paragraph.alignment = PP_ALIGN.CENTER\n",
        "        run = paragraph.runs[0]\n",
        "        run.font.size = Pt(44)\n",
        "        run.font.bold = True\n",
        "        run.font.color.rgb = RGBColor(44, 62, 80)\n",
        "\n",
        "    def _create_content_slides(self, title, content_chunk, slide_number=1, total_slides=1):\n",
        "        \"\"\"Create a content slide\"\"\"\n",
        "        slide = self.prs.slides.add_slide(self.prs.slide_layouts[1])\n",
        "        content_manager = SlideContentManager(slide)\n",
        "\n",
        "        # Add slide title\n",
        "        title_shape = slide.shapes.title\n",
        "        clean_title = self._clean_title(title)\n",
        "\n",
        "        # Add continuation number for split slides\n",
        "        if total_slides > 1:\n",
        "            title_shape.text = f\"{clean_title} ({slide_number}/{total_slides})\"\n",
        "        else:\n",
        "            title_shape.text = clean_title\n",
        "\n",
        "        # Format title\n",
        "        title_run = title_shape.text_frame.paragraphs[0].runs[0]\n",
        "        title_run.font.size = Pt(32)\n",
        "        title_run.font.bold = True\n",
        "\n",
        "        # Add content\n",
        "        for content, level, content_type in content_chunk:\n",
        "            content_manager.add_content(content, level, content_type)\n",
        "\n",
        "    def _clean_title(self, title):\n",
        "        \"\"\"Remove markdown formatting from title\"\"\"\n",
        "        return title.replace('**', '').strip()\n",
        "\n",
        "    def generate_presentation(self, content):\n",
        "        \"\"\"Generate presentation with properly distributed content\"\"\"\n",
        "        sections = re.split(r'##\\s+\\d+\\.\\s+', content)[1:]\n",
        "        self._add_title_slide()\n",
        "\n",
        "        for section in sections:\n",
        "            title_match = re.match(r'\\*\\*(.*?)\\*\\*', section)\n",
        "            if title_match:\n",
        "                title = title_match.group(1)\n",
        "                content = section[title_match.end():].strip()\n",
        "\n",
        "                # Distribute content across slides\n",
        "                chunks = self.content_distributor.distribute_content(content)\n",
        "                for i, chunk in enumerate(chunks, 1):\n",
        "                    self._create_content_slides(title, chunk, i, len(chunks))\n",
        "\n",
        "    def save(self):\n",
        "        \"\"\"Save presentation with query-based filename\"\"\"\n",
        "        filename = f\"{self.presentation_title.replace(' ', '_')}.pptx\"\n",
        "        self.prs.save(filename)\n",
        "        files.download(filename)\n",
        "\n",
        "def create_presentation(query, content, template_path):\n",
        "    \"\"\"Main function to create presentation\"\"\"\n",
        "    generator = SlideGenerator(query.upper(), template_path)\n",
        "    generator.generate_presentation(content)\n",
        "    generator.save()\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Please upload your PowerPoint template...\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    presentation_title = \"Understanding LSTM Networks\"\n",
        "    template_path = next(iter(uploaded.keys()))\n",
        "\n",
        "    with open('content.txt', 'r') as file:\n",
        "        content = file.read()\n",
        "\n",
        "    create_presentation(presentation_title, content, template_path)"
      ],
      "metadata": {
        "id": "qQBXQDzAJ9DH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2 python-pptx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTAtSUyplGTu",
        "outputId": "539f0ac2-6678-4a29-bc5b-a01578b3e220"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: python-pptx in /usr/local/lib/python3.11/dist-packages (1.0.2)\n",
            "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (11.1.0)\n",
            "Requirement already satisfied: XlsxWriter>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (3.2.2)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (5.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-pptx) (4.12.2)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m225.3/232.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "########################### LATEX CODE USE THIS ####################################\n",
        "import os\n",
        "import re\n",
        "from pptx import Presentation\n",
        "from pptx.util import Inches, Pt\n",
        "from pptx.enum.text import PP_ALIGN\n",
        "from pptx.dml.color import RGBColor\n",
        "import PyPDF2\n",
        "\n",
        "def convert_to_tex(content):\n",
        "    \"\"\"\n",
        "    Convert content to LaTeX with proper section hierarchy\n",
        "    \"\"\"\n",
        "    tex_content = \"\"\"\\\\documentclass{article}\n",
        "\\\\usepackage{amsmath}\n",
        "\\\\usepackage{listings}\n",
        "\\\\usepackage{xcolor}\n",
        "\\\\usepackage{enumitem}\n",
        "\\\\usepackage{titlesec}\n",
        "\\\\usepackage{geometry}\n",
        "\n",
        "\\\\geometry{\n",
        "    a4paper,\n",
        "    left=1in,\n",
        "    right=1in,\n",
        "    top=1in,\n",
        "    bottom=1in\n",
        "}\n",
        "\n",
        "% Format section titles\n",
        "\\\\titleformat{\\\\section}\n",
        "  {\\\\Large\\\\bfseries}  % format\n",
        "  {\\\\thesection.}      % label\n",
        "  {1em}                % sep\n",
        "  {}                   % before-code\n",
        "  []                   % after-code\n",
        "\n",
        "% Format subsection titles\n",
        "\\\\titleformat{\\\\subsection}\n",
        "  {\\\\large\\\\bfseries}   % format\n",
        "  {}                    % label\n",
        "  {0em}                % sep\n",
        "  {}                   % before-code\n",
        "  []                   % after-code\n",
        "\n",
        "% Code listing settings\n",
        "\\\\lstset{\n",
        "    backgroundcolor=\\\\color{gray!10},\n",
        "    basicstyle=\\\\ttfamily\\\\small,\n",
        "    breaklines=true,\n",
        "    frame=single,\n",
        "    numbers=left,\n",
        "    numberstyle=\\\\tiny,\n",
        "    keywordstyle=\\\\color{blue},\n",
        "    commentstyle=\\\\color{green!60!black},\n",
        "    stringstyle=\\\\color{red}\n",
        "}\n",
        "\n",
        "\\\\begin{document}\n",
        "\\\\pagestyle{plain}\n",
        "\"\"\"\n",
        "    sections = content.split(\"1.--\\n\\n\")\n",
        "    current_section = None\n",
        "\n",
        "    for section in sections:\n",
        "        if not section.strip():\n",
        "            continue\n",
        "\n",
        "        # Process main section headers (##)\n",
        "        if \"## \" in section:\n",
        "            title = re.search(r\"## \\d+\\. \\*\\*(.*?)\\*\\*\", section)\n",
        "            if title:\n",
        "                section_title = title.group(1).strip()\n",
        "                tex_content += f\"\\\\section{{{section_title}}}\\n\\n\"\n",
        "                section = re.sub(r\"## \\d+\\. \\*\\*.*?\\*\\*\\n\", \"\", section)\n",
        "\n",
        "        paragraphs = section.split(\"\\n\")\n",
        "        in_itemize = False\n",
        "        in_paragraph = False\n",
        "        in_code_block = False\n",
        "\n",
        "        for paragraph in paragraphs:\n",
        "            paragraph = paragraph.strip()\n",
        "            if not paragraph:\n",
        "                if in_itemize:\n",
        "                    tex_content += \"\\\\end{itemize}\\n\"\n",
        "                    in_itemize = False\n",
        "                if in_paragraph:\n",
        "                    tex_content += \"\\n\\n\"\n",
        "                    in_paragraph = False\n",
        "                continue\n",
        "\n",
        "            # Handle different content types\n",
        "            if paragraph.startswith(\"```python\"):\n",
        "                if in_itemize:\n",
        "                    tex_content += \"\\\\end{itemize}\\n\"\n",
        "                    in_itemize = False\n",
        "                in_code_block = True\n",
        "                tex_content += \"\\\\begin{lstlisting}[language=Python]\\n\"\n",
        "            elif paragraph.startswith(\"```\") and in_code_block:\n",
        "                in_code_block = False\n",
        "                tex_content += \"\\\\end{lstlisting}\\n\\n\"\n",
        "            elif in_code_block:\n",
        "                tex_content += paragraph + \"\\n\"\n",
        "            elif paragraph.startswith(\"• \"):\n",
        "                if any(keyword in paragraph.lower() for keyword in\n",
        "                    [\"elements\", \"principles\", \"management\", \"handling\", \"practices\",\n",
        "                     \"cases\", \"patterns\", \"metrics\", \"approaches\", \"strategies\"]):\n",
        "                    if in_itemize:\n",
        "                        tex_content += \"\\\\end{itemize}\\n\"\n",
        "                        in_itemize = False\n",
        "                    tex_content += f\"\\\\subsection{{{paragraph[2:]}}}\\n\\n\"\n",
        "                else:\n",
        "                    if not in_itemize:\n",
        "                        tex_content += \"\\\\begin{itemize}\\n\"\n",
        "                        in_itemize = True\n",
        "                    tex_content += f\"\\\\item {paragraph[2:]}\\n\"\n",
        "            elif paragraph.startswith(\"•# \"):\n",
        "                if in_itemize:\n",
        "                    tex_content += \"\\\\end{itemize}\\n\"\n",
        "                    in_itemize = False\n",
        "                tex_content += f\"\\\\subsection{{{paragraph[3:]}}}\\n\\n\"\n",
        "            elif re.match(r'^\\d+\\.\\s', paragraph):\n",
        "                if not in_itemize:\n",
        "                    tex_content += \"\\\\begin{itemize}\\n\"\n",
        "                    in_itemize = True\n",
        "                paragraph = re.sub(r'^\\d+\\.\\s', '', paragraph)\n",
        "                tex_content += f\"\\\\item {paragraph}\\n\"\n",
        "            else:\n",
        "                if in_itemize:\n",
        "                    tex_content += \"\\\\end{itemize}\\n\"\n",
        "                    in_itemize = False\n",
        "                # Handle equations and regular text\n",
        "                if \"$\" in paragraph:\n",
        "                    tex_content += paragraph + \"\\n\\n\"\n",
        "                else:\n",
        "                    if not paragraph.startswith(\"\\\\\"):\n",
        "                        if not in_paragraph:\n",
        "                            in_paragraph = True\n",
        "                        tex_content += paragraph + \" \"\n",
        "\n",
        "        if in_itemize:\n",
        "            tex_content += \"\\\\end{itemize}\\n\"\n",
        "        if in_paragraph:\n",
        "            tex_content += \"\\n\\n\"\n",
        "\n",
        "    tex_content += \"\\\\end{document}\"\n",
        "    return tex_content\n",
        "\n",
        "def create_tex_and_compile(tex_content, filename=\"output\"):\n",
        "    \"\"\"Create and compile LaTeX file\"\"\"\n",
        "    with open(f\"{filename}.tex\", \"w\", encoding='utf-8') as f:\n",
        "        f.write(tex_content)\n",
        "\n",
        "    os.system(f\"pdflatex -interaction=nonstopmode {filename}.tex\")\n",
        "    return f\"{filename}.pdf\"\n",
        "\n",
        "def split_content_into_slides(lines, max_points=3):\n",
        "    \"\"\"Split content into slides with specific heading and subheading handling\"\"\"\n",
        "    slides = []\n",
        "    current_slide = {\"title\": \"\", \"subtitle\": \"\", \"content\": [], \"type\": \"normal\"}\n",
        "    content_count = 0\n",
        "    paragraph_content = []\n",
        "\n",
        "    def create_new_slide(title, subtitle=\"\", slide_type=\"normal\"):\n",
        "        return {\n",
        "            \"title\": title,\n",
        "            \"subtitle\": subtitle,\n",
        "            \"content\": [],\n",
        "            \"type\": slide_type\n",
        "        }\n",
        "\n",
        "    def add_current_slide():\n",
        "        if current_slide[\"content\"]:\n",
        "            slides.append(current_slide.copy())\n",
        "\n",
        "    def clean_title(title):\n",
        "        \"\"\"Clean heading/subheading text\"\"\"\n",
        "        return title.replace(\"•\", \"\").replace(\"**\", \"\").strip()\n",
        "\n",
        "    def is_main_heading(line):\n",
        "        \"\"\"Check if line is a main heading\"\"\"\n",
        "        return bool(re.match(r'^##\\s+\\d+\\.\\s+\\*\\*.*?\\*\\*$', line))\n",
        "\n",
        "    def is_subheading(line):\n",
        "        \"\"\"Check if line matches subheading patterns\"\"\"\n",
        "        subheading_patterns = [\n",
        "            \"Core Definition and Purpose\",\n",
        "            \"Key Principles\",\n",
        "            \"Primary Elements and Their Role\",\n",
        "            \"Relationships and Interactions\"\n",
        "        ]\n",
        "        # Remove bullet point if present\n",
        "        clean_line = line.replace(\"• \", \"\").strip()\n",
        "        return any(pattern in clean_line for pattern in subheading_patterns)\n",
        "\n",
        "    current_main_heading = \"\"\n",
        "\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "\n",
        "        # Handle main headings (e.g., \"## 1. **Concept Overview**\")\n",
        "        if is_main_heading(line):\n",
        "            if current_slide[\"content\"]:\n",
        "                add_current_slide()\n",
        "\n",
        "            # Extract title from between ** markers\n",
        "            title_match = re.search(r'\\*\\*(.*?)\\*\\*', line)\n",
        "            if title_match:\n",
        "                current_main_heading = title_match.group(1).strip()\n",
        "                current_slide = create_new_slide(current_main_heading)\n",
        "                content_count = 0\n",
        "\n",
        "        # Handle subheadings\n",
        "        elif is_subheading(line):\n",
        "            if current_slide[\"content\"]:\n",
        "                add_current_slide()\n",
        "\n",
        "            # Clean subheading text and create new slide\n",
        "            clean_subheading = clean_title(line)\n",
        "            current_slide = create_new_slide(\n",
        "                current_main_heading,  # Keep main heading as title\n",
        "                clean_subheading      # Use subheading as subtitle\n",
        "            )\n",
        "            content_count = 0\n",
        "\n",
        "        # Handle bullet points\n",
        "        elif line.startswith(\"• \") or line.startswith(\"- \"):\n",
        "            if content_count >= max_points:\n",
        "                add_current_slide()\n",
        "                # Maintain same heading and subheading\n",
        "                current_slide = create_new_slide(\n",
        "                    current_slide[\"title\"],\n",
        "                    current_slide[\"subtitle\"] + \" (continued)\" if current_slide[\"subtitle\"] else \"\"\n",
        "                )\n",
        "                content_count = 0\n",
        "\n",
        "            current_slide[\"content\"].append({\n",
        "                \"type\": \"bullet\",\n",
        "                \"text\": line[2:].strip()\n",
        "            })\n",
        "            content_count += 1\n",
        "\n",
        "        # Handle regular paragraphs\n",
        "        else:\n",
        "            if content_count >= 1:  # Start new slide for paragraphs\n",
        "                add_current_slide()\n",
        "                current_slide = create_new_slide(\n",
        "                    current_slide[\"title\"],\n",
        "                    current_slide[\"subtitle\"]\n",
        "                )\n",
        "                content_count = 0\n",
        "\n",
        "            current_slide[\"content\"].append({\n",
        "                \"type\": \"paragraph\",\n",
        "                \"text\": line\n",
        "            })\n",
        "            content_count += 1\n",
        "\n",
        "    # Add any remaining content\n",
        "    if current_slide[\"content\"]:\n",
        "        add_current_slide()\n",
        "\n",
        "    return slides\n",
        "\n",
        "def create_presentation(slides, output_filename=\"presentation.pptx\"):\n",
        "    \"\"\"Create PowerPoint presentation with enhanced formatting\"\"\"\n",
        "    prs = Presentation()\n",
        "\n",
        "    # Set slide dimensions to 16:9\n",
        "    prs.slide_width = Inches(13.333)\n",
        "    prs.slide_height = Inches(7.5)\n",
        "\n",
        "    # Create title slide layout\n",
        "    title_slide_layout = prs.slide_layouts[0]\n",
        "    content_slide_layout = prs.slide_layouts[1]\n",
        "\n",
        "    for slide_num, slide_content in enumerate(slides, 1):\n",
        "        slide = prs.slides.add_slide(content_slide_layout)\n",
        "\n",
        "        # Add title\n",
        "        title = slide.shapes.title\n",
        "        title.text = slide_content[\"title\"]\n",
        "        title_tf = title.text_frame.paragraphs[0]\n",
        "        title_tf.font.size = Pt(40)\n",
        "        title_tf.font.bold = True\n",
        "        title_tf.font.color.rgb = RGBColor(0, 51, 102)\n",
        "\n",
        "        # Add content\n",
        "        content_shape = slide.shapes.placeholders[1]\n",
        "        tf = content_shape.text_frame\n",
        "        tf.word_wrap = True\n",
        "\n",
        "        # Add subtitle if exists\n",
        "        if slide_content[\"subtitle\"]:\n",
        "            subtitle = tf.add_paragraph()\n",
        "            subtitle.text = slide_content[\"subtitle\"]\n",
        "            subtitle.font.bold = True\n",
        "            subtitle.font.size = Pt(32)\n",
        "            subtitle.font.color.rgb = RGBColor(51, 51, 51)\n",
        "            subtitle.space_before = Pt(20)\n",
        "            subtitle.space_after = Pt(20)\n",
        "\n",
        "        # Add content with proper spacing\n",
        "        for content_item in slide_content[\"content\"]:\n",
        "            p = tf.add_paragraph()\n",
        "\n",
        "            if content_item[\"type\"] == \"bullet\":\n",
        "                p.text = \"• \" + content_item[\"text\"]  # Add bullet point character\n",
        "                p.level = 1\n",
        "                p.font.size = Pt(24)\n",
        "                p.space_before = Pt(12)\n",
        "                p.space_after = Pt(12)\n",
        "            elif content_item[\"type\"] == \"paragraph\":\n",
        "                p.text = content_item[\"text\"]\n",
        "                p.font.size = Pt(24)\n",
        "                p.space_before = Pt(12)\n",
        "                p.space_after = Pt(12)\n",
        "\n",
        "        # Add page number\n",
        "        page_number = slide.shapes.add_textbox(\n",
        "            Inches(12.33), Inches(6.9), Inches(0.5), Inches(0.3))\n",
        "        page_number.text_frame.text = str(slide_num)\n",
        "        page_number.text_frame.paragraphs[0].alignment = PP_ALIGN.RIGHT\n",
        "\n",
        "    prs.save(output_filename)\n",
        "    return output_filename\n",
        "\n",
        "def run_pipeline(content):\n",
        "    \"\"\"Complete pipeline from content to PDF and PPTX\"\"\"\n",
        "    # Convert to TeX\n",
        "    tex_content = convert_to_tex(content)\n",
        "    print(\"TeX content created.\")\n",
        "\n",
        "    # Create and compile PDF\n",
        "    pdf_path = create_tex_and_compile(tex_content)\n",
        "    print(\"PDF compiled.\")\n",
        "\n",
        "    # Extract and format content for slides\n",
        "    lines = content.split('\\n')\n",
        "    slides = split_content_into_slides(lines)\n",
        "    print(\"Slides content organized.\")\n",
        "\n",
        "    # Create presentation\n",
        "    pptx_path = create_presentation(slides)\n",
        "    print(\"PowerPoint presentation created.\")\n",
        "\n",
        "    return pdf_path, pptx_path\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to run the conversion process\"\"\"\n",
        "    try:\n",
        "        # Read the content\n",
        "        with open('content.txt', 'r', encoding='utf-8') as file:\n",
        "            content = file.read()\n",
        "\n",
        "        # Run the pipeline\n",
        "        pdf_path, pptx_path = run_pipeline(content)\n",
        "        print(f\"\\nSuccessfully generated files:\")\n",
        "        print(f\"PDF: {pdf_path}\")\n",
        "        print(f\"Presentation: {pptx_path}\")\n",
        "\n",
        "        # Verify generated files\n",
        "        if os.path.exists(pdf_path) and os.path.exists(pptx_path):\n",
        "            print(\"\\nVerification successful - both files were created.\")\n",
        "            print(f\"PDF size: {os.path.getsize(pdf_path):,} bytes\")\n",
        "            print(f\"PPTX size: {os.path.getsize(pptx_path):,} bytes\")\n",
        "        else:\n",
        "            missing = []\n",
        "            if not os.path.exists(pdf_path):\n",
        "                missing.append(\"PDF\")\n",
        "            if not os.path.exists(pptx_path):\n",
        "                missing.append(\"PPTX\")\n",
        "            print(f\"\\nWarning: The following files were not created: {', '.join(missing)}\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(\"Error: content.txt file not found. Please ensure the file exists in the current directory.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred during conversion: {str(e)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiD_bcI-hIng",
        "outputId": "889c8a94-4fed-44cc-b1f3-2d629d8b1168"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TeX content created.\n",
            "PDF compiled.\n",
            "Slides content organized.\n",
            "PowerPoint presentation created.\n",
            "\n",
            "Successfully generated files:\n",
            "PDF: output.pdf\n",
            "Presentation: presentation.pptx\n",
            "\n",
            "Verification successful - both files were created.\n",
            "PDF size: 71,737 bytes\n",
            "PPTX size: 121,462 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "QUIZ MODULE"
      ],
      "metadata": {
        "id": "Upy0_1-u0ZRG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import time\n",
        "import os\n",
        "from typing import Dict, List, Union\n",
        "from groq import Groq\n",
        "\n",
        "class GroqClient:\n",
        "    def __init__(self, api_key):\n",
        "        self.client = Groq(api_key=api_key)\n",
        "\n",
        "    def get_completion(self, query, max_tokens=4000):\n",
        "        try:\n",
        "            chat_completion = self.client.chat.completions.create(\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"system\",\n",
        "                        \"content\": \"You are a technical quiz generation expert. You must follow the format EXACTLY as specified and start your response with === MULTIPLE CHOICE QUESTIONS ===\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": query\n",
        "                    }\n",
        "                ],\n",
        "                model=\"deepseek-r1-distill-llama-70b\",\n",
        "                temperature=0.5,\n",
        "                max_tokens=max_tokens,\n",
        "                top_p=0.7,\n",
        "                stream=False\n",
        "            )\n",
        "            return chat_completion.choices[0].message.content\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"API request failed: {str(e)}\")\n",
        "\n",
        "class QuizGenerator:\n",
        "    def __init__(self, api_key: str, debug=True):\n",
        "        \"\"\"Initialize with Groq client and debug option.\"\"\"\n",
        "        self.debug = debug\n",
        "        self.client = GroqClient(api_key=api_key)\n",
        "\n",
        "    def read_context_file(self, file_path: str) -> str:\n",
        "        \"\"\"Read content from the context file with proper error handling.\"\"\"\n",
        "        try:\n",
        "            if not os.path.exists(file_path):\n",
        "                raise FileNotFoundError(f\"Content file not found: {file_path}\")\n",
        "\n",
        "            if not os.access(file_path, os.R_OK):\n",
        "                raise PermissionError(f\"Cannot read content file: {file_path}\")\n",
        "\n",
        "            with open(file_path, 'r', encoding='utf-8') as file:\n",
        "                content = file.read()\n",
        "\n",
        "            if not content.strip():\n",
        "                raise ValueError(f\"Content file is empty: {file_path}\")\n",
        "\n",
        "            if self.debug:\n",
        "                print(f\"Successfully read {len(content)} characters from {file_path}\")\n",
        "\n",
        "            # Clean up content\n",
        "            content = content.replace('\\ufeff', '').replace('\\r\\n', '\\n')\n",
        "\n",
        "            return content\n",
        "\n",
        "        except UnicodeDecodeError:\n",
        "            raise Exception(f\"File encoding error. Please ensure {file_path} is saved in UTF-8 format.\")\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"Error reading content file: {str(e)}\")\n",
        "\n",
        "    def generate_quiz_prompt(self, content: str) -> str:\n",
        "        \"\"\"Generate a structured prompt for the quiz.\"\"\"\n",
        "        return f\"\"\"<s>[INST] IMPORTANT: Follow these instructions EXACTLY. DO NOT include any thinking, planning, or additional text.\n",
        "START YOUR RESPONSE DIRECTLY with \"=== MULTIPLE CHOICE QUESTIONS ===\" and ONLY use the specified format.\n",
        "\n",
        "Based on the provided technical content, create:\n",
        "\n",
        "1. Multiple Choice Questions (10 total):\n",
        "   - 4 Easy questions: Test basic terminology and concept recall\n",
        "   - 3 Medium questions: Test understanding of relationships and principles\n",
        "   - 3 Hard questions: Test advanced concepts and technical analysis\n",
        "\n",
        "2. Fill in the Blanks (10 total):\n",
        "   - 4 Easy questions: Basic terminology and definitions\n",
        "   - 3 Medium questions: Technical relationships and components\n",
        "   - 3 Hard questions: Complex technical concepts and implementations\n",
        "\n",
        "3. Short Answer Questions (15 total):\n",
        "   - 5 Easy questions: Basic concept explanation\n",
        "   - 5 Medium questions: Understanding mechanisms and relationships\n",
        "   - 5 Hard questions: Technical analysis and practical applications\n",
        "\n",
        "USE THIS EXACT FORMAT - DO NOT DEVIATE:\n",
        "\n",
        "=== MULTIPLE CHOICE QUESTIONS ===\n",
        "[Difficulty: Easy]\n",
        "Q1. Question text\n",
        "A) Option A\n",
        "B) Option B\n",
        "C) Option C\n",
        "D) Option D\n",
        "Correct: [Letter]\n",
        "Explanation: Brief explanation\n",
        "\n",
        "=== FILL IN THE BLANKS ===\n",
        "[Difficulty: Easy]\n",
        "Q1. Sentence with _____ to fill\n",
        "Answer: Correct answer\n",
        "Explanation: Brief explanation\n",
        "\n",
        "=== SHORT ANSWER QUESTIONS ===\n",
        "[Difficulty: Easy]\n",
        "Q1. Question text\n",
        "Answer: Model answer\n",
        "Key Points: Key point 1, Key point 2\n",
        "\n",
        "Content to create questions from:\n",
        "{content}\n",
        "\n",
        "REQUIREMENTS:\n",
        "- Start IMMEDIATELY with \"=== MULTIPLE CHOICE QUESTIONS ===\"\n",
        "- Use EXACT formatting shown above\n",
        "- Include ALL THREE sections in order\n",
        "- Follow difficulty distribution exactly\n",
        "- NO additional text or thinking process\n",
        "[/INST]</s>\"\"\"\n",
        "\n",
        "    def query_groq_api(self, prompt: str, max_tokens: int = 4000) -> str:\n",
        "        \"\"\"Query the Groq API with proper error handling.\"\"\"\n",
        "        max_retries = 3\n",
        "        wait_time = 50  # Initial wait time of 50 seconds\n",
        "\n",
        "        for attempt in range(max_retries):\n",
        "            try:\n",
        "                if self.debug:\n",
        "                    print(f\"\\nAttempt {attempt + 1} of {max_retries}\")\n",
        "\n",
        "                response = self.client.get_completion(query=prompt, max_tokens=max_tokens)\n",
        "\n",
        "                if self.debug:\n",
        "                    print(\"Successfully received response from Groq API\")\n",
        "\n",
        "                return response\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Attempt {attempt + 1} failed: {str(e)}\")\n",
        "                if attempt < max_retries - 1:\n",
        "                    print(f\"Waiting {wait_time} seconds before retry...\")\n",
        "                    time.sleep(wait_time)\n",
        "                    wait_time *= 1.5  # Increase wait time by 50% for each retry\n",
        "                else:\n",
        "                    raise Exception(\"Failed to get valid response after all retries\")\n",
        "\n",
        "    def parse_quiz_response(self, quiz_text: str, prompt: str) -> Dict:\n",
        "        \"\"\"Parse the API response into structured format with dynamic difficulty validation.\"\"\"\n",
        "        try:\n",
        "            if not quiz_text:\n",
        "                raise ValueError(\"No generated text in API response\")\n",
        "\n",
        "            # Clean response: Remove any text before the first section marker\n",
        "            start_marker = \"=== MULTIPLE CHOICE QUESTIONS ===\"\n",
        "            start_index = quiz_text.find(start_marker)\n",
        "            if start_index == -1:\n",
        "                if self.debug:\n",
        "                    print(\"Response format error. Raw response:\")\n",
        "                    print(quiz_text[:500] + \"...\" if len(quiz_text) > 500 else quiz_text)\n",
        "                raise ValueError(\"Response does not contain expected section markers\")\n",
        "\n",
        "            quiz_text = quiz_text[start_index:]\n",
        "\n",
        "            # Initialize structured quiz\n",
        "            structured_quiz = {\n",
        "                \"multiple_choice\": [],\n",
        "                \"fill_in_blanks\": [],\n",
        "                \"short_answer\": []\n",
        "            }\n",
        "\n",
        "            current_section_type = None\n",
        "            current_difficulty = None\n",
        "            current_question = None\n",
        "\n",
        "            for line in quiz_text.split('\\n'):\n",
        "                line = line.strip()\n",
        "                if not line:\n",
        "                    continue\n",
        "\n",
        "                # Determine section type\n",
        "                if \"=== MULTIPLE CHOICE QUESTIONS ===\" in line:\n",
        "                    current_section_type = \"multiple_choice\"\n",
        "                    continue\n",
        "                elif \"=== FILL IN THE BLANKS ===\" in line:\n",
        "                    current_section_type = \"fill_in_blanks\"\n",
        "                    continue\n",
        "                elif \"=== SHORT ANSWER QUESTIONS ===\" in line:\n",
        "                    current_section_type = \"short_answer\"\n",
        "                    continue\n",
        "\n",
        "                # Check for difficulty\n",
        "                if line.startswith('[Difficulty:'):\n",
        "                    try:\n",
        "                        current_difficulty = line.split(':')[1].strip().rstrip(']').lower()\n",
        "                        if current_difficulty not in ['easy', 'medium', 'hard']:\n",
        "                            print(f\"Warning: Invalid difficulty level found: {current_difficulty}\")\n",
        "                            current_difficulty = 'medium'  # Default to medium if invalid\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error parsing difficulty: {str(e)}\")\n",
        "                        current_difficulty = 'medium'  # Default to medium if parsing fails\n",
        "                    continue\n",
        "\n",
        "                try:\n",
        "                    # Parse Multiple Choice Questions\n",
        "                    if current_section_type == \"multiple_choice\":\n",
        "                        if line.startswith('Q'):\n",
        "                            if current_question:\n",
        "                                structured_quiz[\"multiple_choice\"].append(current_question)\n",
        "                            current_question = {\n",
        "                                \"type\": \"multiple_choice\",\n",
        "                                \"difficulty\": current_difficulty,\n",
        "                                \"question\": line.split('.', 1)[1].strip() if '.' in line else line,\n",
        "                                \"options\": [],\n",
        "                                \"correct_answer\": \"\",\n",
        "                                \"explanation\": \"\",\n",
        "                                \"user_answer\": \"\"  # Add user_answer field\n",
        "                            }\n",
        "                        elif line.startswith(('A)', 'B)', 'C)', 'D)')):\n",
        "                            if current_question:\n",
        "                                current_question[\"options\"].append({\n",
        "                                    \"label\": line[0],\n",
        "                                    \"text\": line[2:].strip()\n",
        "                                })\n",
        "                        elif line.startswith('Correct:'):\n",
        "                            if current_question:\n",
        "                                current_question[\"correct_answer\"] = line.split(':')[1].strip()\n",
        "                        elif line.startswith('Explanation:'):\n",
        "                            if current_question:\n",
        "                                current_question[\"explanation\"] = line.split(':', 1)[1].strip()\n",
        "                                structured_quiz[\"multiple_choice\"].append(current_question)\n",
        "                                current_question = None\n",
        "\n",
        "                    # Parse Fill in the Blanks\n",
        "                    elif current_section_type == \"fill_in_blanks\":\n",
        "                        if line.startswith('Q'):\n",
        "                            if current_question:\n",
        "                                structured_quiz[\"fill_in_blanks\"].append(current_question)\n",
        "                            current_question = {\n",
        "                                \"type\": \"fill_in_blanks\",\n",
        "                                \"difficulty\": current_difficulty,\n",
        "                                \"question\": line.split('.', 1)[1].strip() if '.' in line else line,\n",
        "                                \"answer\": \"\",\n",
        "                                \"explanation\": \"\",\n",
        "                                \"user_answer\": \"\"  # Add user_answer field\n",
        "                            }\n",
        "                        elif line.startswith('Answer:'):\n",
        "                            if current_question:\n",
        "                                current_question[\"answer\"] = line.split(':', 1)[1].strip()\n",
        "                        elif line.startswith('Explanation:'):\n",
        "                            if current_question:\n",
        "                                current_question[\"explanation\"] = line.split(':', 1)[1].strip()\n",
        "                                structured_quiz[\"fill_in_blanks\"].append(current_question)\n",
        "                                current_question = None\n",
        "\n",
        "                    # Parse Short Answer Questions\n",
        "                    elif current_section_type == \"short_answer\":\n",
        "                        if line.startswith('Q'):\n",
        "                            if current_question:\n",
        "                                structured_quiz[\"short_answer\"].append(current_question)\n",
        "                            current_question = {\n",
        "                                \"type\": \"short_answer\",\n",
        "                                \"difficulty\": current_difficulty,\n",
        "                                \"question\": line.split('.', 1)[1].strip() if '.' in line else line,\n",
        "                                \"answer\": \"\",\n",
        "                                \"key_points\": [],\n",
        "                                \"user_answer\": \"\"\n",
        "                            }\n",
        "                        elif line.startswith('Answer:'):\n",
        "                            if current_question:\n",
        "                                current_question[\"answer\"] = line.split(':', 1)[1].strip()\n",
        "                        elif line.startswith('Key Points:'):\n",
        "                            if current_question:\n",
        "                                current_question[\"key_points\"] = [\n",
        "                                    point.strip()\n",
        "                                    for point in line.split(':', 1)[1].strip().split(',')\n",
        "                                ]\n",
        "                                structured_quiz[\"short_answer\"].append(current_question)\n",
        "                                current_question = None\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error parsing line '{line}': {str(e)}\")\n",
        "                    continue\n",
        "\n",
        "            # Add the last question if it exists\n",
        "            if current_question:\n",
        "                if current_section_type == \"multiple_choice\":\n",
        "                    structured_quiz[\"multiple_choice\"].append(current_question)\n",
        "                elif current_section_type == \"fill_in_blanks\":\n",
        "                    structured_quiz[\"fill_in_blanks\"].append(current_question)\n",
        "                elif current_section_type == \"short_answer\":\n",
        "                    structured_quiz[\"short_answer\"].append(current_question)\n",
        "\n",
        "            # Calculate metadata\n",
        "            quiz_metadata = self._calculate_metadata(structured_quiz)\n",
        "\n",
        "            return {\n",
        "                \"metadata\": quiz_metadata,\n",
        "                \"quiz\": structured_quiz,\n",
        "                \"raw_response\": quiz_text\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error parsing quiz response: {str(e)}\")\n",
        "            if self.debug:\n",
        "                print(\"\\nFull response for debugging:\")\n",
        "                print(quiz_text[:500] + \"...\" if len(quiz_text) > 500 else quiz_text)\n",
        "            raise\n",
        "\n",
        "    def _calculate_metadata(self, quiz: Dict) -> Dict:\n",
        "        \"\"\"Calculate quiz metadata with accurate difficulty distribution.\"\"\"\n",
        "        try:\n",
        "            # Calculate total questions\n",
        "            total_questions = sum(len(questions) for questions in quiz.values())\n",
        "\n",
        "            # Calculate question type counts\n",
        "            question_types = {\n",
        "                qtype: len(questions)\n",
        "                for qtype, questions in quiz.items()\n",
        "            }\n",
        "\n",
        "            # Calculate difficulty distribution\n",
        "            difficulty_distribution = {\n",
        "                \"easy\": sum(1 for questions in quiz.values()\n",
        "                           for q in questions if q.get(\"difficulty\") == \"easy\"),\n",
        "                \"medium\": sum(1 for questions in quiz.values()\n",
        "                             for q in questions if q.get(\"difficulty\") == \"medium\"),\n",
        "                \"hard\": sum(1 for questions in quiz.values()\n",
        "                           for q in questions if q.get(\"difficulty\") == \"hard\")\n",
        "            }\n",
        "\n",
        "            # Calculate per-section difficulty distribution\n",
        "            section_difficulty_distribution = {\n",
        "                section_type: {\n",
        "                    \"easy\": sum(1 for q in questions if q.get(\"difficulty\") == \"easy\"),\n",
        "                    \"medium\": sum(1 for q in questions if q.get(\"difficulty\") == \"medium\"),\n",
        "                    \"hard\": sum(1 for q in questions if q.get(\"difficulty\") == \"hard\")\n",
        "                }\n",
        "                for section_type, questions in quiz.items()\n",
        "            }\n",
        "\n",
        "            return {\n",
        "                \"total_questions\": total_questions,\n",
        "                \"question_types\": question_types,\n",
        "                \"difficulty_distribution\": difficulty_distribution,\n",
        "                \"section_difficulty_distribution\": section_difficulty_distribution,\n",
        "                \"generation_timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "            }\n",
        "        except Exception as e:\n",
        "            print(f\"Error calculating metadata: {str(e)}\")\n",
        "            return {\n",
        "                \"total_questions\": 0,\n",
        "                \"question_types\": {\n",
        "                    \"multiple_choice\": 0,\n",
        "                    \"fill_in_blanks\": 0,\n",
        "                    \"short_answer\": 0\n",
        "                },\n",
        "                \"difficulty_distribution\": {\n",
        "                    \"easy\": 0,\n",
        "                    \"medium\": 0,\n",
        "                    \"hard\": 0\n",
        "                },\n",
        "                \"section_difficulty_distribution\": {},\n",
        "                \"generation_timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "            }\n",
        "\n",
        "    def generate_quiz(self, context_file_path: str) -> Dict:\n",
        "        \"\"\"Generate a complete quiz with error handling.\"\"\"\n",
        "        try:\n",
        "            content = self.read_context_file(context_file_path)\n",
        "            if self.debug:\n",
        "                print(f\"\\nRead {len(content)} characters from {context_file_path}\")\n",
        "\n",
        "            prompt = self.generate_quiz_prompt(content)\n",
        "            response = self.query_groq_api(prompt)\n",
        "\n",
        "            # Verify all sections are present\n",
        "            required_sections = [\n",
        "                \"=== MULTIPLE CHOICE QUESTIONS ===\",\n",
        "                \"=== FILL IN THE BLANKS ===\",\n",
        "                \"=== SHORT ANSWER QUESTIONS ===\"\n",
        "            ]\n",
        "\n",
        "            missing_sections = [\n",
        "                section for section in required_sections\n",
        "                if section not in response\n",
        "            ]\n",
        "\n",
        "            if missing_sections:\n",
        "                raise Exception(f\"Missing required sections: {', '.join(missing_sections)}\")\n",
        "\n",
        "            return self.parse_quiz_response(response, prompt)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Quiz generation failed: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        print(\"Starting quiz generation...\")\n",
        "\n",
        "        # Check for API key\n",
        "        api_key = os.getenv('GROQ_API_KEY')\n",
        "        if not api_key:\n",
        "            print(\"Error: GROQ_API_KEY environment variable not found!\")\n",
        "            print(\"\\nPlease set your Groq API key as an environment variable:\")\n",
        "            print(\"export GROQ_API_KEY='your-api-key'\")\n",
        "            return\n",
        "\n",
        "        if not os.path.exists(\"content.txt\"):\n",
        "            print(\"Error: content.txt file not found!\")\n",
        "            print(\"\\nPlease create a content.txt file with your technical content.\")\n",
        "            print(\"The content can be about any computer science or technical topic.\")\n",
        "            print(\"\\nFile requirements:\")\n",
        "            print(\"1. Save as 'content.txt' in the same directory as this script\")\n",
        "            print(\"2. Use UTF-8 encoding\")\n",
        "            print(\"3. Include sufficient content for meaningful questions\")\n",
        "            return\n",
        "\n",
        "        quiz_gen = QuizGenerator(api_key=api_key, debug=True)\n",
        "\n",
        "        print(\"\\nReading content and generating quiz...\")\n",
        "        print(\"This may take a few minutes depending on the content length.\")\n",
        "        quiz = quiz_gen.generate_quiz(\"content.txt\")\n",
        "\n",
        "        # Create output directory\n",
        "        output_dir = \"quiz_output\"\n",
        "        if not os.path.exists(output_dir):\n",
        "            os.makedirs(output_dir)\n",
        "\n",
        "        # Save outputs\n",
        "        print(\"\\nSaving quiz files...\")\n",
        "\n",
        "        # Save raw response\n",
        "        raw_path = os.path.join(output_dir, 'quiz_raw.txt')\n",
        "        with open(raw_path, 'w', encoding='utf-8') as f:\n",
        "            f.write(quiz['raw_response'])\n",
        "\n",
        "        # Save structured quiz\n",
        "        json_path = os.path.join(output_dir, 'generated_quiz.json')\n",
        "        with open(json_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(quiz, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "        print(\"\\nQuiz generation completed successfully!\")\n",
        "        print(f\"\\nOutput files (in {output_dir}/):\")\n",
        "        print(\"- generated_quiz.json (structured quiz data)\")\n",
        "        print(\"- quiz_raw.txt (raw quiz text)\")\n",
        "\n",
        "        # Print quiz statistics\n",
        "        print(\"\\nQuiz Statistics:\")\n",
        "        print(f\"Total Questions: {quiz['metadata']['total_questions']}\")\n",
        "        print(\"\\nQuestion Types:\")\n",
        "        for qtype, count in quiz['metadata']['question_types'].items():\n",
        "            print(f\"- {qtype}: {count}\")\n",
        "\n",
        "        print(\"\\nOverall Difficulty Distribution:\")\n",
        "        for diff, count in quiz['metadata']['difficulty_distribution'].items():\n",
        "            print(f\"- {diff}: {count}\")\n",
        "\n",
        "        print(\"\\nPer-Section Difficulty Distribution:\")\n",
        "        for section, distribution in quiz['metadata']['section_difficulty_distribution'].items():\n",
        "            print(f\"\\n{section.replace('_', ' ').title()}:\")\n",
        "            for diff, count in distribution.items():\n",
        "                print(f\"- {diff}: {count}\")\n",
        "\n",
        "        print(\"\\nYou can find your quiz in the following files:\")\n",
        "        print(f\"1. {raw_path} - Contains the raw quiz text\")\n",
        "        print(f\"2. {json_path} - Contains the structured quiz data\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError: {str(e)}\")\n",
        "        print(\"\\nTroubleshooting tips:\")\n",
        "        print(\"1. Check that content.txt exists and is readable\")\n",
        "        print(\"2. Verify the content.txt has enough text to generate questions\")\n",
        "        print(\"3. Ensure content.txt is saved with UTF-8 encoding\")\n",
        "        print(\"4. Try running the script again (API might be temporarily busy)\")\n",
        "        print(\"5. Check your internet connection\")\n",
        "        print(\"6. Verify your Groq API key is set correctly\")\n",
        "        print(\"\\nFor more details, check:\")\n",
        "        print(\"- The error message above\")\n",
        "        print(\"- quiz_raw.txt file (if created)\")\n",
        "        print(\"- generated_quiz.json file (if created)\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "EDOb9AHjsTV-",
        "outputId": "fe0be470-79a4-4144-eb79-c4450c82a8c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting quiz generation...\n",
            "\n",
            "Reading content and generating quiz...\n",
            "This may take a few minutes depending on the content length.\n",
            "Successfully read 7233 characters from content.txt\n",
            "\n",
            "Read 7233 characters from content.txt\n",
            "\n",
            "Attempt 1 of 3\n",
            "Successfully received response from Groq API\n",
            "\n",
            "Saving quiz files...\n",
            "\n",
            "Quiz generation completed successfully!\n",
            "\n",
            "Output files (in quiz_output/):\n",
            "- generated_quiz.json (structured quiz data)\n",
            "- quiz_raw.txt (raw quiz text)\n",
            "\n",
            "Quiz Statistics:\n",
            "Total Questions: 35\n",
            "\n",
            "Question Types:\n",
            "- multiple_choice: 10\n",
            "- fill_in_blanks: 10\n",
            "- short_answer: 15\n",
            "\n",
            "Overall Difficulty Distribution:\n",
            "- easy: 13\n",
            "- medium: 11\n",
            "- hard: 11\n",
            "\n",
            "Per-Section Difficulty Distribution:\n",
            "\n",
            "Multiple Choice:\n",
            "- easy: 4\n",
            "- medium: 3\n",
            "- hard: 3\n",
            "\n",
            "Fill In Blanks:\n",
            "- easy: 4\n",
            "- medium: 3\n",
            "- hard: 3\n",
            "\n",
            "Short Answer:\n",
            "- easy: 5\n",
            "- medium: 5\n",
            "- hard: 5\n",
            "\n",
            "You can find your quiz in the following files:\n",
            "1. quiz_output/quiz_raw.txt - Contains the raw quiz text\n",
            "2. quiz_output/generated_quiz.json - Contains the structured quiz data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FEEDBACK MODULE"
      ],
      "metadata": {
        "id": "xoEFyVau0dpM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import time\n",
        "import os\n",
        "from typing import Dict, List, Union\n",
        "from groq import Groq\n",
        "\n",
        "class GroqClient:\n",
        "    def __init__(self, api_key):\n",
        "        self.client = Groq(api_key=api_key)\n",
        "\n",
        "    def get_completion(self, query, max_tokens=4000):\n",
        "        try:\n",
        "            chat_completion = self.client.chat.completions.create(\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"system\",\n",
        "                        \"content\": \"You are a technical quiz generation expert. You must follow the format EXACTLY as specified and start your response with === MULTIPLE CHOICE QUESTIONS ===\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": query\n",
        "                    }\n",
        "                ],\n",
        "                model=\"deepseek-r1-distill-llama-70b\",\n",
        "                temperature=0.5,\n",
        "                max_tokens=max_tokens,\n",
        "                top_p=0.7,\n",
        "                stream=False\n",
        "            )\n",
        "            return chat_completion.choices[0].message.content\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"API request failed: {str(e)}\")\n",
        "\n",
        "class QuizGenerator:\n",
        "    def __init__(self, api_key: str, debug=True):\n",
        "        \"\"\"Initialize with Groq client and debug option.\"\"\"\n",
        "        self.debug = debug\n",
        "        self.client = GroqClient(api_key=api_key)\n",
        "\n",
        "    def read_context_file(self, file_path: str) -> str:\n",
        "        \"\"\"Read content from the context file with proper error handling.\"\"\"\n",
        "        try:\n",
        "            if not os.path.exists(file_path):\n",
        "                raise FileNotFoundError(f\"Content file not found: {file_path}\")\n",
        "\n",
        "            if not os.access(file_path, os.R_OK):\n",
        "                raise PermissionError(f\"Cannot read content file: {file_path}\")\n",
        "\n",
        "            with open(file_path, 'r', encoding='utf-8') as file:\n",
        "                content = file.read()\n",
        "\n",
        "            if not content.strip():\n",
        "                raise ValueError(f\"Content file is empty: {file_path}\")\n",
        "\n",
        "            if self.debug:\n",
        "                print(f\"Successfully read {len(content)} characters from {file_path}\")\n",
        "\n",
        "            # Clean up content\n",
        "            content = content.replace('\\ufeff', '').replace('\\r\\n', '\\n')\n",
        "\n",
        "            return content\n",
        "\n",
        "        except UnicodeDecodeError:\n",
        "            raise Exception(f\"File encoding error. Please ensure {file_path} is saved in UTF-8 format.\")\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"Error reading content file: {str(e)}\")\n",
        "\n",
        "    def generate_quiz_prompt(self, content: str) -> str:\n",
        "\n",
        "      \"\"\"Generate a structured prompt for the quiz.\"\"\"\n",
        "      return f\"\"\"<s>[INST] IMPORTANT: Follow these instructions EXACTLY. DO NOT include any thinking, planning, or additional text.\n",
        "START YOUR RESPONSE DIRECTLY with \"=== MULTIPLE CHOICE QUESTIONS ===\" and ONLY use the specified format.\n",
        "\n",
        "Based on the provided technical content, create:\n",
        "\n",
        "1. Multiple Choice Questions (15 total):\n",
        "   - 5 Easy questions: Test basic terminology and concept recall\n",
        "   - 5 Medium questions: Test understanding of relationships and principles\n",
        "   - 5 Hard questions: Test advanced concepts and technical analysis\n",
        "\n",
        "2. Fill in the Blanks (15 total):\n",
        "   - 5 Easy questions: Basic terminology and definitions\n",
        "   - 5 Medium questions: Technical relationships and components\n",
        "   - 5 Hard questions: Complex technical concepts and implementations\n",
        "\n",
        "3. Short Answer Questions (15 total):\n",
        "   - 5 Easy questions: Basic concept explanation\n",
        "   - 5 Medium questions: Understanding mechanisms and relationships\n",
        "   - 5 Hard questions: Technical analysis and practical applications\n",
        "\n",
        "USE THIS EXACT FORMAT - DO NOT DEVIATE:\n",
        "\n",
        "=== MULTIPLE CHOICE QUESTIONS ===\n",
        "[Difficulty: Easy]\n",
        "Q1. Question text\n",
        "A) Option A\n",
        "B) Option B\n",
        "C) Option C\n",
        "D) Option D\n",
        "Correct: [Letter]\n",
        "Explanation: Brief explanation\n",
        "\n",
        "=== FILL IN THE BLANKS ===\n",
        "[Difficulty: Easy]\n",
        "Q1. Sentence with _____ to fill\n",
        "Answer: Correct answer\n",
        "Explanation: Brief explanation\n",
        "\n",
        "=== SHORT ANSWER QUESTIONS ===\n",
        "[Difficulty: Easy]\n",
        "Q1. Question text\n",
        "Answer: Model answer\n",
        "Key Points: Key point 1, Key point 2\n",
        "\n",
        "Content to create questions from:\n",
        "{content}\n",
        "\n",
        "REQUIREMENTS:\n",
        "- Start IMMEDIATELY with \"=== MULTIPLE CHOICE QUESTIONS ===\"\n",
        "- Use EXACT formatting shown above\n",
        "- Include ALL THREE sections in order\n",
        "- Follow the difficulty distribution exactly (5 Easy, 5 Medium, 5 Hard for each section)\n",
        "- NO additional text or thinking process\n",
        "[/INST]</s>\"\"\"\n",
        "\n",
        "    def query_groq_api(self, prompt: str, max_tokens: int = 4000) -> str:\n",
        "        \"\"\"Query the Groq API with proper error handling.\"\"\"\n",
        "        max_retries = 3\n",
        "        wait_time = 50  # Initial wait time of 50 seconds\n",
        "\n",
        "        for attempt in range(max_retries):\n",
        "            try:\n",
        "                if self.debug:\n",
        "                    print(f\"\\nAttempt {attempt + 1} of {max_retries}\")\n",
        "\n",
        "                response = self.client.get_completion(query=prompt, max_tokens=max_tokens)\n",
        "\n",
        "                if self.debug:\n",
        "                    print(\"Successfully received response from Groq API\")\n",
        "\n",
        "                return response\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Attempt {attempt + 1} failed: {str(e)}\")\n",
        "                if attempt < max_retries - 1:\n",
        "                    print(f\"Waiting {wait_time} seconds before retry...\")\n",
        "                    time.sleep(wait_time)\n",
        "                    wait_time *= 1.5  # Increase wait time by 50% for each retry\n",
        "                else:\n",
        "                    raise Exception(\"Failed to get valid response after all retries\")\n",
        "\n",
        "    def parse_quiz_response(self, quiz_text: str, prompt: str) -> Dict:\n",
        "        \"\"\"Parse the API response into structured format with dynamic difficulty validation.\"\"\"\n",
        "        try:\n",
        "            if not quiz_text:\n",
        "                raise ValueError(\"No generated text in API response\")\n",
        "\n",
        "            # Clean response: Remove any text before the first section marker\n",
        "            start_marker = \"=== MULTIPLE CHOICE QUESTIONS ===\"\n",
        "            start_index = quiz_text.find(start_marker)\n",
        "            if start_index == -1:\n",
        "                if self.debug:\n",
        "                    print(\"Response format error. Raw response:\")\n",
        "                    print(quiz_text[:500] + \"...\" if len(quiz_text) > 500 else quiz_text)\n",
        "                raise ValueError(\"Response does not contain expected section markers\")\n",
        "\n",
        "            quiz_text = quiz_text[start_index:]\n",
        "\n",
        "            # Initialize structured quiz\n",
        "            structured_quiz = {\n",
        "                \"multiple_choice\": [],\n",
        "                \"fill_in_blanks\": [],\n",
        "                \"short_answer\": []\n",
        "            }\n",
        "\n",
        "            current_section_type = None\n",
        "            current_difficulty = None\n",
        "            current_question = None\n",
        "\n",
        "            for line in quiz_text.split('\\n'):\n",
        "                line = line.strip()\n",
        "                if not line:\n",
        "                    continue\n",
        "\n",
        "                # Determine section type\n",
        "                if \"=== MULTIPLE CHOICE QUESTIONS ===\" in line:\n",
        "                    current_section_type = \"multiple_choice\"\n",
        "                    continue\n",
        "                elif \"=== FILL IN THE BLANKS ===\" in line:\n",
        "                    current_section_type = \"fill_in_blanks\"\n",
        "                    continue\n",
        "                elif \"=== SHORT ANSWER QUESTIONS ===\" in line:\n",
        "                    current_section_type = \"short_answer\"\n",
        "                    continue\n",
        "\n",
        "                # Check for difficulty\n",
        "                if line.startswith('[Difficulty:'):\n",
        "                    try:\n",
        "                        current_difficulty = line.split(':')[1].strip().rstrip(']').lower()\n",
        "                        if current_difficulty not in ['easy', 'medium', 'hard']:\n",
        "                            print(f\"Warning: Invalid difficulty level found: {current_difficulty}\")\n",
        "                            current_difficulty = 'medium'  # Default to medium if invalid\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error parsing difficulty: {str(e)}\")\n",
        "                        current_difficulty = 'medium'  # Default to medium if parsing fails\n",
        "                    continue\n",
        "\n",
        "                try:\n",
        "                    # Parse Multiple Choice Questions\n",
        "                    if current_section_type == \"multiple_choice\":\n",
        "                        if line.startswith('Q'):\n",
        "                            if current_question:\n",
        "                                structured_quiz[\"multiple_choice\"].append(current_question)\n",
        "                            current_question = {\n",
        "                                \"type\": \"multiple_choice\",\n",
        "                                \"difficulty\": current_difficulty,\n",
        "                                \"question\": line.split('.', 1)[1].strip() if '.' in line else line,\n",
        "                                \"options\": [],\n",
        "                                \"correct_answer\": \"\",\n",
        "                                \"explanation\": \"\",\n",
        "                                \"user_answer\": \"\"  # Add user_answer field\n",
        "                            }\n",
        "                        elif line.startswith(('A)', 'B)', 'C)', 'D)')):\n",
        "                            if current_question:\n",
        "                                current_question[\"options\"].append({\n",
        "                                    \"label\": line[0],\n",
        "                                    \"text\": line[2:].strip()\n",
        "                                })\n",
        "                        elif line.startswith('Correct:'):\n",
        "                            if current_question:\n",
        "                                current_question[\"correct_answer\"] = line.split(':')[1].strip()\n",
        "                        elif line.startswith('Explanation:'):\n",
        "                            if current_question:\n",
        "                                current_question[\"explanation\"] = line.split(':', 1)[1].strip()\n",
        "                                structured_quiz[\"multiple_choice\"].append(current_question)\n",
        "                                current_question = None\n",
        "\n",
        "                    # Parse Fill in the Blanks\n",
        "                    elif current_section_type == \"fill_in_blanks\":\n",
        "                        if line.startswith('Q'):\n",
        "                            if current_question:\n",
        "                                structured_quiz[\"fill_in_blanks\"].append(current_question)\n",
        "                            current_question = {\n",
        "                                \"type\": \"fill_in_blanks\",\n",
        "                                \"difficulty\": current_difficulty,\n",
        "                                \"question\": line.split('.', 1)[1].strip() if '.' in line else line,\n",
        "                                \"answer\": \"\",\n",
        "                                \"explanation\": \"\",\n",
        "                                \"user_answer\": \"\"  # Add user_answer field\n",
        "                            }\n",
        "                        elif line.startswith('Answer:'):\n",
        "                            if current_question:\n",
        "                                current_question[\"answer\"] = line.split(':', 1)[1].strip()\n",
        "                        elif line.startswith('Explanation:'):\n",
        "                            if current_question:\n",
        "                                current_question[\"explanation\"] = line.split(':', 1)[1].strip()\n",
        "                                structured_quiz[\"fill_in_blanks\"].append(current_question)\n",
        "                                current_question = None\n",
        "\n",
        "                    # Parse Short Answer Questions\n",
        "                    elif current_section_type == \"short_answer\":\n",
        "                        if line.startswith('Q'):\n",
        "                            if current_question:\n",
        "                                structured_quiz[\"short_answer\"].append(current_question)\n",
        "                            current_question = {\n",
        "                                \"type\": \"short_answer\",\n",
        "                                \"difficulty\": current_difficulty,\n",
        "                                \"question\": line.split('.', 1)[1].strip() if '.' in line else line,\n",
        "                                \"answer\": \"\",\n",
        "                                \"key_points\": [],\n",
        "                                \"user_answer\": \"\"  # Add user_answer field\n",
        "                            }\n",
        "                        elif line.startswith('Answer:'):\n",
        "                            if current_question:\n",
        "                                current_question[\"answer\"] = line.split(':', 1)[1].strip()\n",
        "                        elif line.startswith('Key Points:'):\n",
        "                            if current_question:\n",
        "                                current_question[\"key_points\"] = [\n",
        "                                    point.strip()\n",
        "                                    for point in line.split(':', 1)[1].strip().split(',')\n",
        "                                ]\n",
        "                                structured_quiz[\"short_answer\"].append(current_question)\n",
        "                                current_question = None\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error parsing line '{line}': {str(e)}\")\n",
        "                    continue\n",
        "\n",
        "            # Add the last question if it exists\n",
        "            if current_question:\n",
        "                if current_section_type == \"multiple_choice\":\n",
        "                    structured_quiz[\"multiple_choice\"].append(current_question)\n",
        "                elif current_section_type == \"fill_in_blanks\":\n",
        "                    structured_quiz[\"fill_in_blanks\"].append(current_question)\n",
        "                elif current_section_type == \"short_answer\":\n",
        "                    structured_quiz[\"short_answer\"].append(current_question)\n",
        "\n",
        "            # Calculate metadata\n",
        "            quiz_metadata = self._calculate_metadata(structured_quiz)\n",
        "\n",
        "            return {\n",
        "                \"metadata\": quiz_metadata,\n",
        "                \"quiz\": structured_quiz,\n",
        "                \"raw_response\": quiz_text\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error parsing quiz response: {str(e)}\")\n",
        "            if self.debug:\n",
        "                print(\"\\nFull response for debugging:\")\n",
        "                print(quiz_text[:500] + \"...\" if len(quiz_text) > 500 else quiz_text)\n",
        "            raise\n",
        "\n",
        "    def _calculate_metadata(self, quiz: Dict) -> Dict:\n",
        "        \"\"\"Calculate quiz metadata with accurate difficulty distribution.\"\"\"\n",
        "        try:\n",
        "            # Calculate total questions\n",
        "            total_questions = sum(len(questions) for questions in quiz.values())\n",
        "\n",
        "            # Calculate question type counts\n",
        "            question_types = {\n",
        "                qtype: len(questions)\n",
        "                for qtype, questions in quiz.items()\n",
        "            }\n",
        "\n",
        "            # Calculate difficulty distribution\n",
        "            difficulty_distribution = {\n",
        "                \"easy\": sum(1 for questions in quiz.values()\n",
        "                           for q in questions if q.get(\"difficulty\") == \"easy\"),\n",
        "                \"medium\": sum(1 for questions in quiz.values()\n",
        "                             for q in questions if q.get(\"difficulty\") == \"medium\"),\n",
        "                \"hard\": sum(1 for questions in quiz.values()\n",
        "                           for q in questions if q.get(\"difficulty\") == \"hard\")\n",
        "            }\n",
        "\n",
        "            # Calculate per-section difficulty distribution\n",
        "            section_difficulty_distribution = {\n",
        "                section_type: {\n",
        "                    \"easy\": sum(1 for q in questions if q.get(\"difficulty\") == \"easy\"),\n",
        "                    \"medium\": sum(1 for q in questions if q.get(\"difficulty\") == \"medium\"),\n",
        "                    \"hard\": sum(1 for q in questions if q.get(\"difficulty\") == \"hard\")\n",
        "                }\n",
        "                for section_type, questions in quiz.items()\n",
        "            }\n",
        "\n",
        "            return {\n",
        "                \"total_questions\": total_questions,\n",
        "                \"question_types\": question_types,\n",
        "                \"difficulty_distribution\": difficulty_distribution,\n",
        "                \"section_difficulty_distribution\": section_difficulty_distribution,\n",
        "                \"generation_timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "            }\n",
        "        except Exception as e:\n",
        "            print(f\"Error calculating metadata: {str(e)}\")\n",
        "            return {\n",
        "                \"total_questions\": 0,\n",
        "                \"question_types\": {\n",
        "                    \"multiple_choice\": 0,\n",
        "                    \"fill_in_blanks\": 0,\n",
        "                    \"short_answer\": 0\n",
        "                },\n",
        "                \"difficulty_distribution\": {\n",
        "                    \"easy\": 0,\n",
        "                    \"medium\": 0,\n",
        "                    \"hard\": 0\n",
        "                },\n",
        "                \"section_difficulty_distribution\": {},\n",
        "                \"generation_timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "            }\n",
        "\n",
        "    def generate_quiz(self, context_file_path: str) -> Dict:\n",
        "        \"\"\"Generate a complete quiz with error handling.\"\"\"\n",
        "        try:\n",
        "            content = self.read_context_file(context_file_path)\n",
        "            if self.debug:\n",
        "                print(f\"\\nRead {len(content)} characters from {context_file_path}\")\n",
        "\n",
        "            prompt = self.generate_quiz_prompt(content)\n",
        "            response = self.query_groq_api(prompt)\n",
        "\n",
        "            # Verify all sections are present\n",
        "            required_sections = [\n",
        "                \"=== MULTIPLE CHOICE QUESTIONS ===\",\n",
        "                \"=== FILL IN THE BLANKS ===\",\n",
        "                \"=== SHORT ANSWER QUESTIONS ===\"\n",
        "            ]\n",
        "\n",
        "            missing_sections = [\n",
        "                section for section in required_sections\n",
        "                if section not in response\n",
        "            ]\n",
        "\n",
        "            if missing_sections:\n",
        "                raise Exception(f\"Missing required sections: {', '.join(missing_sections)}\")\n",
        "\n",
        "            return self.parse_quiz_response(response, prompt)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Quiz generation failed: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def conduct_quiz(self, quiz: Dict) -> Dict:\n",
        "      \"\"\"\n",
        "    Conduct the quiz dynamically, adjusting difficulty based on user performance.\n",
        "    If the user does not correctly answer all of the first 5 questions in a section,\n",
        "    display a message to revisit the slides and do not proceed with further questions.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(\"\\nWelcome to the Quiz!\")\n",
        "        print(\"You will be asked questions one by one. Answer them to the best of your ability.\\n\")\n",
        "\n",
        "        # Initialize counters for overall correct answers\n",
        "        overall_correct_count = 0\n",
        "        total_questions = quiz['metadata']['total_questions']\n",
        "\n",
        "        # Iterate through each question type section\n",
        "        for section_type, questions in quiz['quiz'].items():\n",
        "            print(f\"\\n=== {section_type.replace('_', ' ').title()} ===\")\n",
        "            section_correct = 0\n",
        "\n",
        "            # First, ask the first 5 questions for the section\n",
        "            for idx, question in enumerate(questions):\n",
        "                if idx == 5:\n",
        "                    break\n",
        "\n",
        "                print(f\"\\nQuestion: {question['question']}\")\n",
        "\n",
        "                # Handle different question types\n",
        "                if section_type == \"multiple_choice\":\n",
        "                    print(\"Options:\")\n",
        "                    for option in question['options']:\n",
        "                        print(f\"{option['label']}) {option['text']}\")\n",
        "                    user_answer = input(\"Your answer (A/B/C/D): \").strip().upper()\n",
        "                elif section_type == \"fill_in_blanks\":\n",
        "                    user_answer = input(\"Fill in the blank: \").strip()\n",
        "                elif section_type == \"short_answer\":\n",
        "                    user_answer = input(\"Your answer: \").strip()\n",
        "\n",
        "                # Update the user_answer field\n",
        "                question['user_answer'] = user_answer\n",
        "\n",
        "                # Check if the answer is correct; note that for short answer, you may need additional logic\n",
        "                # Here, we assume 'correct_answer' is provided in the prompt for consistency.\n",
        "                if user_answer.lower() == question.get('correct_answer', '').lower():\n",
        "                    print(\"Correct! 🎉\")\n",
        "                    overall_correct_count += 1\n",
        "                    section_correct += 1\n",
        "                else:\n",
        "                    print(f\"Incorrect. The correct answer is: {question.get('correct_answer', 'N/A')}\")\n",
        "\n",
        "            # If not all of the first 5 questions were answered correctly, stop the quiz for this section.\n",
        "            if section_correct < 5:\n",
        "                print(\"\\nYou did not answer all of the first 5 questions correctly.\")\n",
        "                print(\"Please revisit the slides and try again later.\")\n",
        "                # Optionally, you can break out of the entire quiz here or just skip remaining questions in this section.\n",
        "                continue  # Skip remaining questions in this section\n",
        "\n",
        "            # If the first 5 are all correct, then proceed with the rest of the questions in the section.\n",
        "            for question in questions[5:]:\n",
        "                print(f\"\\nQuestion: {question['question']}\")\n",
        "\n",
        "                if section_type == \"multiple_choice\":\n",
        "                    print(\"Options:\")\n",
        "                    for option in question['options']:\n",
        "                        print(f\"{option['label']}) {option['text']}\")\n",
        "                    user_answer = input(\"Your answer (A/B/C/D): \").strip().upper()\n",
        "                elif section_type == \"fill_in_blanks\":\n",
        "                    user_answer = input(\"Fill in the blank: \").strip()\n",
        "                elif section_type == \"short_answer\":\n",
        "                    user_answer = input(\"Your answer: \").strip()\n",
        "\n",
        "                question['user_answer'] = user_answer\n",
        "\n",
        "                if user_answer.lower() == question.get('correct_answer', '').lower():\n",
        "                    print(\"Correct! 🎉\")\n",
        "                    overall_correct_count += 1\n",
        "                else:\n",
        "                    print(f\"Incorrect. The correct answer is: {question.get('correct_answer', 'N/A')}\")\n",
        "\n",
        "        # Provide explanations for incorrect answers at the end\n",
        "        print(\"\\n=== Quiz Results ===\")\n",
        "        print(f\"You answered {overall_correct_count} out of {total_questions} questions correctly.\")\n",
        "\n",
        "        if overall_correct_count < total_questions:\n",
        "            print(\"\\nHere are the explanations for the questions you got wrong:\")\n",
        "            for section_type, questions in quiz['quiz'].items():\n",
        "                for question in questions:\n",
        "                    if question.get('correct_answer') and question['user_answer'].lower() != question['correct_answer'].lower():\n",
        "                        print(f\"\\nQuestion: {question['question']}\")\n",
        "                        print(f\"Your answer: {question['user_answer']}\")\n",
        "                        print(f\"Correct answer: {question['correct_answer']}\")\n",
        "                        print(f\"Explanation: {question['explanation']}\")\n",
        "\n",
        "        # Save the updated quiz with user answers\n",
        "        output_dir = \"quiz_output\"\n",
        "        if not os.path.exists(output_dir):\n",
        "            os.makedirs(output_dir)\n",
        "\n",
        "        updated_quiz_path = os.path.join(output_dir, 'updated_quiz_with_answers.json')\n",
        "        with open(updated_quiz_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(quiz, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "        print(f\"\\nYour quiz results have been saved to {updated_quiz_path}\")\n",
        "        return quiz\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error conducting quiz: {str(e)}\")\n",
        "        raise\n",
        "def main():\n",
        "    try:\n",
        "        print(\"Starting quiz generation...\")\n",
        "\n",
        "        # Check for API key\n",
        "        api_key = os.getenv('GROQ_API_KEY')\n",
        "        if not api_key:\n",
        "            print(\"Error: GROQ_API_KEY environment variable not found!\")\n",
        "            print(\"\\nPlease set your Groq API key as an environment variable:\")\n",
        "            print(\"export GROQ_API_KEY='your-api-key'\")\n",
        "            return\n",
        "\n",
        "        if not os.path.exists(\"content.txt\"):\n",
        "            print(\"Error: content.txt file not found!\")\n",
        "            print(\"\\nPlease create a content.txt file with your technical content.\")\n",
        "            print(\"The content can be about any computer science or technical topic.\")\n",
        "            print(\"\\nFile requirements:\")\n",
        "            print(\"1. Save as 'content.txt' in the same directory as this script\")\n",
        "            print(\"2. Use UTF-8 encoding\")\n",
        "            print(\"3. Include sufficient content for meaningful questions\")\n",
        "            return\n",
        "\n",
        "        quiz_gen = QuizGenerator(api_key=api_key, debug=True)\n",
        "\n",
        "        print(\"\\nReading content and generating quiz...\")\n",
        "        print(\"This may take a few minutes depending on the content length.\")\n",
        "        quiz = quiz_gen.generate_quiz(\"content.txt\")\n",
        "\n",
        "        # Conduct the quiz\n",
        "        quiz_gen.conduct_quiz(quiz)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError: {str(e)}\")\n",
        "        print(\"\\nTroubleshooting tips:\")\n",
        "        print(\"1. Check that content.txt exists and is readable\")\n",
        "        print(\"2. Verify the content.txt has enough text to generate questions\")\n",
        "        print(\"3. Ensure content.txt is saved with UTF-8 encoding\")\n",
        "        print(\"4. Try running the script again (API might be temporarily busy)\")\n",
        "        print(\"5. Check your internet connection\")\n",
        "        print(\"6. Verify your Groq API key is set correctly\")\n",
        "        print(\"\\nFor more details, check:\")\n",
        "        print(\"- The error message above\")\n",
        "        print(\"- quiz_raw.txt file (if created)\")\n",
        "        print(\"- generated_quiz.json file (if created)\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "zE2n8Q3-0dV_",
        "outputId": "e2495ea6-a4d3-4767-ed86-ea0543f18ea5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "'return' outside function (<ipython-input-10-4cb05f653cf1>, line 505)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-4cb05f653cf1>\"\u001b[0;36m, line \u001b[0;32m505\u001b[0m\n\u001b[0;31m    return quiz\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'return' outside function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import time\n",
        "import os\n",
        "from typing import Dict, List, Union\n",
        "from groq import Groq\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# Initialize Sentence Transformer model (load once)\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "def is_similar(user_answer: str, correct_answer: str, threshold: float = 0.65) -> bool:\n",
        "    \"\"\"\n",
        "    Compute the cosine similarity between user_answer and correct_answer using Sentence Transformers.\n",
        "    Return True if similarity is above the threshold, otherwise False.\n",
        "    \"\"\"\n",
        "    embeddings = model.encode([user_answer, correct_answer])\n",
        "    similarity = util.cos_sim(embeddings[0], embeddings[1]).item()\n",
        "    # Debug: Uncomment the next line if you want to see the similarity score.\n",
        "    # print(f\"Similarity score: {similarity}\")\n",
        "    return similarity >= threshold\n",
        "\n",
        "class GroqClient:\n",
        "    def __init__(self, api_key):\n",
        "        self.client = Groq(api_key=api_key)\n",
        "\n",
        "    def get_completion(self, query, max_tokens=4000):\n",
        "        try:\n",
        "            chat_completion = self.client.chat.completions.create(\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"system\",\n",
        "                        \"content\": \"You are a technical quiz generation expert. You must follow the format EXACTLY as specified and start your response with === MULTIPLE CHOICE QUESTIONS ===\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": query\n",
        "                    }\n",
        "                ],\n",
        "                model=\"deepseek-r1-distill-llama-70b\",\n",
        "                temperature=0.5,\n",
        "                max_tokens=max_tokens,\n",
        "                top_p=0.7,\n",
        "                stream=False\n",
        "            )\n",
        "            return chat_completion.choices[0].message.content\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"API request failed: {str(e)}\")\n",
        "\n",
        "class QuizGenerator:\n",
        "    def __init__(self, api_key: str, debug=True):\n",
        "        \"\"\"Initialize with Groq client and debug option.\"\"\"\n",
        "        self.debug = debug\n",
        "        self.client = GroqClient(api_key=api_key)\n",
        "\n",
        "    def read_context_file(self, file_path: str) -> str:\n",
        "        \"\"\"Read content from the context file with proper error handling.\"\"\"\n",
        "        try:\n",
        "            if not os.path.exists(file_path):\n",
        "                raise FileNotFoundError(f\"Content file not found: {file_path}\")\n",
        "\n",
        "            if not os.access(file_path, os.R_OK):\n",
        "                raise PermissionError(f\"Cannot read content file: {file_path}\")\n",
        "\n",
        "            with open(file_path, 'r', encoding='utf-8') as file:\n",
        "                content = file.read()\n",
        "\n",
        "            if not content.strip():\n",
        "                raise ValueError(f\"Content file is empty: {file_path}\")\n",
        "\n",
        "            if self.debug:\n",
        "                print(f\"Successfully read {len(content)} characters from {file_path}\")\n",
        "\n",
        "            # Clean up content\n",
        "            content = content.replace('\\ufeff', '').replace('\\r\\n', '\\n')\n",
        "\n",
        "            return content\n",
        "\n",
        "        except UnicodeDecodeError:\n",
        "            raise Exception(f\"File encoding error. Please ensure {file_path} is saved in UTF-8 format.\")\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"Error reading content file: {str(e)}\")\n",
        "\n",
        "    def generate_quiz_prompt(self, content: str) -> str:\n",
        "        \"\"\"Generate a structured prompt for the quiz.\"\"\"\n",
        "        return f\"\"\"<s>[INST] IMPORTANT: Follow these instructions EXACTLY. DO NOT include any thinking, planning, or additional text.\n",
        "START YOUR RESPONSE DIRECTLY with \"=== MULTIPLE CHOICE QUESTIONS ===\" and ONLY use the specified format.\n",
        "\n",
        "Based on the provided technical content, create:\n",
        "\n",
        "1. Multiple Choice Questions (15 total):\n",
        "   - 5 Easy questions: Test basic terminology and concept recall\n",
        "   - 5 Medium questions: Test understanding of relationships and principles\n",
        "   - 5 Hard questions: Test advanced concepts and technical analysis\n",
        "\n",
        "2. Fill in the Blanks (15 total):\n",
        "   - 5 Easy questions: Basic terminology and definitions\n",
        "   - 5 Medium questions: Technical relationships and components\n",
        "   - 5 Hard questions: Complex technical concepts and implementations\n",
        "\n",
        "3. Short Answer Questions (15 total):\n",
        "   - 5 Easy questions: Basic concept explanation\n",
        "   - 5 Medium questions: Understanding mechanisms and relationships\n",
        "   - 5 Hard questions: Technical analysis and practical applications\n",
        "\n",
        "USE THIS EXACT FORMAT - DO NOT DEVIATE:\n",
        "\n",
        "=== MULTIPLE CHOICE QUESTIONS ===\n",
        "[Difficulty: Easy]\n",
        "Q1. Question text\n",
        "A) Option A\n",
        "B) Option B\n",
        "C) Option C\n",
        "D) Option D\n",
        "Correct: [Letter]\n",
        "Explanation: Brief explanation\n",
        "\n",
        "=== FILL IN THE BLANKS ===\n",
        "[Difficulty: Easy]\n",
        "Q1. Sentence with _____ to fill\n",
        "Answer: Correct answer\n",
        "Explanation: Brief explanation\n",
        "\n",
        "=== SHORT ANSWER QUESTIONS ===\n",
        "[Difficulty: Easy]\n",
        "Q1. Question text\n",
        "Answer: Model answer\n",
        "Key Points: Key point 1, Key point 2\n",
        "\n",
        "Content to create questions from:\n",
        "{content}\n",
        "\n",
        "REQUIREMENTS:\n",
        "- Start IMMEDIATELY with \"=== MULTIPLE CHOICE QUESTIONS ===\"\n",
        "- Use EXACT formatting shown above\n",
        "- Include ALL THREE sections in order\n",
        "- Follow the difficulty distribution exactly (5 Easy, 5 Medium, 5 Hard for each section)\n",
        "- NO additional text or thinking process\n",
        "[/INST]</s>\"\"\"\n",
        "\n",
        "    def query_groq_api(self, prompt: str, max_tokens: int = 4000) -> str:\n",
        "        \"\"\"Query the Groq API with proper error handling.\"\"\"\n",
        "        max_retries = 3\n",
        "        wait_time = 50  # Initial wait time of 50 seconds\n",
        "\n",
        "        for attempt in range(max_retries):\n",
        "            try:\n",
        "                if self.debug:\n",
        "                    print(f\"\\nAttempt {attempt + 1} of {max_retries}\")\n",
        "\n",
        "                response = self.client.get_completion(query=prompt, max_tokens=max_tokens)\n",
        "\n",
        "                if self.debug:\n",
        "                    print(\"Successfully received response from Groq API\")\n",
        "\n",
        "                return response\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Attempt {attempt + 1} failed: {str(e)}\")\n",
        "                if attempt < max_retries - 1:\n",
        "                    print(f\"Waiting {wait_time} seconds before retry...\")\n",
        "                    time.sleep(wait_time)\n",
        "                    wait_time *= 1.5  # Increase wait time by 50% for each retry\n",
        "                else:\n",
        "                    raise Exception(\"Failed to get valid response after all retries\")\n",
        "\n",
        "    def parse_quiz_response(self, quiz_text: str, prompt: str) -> Dict:\n",
        "        \"\"\"Parse the API response into structured format with dynamic difficulty validation.\"\"\"\n",
        "        try:\n",
        "            if not quiz_text:\n",
        "                raise ValueError(\"No generated text in API response\")\n",
        "\n",
        "            # Clean response: Remove any text before the first section marker\n",
        "            start_marker = \"=== MULTIPLE CHOICE QUESTIONS ===\"\n",
        "            start_index = quiz_text.find(start_marker)\n",
        "            if start_index == -1:\n",
        "                if self.debug:\n",
        "                    print(\"Response format error. Raw response:\")\n",
        "                    print(quiz_text[:500] + \"...\" if len(quiz_text) > 500 else quiz_text)\n",
        "                raise ValueError(\"Response does not contain expected section markers\")\n",
        "\n",
        "            quiz_text = quiz_text[start_index:]\n",
        "\n",
        "            # Initialize structured quiz\n",
        "            structured_quiz = {\n",
        "                \"multiple_choice\": [],\n",
        "                \"fill_in_blanks\": [],\n",
        "                \"short_answer\": []\n",
        "            }\n",
        "\n",
        "            current_section_type = None\n",
        "            current_difficulty = None\n",
        "            current_question = None\n",
        "\n",
        "            for line in quiz_text.split('\\n'):\n",
        "                line = line.strip()\n",
        "                if not line:\n",
        "                    continue\n",
        "\n",
        "                # Determine section type\n",
        "                if \"=== MULTIPLE CHOICE QUESTIONS ===\" in line:\n",
        "                    current_section_type = \"multiple_choice\"\n",
        "                    continue\n",
        "                elif \"=== FILL IN THE BLANKS ===\" in line:\n",
        "                    current_section_type = \"fill_in_blanks\"\n",
        "                    continue\n",
        "                elif \"=== SHORT ANSWER QUESTIONS ===\" in line:\n",
        "                    current_section_type = \"short_answer\"\n",
        "                    continue\n",
        "\n",
        "                # Check for difficulty\n",
        "                if line.startswith('[Difficulty:'):\n",
        "                    try:\n",
        "                        current_difficulty = line.split(':')[1].strip().rstrip(']').lower()\n",
        "                        if current_difficulty not in ['easy', 'medium', 'hard']:\n",
        "                            print(f\"Warning: Invalid difficulty level found: {current_difficulty}\")\n",
        "                            current_difficulty = 'medium'  # Default to medium if invalid\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error parsing difficulty: {str(e)}\")\n",
        "                        current_difficulty = 'medium'  # Default to medium if parsing fails\n",
        "                    continue\n",
        "\n",
        "                try:\n",
        "                    # Parse Multiple Choice Questions\n",
        "                    if current_section_type == \"multiple_choice\":\n",
        "                        if line.startswith('Q'):\n",
        "                            if current_question:\n",
        "                                structured_quiz[\"multiple_choice\"].append(current_question)\n",
        "                            current_question = {\n",
        "                                \"type\": \"multiple_choice\",\n",
        "                                \"difficulty\": current_difficulty,\n",
        "                                \"question\": line.split('.', 1)[1].strip() if '.' in line else line,\n",
        "                                \"options\": [],\n",
        "                                \"correct_answer\": \"\",\n",
        "                                \"explanation\": \"\",\n",
        "                                \"user_answer\": \"\"\n",
        "                            }\n",
        "                        elif line.startswith(('A)', 'B)', 'C)', 'D)')):\n",
        "                            if current_question:\n",
        "                                current_question[\"options\"].append({\n",
        "                                    \"label\": line[0],\n",
        "                                    \"text\": line[2:].strip()\n",
        "                                })\n",
        "                        elif line.startswith('Correct:'):\n",
        "                            if current_question:\n",
        "                                current_question[\"correct_answer\"] = line.split(':')[1].strip()\n",
        "                        elif line.startswith('Explanation:'):\n",
        "                            if current_question:\n",
        "                                current_question[\"explanation\"] = line.split(':', 1)[1].strip()\n",
        "                                structured_quiz[\"multiple_choice\"].append(current_question)\n",
        "                                current_question = None\n",
        "\n",
        "                    # Parse Fill in the Blanks\n",
        "                    elif current_section_type == \"fill_in_blanks\":\n",
        "                        if line.startswith('Q'):\n",
        "                            if current_question:\n",
        "                                structured_quiz[\"fill_in_blanks\"].append(current_question)\n",
        "                            current_question = {\n",
        "                                \"type\": \"fill_in_blanks\",\n",
        "                                \"difficulty\": current_difficulty,\n",
        "                                \"question\": line.split('.', 1)[1].strip() if '.' in line else line,\n",
        "                                \"answer\": \"\",\n",
        "                                \"explanation\": \"\",\n",
        "                                \"user_answer\": \"\"\n",
        "                            }\n",
        "                        elif line.startswith('Answer:'):\n",
        "                            if current_question:\n",
        "                                current_question[\"answer\"] = line.split(':', 1)[1].strip()\n",
        "                        elif line.startswith('Explanation:'):\n",
        "                            if current_question:\n",
        "                                current_question[\"explanation\"] = line.split(':', 1)[1].strip()\n",
        "                                structured_quiz[\"fill_in_blanks\"].append(current_question)\n",
        "                                current_question = None\n",
        "\n",
        "                    # Parse Short Answer Questions\n",
        "                    elif current_section_type == \"short_answer\":\n",
        "                        if line.startswith('Q'):\n",
        "                            if current_question:\n",
        "                                structured_quiz[\"short_answer\"].append(current_question)\n",
        "                            current_question = {\n",
        "                                \"type\": \"short_answer\",\n",
        "                                \"difficulty\": current_difficulty,\n",
        "                                \"question\": line.split('.', 1)[1].strip() if '.' in line else line,\n",
        "                                \"answer\": \"\",\n",
        "                                \"key_points\": [],\n",
        "                                \"user_answer\": \"\"\n",
        "                            }\n",
        "                        elif line.startswith('Answer:'):\n",
        "                            if current_question:\n",
        "                                current_question[\"answer\"] = line.split(':', 1)[1].strip()\n",
        "                        elif line.startswith('Key Points:'):\n",
        "                            if current_question:\n",
        "                                current_question[\"key_points\"] = [\n",
        "                                    point.strip()\n",
        "                                    for point in line.split(':', 1)[1].strip().split(',')\n",
        "                                ]\n",
        "                                structured_quiz[\"short_answer\"].append(current_question)\n",
        "                                current_question = None\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error parsing line '{line}': {str(e)}\")\n",
        "                    continue\n",
        "\n",
        "            # Add the last question if it exists\n",
        "            if current_question:\n",
        "                if current_section_type == \"multiple_choice\":\n",
        "                    structured_quiz[\"multiple_choice\"].append(current_question)\n",
        "                elif current_section_type == \"fill_in_blanks\":\n",
        "                    structured_quiz[\"fill_in_blanks\"].append(current_question)\n",
        "                elif current_section_type == \"short_answer\":\n",
        "                    structured_quiz[\"short_answer\"].append(current_question)\n",
        "\n",
        "            # Calculate metadata\n",
        "            quiz_metadata = self._calculate_metadata(structured_quiz)\n",
        "\n",
        "            return {\n",
        "                \"metadata\": quiz_metadata,\n",
        "                \"quiz\": structured_quiz,\n",
        "                \"raw_response\": quiz_text\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error parsing quiz response: {str(e)}\")\n",
        "            if self.debug:\n",
        "                print(\"\\nFull response for debugging:\")\n",
        "                print(quiz_text[:500] + \"...\" if len(quiz_text) > 500 else quiz_text)\n",
        "            raise\n",
        "\n",
        "    def _calculate_metadata(self, quiz: Dict) -> Dict:\n",
        "        \"\"\"Calculate quiz metadata with accurate difficulty distribution.\"\"\"\n",
        "        try:\n",
        "            # Calculate total questions\n",
        "            total_questions = sum(len(questions) for questions in quiz.values())\n",
        "\n",
        "            # Calculate question type counts\n",
        "            question_types = {\n",
        "                qtype: len(questions)\n",
        "                for qtype, questions in quiz.items()\n",
        "            }\n",
        "\n",
        "            # Calculate difficulty distribution\n",
        "            difficulty_distribution = {\n",
        "                \"easy\": sum(1 for questions in quiz.values()\n",
        "                           for q in questions if q.get(\"difficulty\") == \"easy\"),\n",
        "                \"medium\": sum(1 for questions in quiz.values()\n",
        "                             for q in questions if q.get(\"difficulty\") == \"medium\"),\n",
        "                \"hard\": sum(1 for questions in quiz.values()\n",
        "                           for q in questions if q.get(\"difficulty\") == \"hard\")\n",
        "            }\n",
        "\n",
        "            # Calculate per-section difficulty distribution\n",
        "            section_difficulty_distribution = {\n",
        "                section_type: {\n",
        "                    \"easy\": sum(1 for q in questions if q.get(\"difficulty\") == \"easy\"),\n",
        "                    \"medium\": sum(1 for q in questions if q.get(\"difficulty\") == \"medium\"),\n",
        "                    \"hard\": sum(1 for q in questions if q.get(\"difficulty\") == \"hard\")\n",
        "                }\n",
        "                for section_type, questions in quiz.items()\n",
        "            }\n",
        "\n",
        "            return {\n",
        "                \"total_questions\": total_questions,\n",
        "                \"question_types\": question_types,\n",
        "                \"difficulty_distribution\": difficulty_distribution,\n",
        "                \"section_difficulty_distribution\": section_difficulty_distribution,\n",
        "                \"generation_timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "            }\n",
        "        except Exception as e:\n",
        "            print(f\"Error calculating metadata: {str(e)}\")\n",
        "            return {\n",
        "                \"total_questions\": 0,\n",
        "                \"question_types\": {\n",
        "                    \"multiple_choice\": 0,\n",
        "                    \"fill_in_blanks\": 0,\n",
        "                    \"short_answer\": 0\n",
        "                },\n",
        "                \"difficulty_distribution\": {\n",
        "                    \"easy\": 0,\n",
        "                    \"medium\": 0,\n",
        "                    \"hard\": 0\n",
        "                },\n",
        "                \"section_difficulty_distribution\": {},\n",
        "                \"generation_timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "            }\n",
        "\n",
        "    def generate_quiz(self, context_file_path: str) -> Dict:\n",
        "        \"\"\"Generate a complete quiz with error handling.\"\"\"\n",
        "        try:\n",
        "            content = self.read_context_file(context_file_path)\n",
        "            if self.debug:\n",
        "                print(f\"\\nRead {len(content)} characters from {context_file_path}\")\n",
        "\n",
        "            prompt = self.generate_quiz_prompt(content)\n",
        "            response = self.query_groq_api(prompt)\n",
        "\n",
        "            # Verify all sections are present\n",
        "            required_sections = [\n",
        "                \"=== MULTIPLE CHOICE QUESTIONS ===\",\n",
        "                \"=== FILL IN THE BLANKS ===\",\n",
        "                \"=== SHORT ANSWER QUESTIONS ===\"\n",
        "            ]\n",
        "\n",
        "            missing_sections = [\n",
        "                section for section in required_sections\n",
        "                if section not in response\n",
        "            ]\n",
        "\n",
        "            if missing_sections:\n",
        "                raise Exception(f\"Missing required sections: {', '.join(missing_sections)}\")\n",
        "\n",
        "            return self.parse_quiz_response(response, prompt)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Quiz generation failed: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def conduct_quiz(self, quiz: Dict) -> Dict:\n",
        "\n",
        "      \"\"\"\n",
        "      Conduct the quiz dynamically, adjusting difficulty based on user performance.\n",
        "      For each section, first ask 5 questions. If not all of these 5 are answered correctly,\n",
        "      instruct the user to revisit the slides and do not proceed with further questions in that section.\n",
        "      \"\"\"\n",
        "    try:\n",
        "        print(\"\\nWelcome to the Quiz!\")\n",
        "        print(\"You will be asked questions one by one. Answer them to the best of your ability.\\n\")\n",
        "\n",
        "        overall_correct_count = 0\n",
        "        total_questions = quiz['metadata']['total_questions']\n",
        "\n",
        "        # Iterate through each question type section\n",
        "        for section_type, questions in quiz['quiz'].items():\n",
        "            print(f\"\\n=== {section_type.replace('_', ' ').title()} ===\")\n",
        "            section_correct = 0\n",
        "\n",
        "            # Ask the first 5 questions for the section\n",
        "            for idx, question in enumerate(questions):\n",
        "                if idx == 5:\n",
        "                    break\n",
        "\n",
        "                print(f\"\\nQuestion: {question['question']}\")\n",
        "\n",
        "                if section_type == \"multiple_choice\":\n",
        "                    print(\"Options:\")\n",
        "                    for option in question['options']:\n",
        "                        print(f\"{option['label']}) {option['text']}\")\n",
        "                    user_answer = input(\"Your answer (A/B/C/D): \").strip().upper()\n",
        "                elif section_type == \"fill_in_blanks\":\n",
        "                    user_answer = input(\"Fill in the blank: \").strip()\n",
        "                elif section_type == \"short_answer\":\n",
        "                    user_answer = input(\"Your answer: \").strip()\n",
        "\n",
        "                question['user_answer'] = user_answer\n",
        "\n",
        "                # Check the answer based on question type\n",
        "                if section_type == \"short_answer\":\n",
        "                    if is_similar(user_answer, question['answer']):\n",
        "                        print(\"Correct! 🎉\")\n",
        "                        overall_correct_count += 1\n",
        "                        section_correct += 1\n",
        "                    else:\n",
        "                        print(f\"Incorrect. The correct answer is: {question['answer']}\")\n",
        "                elif section_type == \"fill_in_blanks\":\n",
        "                    if user_answer.lower() == question['answer'].lower():\n",
        "                        print(\"Correct! 🎉\")\n",
        "                        overall_correct_count += 1\n",
        "                        section_correct += 1\n",
        "                    else:\n",
        "                        print(f\"Incorrect. The correct answer is: {question['answer']}\")\n",
        "                else:  # multiple_choice\n",
        "                    # Remove any brackets from the correct answer before comparison\n",
        "                    correct = question['correct_answer'].replace(\"[\", \"\").replace(\"]\", \"\").strip().upper()\n",
        "                    if user_answer == correct:\n",
        "                        print(\"Correct! 🎉\")\n",
        "                        overall_correct_count += 1\n",
        "                        section_correct += 1\n",
        "                    else:\n",
        "                        print(f\"Incorrect. The correct answer is: {question['correct_answer']}\")\n",
        "\n",
        "            # If not all of the first 5 questions were answered correctly, stop further questions in this section.\n",
        "            if section_correct < 5:\n",
        "                print(\"\\nYou did not answer all of the first 5 questions correctly in this section.\")\n",
        "                print(\"Please revisit the slides and try again later.\")\n",
        "                continue\n",
        "\n",
        "            # If the first 5 are all correct, proceed with the remaining questions in the section.\n",
        "            for question in questions[5:]:\n",
        "                print(f\"\\nQuestion: {question['question']}\")\n",
        "\n",
        "                if section_type == \"multiple_choice\":\n",
        "                    print(\"Options:\")\n",
        "                    for option in question['options']:\n",
        "                        print(f\"{option['label']}) {option['text']}\")\n",
        "                    user_answer = input(\"Your answer (A/B/C/D): \").strip().upper()\n",
        "                elif section_type == \"fill_in_blanks\":\n",
        "                    user_answer = input(\"Fill in the blank: \").strip()\n",
        "                elif section_type == \"short_answer\":\n",
        "                    user_answer = input(\"Your answer: \").strip()\n",
        "\n",
        "                question['user_answer'] = user_answer\n",
        "\n",
        "                if section_type == \"short_answer\":\n",
        "                    if is_similar(user_answer, question['answer']):\n",
        "                        print(\"Correct! 🎉\")\n",
        "                        overall_correct_count += 1\n",
        "                    else:\n",
        "                        print(f\"Incorrect. The correct answer is: {question['answer']}\")\n",
        "                elif section_type == \"fill_in_blanks\":\n",
        "                    if user_answer.lower() == question['answer'].lower():\n",
        "                        print(\"Correct! 🎉\")\n",
        "                        overall_correct_count += 1\n",
        "                    else:\n",
        "                        print(f\"Incorrect. The correct answer is: {question['answer']}\")\n",
        "                else:  # multiple_choice\n",
        "                    correct = question['correct_answer'].replace(\"[\", \"\").replace(\"]\", \"\").strip().upper()\n",
        "                    if user_answer == correct:\n",
        "                        print(\"Correct! 🎉\")\n",
        "                        overall_correct_count += 1\n",
        "                    else:\n",
        "                        print(f\"Incorrect. The correct answer is: {question['correct_answer']}\")\n",
        "\n",
        "        # Provide explanations for incorrect answers at the end\n",
        "        print(\"\\n=== Quiz Results ===\")\n",
        "        print(f\"You answered {overall_correct_count} out of {total_questions} questions correctly.\")\n",
        "\n",
        "        if overall_correct_count < total_questions:\n",
        "            print(\"\\nHere are the explanations for the questions you got wrong:\")\n",
        "            for section_type, questions in quiz['quiz'].items():\n",
        "                for question in questions:\n",
        "                    if section_type == \"short_answer\":\n",
        "                        if not is_similar(question['user_answer'], question['answer']):\n",
        "                            print(f\"\\nQuestion: {question['question']}\")\n",
        "                            print(f\"Your answer: {question['user_answer']}\")\n",
        "                            print(f\"Correct answer: {question['answer']}\")\n",
        "                    else:\n",
        "                        correct = question.get('correct_answer', \"\").replace(\"[\", \"\").replace(\"]\", \"\").strip().lower()\n",
        "                        if question.get('correct_answer') and question['user_answer'].lower() != correct:\n",
        "                            print(f\"\\nQuestion: {question['question']}\")\n",
        "                            print(f\"Your answer: {question['user_answer']}\")\n",
        "                            print(f\"Correct answer: {question['correct_answer']}\")\n",
        "                            print(f\"Explanation: {question['explanation']}\")\n",
        "\n",
        "        # Save the updated quiz with user answers\n",
        "        output_dir = \"quiz_output\"\n",
        "        if not os.path.exists(output_dir):\n",
        "            os.makedirs(output_dir)\n",
        "\n",
        "        updated_quiz_path = os.path.join(output_dir, 'updated_quiz_with_answers.json')\n",
        "        with open(updated_quiz_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(quiz, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "        print(f\"\\nYour quiz results have been saved to {updated_quiz_path}\")\n",
        "\n",
        "      return quiz\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error conducting quiz: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        print(\"Starting quiz generation...\")\n",
        "\n",
        "        # Check for API key\n",
        "        api_key = os.getenv('GROQ_API_KEY')\n",
        "        if not api_key:\n",
        "            print(\"Error: GROQ_API_KEY environment variable not found!\")\n",
        "            print(\"\\nPlease set your Groq API key as an environment variable:\")\n",
        "            print(\"export GROQ_API_KEY='your-api-key'\")\n",
        "            return\n",
        "\n",
        "        if not os.path.exists(\"content.txt\"):\n",
        "            print(\"Error: content.txt file not found!\")\n",
        "            print(\"\\nPlease create a content.txt file with your technical content.\")\n",
        "            print(\"The content can be about any computer science or technical topic.\")\n",
        "            print(\"\\nFile requirements:\")\n",
        "            print(\"1. Save as 'content.txt' in the same directory as this script\")\n",
        "            print(\"2. Use UTF-8 encoding\")\n",
        "            print(\"3. Include sufficient content for meaningful questions\")\n",
        "            return\n",
        "\n",
        "        quiz_gen = QuizGenerator(api_key=api_key, debug=True)\n",
        "\n",
        "        print(\"\\nReading content and generating quiz...\")\n",
        "        print(\"This may take a few minutes depending on the content length.\")\n",
        "        quiz = quiz_gen.generate_quiz(\"content.txt\")\n",
        "\n",
        "        # Save the generated quiz as JSON immediately\n",
        "        with open(\"generated_quiz.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(quiz, f, indent=2, ensure_ascii=False)\n",
        "        print(\"Generated quiz has been saved to generated_quiz.json\")\n",
        "\n",
        "        # Conduct the quiz\n",
        "        quiz_gen.conduct_quiz(quiz)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError: {str(e)}\")\n",
        "        print(\"\\nTroubleshooting tips:\")\n",
        "        print(\"1. Check that content.txt exists and is readable\")\n",
        "        print(\"2. Verify the content.txt has enough text to generate questions\")\n",
        "        print(\"3. Ensure content.txt is saved with UTF-8 encoding\")\n",
        "        print(\"4. Try running the script again (API might be temporarily busy)\")\n",
        "        print(\"5. Check your internet connection\")\n",
        "        print(\"6. Verify your Groq API key is set correctly\")\n",
        "        print(\"\\nFor more details, check:\")\n",
        "        print(\"- The error message above\")\n",
        "        print(\"- quiz_raw.txt file (if created)\")\n",
        "        print(\"- generated_quiz.json file (if created)\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "BfWjiDLwLojv",
        "outputId": "4be557a4-cd41-475a-e120-16f90e457787",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "'return' outside function (<ipython-input-16-ff9d1562341d>, line 553)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-ff9d1562341d>\"\u001b[0;36m, line \u001b[0;32m553\u001b[0m\n\u001b[0;31m    return quiz\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'return' outside function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import time\n",
        "import os\n",
        "from typing import Dict, List, Union\n",
        "from groq import Groq\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# Initialize Sentence Transformer model (load once)\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "def is_similar(user_answer: str, correct_answer: str, threshold: float = 0.65) -> bool:\n",
        "    \"\"\"\n",
        "    Compute the cosine similarity between user_answer and correct_answer using Sentence Transformers.\n",
        "    Return True if similarity is above the threshold, otherwise False.\n",
        "    \"\"\"\n",
        "    embeddings = model.encode([user_answer, correct_answer])\n",
        "    similarity = util.cos_sim(embeddings[0], embeddings[1]).item()\n",
        "    # Debug: Uncomment the next line if you want to see the similarity score.\n",
        "    # print(f\"Similarity score: {similarity}\")\n",
        "    return similarity >= threshold\n",
        "\n",
        "class GroqClient:\n",
        "    def __init__(self, api_key):\n",
        "        self.client = Groq(api_key=api_key)\n",
        "\n",
        "    def get_completion(self, query, max_tokens=4000):\n",
        "        try:\n",
        "            chat_completion = self.client.chat.completions.create(\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"system\",\n",
        "                        \"content\": \"You are a technical quiz generation expert. You must follow the format EXACTLY as specified and start your response with === MULTIPLE CHOICE QUESTIONS ===\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": query\n",
        "                    }\n",
        "                ],\n",
        "                model=\"deepseek-r1-distill-llama-70b\",\n",
        "                temperature=0.5,\n",
        "                max_tokens=max_tokens,\n",
        "                top_p=0.7,\n",
        "                stream=False\n",
        "            )\n",
        "            return chat_completion.choices[0].message.content\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"API request failed: {str(e)}\")\n",
        "\n",
        "class QuizGenerator:\n",
        "    def __init__(self, api_key: str, debug=True):\n",
        "        \"\"\"Initialize with Groq client and debug option.\"\"\"\n",
        "        self.debug = debug\n",
        "        self.client = GroqClient(api_key=api_key)\n",
        "\n",
        "    def read_context_file(self, file_path: str) -> str:\n",
        "        \"\"\"Read content from the context file with proper error handling.\"\"\"\n",
        "        try:\n",
        "            if not os.path.exists(file_path):\n",
        "                raise FileNotFoundError(f\"Content file not found: {file_path}\")\n",
        "\n",
        "            if not os.access(file_path, os.R_OK):\n",
        "                raise PermissionError(f\"Cannot read content file: {file_path}\")\n",
        "\n",
        "            with open(file_path, 'r', encoding='utf-8') as file:\n",
        "                content = file.read()\n",
        "\n",
        "            if not content.strip():\n",
        "                raise ValueError(f\"Content file is empty: {file_path}\")\n",
        "\n",
        "            if self.debug:\n",
        "                print(f\"Successfully read {len(content)} characters from {file_path}\")\n",
        "\n",
        "            # Clean up content\n",
        "            content = content.replace('\\ufeff', '').replace('\\r\\n', '\\n')\n",
        "\n",
        "            return content\n",
        "\n",
        "        except UnicodeDecodeError:\n",
        "            raise Exception(f\"File encoding error. Please ensure {file_path} is saved in UTF-8 format.\")\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"Error reading content file: {str(e)}\")\n",
        "\n",
        "    def generate_quiz_prompt(self, content: str) -> str:\n",
        "        \"\"\"Generate a structured prompt for the quiz.\"\"\"\n",
        "        return f\"\"\"<s>[INST] IMPORTANT: Follow these instructions EXACTLY. DO NOT include any thinking, planning, or additional text.\n",
        "START YOUR RESPONSE DIRECTLY with \"=== MULTIPLE CHOICE QUESTIONS ===\" and ONLY use the specified format.\n",
        "\n",
        "Based on the provided technical content, create:\n",
        "\n",
        "1. Multiple Choice Questions (15 total):\n",
        "   - 5 Easy questions: Test basic terminology and concept recall\n",
        "   - 5 Medium questions: Test understanding of relationships and principles\n",
        "   - 5 Hard questions: Test advanced concepts and technical analysis\n",
        "\n",
        "2. Fill in the Blanks (15 total):\n",
        "   - 5 Easy questions: Basic terminology and definitions\n",
        "   - 5 Medium questions: Technical relationships and components\n",
        "   - 5 Hard questions: Complex technical concepts and implementations\n",
        "\n",
        "3. Short Answer Questions (15 total):\n",
        "   - 5 Easy questions: Basic concept explanation\n",
        "   - 5 Medium questions: Understanding mechanisms and relationships\n",
        "   - 5 Hard questions: Technical analysis and practical applications\n",
        "\n",
        "USE THIS EXACT FORMAT - DO NOT DEVIATE:\n",
        "\n",
        "=== MULTIPLE CHOICE QUESTIONS ===\n",
        "[Difficulty: Easy]\n",
        "Q1. Question text\n",
        "A) Option A\n",
        "B) Option B\n",
        "C) Option C\n",
        "D) Option D\n",
        "Correct: [Letter]\n",
        "Explanation: Brief explanation\n",
        "\n",
        "=== FILL IN THE BLANKS ===\n",
        "[Difficulty: Easy]\n",
        "Q1. Sentence with _____ to fill\n",
        "Answer: Correct answer\n",
        "Explanation: Brief explanation\n",
        "\n",
        "=== SHORT ANSWER QUESTIONS ===\n",
        "[Difficulty: Easy]\n",
        "Q1. Question text\n",
        "Answer: Model answer\n",
        "Key Points: Key point 1, Key point 2\n",
        "\n",
        "Content to create questions from:\n",
        "{content}\n",
        "\n",
        "REQUIREMENTS:\n",
        "- Start IMMEDIATELY with \"=== MULTIPLE CHOICE QUESTIONS ===\"\n",
        "- Use EXACT formatting shown above\n",
        "- Include ALL THREE sections in order\n",
        "- Follow the difficulty distribution exactly (5 Easy, 5 Medium, 5 Hard for each section)\n",
        "- NO additional text or thinking process\n",
        "[/INST]</s>\"\"\"\n",
        "\n",
        "    def query_groq_api(self, prompt: str, max_tokens: int = 4000) -> str:\n",
        "        \"\"\"Query the Groq API with proper error handling.\"\"\"\n",
        "        max_retries = 3\n",
        "        wait_time = 50  # Initial wait time of 50 seconds\n",
        "\n",
        "        for attempt in range(max_retries):\n",
        "            try:\n",
        "                if self.debug:\n",
        "                    print(f\"\\nAttempt {attempt + 1} of {max_retries}\")\n",
        "\n",
        "                response = self.client.get_completion(query=prompt, max_tokens=max_tokens)\n",
        "\n",
        "                if self.debug:\n",
        "                    print(\"Successfully received response from Groq API\")\n",
        "\n",
        "                return response\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Attempt {attempt + 1} failed: {str(e)}\")\n",
        "                if attempt < max_retries - 1:\n",
        "                    print(f\"Waiting {wait_time} seconds before retry...\")\n",
        "                    time.sleep(wait_time)\n",
        "                    wait_time *= 1.5  # Increase wait time by 50% for each retry\n",
        "                else:\n",
        "                    raise Exception(\"Failed to get valid response after all retries\")\n",
        "\n",
        "    def parse_quiz_response(self, quiz_text: str, prompt: str) -> Dict:\n",
        "        \"\"\"Parse the API response into structured format with dynamic difficulty validation.\"\"\"\n",
        "        try:\n",
        "            if not quiz_text:\n",
        "                raise ValueError(\"No generated text in API response\")\n",
        "\n",
        "            # Clean response: Remove any text before the first section marker\n",
        "            start_marker = \"=== MULTIPLE CHOICE QUESTIONS ===\"\n",
        "            start_index = quiz_text.find(start_marker)\n",
        "            if start_index == -1:\n",
        "                if self.debug:\n",
        "                    print(\"Response format error. Raw response:\")\n",
        "                    print(quiz_text[:500] + \"...\" if len(quiz_text) > 500 else quiz_text)\n",
        "                raise ValueError(\"Response does not contain expected section markers\")\n",
        "\n",
        "            quiz_text = quiz_text[start_index:]\n",
        "\n",
        "            # Initialize structured quiz\n",
        "            structured_quiz = {\n",
        "                \"multiple_choice\": [],\n",
        "                \"fill_in_blanks\": [],\n",
        "                \"short_answer\": []\n",
        "            }\n",
        "\n",
        "            current_section_type = None\n",
        "            current_difficulty = None\n",
        "            current_question = None\n",
        "\n",
        "            for line in quiz_text.split('\\n'):\n",
        "                line = line.strip()\n",
        "                if not line:\n",
        "                    continue\n",
        "\n",
        "                # Determine section type\n",
        "                if \"=== MULTIPLE CHOICE QUESTIONS ===\" in line:\n",
        "                    current_section_type = \"multiple_choice\"\n",
        "                    continue\n",
        "                elif \"=== FILL IN THE BLANKS ===\" in line:\n",
        "                    current_section_type = \"fill_in_blanks\"\n",
        "                    continue\n",
        "                elif \"=== SHORT ANSWER QUESTIONS ===\" in line:\n",
        "                    current_section_type = \"short_answer\"\n",
        "                    continue\n",
        "\n",
        "                # Check for difficulty\n",
        "                if line.startswith('[Difficulty:'):\n",
        "                    try:\n",
        "                        current_difficulty = line.split(':')[1].strip().rstrip(']').lower()\n",
        "                        if current_difficulty not in ['easy', 'medium', 'hard']:\n",
        "                            print(f\"Warning: Invalid difficulty level found: {current_difficulty}\")\n",
        "                            current_difficulty = 'medium'  # Default to medium if invalid\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error parsing difficulty: {str(e)}\")\n",
        "                        current_difficulty = 'medium'  # Default to medium if parsing fails\n",
        "                    continue\n",
        "\n",
        "                try:\n",
        "                    # Parse Multiple Choice Questions\n",
        "                    if current_section_type == \"multiple_choice\":\n",
        "                        if line.startswith('Q'):\n",
        "                            if current_question:\n",
        "                                structured_quiz[\"multiple_choice\"].append(current_question)\n",
        "                            current_question = {\n",
        "                                \"type\": \"multiple_choice\",\n",
        "                                \"difficulty\": current_difficulty,\n",
        "                                \"question\": line.split('.', 1)[1].strip() if '.' in line else line,\n",
        "                                \"options\": [],\n",
        "                                \"correct_answer\": \"\",\n",
        "                                \"explanation\": \"\",\n",
        "                                \"user_answer\": \"\"\n",
        "                            }\n",
        "                        elif line.startswith(('A)', 'B)', 'C)', 'D)')):\n",
        "                            if current_question:\n",
        "                                current_question[\"options\"].append({\n",
        "                                    \"label\": line[0],\n",
        "                                    \"text\": line[2:].strip()\n",
        "                                })\n",
        "                        elif line.startswith('Correct:'):\n",
        "                            if current_question:\n",
        "                                current_question[\"correct_answer\"] = line.split(':')[1].strip()\n",
        "                        elif line.startswith('Explanation:'):\n",
        "                            if current_question:\n",
        "                                current_question[\"explanation\"] = line.split(':', 1)[1].strip()\n",
        "                                structured_quiz[\"multiple_choice\"].append(current_question)\n",
        "                                current_question = None\n",
        "\n",
        "                    # Parse Fill in the Blanks\n",
        "                    elif current_section_type == \"fill_in_blanks\":\n",
        "                        if line.startswith('Q'):\n",
        "                            if current_question:\n",
        "                                structured_quiz[\"fill_in_blanks\"].append(current_question)\n",
        "                            current_question = {\n",
        "                                \"type\": \"fill_in_blanks\",\n",
        "                                \"difficulty\": current_difficulty,\n",
        "                                \"question\": line.split('.', 1)[1].strip() if '.' in line else line,\n",
        "                                \"answer\": \"\",\n",
        "                                \"explanation\": \"\",\n",
        "                                \"user_answer\": \"\"\n",
        "                            }\n",
        "                        elif line.startswith('Answer:'):\n",
        "                            if current_question:\n",
        "                                current_question[\"answer\"] = line.split(':', 1)[1].strip()\n",
        "                        elif line.startswith('Explanation:'):\n",
        "                            if current_question:\n",
        "                                current_question[\"explanation\"] = line.split(':', 1)[1].strip()\n",
        "                                structured_quiz[\"fill_in_blanks\"].append(current_question)\n",
        "                                current_question = None\n",
        "\n",
        "                    # Parse Short Answer Questions\n",
        "                    elif current_section_type == \"short_answer\":\n",
        "                        if line.startswith('Q'):\n",
        "                            if current_question:\n",
        "                                structured_quiz[\"short_answer\"].append(current_question)\n",
        "                            current_question = {\n",
        "                                \"type\": \"short_answer\",\n",
        "                                \"difficulty\": current_difficulty,\n",
        "                                \"question\": line.split('.', 1)[1].strip() if '.' in line else line,\n",
        "                                \"answer\": \"\",\n",
        "                                \"key_points\": [],\n",
        "                                \"user_answer\": \"\"\n",
        "                            }\n",
        "                        elif line.startswith('Answer:'):\n",
        "                            if current_question:\n",
        "                                current_question[\"answer\"] = line.split(':', 1)[1].strip()\n",
        "                        elif line.startswith('Key Points:'):\n",
        "                            if current_question:\n",
        "                                current_question[\"key_points\"] = [\n",
        "                                    point.strip()\n",
        "                                    for point in line.split(':', 1)[1].strip().split(',')\n",
        "                                ]\n",
        "                                structured_quiz[\"short_answer\"].append(current_question)\n",
        "                                current_question = None\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error parsing line '{line}': {str(e)}\")\n",
        "                    continue\n",
        "\n",
        "            # Add the last question if it exists\n",
        "            if current_question:\n",
        "                if current_section_type == \"multiple_choice\":\n",
        "                    structured_quiz[\"multiple_choice\"].append(current_question)\n",
        "                elif current_section_type == \"fill_in_blanks\":\n",
        "                    structured_quiz[\"fill_in_blanks\"].append(current_question)\n",
        "                elif current_section_type == \"short_answer\":\n",
        "                    structured_quiz[\"short_answer\"].append(current_question)\n",
        "\n",
        "            # Calculate metadata\n",
        "            quiz_metadata = self._calculate_metadata(structured_quiz)\n",
        "\n",
        "            return {\n",
        "                \"metadata\": quiz_metadata,\n",
        "                \"quiz\": structured_quiz,\n",
        "                \"raw_response\": quiz_text\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error parsing quiz response: {str(e)}\")\n",
        "            if self.debug:\n",
        "                print(\"\\nFull response for debugging:\")\n",
        "                print(quiz_text[:500] + \"...\" if len(quiz_text) > 500 else quiz_text)\n",
        "            raise\n",
        "\n",
        "    def _calculate_metadata(self, quiz: Dict) -> Dict:\n",
        "        \"\"\"Calculate quiz metadata with accurate difficulty distribution.\"\"\"\n",
        "        try:\n",
        "            # Calculate total questions\n",
        "            total_questions = sum(len(questions) for questions in quiz.values())\n",
        "\n",
        "            # Calculate question type counts\n",
        "            question_types = {\n",
        "                qtype: len(questions)\n",
        "                for qtype, questions in quiz.items()\n",
        "            }\n",
        "\n",
        "            # Calculate difficulty distribution\n",
        "            difficulty_distribution = {\n",
        "                \"easy\": sum(1 for questions in quiz.values()\n",
        "                           for q in questions if q.get(\"difficulty\") == \"easy\"),\n",
        "                \"medium\": sum(1 for questions in quiz.values()\n",
        "                             for q in questions if q.get(\"difficulty\") == \"medium\"),\n",
        "                \"hard\": sum(1 for questions in quiz.values()\n",
        "                           for q in questions if q.get(\"difficulty\") == \"hard\")\n",
        "            }\n",
        "\n",
        "            # Calculate per-section difficulty distribution\n",
        "            section_difficulty_distribution = {\n",
        "                section_type: {\n",
        "                    \"easy\": sum(1 for q in questions if q.get(\"difficulty\") == \"easy\"),\n",
        "                    \"medium\": sum(1 for q in questions if q.get(\"difficulty\") == \"medium\"),\n",
        "                    \"hard\": sum(1 for q in questions if q.get(\"difficulty\") == \"hard\")\n",
        "                }\n",
        "                for section_type, questions in quiz.items()\n",
        "            }\n",
        "\n",
        "            return {\n",
        "                \"total_questions\": total_questions,\n",
        "                \"question_types\": question_types,\n",
        "                \"difficulty_distribution\": difficulty_distribution,\n",
        "                \"section_difficulty_distribution\": section_difficulty_distribution,\n",
        "                \"generation_timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "            }\n",
        "        except Exception as e:\n",
        "            print(f\"Error calculating metadata: {str(e)}\")\n",
        "            return {\n",
        "                \"total_questions\": 0,\n",
        "                \"question_types\": {\n",
        "                    \"multiple_choice\": 0,\n",
        "                    \"fill_in_blanks\": 0,\n",
        "                    \"short_answer\": 0\n",
        "                },\n",
        "                \"difficulty_distribution\": {\n",
        "                    \"easy\": 0,\n",
        "                    \"medium\": 0,\n",
        "                    \"hard\": 0\n",
        "                },\n",
        "                \"section_difficulty_distribution\": {},\n",
        "                \"generation_timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "            }\n",
        "\n",
        "    def generate_quiz(self, context_file_path: str) -> Dict:\n",
        "        \"\"\"Generate a complete quiz with error handling.\"\"\"\n",
        "        try:\n",
        "            content = self.read_context_file(context_file_path)\n",
        "            if self.debug:\n",
        "                print(f\"\\nRead {len(content)} characters from {context_file_path}\")\n",
        "\n",
        "            prompt = self.generate_quiz_prompt(content)\n",
        "            response = self.query_groq_api(prompt)\n",
        "\n",
        "            # Verify all sections are present\n",
        "            required_sections = [\n",
        "                \"=== MULTIPLE CHOICE QUESTIONS ===\",\n",
        "                \"=== FILL IN THE BLANKS ===\",\n",
        "                \"=== SHORT ANSWER QUESTIONS ===\"\n",
        "            ]\n",
        "\n",
        "            missing_sections = [\n",
        "                section for section in required_sections\n",
        "                if section not in response\n",
        "            ]\n",
        "\n",
        "            if missing_sections:\n",
        "                raise Exception(f\"Missing required sections: {', '.join(missing_sections)}\")\n",
        "\n",
        "            return self.parse_quiz_response(response, prompt)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Quiz generation failed: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def conduct_quiz(self, quiz: Dict) -> Dict:\n",
        "        \"\"\"\n",
        "        Conduct the quiz dynamically, adjusting difficulty based on user performance.\n",
        "        For each section, first ask 5 questions. If not all of these 5 are answered correctly,\n",
        "        instruct the user to revisit the slides and do not proceed with further questions in that section.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            print(\"\\nWelcome to the Quiz!\")\n",
        "            print(\"You will be asked questions one by one. Answer them to the best of your ability.\\n\")\n",
        "\n",
        "            overall_correct_count = 0\n",
        "            total_questions = quiz['metadata']['total_questions']\n",
        "\n",
        "            # Iterate through each question type section\n",
        "            for section_type, questions in quiz['quiz'].items():\n",
        "                print(f\"\\n=== {section_type.replace('_', ' ').title()} ===\")\n",
        "                section_correct = 0\n",
        "\n",
        "                # Ask the first 5 questions for the section\n",
        "                for idx, question in enumerate(questions):\n",
        "                    if idx == 5:\n",
        "                        break\n",
        "\n",
        "                    print(f\"\\nQuestion: {question['question']}\")\n",
        "\n",
        "                    if section_type == \"multiple_choice\":\n",
        "                        print(\"Options:\")\n",
        "                        for option in question['options']:\n",
        "                            print(f\"{option['label']}) {option['text']}\")\n",
        "                        user_answer = input(\"Your answer (A/B/C/D): \").strip().upper()\n",
        "                    elif section_type == \"fill_in_blanks\":\n",
        "                        user_answer = input(\"Fill in the blank: \").strip()\n",
        "                    elif section_type == \"short_answer\":\n",
        "                        user_answer = input(\"Your answer: \").strip()\n",
        "\n",
        "                    question['user_answer'] = user_answer\n",
        "\n",
        "                    # Check the answer based on question type\n",
        "                    if section_type == \"short_answer\":\n",
        "                        if is_similar(user_answer, question['answer']):\n",
        "                            print(\"Correct! 🎉\")\n",
        "                            overall_correct_count += 1\n",
        "                            section_correct += 1\n",
        "                        else:\n",
        "                            print(f\"Incorrect. The correct answer is: {question['answer']}\")\n",
        "                    elif section_type == \"fill_in_blanks\":\n",
        "                        if user_answer.lower() == question['answer'].lower():\n",
        "                            print(\"Correct! 🎉\")\n",
        "                            overall_correct_count += 1\n",
        "                            section_correct += 1\n",
        "                        else:\n",
        "                            print(f\"Incorrect. The correct answer is: {question['answer']}\")\n",
        "                    else:  # multiple_choice\n",
        "                        # Remove any brackets from the correct answer before comparison\n",
        "                        correct = question['correct_answer'].replace(\"[\", \"\").replace(\"]\", \"\").strip().upper()\n",
        "                        if user_answer == correct:\n",
        "                            print(\"Correct! 🎉\")\n",
        "                            overall_correct_count += 1\n",
        "                            section_correct += 1\n",
        "                        else:\n",
        "                            print(f\"Incorrect. The correct answer is: {question['correct_answer']}\")\n",
        "\n",
        "                # If not all of the first 5 questions were answered correctly, stop further questions in this section.\n",
        "                if section_correct < 5:\n",
        "                    print(\"\\nYou did not answer all of the first 5 questions correctly in this section.\")\n",
        "                    print(\"Please revisit the slides and try again later.\")\n",
        "                    continue\n",
        "\n",
        "                # If the first 5 are all correct, proceed with the remaining questions in the section.\n",
        "                for question in questions[5:]:\n",
        "                    print(f\"\\nQuestion: {question['question']}\")\n",
        "\n",
        "                    if section_type == \"multiple_choice\":\n",
        "                        print(\"Options:\")\n",
        "                        for option in question['options']:\n",
        "                            print(f\"{option['label']}) {option['text']}\")\n",
        "                        user_answer = input(\"Your answer (A/B/C/D): \").strip().upper()\n",
        "                    elif section_type == \"fill_in_blanks\":\n",
        "                        user_answer = input(\"Fill in the blank: \").strip()\n",
        "                    elif section_type == \"short_answer\":\n",
        "                        user_answer = input(\"Your answer: \").strip()\n",
        "\n",
        "                    question['user_answer'] = user_answer\n",
        "\n",
        "                    if section_type == \"short_answer\":\n",
        "                        if is_similar(user_answer, question['answer']):\n",
        "                            print(\"Correct! 🎉\")\n",
        "                            overall_correct_count += 1\n",
        "                        else:\n",
        "                            print(f\"Incorrect. The correct answer is: {question['answer']}\")\n",
        "                    elif section_type == \"fill_in_blanks\":\n",
        "                        if user_answer.lower() == question['answer'].lower():\n",
        "                            print(\"Correct! 🎉\")\n",
        "                            overall_correct_count += 1\n",
        "                        else:\n",
        "                            print(f\"Incorrect. The correct answer is: {question['answer']}\")\n",
        "                    else:  # multiple_choice\n",
        "                        correct = question['correct_answer'].replace(\"[\", \"\").replace(\"]\", \"\").strip().upper()\n",
        "                        if user_answer == correct:\n",
        "                            print(\"Correct! 🎉\")\n",
        "                            overall_correct_count += 1\n",
        "                        else:\n",
        "                            print(f\"Incorrect. The correct answer is: {question['correct_answer']}\")\n",
        "\n",
        "            # Provide explanations for incorrect answers at the end\n",
        "            print(\"\\n=== Quiz Results ===\")\n",
        "            print(f\"You answered {overall_correct_count} out of {total_questions} questions correctly.\")\n",
        "\n",
        "            if overall_correct_count < total_questions:\n",
        "                print(\"\\nHere are the explanations for the questions you got wrong:\")\n",
        "                for section_type, questions in quiz['quiz'].items():\n",
        "                    for question in questions:\n",
        "                        if section_type == \"short_answer\":\n",
        "                            if not is_similar(question['user_answer'], question['answer']):\n",
        "                                print(f\"\\nQuestion: {question['question']}\")\n",
        "                                print(f\"Your answer: {question['user_answer']}\")\n",
        "                                print(f\"Correct answer: {question['answer']}\")\n",
        "                        else:\n",
        "                            correct = question.get('correct_answer', \"\").replace(\"[\", \"\").replace(\"]\", \"\").strip().lower()\n",
        "                            if question.get('correct_answer') and question['user_answer'].lower() != correct:\n",
        "                                print(f\"\\nQuestion: {question['question']}\")\n",
        "                                print(f\"Your answer: {question['user_answer']}\")\n",
        "                                print(f\"Correct answer: {question['correct_answer']}\")\n",
        "                                print(f\"Explanation: {question['explanation']}\")\n",
        "\n",
        "            # Save the updated quiz with user answers\n",
        "            output_dir = \"quiz_output\"\n",
        "            if not os.path.exists(output_dir):\n",
        "                os.makedirs(output_dir)\n",
        "\n",
        "            updated_quiz_path = os.path.join(output_dir, 'updated_quiz_with_answers.json')\n",
        "            with open(updated_quiz_path, 'w', encoding='utf-8') as f:\n",
        "                json.dump(quiz, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "            print(f\"\\nYour quiz results have been saved to {updated_quiz_path}\")\n",
        "\n",
        "            return quiz\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error conducting quiz: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        print(\"Starting quiz generation...\")\n",
        "\n",
        "        # Check for API key\n",
        "        api_key = os.getenv('GROQ_API_KEY')\n",
        "        if not api_key:\n",
        "            print(\"Error: GROQ_API_KEY environment variable not found!\")\n",
        "            print(\"\\nPlease set your Groq API key as an environment variable:\")\n",
        "            print(\"export GROQ_API_KEY='your-api-key'\")\n",
        "            return\n",
        "\n",
        "        if not os.path.exists(\"content.txt\"):\n",
        "            print(\"Error: content.txt file not found!\")\n",
        "            print(\"\\nPlease create a content.txt file with your technical content.\")\n",
        "            print(\"The content can be about any computer science or technical topic.\")\n",
        "            print(\"\\nFile requirements:\")\n",
        "            print(\"1. Save as 'content.txt' in the same directory as this script\")\n",
        "            print(\"2. Use UTF-8 encoding\")\n",
        "            print(\"3. Include sufficient content for meaningful questions\")\n",
        "            return\n",
        "\n",
        "        quiz_gen = QuizGenerator(api_key=api_key, debug=True)\n",
        "\n",
        "        print(\"\\nReading content and generating quiz...\")\n",
        "        print(\"This may take a few minutes depending on the content length.\")\n",
        "        quiz = quiz_gen.generate_quiz(\"content.txt\")\n",
        "\n",
        "        # Save the generated quiz as JSON immediately\n",
        "        with open(\"generated_quiz.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(quiz, f, indent=2, ensure_ascii=False)\n",
        "        print(\"Generated quiz has been saved to generated_quiz.json\")\n",
        "\n",
        "        # Conduct the quiz\n",
        "        quiz_gen.conduct_quiz(quiz)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError: {str(e)}\")\n",
        "        print(\"\\nTroubleshooting tips:\")\n",
        "        print(\"1. Check that content.txt exists and is readable\")\n",
        "        print(\"2. Verify the content.txt has enough text to generate questions\")\n",
        "        print(\"3. Ensure content.txt is saved with UTF-8 encoding\")\n",
        "        print(\"4. Try running the script again (API might be temporarily busy)\")\n",
        "        print(\"5. Check your internet connection\")\n",
        "        print(\"6. Verify your Groq API key is set correctly\")\n",
        "        print(\"\\nFor more details, check:\")\n",
        "        print(\"- The error message above\")\n",
        "        print(\"- quiz_raw.txt file (if created)\")\n",
        "        print(\"- generated_quiz.json file (if created)\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "uLldDQrOE9ZL",
        "outputId": "cd2f4db5-557a-4ec3-e41a-32697a7f6f74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting quiz generation...\n",
            "\n",
            "Reading content and generating quiz...\n",
            "This may take a few minutes depending on the content length.\n",
            "Successfully read 7280 characters from content.txt\n",
            "\n",
            "Read 7280 characters from content.txt\n",
            "\n",
            "Attempt 1 of 3\n",
            "Successfully received response from Groq API\n",
            "Generated quiz has been saved to generated_quiz.json\n",
            "\n",
            "Welcome to the Quiz!\n",
            "You will be asked questions one by one. Answer them to the best of your ability.\n",
            "\n",
            "\n",
            "=== Multiple Choice ===\n",
            "\n",
            "Question: What is the primary purpose of the bubble sort algorithm?\n",
            "Options:\n",
            "A) To search for elements in a list\n",
            "B) To sort data in ascending or descending order\n",
            "C) To merge two sorted lists\n",
            "D) To find the minimum element in a list\n",
            "Your answer (A/B/C/D): B\n",
            "Correct! 🎉\n",
            "\n",
            "Question: Which of the following is a characteristic of bubble sort?\n",
            "Options:\n",
            "A) It is a non-comparison-based sorting algorithm\n",
            "B) It uses a single loop to sort the data\n",
            "C) It is an in-place sorting algorithm\n",
            "D) It is the fastest sorting algorithm for large datasets\n",
            "Your answer (A/B/C/D): A\n",
            "Incorrect. The correct answer is: C\n",
            "\n",
            "Question: What is the name of the variable used to track whether any swaps were made during a pass in bubble sort?\n",
            "Options:\n",
            "A) swapped\n",
            "B) sorted\n",
            "C) passed\n",
            "D) compared\n",
            "Your answer (A/B/C/D): A\n",
            "Correct! 🎉\n",
            "\n",
            "Question: In bubble sort, what happens to the largest element during the first pass?\n",
            "Options:\n",
            "A) It stays in its original position\n",
            "B) It moves to the second position\n",
            "C) It moves to the end of the array\n",
            "D) It is removed from the array\n",
            "Your answer (A/B/C/D): A\n",
            "Incorrect. The correct answer is: C\n",
            "\n",
            "Question: Which of the following is NOT a type of sorting algorithm?\n",
            "Options:\n",
            "A) Bubble sort\n",
            "B) Quick sort\n",
            "C) Merge sort\n",
            "D) Search sort\n",
            "Your answer (A/B/C/D): A\n",
            "Incorrect. The correct answer is: D\n",
            "\n",
            "You did not answer all of the first 5 questions correctly in this section.\n",
            "Please revisit the slides and try again later.\n",
            "\n",
            "=== Fill In Blanks ===\n",
            "\n",
            "Question: Bubble sort is a simple sorting algorithm that works by comparing and swapping adjacent _______.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-a23aa29730de>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-a23aa29730de>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;31m# Conduct the quiz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m         \u001b[0mquiz_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconduct_quiz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquiz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-a23aa29730de>\u001b[0m in \u001b[0;36mconduct_quiz\u001b[0;34m(self, quiz)\u001b[0m\n\u001b[1;32m    445\u001b[0m                         \u001b[0muser_answer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Your answer (A/B/C/D): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m                     \u001b[0;32melif\u001b[0m \u001b[0msection_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"fill_in_blanks\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m                         \u001b[0muser_answer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fill in the blank: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m                     \u001b[0;32melif\u001b[0m \u001b[0msection_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"short_answer\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m                         \u001b[0muser_answer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Your answer: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "################################ FINAL QUIZ ######################################\n",
        "import json\n",
        "import time\n",
        "import os\n",
        "from typing import Dict, List, Union\n",
        "from groq import Groq\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# Initialize Sentence Transformer model (load once)\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "def is_similar(user_answer: str, correct_answer: str, threshold: float = 0.65) -> bool:\n",
        "    \"\"\"\n",
        "    Compute the cosine similarity between user_answer and correct_answer using Sentence Transformers.\n",
        "    Return True if similarity is above the threshold, otherwise False.\n",
        "    \"\"\"\n",
        "    embeddings = model.encode([user_answer, correct_answer])\n",
        "    similarity = util.cos_sim(embeddings[0], embeddings[1]).item()\n",
        "    # Debug: Uncomment the next line if you want to see the similarity score.\n",
        "    # print(f\"Similarity score: {similarity}\")\n",
        "    return similarity >= threshold\n",
        "\n",
        "class GroqClient:\n",
        "    def __init__(self, api_key):\n",
        "        self.client = Groq(api_key=api_key)\n",
        "\n",
        "    def get_completion(self, query, max_tokens=4000):\n",
        "        try:\n",
        "            chat_completion = self.client.chat.completions.create(\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"system\",\n",
        "                        \"content\": \"You are a technical quiz generation expert. You must follow the format EXACTLY as specified and start your response with === MULTIPLE CHOICE QUESTIONS ===\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": query\n",
        "                    }\n",
        "                ],\n",
        "                model=\"deepseek-r1-distill-llama-70b\",\n",
        "                temperature=0.5,\n",
        "                max_tokens=max_tokens,\n",
        "                top_p=0.7,\n",
        "                stream=False\n",
        "            )\n",
        "            return chat_completion.choices[0].message.content\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"API request failed: {str(e)}\")\n",
        "\n",
        "class QuizGenerator:\n",
        "    def __init__(self, api_key: str, debug=True):\n",
        "        \"\"\"Initialize with Groq client and debug option.\"\"\"\n",
        "        self.debug = debug\n",
        "        self.client = GroqClient(api_key=api_key)\n",
        "\n",
        "    def read_context_file(self, file_path: str) -> str:\n",
        "        \"\"\"Read content from the context file with proper error handling.\"\"\"\n",
        "        try:\n",
        "            if not os.path.exists(file_path):\n",
        "                raise FileNotFoundError(f\"Content file not found: {file_path}\")\n",
        "\n",
        "            if not os.access(file_path, os.R_OK):\n",
        "                raise PermissionError(f\"Cannot read content file: {file_path}\")\n",
        "\n",
        "            with open(file_path, 'r', encoding='utf-8') as file:\n",
        "                content = file.read()\n",
        "\n",
        "            if not content.strip():\n",
        "                raise ValueError(f\"Content file is empty: {file_path}\")\n",
        "\n",
        "            if self.debug:\n",
        "                print(f\"Successfully read {len(content)} characters from {file_path}\")\n",
        "\n",
        "            # Clean up content\n",
        "            content = content.replace('\\ufeff', '').replace('\\r\\n', '\\n')\n",
        "\n",
        "            return content\n",
        "\n",
        "        except UnicodeDecodeError:\n",
        "            raise Exception(f\"File encoding error. Please ensure {file_path} is saved in UTF-8 format.\")\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"Error reading content file: {str(e)}\")\n",
        "\n",
        "    def generate_quiz_prompt(self, content: str) -> str:\n",
        "        \"\"\"Generate a structured prompt for the quiz.\"\"\"\n",
        "        return f\"\"\"<s>[INST] IMPORTANT: Follow these instructions EXACTLY. DO NOT include any thinking, planning, or additional text.\n",
        "START YOUR RESPONSE DIRECTLY with \"=== MULTIPLE CHOICE QUESTIONS ===\" and ONLY use the specified format.\n",
        "\n",
        "Based on the provided technical content, create:\n",
        "\n",
        "1. Multiple Choice Questions (15 total):\n",
        "   - 5 Easy questions: Test basic terminology and concept recall\n",
        "   - 5 Medium questions: Test understanding of relationships and principles\n",
        "   - 5 Hard questions: Test advanced concepts and technical analysis\n",
        "\n",
        "2. Fill in the Blanks (15 total):\n",
        "   - 5 Easy questions: Basic terminology and definitions\n",
        "   - 5 Medium questions: Technical relationships and components\n",
        "   - 5 Hard questions: Complex technical concepts and implementations\n",
        "\n",
        "3. Short Answer Questions (15 total):\n",
        "   - 5 Easy questions: Basic concept explanation\n",
        "   - 5 Medium questions: Understanding mechanisms and relationships\n",
        "   - 5 Hard questions: Technical analysis and practical applications\n",
        "\n",
        "USE THIS EXACT FORMAT - DO NOT DEVIATE:\n",
        "\n",
        "=== MULTIPLE CHOICE QUESTIONS ===\n",
        "[Difficulty: Easy]\n",
        "Q1. Question text\n",
        "A) Option A\n",
        "B) Option B\n",
        "C) Option C\n",
        "D) Option D\n",
        "Correct: [Letter]\n",
        "Explanation: Detailed explanation of why the answer is correct.\n",
        "\n",
        "=== FILL IN THE BLANKS ===\n",
        "[Difficulty: Easy]\n",
        "Q1. Sentence with _____ to fill\n",
        "Answer: Correct answer\n",
        "Explanation: Detailed explanation of why the answer is correct.\n",
        "\n",
        "=== SHORT ANSWER QUESTIONS ===\n",
        "[Difficulty: Easy]\n",
        "Q1. Question text\n",
        "Answer: Model answer\n",
        "Key Points: Key point 1, Key point 2\n",
        "\n",
        "Content to create questions from:\n",
        "{content}\n",
        "\n",
        "REQUIREMENTS:\n",
        "- Start IMMEDIATELY with \"=== MULTIPLE CHOICE QUESTIONS ===\"\n",
        "- Use EXACT formatting shown above\n",
        "- Include ALL THREE sections in order\n",
        "- Follow the difficulty distribution exactly (5 Easy, 5 Medium, 5 Hard for each section)\n",
        "- NO additional text or thinking process\n",
        "[/INST]</s>\"\"\"\n",
        "\n",
        "    def query_groq_api(self, prompt: str, max_tokens: int = 4000) -> str:\n",
        "        \"\"\"Query the Groq API with proper error handling.\"\"\"\n",
        "        max_retries = 3\n",
        "        wait_time = 50  # Initial wait time of 50 seconds\n",
        "\n",
        "        for attempt in range(max_retries):\n",
        "            try:\n",
        "                if self.debug:\n",
        "                    print(f\"\\nAttempt {attempt + 1} of {max_retries}\")\n",
        "\n",
        "                response = self.client.get_completion(query=prompt, max_tokens=max_tokens)\n",
        "\n",
        "                if self.debug:\n",
        "                    print(\"Successfully received response from Groq API\")\n",
        "\n",
        "                return response\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Attempt {attempt + 1} failed: {str(e)}\")\n",
        "                if attempt < max_retries - 1:\n",
        "                    print(f\"Waiting {wait_time} seconds before retry...\")\n",
        "                    time.sleep(wait_time)\n",
        "                    wait_time *= 1.5  # Increase wait time by 50% for each retry\n",
        "                else:\n",
        "                    raise Exception(\"Failed to get valid response after all retries\")\n",
        "\n",
        "    def parse_quiz_response(self, quiz_text: str, prompt: str) -> Dict:\n",
        "        \"\"\"Parse the API response into structured format with dynamic difficulty validation.\"\"\"\n",
        "        try:\n",
        "            if not quiz_text:\n",
        "                raise ValueError(\"No generated text in API response\")\n",
        "\n",
        "            # Clean response: Remove any text before the first section marker\n",
        "            start_marker = \"=== MULTIPLE CHOICE QUESTIONS ===\"\n",
        "            start_index = quiz_text.find(start_marker)\n",
        "            if start_index == -1:\n",
        "                if self.debug:\n",
        "                    print(\"Response format error. Raw response:\")\n",
        "                    print(quiz_text[:500] + \"...\" if len(quiz_text) > 500 else quiz_text)\n",
        "                raise ValueError(\"Response does not contain expected section markers\")\n",
        "\n",
        "            quiz_text = quiz_text[start_index:]\n",
        "\n",
        "            # Initialize structured quiz\n",
        "            structured_quiz = {\n",
        "                \"multiple_choice\": [],\n",
        "                \"fill_in_blanks\": [],\n",
        "                \"short_answer\": []\n",
        "            }\n",
        "\n",
        "            current_section_type = None\n",
        "            current_difficulty = None\n",
        "            current_question = None\n",
        "\n",
        "            for line in quiz_text.split('\\n'):\n",
        "                line = line.strip()\n",
        "                if not line:\n",
        "                    continue\n",
        "\n",
        "                # Determine section type\n",
        "                if \"=== MULTIPLE CHOICE QUESTIONS ===\" in line:\n",
        "                    current_section_type = \"multiple_choice\"\n",
        "                    continue\n",
        "                elif \"=== FILL IN THE BLANKS ===\" in line:\n",
        "                    current_section_type = \"fill_in_blanks\"\n",
        "                    continue\n",
        "                elif \"=== SHORT ANSWER QUESTIONS ===\" in line:\n",
        "                    current_section_type = \"short_answer\"\n",
        "                    continue\n",
        "\n",
        "                # Check for difficulty\n",
        "                if line.startswith('[Difficulty:'):\n",
        "                    try:\n",
        "                        current_difficulty = line.split(':')[1].strip().rstrip(']').lower()\n",
        "                        if current_difficulty not in ['easy', 'medium', 'hard']:\n",
        "                            print(f\"Warning: Invalid difficulty level found: {current_difficulty}\")\n",
        "                            current_difficulty = 'medium'  # Default to medium if invalid\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error parsing difficulty: {str(e)}\")\n",
        "                        current_difficulty = 'medium'  # Default to medium if parsing fails\n",
        "                    continue\n",
        "\n",
        "                try:\n",
        "                    # Parse Multiple Choice Questions\n",
        "                    if current_section_type == \"multiple_choice\":\n",
        "                        if line.startswith('Q'):\n",
        "                            if current_question:\n",
        "                                structured_quiz[\"multiple_choice\"].append(current_question)\n",
        "                            current_question = {\n",
        "                                \"type\": \"multiple_choice\",\n",
        "                                \"difficulty\": current_difficulty,\n",
        "                                \"question\": line.split('.', 1)[1].strip() if '.' in line else line,\n",
        "                                \"options\": [],\n",
        "                                \"correct_answer\": \"\",\n",
        "                                \"explanation\": \"\",\n",
        "                                \"user_answer\": \"\"\n",
        "                            }\n",
        "                        elif line.startswith(('A)', 'B)', 'C)', 'D)')):\n",
        "                            if current_question:\n",
        "                                current_question[\"options\"].append({\n",
        "                                    \"label\": line[0],\n",
        "                                    \"text\": line[2:].strip()\n",
        "                                })\n",
        "                        elif line.startswith('Correct:'):\n",
        "                            if current_question:\n",
        "                                current_question[\"correct_answer\"] = line.split(':')[1].strip()\n",
        "                        elif line.startswith('Explanation:'):\n",
        "                            if current_question:\n",
        "                                current_question[\"explanation\"] = line.split(':', 1)[1].strip()\n",
        "                                structured_quiz[\"multiple_choice\"].append(current_question)\n",
        "                                current_question = None\n",
        "\n",
        "                    # Parse Fill in the Blanks\n",
        "                    elif current_section_type == \"fill_in_blanks\":\n",
        "                        if line.startswith('Q'):\n",
        "                            if current_question:\n",
        "                                structured_quiz[\"fill_in_blanks\"].append(current_question)\n",
        "                            current_question = {\n",
        "                                \"type\": \"fill_in_blanks\",\n",
        "                                \"difficulty\": current_difficulty,\n",
        "                                \"question\": line.split('.', 1)[1].strip() if '.' in line else line,\n",
        "                                \"answer\": \"\",\n",
        "                                \"explanation\": \"\",\n",
        "                                \"user_answer\": \"\"\n",
        "                            }\n",
        "                        elif line.startswith('Answer:'):\n",
        "                            if current_question:\n",
        "                                current_question[\"answer\"] = line.split(':', 1)[1].strip()\n",
        "                        elif line.startswith('Explanation:'):\n",
        "                            if current_question:\n",
        "                                current_question[\"explanation\"] = line.split(':', 1)[1].strip()\n",
        "                                structured_quiz[\"fill_in_blanks\"].append(current_question)\n",
        "                                current_question = None\n",
        "\n",
        "                    # Parse Short Answer Questions\n",
        "                    elif current_section_type == \"short_answer\":\n",
        "                        if line.startswith('Q'):\n",
        "                            if current_question:\n",
        "                                structured_quiz[\"short_answer\"].append(current_question)\n",
        "                            current_question = {\n",
        "                                \"type\": \"short_answer\",\n",
        "                                \"difficulty\": current_difficulty,\n",
        "                                \"question\": line.split('.', 1)[1].strip() if '.' in line else line,\n",
        "                                \"answer\": \"\",\n",
        "                                \"key_points\": [],\n",
        "                                \"user_answer\": \"\"\n",
        "                            }\n",
        "                        elif line.startswith('Answer:'):\n",
        "                            if current_question:\n",
        "                                current_question[\"answer\"] = line.split(':', 1)[1].strip()\n",
        "                        elif line.startswith('Key Points:'):\n",
        "                            if current_question:\n",
        "                                current_question[\"key_points\"] = [\n",
        "                                    point.strip()\n",
        "                                    for point in line.split(':', 1)[1].strip().split(',')\n",
        "                                ]\n",
        "                                structured_quiz[\"short_answer\"].append(current_question)\n",
        "                                current_question = None\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error parsing line '{line}': {str(e)}\")\n",
        "                    continue\n",
        "\n",
        "            # Add the last question if it exists\n",
        "            if current_question:\n",
        "                if current_section_type == \"multiple_choice\":\n",
        "                    structured_quiz[\"multiple_choice\"].append(current_question)\n",
        "                elif current_section_type == \"fill_in_blanks\":\n",
        "                    structured_quiz[\"fill_in_blanks\"].append(current_question)\n",
        "                elif current_section_type == \"short_answer\":\n",
        "                    structured_quiz[\"short_answer\"].append(current_question)\n",
        "\n",
        "            # Calculate metadata\n",
        "            quiz_metadata = self._calculate_metadata(structured_quiz)\n",
        "\n",
        "            return {\n",
        "                \"metadata\": quiz_metadata,\n",
        "                \"quiz\": structured_quiz,\n",
        "                \"raw_response\": quiz_text\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error parsing quiz response: {str(e)}\")\n",
        "            if self.debug:\n",
        "                print(\"\\nFull response for debugging:\")\n",
        "                print(quiz_text[:500] + \"...\" if len(quiz_text) > 500 else quiz_text)\n",
        "            raise\n",
        "\n",
        "    def _calculate_metadata(self, quiz: Dict) -> Dict:\n",
        "        \"\"\"Calculate quiz metadata with accurate difficulty distribution.\"\"\"\n",
        "        try:\n",
        "            # Calculate total questions\n",
        "            total_questions = sum(len(questions) for questions in quiz.values())\n",
        "\n",
        "            # Calculate question type counts\n",
        "            question_types = {\n",
        "                qtype: len(questions)\n",
        "                for qtype, questions in quiz.items()\n",
        "            }\n",
        "\n",
        "            # Calculate difficulty distribution\n",
        "            difficulty_distribution = {\n",
        "                \"easy\": sum(1 for questions in quiz.values()\n",
        "                           for q in questions if q.get(\"difficulty\") == \"easy\"),\n",
        "                \"medium\": sum(1 for questions in quiz.values()\n",
        "                             for q in questions if q.get(\"difficulty\") == \"medium\"),\n",
        "                \"hard\": sum(1 for questions in quiz.values()\n",
        "                           for q in questions if q.get(\"difficulty\") == \"hard\")\n",
        "            }\n",
        "\n",
        "            # Calculate per-section difficulty distribution\n",
        "            section_difficulty_distribution = {\n",
        "                section_type: {\n",
        "                    \"easy\": sum(1 for q in questions if q.get(\"difficulty\") == \"easy\"),\n",
        "                    \"medium\": sum(1 for q in questions if q.get(\"difficulty\") == \"medium\"),\n",
        "                    \"hard\": sum(1 for q in questions if q.get(\"difficulty\") == \"hard\")\n",
        "                }\n",
        "                for section_type, questions in quiz.items()\n",
        "            }\n",
        "\n",
        "            return {\n",
        "                \"total_questions\": total_questions,\n",
        "                \"question_types\": question_types,\n",
        "                \"difficulty_distribution\": difficulty_distribution,\n",
        "                \"section_difficulty_distribution\": section_difficulty_distribution,\n",
        "                \"generation_timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "            }\n",
        "        except Exception as e:\n",
        "            print(f\"Error calculating metadata: {str(e)}\")\n",
        "            return {\n",
        "                \"total_questions\": 0,\n",
        "                \"question_types\": {\n",
        "                    \"multiple_choice\": 0,\n",
        "                    \"fill_in_blanks\": 0,\n",
        "                    \"short_answer\": 0\n",
        "                },\n",
        "                \"difficulty_distribution\": {\n",
        "                    \"easy\": 0,\n",
        "                    \"medium\": 0,\n",
        "                    \"hard\": 0\n",
        "                },\n",
        "                \"section_difficulty_distribution\": {},\n",
        "                \"generation_timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "            }\n",
        "\n",
        "    def generate_quiz(self, context_file_path: str) -> Dict:\n",
        "        \"\"\"Generate a complete quiz with error handling.\"\"\"\n",
        "        try:\n",
        "            content = self.read_context_file(context_file_path)\n",
        "            if self.debug:\n",
        "                print(f\"\\nRead {len(content)} characters from {context_file_path}\")\n",
        "\n",
        "            prompt = self.generate_quiz_prompt(content)\n",
        "            response = self.query_groq_api(prompt)\n",
        "\n",
        "            # Verify all sections are present\n",
        "            required_sections = [\n",
        "                \"=== MULTIPLE CHOICE QUESTIONS ===\",\n",
        "                \"=== FILL IN THE BLANKS ===\",\n",
        "                \"=== SHORT ANSWER QUESTIONS ===\"\n",
        "            ]\n",
        "\n",
        "            missing_sections = [\n",
        "                section for section in required_sections\n",
        "                if section not in response\n",
        "            ]\n",
        "\n",
        "            if missing_sections:\n",
        "                raise Exception(f\"Missing required sections: {', '.join(missing_sections)}\")\n",
        "\n",
        "            return self.parse_quiz_response(response, prompt)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Quiz generation failed: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    def conduct_quiz(self, quiz: Dict) -> Dict:\n",
        "        \"\"\"\n",
        "        Conduct the quiz dynamically with adaptive feedback.\n",
        "        For each section, after a minimum number of questions, if the user's accuracy falls below\n",
        "        a set threshold, ask whether they would like to review the slides.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            print(\"\\nWelcome to the Quiz!\")\n",
        "            print(\"You will be asked questions one by one. Answer them to the best of your ability.\\n\")\n",
        "\n",
        "            overall_correct_count = 0\n",
        "            total_questions = quiz['metadata']['total_questions']\n",
        "            min_questions_before_check = 3   # Minimum number of questions before evaluating performance\n",
        "            performance_threshold = 0.5      # 50% accuracy threshold\n",
        "\n",
        "            # Iterate through each question type section\n",
        "            for section_type, questions in quiz['quiz'].items():\n",
        "                print(f\"\\n=== {section_type.replace('_', ' ').title()} ===\")\n",
        "                section_correct = 0\n",
        "                section_total_answered = 0\n",
        "\n",
        "                for idx, question in enumerate(questions):\n",
        "                    print(f\"\\nQuestion: {question['question']}\")\n",
        "\n",
        "                    if section_type == \"multiple_choice\":\n",
        "                        print(\"Options:\")\n",
        "                        for option in question['options']:\n",
        "                            print(f\"{option['label']}) {option['text']}\")\n",
        "                        user_answer = input(\"Your answer (A/B/C/D): \").strip().upper()\n",
        "                    elif section_type == \"fill_in_blanks\":\n",
        "                        user_answer = input(\"Fill in the blank: \").strip()\n",
        "                    elif section_type == \"short_answer\":\n",
        "                        user_answer = input(\"Your answer: \").strip()\n",
        "\n",
        "                    question['user_answer'] = user_answer\n",
        "                    section_total_answered += 1\n",
        "\n",
        "                    # Check answer based on type\n",
        "                    if section_type == \"short_answer\":\n",
        "                        if is_similar(user_answer, question['answer']):\n",
        "                            print(\"Correct! 🎉\")\n",
        "                            overall_correct_count += 1\n",
        "                            section_correct += 1\n",
        "                        else:\n",
        "                            print(f\"Incorrect. The correct answer is: {question['answer']}\")\n",
        "                    elif section_type == \"fill_in_blanks\":\n",
        "                        if user_answer.lower() == question['answer'].lower():\n",
        "                            print(\"Correct! 🎉\")\n",
        "                            overall_correct_count += 1\n",
        "                            section_correct += 1\n",
        "                        else:\n",
        "                            print(f\"Incorrect. The correct answer is: {question['answer']}\")\n",
        "                    else:  # multiple_choice\n",
        "                        correct = question['correct_answer'].replace(\"[\", \"\").replace(\"]\", \"\").strip().upper()\n",
        "                        if user_answer == correct:\n",
        "                            print(\"Correct! 🎉\")\n",
        "                            overall_correct_count += 1\n",
        "                            section_correct += 1\n",
        "                        else:\n",
        "                            print(f\"Incorrect. The correct answer is: {question['correct_answer']}\")\n",
        "\n",
        "                    # Adaptive check after minimum questions have been answered\n",
        "                    if section_total_answered >= min_questions_before_check:\n",
        "                        current_accuracy = section_correct / section_total_answered\n",
        "                        print(f\"\\nCurrent accuracy in this section: {current_accuracy*100:.1f}%\")\n",
        "                        if current_accuracy < performance_threshold:\n",
        "                            choice = input(\"Your performance seems low. Would you like to review the slides for this section? (Y/N): \").strip().upper()\n",
        "                            if choice == \"Y\":\n",
        "                                print(\"Please review the slides and try this section again later.\\n\")\n",
        "                                break  # Exit current section and move to next\n",
        "                            else:\n",
        "                                print(\"Okay, continuing with the quiz.\\n\")\n",
        "\n",
        "                print(f\"\\nFinished section '{section_type.replace('_', ' ').title()}' - Correct: {section_correct} out of {section_total_answered}\")\n",
        "\n",
        "            # Provide overall results and explanations for incorrect answers\n",
        "            print(\"\\n=== Quiz Results ===\")\n",
        "            print(f\"You answered {overall_correct_count} out of {total_questions} questions correctly.\")\n",
        "\n",
        "            if overall_correct_count < total_questions:\n",
        "                print(\"\\nHere are the explanations for the questions you got wrong:\")\n",
        "                for section_type, questions in quiz['quiz'].items():\n",
        "                    for question in questions:\n",
        "                        if section_type == \"short_answer\":\n",
        "                            if not is_similar(question['user_answer'], question['answer']):\n",
        "                                print(f\"\\nQuestion: {question['question']}\")\n",
        "                                print(f\"Your answer: {question['user_answer']}\")\n",
        "                                print(f\"Correct answer: {question['answer']}\")\n",
        "                        else:\n",
        "                            correct = question.get('correct_answer', \"\").replace(\"[\", \"\").replace(\"]\", \"\").strip().lower()\n",
        "                            if question.get('correct_answer') and question['user_answer'].lower() != correct:\n",
        "                                print(f\"\\nQuestion: {question['question']}\")\n",
        "                                print(f\"Your answer: {question['user_answer']}\")\n",
        "                                print(f\"Correct answer: {question['correct_answer']}\")\n",
        "                                print(f\"Explanation: {question['explanation']}\")\n",
        "\n",
        "            # Save the updated quiz with user answers\n",
        "            output_dir = \"quiz_output\"\n",
        "            if not os.path.exists(output_dir):\n",
        "                os.makedirs(output_dir)\n",
        "\n",
        "            updated_quiz_path = os.path.join(output_dir, 'updated_quiz_with_answers.json')\n",
        "            with open(updated_quiz_path, 'w', encoding='utf-8') as f:\n",
        "                json.dump(quiz, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "            print(f\"\\nYour quiz results have been saved to {updated_quiz_path}\")\n",
        "\n",
        "            return quiz\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error conducting quiz: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        print(\"Starting quiz generation...\")\n",
        "\n",
        "        # Check for API key\n",
        "        api_key = os.getenv('GROQ_API_KEY')\n",
        "        if not api_key:\n",
        "            print(\"Error: GROQ_API_KEY environment variable not found!\")\n",
        "            print(\"\\nPlease set your Groq API key as an environment variable:\")\n",
        "            print(\"export GROQ_API_KEY='your-api-key'\")\n",
        "            return\n",
        "\n",
        "        if not os.path.exists(\"content.txt\"):\n",
        "            print(\"Error: content.txt file not found!\")\n",
        "            print(\"\\nPlease create a content.txt file with your technical content.\")\n",
        "            print(\"The content can be about any computer science or technical topic.\")\n",
        "            print(\"\\nFile requirements:\")\n",
        "            print(\"1. Save as 'content.txt' in the same directory as this script\")\n",
        "            print(\"2. Use UTF-8 encoding\")\n",
        "            print(\"3. Include sufficient content for meaningful questions\")\n",
        "            return\n",
        "\n",
        "        quiz_gen = QuizGenerator(api_key=api_key, debug=True)\n",
        "\n",
        "        print(\"\\nReading content and generating quiz...\")\n",
        "        print(\"This may take a few minutes depending on the content length.\")\n",
        "        quiz = quiz_gen.generate_quiz(\"content.txt\")\n",
        "\n",
        "        # Save the generated quiz as JSON immediately\n",
        "        with open(\"generated_quiz.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(quiz, f, indent=2, ensure_ascii=False)\n",
        "        print(\"Generated quiz has been saved to generated_quiz.json\")\n",
        "\n",
        "        # Conduct the quiz\n",
        "        quiz_gen.conduct_quiz(quiz)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError: {str(e)}\")\n",
        "        print(\"\\nTroubleshooting tips:\")\n",
        "        print(\"1. Check that content.txt exists and is readable\")\n",
        "        print(\"2. Verify the content.txt has enough text to generate questions\")\n",
        "        print(\"3. Ensure content.txt is saved with UTF-8 encoding\")\n",
        "        print(\"4. Try running the script again (API might be temporarily busy)\")\n",
        "        print(\"5. Check your internet connection\")\n",
        "        print(\"6. Verify your Groq API key is set correctly\")\n",
        "        print(\"\\nFor more details, check:\")\n",
        "        print(\"- The error message above\")\n",
        "        print(\"- quiz_raw.txt file (if created)\")\n",
        "        print(\"- generated_quiz.json file (if created)\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "8ImUBnf8K_Lz",
        "outputId": "868b8ad0-dff7-49ac-8fae-1cb0a546cf52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 932
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting quiz generation...\n",
            "\n",
            "Reading content and generating quiz...\n",
            "This may take a few minutes depending on the content length.\n",
            "Successfully read 7280 characters from content.txt\n",
            "\n",
            "Read 7280 characters from content.txt\n",
            "\n",
            "Attempt 1 of 3\n",
            "Successfully received response from Groq API\n",
            "Generated quiz has been saved to generated_quiz.json\n",
            "\n",
            "Welcome to the Quiz!\n",
            "You will be asked questions one by one. Answer them to the best of your ability.\n",
            "\n",
            "\n",
            "=== Multiple Choice ===\n",
            "\n",
            "Question: What is the primary purpose of the bubble sort algorithm?\n",
            "Options:\n",
            "A) To search for elements in a list\n",
            "B) To sort data in ascending or descending order\n",
            "C) To insert elements into a list\n",
            "D) To delete elements from a list\n",
            "Your answer (A/B/C/D): b\n",
            "Correct! 🎉\n",
            "\n",
            "Question: Which of the following is a characteristic of bubble sort?\n",
            "Options:\n",
            "A) It is a non-comparison-based sorting algorithm\n",
            "B) It is an out-place sorting algorithm\n",
            "C) It uses nested loops to sort elements\n",
            "D) It is the fastest sorting algorithm for large datasets\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-2ed7ad6e1394>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-2ed7ad6e1394>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;31m# Conduct the quiz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m         \u001b[0mquiz_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconduct_quiz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquiz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-2ed7ad6e1394>\u001b[0m in \u001b[0;36mconduct_quiz\u001b[0;34m(self, quiz)\u001b[0m\n\u001b[1;32m    442\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0moption\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'options'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m                             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{option['label']}) {option['text']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m                         \u001b[0muser_answer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Your answer (A/B/C/D): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m                     \u001b[0;32melif\u001b[0m \u001b[0msection_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"fill_in_blanks\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m                         \u001b[0muser_answer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fill in the blank: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uFlytBbfNFJo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}